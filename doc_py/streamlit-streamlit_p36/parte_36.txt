  string form_id = 8;

  bool disabled = 9;

  LabelVisibilityMessage label_visibility = 10;

  reserved 5;
}


================================================
File: /proto/streamlit/proto/ForwardMsg.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "ForwardMsgProto";

import "streamlit/proto/AutoRerun.proto";
import "streamlit/proto/Common.proto";
import "streamlit/proto/Delta.proto";
import "streamlit/proto/GitInfo.proto";
import "streamlit/proto/Logo.proto";
import "streamlit/proto/Navigation.proto";
import "streamlit/proto/NewSession.proto";
import "streamlit/proto/PageConfig.proto";
import "streamlit/proto/PageInfo.proto";
import "streamlit/proto/PageProfile.proto";
import "streamlit/proto/PageNotFound.proto";
import "streamlit/proto/PagesChanged.proto";
import "streamlit/proto/ParentMessage.proto";
import "streamlit/proto/SessionEvent.proto";
import "streamlit/proto/SessionStatus.proto";
import "streamlit/proto/AuthRedirect.proto";

// A message sent from Proxy to the browser
message ForwardMsg {
  // A hash that uniquely identifies this ForwardMsg, for caching.
  string hash = 1;

  // Contains 'non-payload' ForwardMsg data that isn't cached for the purposes
  // of ForwardMsg de-duping.
  ForwardMsgMetadata metadata = 2;

  // Values for the 'script_finished` type
  enum ScriptFinishedStatus {
    // The script compiled and ran.
    FINISHED_SUCCESSFULLY = 0;

    // The script failed to compile
    FINISHED_WITH_COMPILE_ERROR = 1;

    // Script was interrupted by rerun
    FINISHED_EARLY_FOR_RERUN = 2;

    // A fragment of the script ran successfully.
    FINISHED_FRAGMENT_RUN_SUCCESSFULLY = 3;
  }

  oneof type {
    // App lifecycle messages.
    NewSession new_session = 4;
    Delta delta = 5;
    PageInfo page_info_changed = 12;
    PageConfig page_config_changed = 13;
    ScriptFinishedStatus script_finished = 6;
    GitInfo git_info_changed = 14;
    PageProfile page_profile = 18;

    // Status change and event messages.
    SessionStatus session_status_changed = 9;
    SessionEvent session_event = 10;

    // Other messages.
    Navigation navigation = 23;
    PageNotFound page_not_found = 15;
    PagesChanged pages_changed = 16;
    FileURLsResponse file_urls_response = 19;
    AutoRerun auto_rerun = 21;

    // App logo message
    Logo logo = 22;

    // Auth redirect message
    AuthRedirect auth_redirect = 24;

    // Platform - message to host
    ParentMessage parent_message = 20;

    // A reference to a ForwardMsg that has already been delivered.
    // The client should substitute the message with the given hash
    // for this one. If the client does not have the referenced message
    // in its cache, it can retrieve it from the server.
    string ref_hash = 11;
  }

  // The ID of the last BackMsg that we received before sending this
  // ForwardMsg. As its name suggests, this field should only be used for
  // testing.
  string debug_last_backmsg_id = 17;

  reserved 7, 8;
  // Next: 25
}

// ForwardMsgMetadata contains all data that does _not_ get hashed (or cached)
// in our ForwardMsgCache. (That is, when we cache a ForwardMsg, we clear its
// metadata field first.) This allows us to, e.g., have a large unchanging
// dataframe appear in different places across multiple reruns - or even appear
// multiple times in a single run - and only send its dataframe bytes once.
message ForwardMsgMetadata {
  // If this is set, the server will have cached this message,
  // and a client that receives it should do the same.
  bool cacheable = 1;

  // The path that identifies a delta's location in the report tree.
  // Only set for Delta messages.
  repeated uint32 delta_path = 2;

  // DEPRECATED: This is not used anymore.
  ElementDimensionSpec element_dimension_spec = 3;

  // active_script_hash the forward message is associated from.
  // For multipage apps v1, this will always be the page file running
  // For multipage apps v2, this can be the main script or the page script
  string active_script_hash = 4;
}

// DEPRECATED: This is not used anymore.
// Specifies the dimensions for the element
message ElementDimensionSpec {
  // width in pixels
  uint32 width = 1;

  // height in pixels
  uint32 height = 2;
}

// This is a list of ForwardMessages used to have a single protobuf message
// that encapsulates multiple ForwardMessages. This is used in static streamlit app
// generation in replaying all of the protobuf messages of a streamlit app. The
// ForwardMsgList allows us to leverage the built-ins of protobuf in delimiting the ForwardMsgs
// instead of needing to do that ourselves.
message ForwardMsgList {
  repeated ForwardMsg messages = 1;
}


================================================
File: /proto/streamlit/proto/GitInfo.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "GitInfoProto";

// Message used to update page metadata.
message GitInfo {
  string repository = 1;
  string branch = 2;
  string module = 3;
  repeated string untracked_files = 4;
  repeated string uncommitted_files = 5;

  enum GitStates {
    DEFAULT = 0;
    HEAD_DETACHED = 1;
    AHEAD_OF_REMOTE = 2;
  }

  GitStates state = 6;
}


================================================
File: /proto/streamlit/proto/GraphVizChart.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "GraphVizChartProto";

message GraphVizChart {
  // A specification of the GraphViz graph in the "Dot" language.
  string spec = 1;

  // If True, will overwrite the chart width spec to fit to container.
  bool use_container_width = 4;

  // A unique ID of this element.
  string element_id = 5;

  // The engine used to layout and render the graph.
  string engine = 6;

  reserved 2, 3;
}


================================================
File: /proto/streamlit/proto/Heading.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "HeadingProto";

message Heading {
    // h1, h2, h3, div, etc
    string tag = 1;

    string anchor = 2;
    string body = 3;

    string help = 4;
    bool hide_anchor = 5;
    string divider = 6;
}


================================================
File: /proto/streamlit/proto/Html.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "HtmlProto";

// st.html
message Html {
  string body = 1;
}


================================================
File: /proto/streamlit/proto/IFrame.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "IFrameProto";

message IFrame {
  oneof type {
    // A URL to load
    string src = 1;

    // Inline HTML
    string srcdoc = 2;
  }

  float width = 3;
  bool has_width = 4;
  float height = 5;

  bool scrolling = 7;
}


================================================
File: /proto/streamlit/proto/Image.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "ImageProto";

// An image which can be displayed on the screen.
message Image {
  string url = 3;
  string caption = 2;

  // DEPRECATED: markup is not used anymore.
  // SVGs are added as data uris in the url field.
  string markup = 4;

  reserved 1;
  reserved "data";
}

// A set of images.
message ImageList {
  repeated Image imgs = 1;

  // @see WidthBehavior on the backend
  // @see WidthBehavior on the frontend
  // The width of each image.
  // >0 sets the image width explicitly
  // -1 means use the image width
  // -2 means use the column width (deprecated)
  // -3 means use the smaller of image width & column width (deprecated)
  // -4 means use the smaller of image width & container width
  // -5 means use the larger of image width & container width
  int32 width = 2;
}



================================================
File: /proto/streamlit/proto/Json.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "JsonProto";

message Json {
  // Content to display.
  string body = 1;
  // Controls the initial expansion state of the json element.
  // Is superseded by max_expand_depth if provided.
  bool expanded = 2;
  // The maximum depth to expand the JSON object.
  optional int32 max_expand_depth = 3;
}


================================================
File: /proto/streamlit/proto/LabelVisibilityMessage.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "LabelVisibilityMessageProto";

message LabelVisibilityMessage {
  // We use separate LabelVisibilityMessage instead of just defining Enum and
  // use it in other widgets proto files due to protobuf js error, when just
  // enum defined and imported
  // https://github.com/protobufjs/protobuf.js/issues/1414
  enum LabelVisibilityOptions {
    VISIBLE = 0;
    HIDDEN = 1;
    COLLAPSED = 2;
  }
  LabelVisibilityOptions value = 1;
}


================================================
File: /proto/streamlit/proto/LinkButton.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "LinkButtonProto";

message LinkButton {
  string label = 2;
  string help = 4;
  string url = 6;
  bool disabled = 7;
  bool use_container_width = 8;
  string type = 9;
  string icon = 10;
}


================================================
File: /proto/streamlit/proto/Logo.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "LogoProto";

// Handle the logo for an app
message Logo {
  string image = 1;
  string link = 2;
  string icon_image = 3;
  string size = 4;
}


================================================
File: /proto/streamlit/proto/Markdown.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "MarkdownProto";

// Formatted text
message Markdown {
  // Content to display.
  string body = 1;

  bool allow_html = 2;
  bool is_caption = 3; // TODO [Karen]: Remove this field if favor of element_type

  enum Type {
    UNSPECIFIED = 0;  // This is recommended to be reserved for proto files backwards compatibility reasons.
    NATIVE = 1;
    CAPTION = 2;
    CODE = 3;
    LATEX = 4;
    DIVIDER = 5;
  }
  Type element_type = 4;

  string help = 5;
}


================================================
File: /proto/streamlit/proto/Metric.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "MetricProto";

import "streamlit/proto/LabelVisibilityMessage.proto";

message Metric {
  string label = 1;
  string body = 2;
  string delta = 3;
  MetricDirection direction = 4;
  MetricColor color = 5;
  string help = 6;
  LabelVisibilityMessage label_visibility = 7;
  bool show_border = 8;

  enum MetricColor{
    RED = 0;
    GREEN = 1;
    GRAY = 2;
  }
  enum MetricDirection{
    DOWN = 0;
    UP = 1;
    NONE = 2;
  }
}


================================================
File: /proto/streamlit/proto/MetricsEvent.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "MetricsEventProto";

import "streamlit/proto/PageProfile.proto";

// Metrics events:
message MetricsEvent {

  // Common Event Fields:
  string event = 1;
  string anonymous_id = 2;
  string machine_id_v3 = 3;
  string report_hash = 4;
  bool dev = 5;
  string source = 6;
  string streamlit_version = 7;
  bool is_hello = 8;

  // Host tracking fields:
  string hosted_at = 9;
  string owner = 10;
  string repo = 11;
  string branch = 12;
  string main_module = 13;
  string creator_id = 14;

  // Context fields:
  string context_page_url = 15;
  string context_page_title = 16;
  string context_page_path = 17;
  string context_page_referrer = 18;
  string context_page_search = 19;
  string context_locale = 20;
  string context_user_agent = 21;


  // Menu Click Event field:
  string label = 22;


  // Page Profile Event fields:
  // Same as PageProfile msg
  repeated Command commands = 23;
  int64 exec_time = 24;
  int64 prep_time = 25;
  repeated string config = 26;
  string uncaught_exception = 27;
  repeated string attributions = 28;
  string os = 29;
  string timezone = 30;
  bool headless = 31;
  bool is_fragment_run = 32;

  // Addtl for page profile metrics
  string app_id = 33;
  int64 numPages = 34;
  string session_id = 35;
  string python_version = 36;
  string page_script_hash = 37;
  string active_theme = 38;
  int64 total_load_time = 39;
  BrowserInfo browser_info = 40;

  // Next ID: 41
}

message BrowserInfo {
  string browser_name = 1;
  string browser_version = 2;
  string device_type = 3;
  string os = 4;
}


================================================
File: /proto/streamlit/proto/MultiSelect.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "MultiSelectProto";

import "streamlit/proto/LabelVisibilityMessage.proto";

message MultiSelect {
  string id = 1;
  string label = 2;
  repeated int32 default = 3;
  repeated string options = 4;
  string help = 5;
  string form_id = 6;
  repeated int32 value = 7;
  bool set_value = 8;
  bool disabled = 9;
  LabelVisibilityMessage label_visibility = 10;
  int32 max_selections = 11;
  string placeholder = 12;
}


================================================
File: /proto/streamlit/proto/NamedDataSet.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "NamedDataSetProto";

import "streamlit/proto/DataFrame.proto";

// DEPRECATED: This proto message is deprecated and unsused.
// A dataset that can be referenced by name.
message NamedDataSet {
  // The dataset name.
  string name = 1;

  // True if the name field (above) was manually set. This is used to get
  // around proto3 not having a way to check whether something was set.
  bool has_name = 3;

  // The data itself.
  DataFrame data = 2;
}


================================================
File: /proto/streamlit/proto/Navigation.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";


import "streamlit/proto/AppPage.proto";

message Navigation {
  repeated string sections = 1;
  repeated AppPage app_pages = 2;
  Position position = 3;

  // The script hash for the page identified by st.navigation
  string page_script_hash = 4;

  bool expanded = 5;

  // Position of the Navigation
  enum Position {
    // do not display the navigation
    HIDDEN = 0;

    // display navigation in the sidebar
    SIDEBAR = 1;
  }
}


================================================
File: /proto/streamlit/proto/NewSession.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "NewSessionProto";

import "streamlit/proto/AppPage.proto";
import "streamlit/proto/SessionStatus.proto";

// NOTE: These proto types are used by some external services so need to
// remain relatively stable. While they aren't entirely set in stone, changing
// them may require a good amount of effort so should be avoided if possible.

// This is the first message that is sent when a new session starts.
message NewSession {
  // Initialization data. This data does *not* change from rerun to rerun,
  // but we send it every time so that we don't have to track whether the
  // client has already received it. The client is responsible for
  // performing initialization logic only once.
  Initialize initialize = 1;

  // The script run ID
  string script_run_id = 2;

  // The basename of the script that launched this app. Example: 'foo.py'
  string name = 3;

  // The full path of the script that launched this app. Example:
  // '/foo/bar/foo.py'
  string main_script_path = 4;

  // DEPRECATED.
  // DeployParams deploy_params = 5;

  reserved 5;

  // Config options that are (mostly) defined in the .streamlit/config.toml
  // file.
  Config config = 6;

  // Theme configuration options defined in the .streamlit/config.toml file.
  // See the "theme" config section.
  CustomThemeConfig custom_theme = 7;

  // A list of all of this app's pages, in order and including the main page.
  repeated AppPage app_pages = 8;

  // A hash of the script corresponding to the page currently being viewed.
  string page_script_hash = 9;

  // The fragment IDs being run in this session if it corresponds to a fragment
  // script run.
  repeated string fragment_ids_this_run = 10;

  // Hash of the main script running (ie streamlit run main_script.py)
  string main_script_hash = 11;
}

// Contains the session status that existed at the time the user connected.
// The contents of this message don't change over the lifetime of the app by
// definition.
message Initialize {
  UserInfo user_info = 1;

  EnvironmentInfo environment_info = 3;

  // The session status at the time the connection was established
  SessionStatus session_status = 4;

  // DEPRECATED: We no longer send this to the frontend for security reasons.
  // The actual command line as a string
  string command_line = 5;

  // The AppSession.id for this connection's AppSession.
  // This is used to associate uploaded files with the client that uploaded
  // them.
  string session_id = 6;

  // True if the command used to start this app was `streamlit hello`.
  bool is_hello = 7;
}

// App configuration options, initialized mainly from the
// .streamlit/config.toml file.
message Config {
  // See config option "browser.gatherUsageStats".
  bool gather_usage_stats = 2;

  // See config option "global.maxCachedMessageAge".
  int32 max_cached_message_age = 3;

  // DEPRECATED: the mapbox token was moved to the DeckGlJsonChart message.
  string mapbox_token = 4;

  // See config option "server.allowRunOnSave".
  bool allow_run_on_save = 5;

  // See config option "ui.hideTopBar".
  bool hide_top_bar = 6;

  // See config option "client.showSidebarNavigation".
  bool hide_sidebar_nav = 7;

  // See config option "client.toolbarMode".
  enum ToolbarMode {
    AUTO = 0;
    DEVELOPER = 1;
    VIEWER = 2;
    MINIMAL = 3;
  }
  ToolbarMode toolbar_mode = 8;

  reserved 1;
}

// Custom theme configuration options. Like other config options, these are set
// in .streamlit/config.toml.
//
// IMPORTANT: This message is passed in JSON format in a host-to-guest postMessage. So DOT NOT
// rename its proto fields!
message CustomThemeConfig {
  enum BaseTheme {
    LIGHT = 0;
    DARK = 1;
  }

  enum FontFamily {
    SANS_SERIF = 0;
    SERIF = 1;
    MONOSPACE = 2;
  }

  string primary_color = 1;
  string secondary_background_color = 2;
  string background_color = 3;
  string text_color = 4;
  FontFamily font = 5;
  BaseTheme base = 6;
  string widget_background_color = 7;
  string widget_border_color = 8;
  Radii radii = 9;
  string body_font = 13;
  string code_font = 14;
  repeated FontFace font_faces = 15;
  FontSizes font_sizes = 16;
  string skeleton_background_color = 17;
}

message FontFace {
  string url = 1;
  string family = 2;
  int32 weight = 3;
  string style = 4;
}

message Radii {
  // In pixels.
  int32 base_widget_radius = 1;
  int32 checkbox_radius = 2;
}

message FontSizes {
  // In pixels.
  int32 tiny_font_size = 1;
  int32 small_font_size = 2;
  int32 base_font_size = 3;
}

// Data that identifies the Streamlit app creator.
// Does not change over the app's lifetime.
message UserInfo {
  string installation_id = 1;
  string installation_id_v3 = 5;

  // DEPRECATED:
  // string email = 2;
  reserved 2;
}

// Data that identifies the Streamlit app's environment.
// Does not change over the app lifetime.
//
// NB: unlike most of our protobuf data, the EnvironmentInfo message (and all
// its ancestors' IDs) *must* maintain backward- and forward-compatibility.
// When a Streamlit instance is updated to a new version, all connected clients
// will be outdated. Those clients need to be able to read the
// `streamlit_version` property so they can auto-update to the new version.
message EnvironmentInfo {
  string streamlit_version = 1;
  string python_version = 2;
}


================================================
File: /proto/streamlit/proto/NumberInput.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "NumberInputProto";

import "streamlit/proto/LabelVisibilityMessage.proto";

message NumberInput {
  enum DataType {
    // Does the input operate on ints or floats? This doesn't change how the
    // data is stored, but the frontend needs to know for input parsing.
    INT = 0;
    FLOAT = 1;
  }

  string id = 1;
  string label = 2;
  string form_id = 3;

  string format = 8;
  bool has_min = 11;
  bool has_max = 12;

  DataType data_type = 13;
  optional double default = 14;
  double step = 15;
  double min = 16;
  double max = 17;
  string help = 18;
  optional double value = 19;
  bool set_value = 20;
  bool disabled = 21;
  LabelVisibilityMessage label_visibility = 22;
  string placeholder = 23;

  reserved 4, 5, 6, 7, 9, 10;
}


================================================
File: /proto/streamlit/proto/PageConfig.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "PageConfigProto";

// Properties of the page that the app creator may configure.
message PageConfig {
  string title = 1;
  string favicon = 2;
  Layout layout = 3;
  SidebarState initial_sidebar_state = 4;
  MenuItems menu_items = 5;

  message MenuItems {
    string get_help_url = 1;
    bool hide_get_help = 2;
    string report_a_bug_url = 3;
    bool hide_report_a_bug = 4;
    string about_section_md = 5;
  }

  enum Layout {
    // Render page elements in a centered block, roughly 730px wide.
    CENTERED = 0;

    // Use the full browser width to render elements.
    WIDE = 1;
  }

  enum SidebarState {
    // Expand the sidebar if page width exceeds ~1000px; otherwise, collapse it
    AUTO = 0;

    // Force the sidebar to be shown.
    EXPANDED = 1;

    // Force the sidebar to be hidden.
    COLLAPSED = 2;
  }
}


================================================
File: /proto/streamlit/proto/PageInfo.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "PageInfoProto";

// Message used to update page metadata.
message PageInfo {
  // The page's query string, if the user decided to set it.
  string query_string = 1;
}


================================================
File: /proto/streamlit/proto/PageLink.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "PageLinkProto";

message PageLink {
  string page = 1;
  string label = 2;
  string icon = 3;
  string page_script_hash = 4;
  string help = 5;
  optional bool use_container_width = 6;
  bool disabled = 7;
  bool external = 8;
}

================================================
File: /proto/streamlit/proto/PageNotFound.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "PageNotFoundProto";

// Message used to tell the client that the requested page does not exist.
message PageNotFound {
  string page_name = 1;
}


================================================
File: /proto/streamlit/proto/PageProfile.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "PageProfileProto";


message PageProfile {
  repeated Command commands = 1;
  int64 exec_time = 2;
  int64 prep_time = 3;
  repeated string config = 5;
  string uncaught_exception = 6;
  repeated string attributions = 7;
  string os = 8;
  string timezone = 9;
  bool headless = 10;
  bool is_fragment_run = 11;
}

// The field names are used as part of the event json sent
// to our metrics provider. we are using short names to
// optimize for the size.
message Argument {
  // The keyword of the argument:
  string k = 1;
  // The type of the argument:
  string t = 2;
  // Some metadata about the argument value:
  string m = 3;
  // Contains the position (if positional argument):
  int32 p = 5;
}

message Command {
  string name = 1;
  repeated Argument args = 2;
  int64 time = 4;
}


================================================
File: /proto/streamlit/proto/PagesChanged.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "PagesChangedProto";

import "streamlit/proto/AppPage.proto";

// Message used to tell the client that the app's pages have changed.
message PagesChanged {
  repeated AppPage app_pages = 1;
}


================================================
File: /proto/streamlit/proto/ParentMessage.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "ParentMessageProto";

// NOTE: This proto type is used by some external services so needs to remain
// relatively stable. While it isn't entirely set in stone, changing it
// may require a good amount of effort so should be avoided if possible.
message ParentMessage {
  // Message to send to the host.
  string message = 1;
}


================================================
File: /proto/streamlit/proto/PlotlyChart.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "PlotlyChartProto";

message PlotlyChart {
  // If True, will overwrite the chart width spec to fit to container.
  bool use_container_width = 5;

  // override the properties with a theme. Currently, only "streamlit" or None are accepted.
  string theme = 6;

  // The unique element ID of this chart.
  string id = 7;

  // Activate selections types on the chart.
  repeated SelectionMode selection_mode = 8;

  // Form ID, filled if selections are activated.
  string form_id = 9;

  // JSON-serialized dict containing keys from the set {data, frames, layout}.
  string spec = 10;

  // JSON-serialized dict with Plotly's config object.
  string config = 11;

  reserved 3, 4;

  // Available selection modes:
  enum SelectionMode {
      POINTS = 0; // Point selection mode
      BOX = 1; // Box selection mode
      LASSO = 2; // Lasso selection mode
  }

  // DEPRECATED and unused.
  oneof chart {
    // DEPRECATED and unused.
    string url = 1;

    // DEPRECATED and unused.
    Figure figure = 2;
  }

}


// DEPRECATED and unused.
message Figure {
  string spec = 1;
  string config = 2;
}


================================================
File: /proto/streamlit/proto/Progress.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "ProgressProto";

message Progress {
  uint32 value = 1;
  string text = 2;
}


================================================
File: /proto/streamlit/proto/Radio.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "RadioProto";

import "streamlit/proto/LabelVisibilityMessage.proto";

message Radio {
  string id = 1;
  string label = 2;
  optional int32 default = 3;
  repeated string options = 4;
  string help = 5;
  string form_id = 6;
  optional int32 value = 7;
  bool set_value = 8;
  bool disabled = 9;
  bool horizontal = 10;
  LabelVisibilityMessage label_visibility = 11;
  repeated string captions = 12;
}


================================================
File: /proto/streamlit/proto/RootContainer.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "RootContainerProto";

// Constants for our "RootContainers" - the top-level containers
// that `st.foo` and `st.sidebar.foo` write to. Each value corresponds
// to the first index in any `delta_path` that uses these containers.
// (This enum is not used in any protobuf messages; we declare it here so
// that the values remain synced between Python and the frontend.)
enum RootContainer {
  MAIN = 0;
  SIDEBAR = 1;
  EVENT = 2;
  BOTTOM = 3;
}


================================================
File: /proto/streamlit/proto/Selectbox.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "SelectboxProto";

import "streamlit/proto/LabelVisibilityMessage.proto";

message Selectbox {
  string id = 1;
  string label = 2;
  optional int32 default = 3;
  repeated string options = 4;
  string help = 5;
  string form_id = 6;
  optional int32 value = 7;
  bool set_value = 8;
  bool disabled = 9;
  LabelVisibilityMessage label_visibility = 10;
  string placeholder = 11;
}


================================================
File: /proto/streamlit/proto/SessionEvent.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "SessionEventProto";

import "streamlit/proto/Exception.proto";

// A transient event sent to all browsers connected to an associated app.
message SessionEvent {
  oneof type {
    // The app's script changed on disk, but is *not* being re-run
    // automatically. The browser should prompt the user to re-run.
    bool script_changed_on_disk = 1;

    // The app's script was running, but it was manually stopped before
    // completion.
    bool script_was_manually_stopped = 2;

    // Script compilation failed with an exception.
    // We can't start running the script.
    Exception script_compilation_exception = 3;
  }
}


================================================
File: /proto/streamlit/proto/SessionStatus.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "SessionStatusProto";

// Status for a session. Sent as part of the Initialize message, and also
// on AppSession status change events.
//
// NOTE: This proto type is used by some external services so needs to remain
// relatively stable. While it isn't entirely set in stone, changing it
// may require a good amount of effort so should be avoided if possible.
message SessionStatus {
  // If true, streamlit will re-run the script if it detects that the script
  // has been changed. This value comes from the server.runOnSave config.
  // The browser can change this option; it's sent here so that the browser
  // shows the correct initial value in its Settings dialog.
  bool run_on_save = 1;

  // True if the script is being run by a client right now.
  bool script_is_running = 2;
}


================================================
File: /proto/streamlit/proto/Skeleton.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "SkeletonProto";

// An empty-like element that displays an app skeleton.
message Skeleton {
  enum SkeletonStyle {
    ELEMENT = 0;
    APP = 1; // internal-only, for now
  }
  // Skeleton visual style
  SkeletonStyle style = 1;

  // Height in pixels
  optional int32 height = 2;
}


================================================
File: /proto/streamlit/proto/Slider.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "SliderProto";

import "streamlit/proto/LabelVisibilityMessage.proto";

message Slider {
  enum DataType {
    // What numeric type are we working with? This doesn't change how the
    // data is stored, but the frontend needs to know for input parsing.
    INT = 0;
    FLOAT = 1;
    // Note: Represented as microseconds since epoch
    DATETIME = 2;
    DATE = 3;
    TIME = 4;
  }

  enum Type {
    UNSPECIFIED = 0;
    SLIDER = 1;
    SELECT_SLIDER = 2;
  }

  string id = 1;
  string form_id = 2;
  string label = 3;
  string format = 4;
  DataType data_type = 5;

  repeated double default = 6;
  double min = 7;
  double max = 8;
  double step = 9;
  repeated double value = 10;
  bool set_value = 11;

  repeated string options = 13;
  string help = 14;
  bool disabled = 15;
  LabelVisibilityMessage label_visibility = 16;

  Type type = 17;
}


================================================
File: /proto/streamlit/proto/Snow.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "SnowProto";

// A python empty.
message Snow {
  bool show = 1;  // Dummy boolean because protos need to have something.
}


================================================
File: /proto/streamlit/proto/Spinner.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "SpinnerProto";

message Spinner {
  // A message to display while executing that block.
  string text = 1;

  // Whether spinner used in caching functions.
  bool cache = 2;

  // Whether to show elapsed time next to the spinner text.
  bool show_time = 3;
}


================================================
File: /proto/streamlit/proto/Text.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "TextProto";

// Preformatted text
message Text {
  // Content to display.
  string body = 1;

  string help = 2;
}


================================================
File: /proto/streamlit/proto/TextArea.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "TextAreaProto";

import "streamlit/proto/LabelVisibilityMessage.proto";

message TextArea {
  string id = 1;
  string label = 2;
  optional string default = 3;
  uint32 height = 4;
  uint32 max_chars = 5;
  string help = 6;
  string form_id = 7;
  optional string value = 8;
  bool set_value = 9;
  string placeholder = 10;
  bool disabled = 11;
  LabelVisibilityMessage label_visibility = 12;
}


================================================
File: /proto/streamlit/proto/TextInput.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "TextInputProto";

import "streamlit/proto/LabelVisibilityMessage.proto";

message TextInput {
  enum Type {
    // A normal text input.
    DEFAULT = 0;

    // A password text input. Typed values are obscured by default.
    PASSWORD = 1;
  }

  string id = 1;
  string label = 2;
  optional string default = 3;
  Type type = 4;
  uint32 max_chars = 5;
  string help = 6;
  string form_id = 7;
  optional string value = 8;
  bool set_value = 9;
  string autocomplete = 10;
  string placeholder = 11;
  bool disabled = 12;
  LabelVisibilityMessage label_visibility = 13;
}


================================================
File: /proto/streamlit/proto/TimeInput.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "TimeInputProto";

import "streamlit/proto/LabelVisibilityMessage.proto";

message TimeInput {
  string id = 1;
  string label = 2;
  optional string default = 3;
  string help = 4;
  string form_id = 5;
  optional string value = 6;
  bool set_value = 7;
  bool disabled = 8;
  LabelVisibilityMessage label_visibility = 9;
  int64 step = 10;
}


================================================
File: /proto/streamlit/proto/Toast.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "ToastProto";

message Toast {
    // Display message
    string body = 1;

    // Emoji
    string icon = 2;
}


================================================
File: /proto/streamlit/proto/VegaLiteChart.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "VegaLiteChartProto";

import "streamlit/proto/DataFrame.proto";
import "streamlit/proto/NamedDataSet.proto";

// DEPRECATED: This proto message is deprecated and unused. The ArrowVegaLiteChart
// proto message should be used instead.
message VegaLiteChart {
  // The a JSON-formatted string with the Vega-Lite spec.
  string spec = 1;

  // TODO Maybe remove
  // The dataframe that will be used as the chart's main data source, if
  // specified using Vega-Lite's inline API.
  DataFrame data = 2;

  // Dataframes associated with this chart using Vega-Lite's datasets API, if
  // any.
  repeated NamedDataSet datasets = 4;

  // If True, will overwrite the chart width spec to fit to container.
  bool use_container_width = 5;

  reserved 3;
}


================================================
File: /proto/streamlit/proto/Video.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "VideoProto";

message SubtitleTrack {
    string label = 1;  // Label for the subtitle e.g. "English" or "Spanish".
    string url = 2;
}

message Video {
  // A url pointing to a video file
  string url = 6;

  enum Type {
    UNUSED = 0;  // This should always exist.
    NATIVE = 1;
    YOUTUBE_IFRAME = 2;
  }

  // The currentTime attribute of the HTML <video> tag's <source> subtag.
  int32 start_time = 3;

  // Type affects how browser wraps the video in tags: plain HTML5, YouTube...
  Type type = 5;

  // Repeated field for subtitle tracks
  repeated SubtitleTrack subtitles = 7;

  // The time at which the video should stop playing. If not specified, plays to the end.
  int32 end_time = 8;

  // Indicates whether the video should start over from the beginning once it ends.
  bool loop = 9;

  bool autoplay = 10;

  bool muted = 11;

  string id = 12;

  reserved 1,2,4;
  reserved "format", "data";
}


================================================
File: /proto/streamlit/proto/WidgetStates.proto
================================================
/**!
 * Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *     http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "WidgetStatesProto";

import "streamlit/proto/Common.proto";
import "streamlit/proto/Components.proto";

// State for every widget in an app.
message WidgetStates {
  repeated WidgetState widgets = 1;
}

// State for a single widget.
message WidgetState {
  string id = 1;

  oneof value {
    // trigger_value is for buttons. A button's value needs to
    // auto-revert back to False after the script has been run with
    // the value set to True. After running the script, the server
    // will reset all trigger_values in its stored Widget state dict.
    // (Use bool_value for widgets like checkboxes, whose state persists
    // beyond a single script run.)
    bool trigger_value = 2;

    bool bool_value = 3;
    double double_value = 4;
    sint64 int_value = 5;
    string string_value = 6;
    DoubleArray double_array_value = 7;
    SInt64Array int_array_value = 8;
    StringArray string_array_value = 9;
    string json_value = 10;
    ArrowTable arrow_value = 11;
    bytes bytes_value = 12;
    FileUploaderState file_uploader_state_value = 13;
    // String value that resets itself to empty after the script has been run.
    // This is used for the chat_input widget.
    StringTriggerValue string_trigger_value = 14;
  }
}


================================================
File: /proto/streamlit/proto/openmetrics_data_model.proto
================================================
syntax = "proto3";

option java_package = "com.snowflake.apps.streamlit";
option java_outer_classname = "OpenmetricsDataModelProto";

// The OpenMetrics protobuf schema which defines the protobuf wire format. 
// Ensure to interpret "required" as semantically required for a valid message.
// All string fields MUST be UTF-8 encoded strings.
package openmetrics;

import "google/protobuf/timestamp.proto";

// The top-level container type that is encoded and sent over the wire.
message MetricSet {
  // Each MetricFamily has one or more MetricPoints for a single Metric.
  repeated MetricFamily metric_families = 1;
}

// One or more Metrics for a single MetricFamily, where each Metric
// has one or more MetricPoints.
message MetricFamily {
  // Required.
  string name = 1;

  // Optional.
  MetricType type = 2;

  // Optional.
  string unit = 3;

  // Optional.
  string help = 4;

  // Optional.
  repeated Metric metrics = 5;
}

// The type of a Metric.
enum MetricType {
  // Unknown must use unknown MetricPoint values.
  UNKNOWN = 0;
  // Gauge must use gauge MetricPoint values.
  GAUGE = 1;
  // Counter must use counter MetricPoint values.
  COUNTER = 2;
  // State set must use state set MetricPoint values.
  STATE_SET = 3;
  // Info must use info MetricPoint values.
  INFO = 4;
  // Histogram must use histogram value MetricPoint values.
  HISTOGRAM = 5;
  // Gauge histogram must use histogram value MetricPoint values.
  GAUGE_HISTOGRAM = 6;
  // Summary quantiles must use summary value MetricPoint values.
  SUMMARY = 7;
}

// A single metric with a unique set of labels within a metric family.
message Metric {
  // Optional.
  repeated Label labels = 1;

  // Optional.
  repeated MetricPoint metric_points = 2;
}

// A name-value pair. These are used in multiple places: identifying
// timeseries, value of INFO metrics, and exemplars in Histograms.
message Label {
  // Required.
  string name = 1;

  // Required.
  string value = 2;
}

// A MetricPoint in a Metric.
message MetricPoint {
  // Required.
  oneof value {
    UnknownValue unknown_value = 1;
    GaugeValue gauge_value = 2;
    CounterValue counter_value = 3;
    HistogramValue histogram_value = 4;
    StateSetValue state_set_value = 5;
    InfoValue info_value = 6;
    SummaryValue summary_value = 7;
  }

  // Optional.
  google.protobuf.Timestamp timestamp = 8;
}

// Value for UNKNOWN MetricPoint.
message UnknownValue {
  // Required.
  oneof value {
    double double_value = 1;
    int64 int_value = 2;
  }
}

// Value for GAUGE MetricPoint.
message GaugeValue {
  // Required.
  oneof value {
    double double_value = 1;
    int64 int_value = 2;
  }
}

// Value for COUNTER MetricPoint.
message CounterValue {
  // Required.
  oneof total {
    double double_value = 1;
    uint64 int_value = 2;
  }

  // The time values began being collected for this counter.
  // Optional.
  google.protobuf.Timestamp created = 3;

  // Optional.
  Exemplar exemplar = 4;
}

// Value for HISTOGRAM or GAUGE_HISTOGRAM MetricPoint.
message HistogramValue {
  // Optional.
  oneof sum {
    double double_value = 1;
    int64 int_value = 2;
  }

  // Optional.
  uint64 count = 3;

  // The time values began being collected for this histogram.
  // Optional.
  google.protobuf.Timestamp created = 4;

  // Optional.
  repeated Bucket buckets = 5;

  // Bucket is the number of values for a bucket in the histogram
  // with an optional exemplar.
  message Bucket {  
    // Required.
    uint64 count = 1;

    // Optional.
    double upper_bound = 2;

    // Optional.
    Exemplar exemplar = 3;
  }
}

message Exemplar {
  // Required.
  double value = 1;

  // Optional.
  google.protobuf.Timestamp timestamp = 2;

  // Labels are additional information about the exemplar value (e.g. trace id).
  // Optional.
  repeated Label label = 3;
}

// Value for STATE_SET MetricPoint.
message StateSetValue {
  // Optional.
  repeated State states = 1;

  message State {
    // Required.
    bool enabled = 1;

    // Required.
    string name = 2;
  }
}

// Value for INFO MetricPoint.
message InfoValue {
  // Optional.
  repeated Label info = 1;
}

// Value for SUMMARY MetricPoint.
message SummaryValue {
  // Optional. 
  oneof sum {
    double double_value = 1;
    int64 int_value = 2;
  }

  // Optional. 
  uint64 count = 3;

  // The time sum and count values began being collected for this summary.
  // Optional.
  google.protobuf.Timestamp created = 4;

  // Optional.
  repeated Quantile quantile = 5;

  message Quantile {
    // Required. 
    double quantile = 1;

    // Required.
    double value = 2;
  }
}


================================================
File: /scripts/append_license.sh
================================================
#!/bin/sh

# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Ensure the file exists.
if [ ! -f "$1" ]; then
    echo "$1 does not exist."
    exit 1
fi

# Infer the name of the software from our path param:
# - Get the filename at the path
# - Replace underscores and dashes with spaces
# - Remove `.LICENSE` and anything after it from the filename
SOFTWARE_NAME=$(basename "$1" | sed 's/[_-]/ /g' | sed 's/.LICENSE.*//')

echo '-----' >> NOTICES
echo '' >> NOTICES
echo "The following software may be included in this product: $SOFTWARE_NAME."\
  "This software contains the following license and notice below:" >> NOTICES
echo '' >> NOTICES
cat "$1" >> NOTICES
echo '' >> NOTICES


================================================
File: /scripts/audit_frontend_licenses.py
================================================
#!/usr/bin/env python
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Audit the licenses of all our frontend dependencies (as defined by our
`yarn.lock` file). If any dependency has an unacceptable license, print it
out and exit with an error code. If all dependencies have acceptable licenses,
exit normally.
"""

import json
import subprocess
import sys
from pathlib import Path
from typing import NoReturn, Set, Tuple, cast

from typing_extensions import TypeAlias

PackageInfo: TypeAlias = Tuple[str, str, str, str, str, str]

SCRIPT_DIR = Path(__file__).resolve().parent
FRONTEND_DIR_LIB = SCRIPT_DIR.parent / "frontend/lib"
FRONTEND_DIR_APP = SCRIPT_DIR.parent / "frontend/app"

# Set of acceptable licenses. If a library uses one of these licenses,
# we can include it as a dependency.
ACCEPTABLE_LICENSES = {
    "MIT",  # https://opensource.org/licenses/MIT
    "Apache-2.0",  # https://opensource.org/licenses/Apache-2.0
    "Apache-2.0 WITH LLVM-exception",  # https://spdx.org/licenses/LLVM-exception.html
    "0BSD",  # https://opensource.org/licenses/0BSD
    "BlueOak-1.0.0",  # https://blueoakcouncil.org/license/1.0.0
    "BSD-2-Clause",  # https://opensource.org/licenses/BSD-2-Clause
    "BSD-3-Clause",  # https://opensource.org/licenses/BSD-3-Clause
    "ISC",  # https://opensource.org/licenses/ISC
    "CC0-1.0",  # https://creativecommons.org/publicdomain/zero/1.0/
    "CC-BY-3.0",  # https://creativecommons.org/licenses/by/3.0/
    "CC-BY-4.0",  # https://creativecommons.org/licenses/by/4.0/
    "Python-2.0",  # https://www.python.org/download/releases/2.0/license/
    "Zlib",  # https://opensource.org/licenses/Zlib
    "Unlicense",  # https://unlicense.org/
    "WTFPL",  # http://www.wtfpl.net/about/
    # Multi-licenses are acceptable if at least one of the licenses is acceptable.
    "(MIT OR Apache-2.0)",
    "(MPL-2.0 OR Apache-2.0)",
    "(MIT OR CC0-1.0)",
    "(Apache-2.0 OR MPL-1.1)",
    "(BSD-3-Clause OR GPL-2.0)",
    "(MIT AND BSD-3-Clause)",
    "(MIT AND Zlib)",
    "(WTFPL OR MIT)",
    "(AFL-2.1 OR BSD-3-Clause)",
    "(BSD-2-Clause OR MIT OR Apache-2.0)",
    "Apache*",
    "(MIT OR GPL-3.0-or-later)",
    "Apache-2.0 AND MIT",
}

# Some of our dependencies have licenses that yarn fails to parse, but that
# are still acceptable. This set contains all those exceptions. Each entry
# should include a comment about why it's an exception.
PACKAGE_EXCEPTIONS: Set[PackageInfo] = {
    (
        # MIT license: https://github.com/mapbox/jsonlint
        "@mapbox/jsonlint-lines-primitives",
        "2.0.2",
        "UNKNOWN",
        "git://github.com/mapbox/jsonlint.git",
        "http://zaa.ch",
        "Zach Carter",
    ),
    (
        # Apache 2.0 license: https://github.com/google/flatbuffers
        "flatbuffers",
        "23.5.26",
        "SEE LICENSE IN LICENSE",
        "git+https://github.com/google/flatbuffers.git",
        "https://google.github.io/flatbuffers/",
        "The FlatBuffers project",
    ),
    (
        # Mapbox Web SDK license: https://github.com/mapbox/mapbox-gl-js/blob/main/LICENSE.txt
        "@plotly/mapbox-gl",
        "1.13.4",
        "SEE LICENSE IN LICENSE.txt",
        "git://github.com/plotly/mapbox-gl-js.git",
        "Unknown",
        "Unknown",
    ),
    (
        # Mapbox Web SDK license: https://github.com/mapbox/mapbox-gl-js/blob/main/LICENSE.txt
        "mapbox-gl",
        "1.13.3",
        "SEE LICENSE IN LICENSE.txt",
        "git://github.com/mapbox/mapbox-gl-js.git",
        "Unknown",
        "Unknown",
    ),
    (
        # CC-BY-3.0 license: https://github.com/cartodb/cartocolor#licensing
        "cartocolor",
        "4.0.2",
        "UNKNOWN",
        "https://github.com/cartodb/cartocolor",
        "http://carto.com/",
        "Unknown",
    ),
    (
        # Apache-2.0 license: https://github.com/saikocat/colorbrewer/blob/master/LICENSE.txt
        "colorbrewer",
        "1.0.0",
        "Apache*",
        "https://github.com/saikocat/colorbrewer",
        "http://colorbrewer2.org/",
        "Cynthia Brewer",
    ),
}


def get_license_type(package: PackageInfo) -> str:
    """Return the license type string for a dependency entry."""
    return package[2]


def check_licenses(licenses) -> NoReturn:
    # `yarn licenses` outputs a bunch of lines.
    # The last line contains the JSON object we care about
    licenses_json = json.loads(licenses[len(licenses) - 1])
    assert licenses_json["type"] == "table"

    # Pull out the list of package infos from the JSON.
    packages = [
        cast(PackageInfo, tuple(package)) for package in licenses_json["data"]["body"]
    ]

    # Discover dependency exceptions that are no longer used and can be
    # jettisoned, and print them out with a warning.
    unused_exceptions = PACKAGE_EXCEPTIONS.difference(set(packages))
    if len(unused_exceptions) > 0:
        for exception in sorted(list(unused_exceptions)):
            print(f"Unused package exception, please remove: {exception}")

    # Discover packages that don't have an acceptable license, and that don't
    # have an explicit exception. If we have any, we print them out and exit
    # with an error.
    bad_packages = [
        package
        for package in packages
        if (get_license_type(package) not in ACCEPTABLE_LICENSES)
        and (package not in PACKAGE_EXCEPTIONS)
        # workspace aggregator is yarn workspaces
        and "workspace-aggregator" not in package[0]
    ]

    if len(bad_packages) > 0:
        for package in bad_packages:
            print(f"Unacceptable license: '{get_license_type(package)}' (in {package})")
        print(f"{len(bad_packages)} unacceptable licenses")
        sys.exit(1)

    print(f"No unacceptable licenses")
    sys.exit(0)


def main() -> NoReturn:
    # Run `yarn licenses` for lib.
    licenses_output = (
        subprocess.check_output(
            ["yarn", "licenses", "list", "--json", "--production", "--ignore-platform"],
            cwd=str(FRONTEND_DIR_LIB),
        )
        .decode()
        .splitlines()
    )

    # Run `yarn licenses` for app.
    licenses_output = licenses_output + (
        subprocess.check_output(
            ["yarn", "licenses", "list", "--json", "--production", "--ignore-platform"],
            cwd=str(FRONTEND_DIR_APP),
        )
        .decode()
        .splitlines()
    )

    check_licenses(licenses_output)


if __name__ == "__main__":
    main()


================================================
File: /scripts/check_license_headers.py
================================================
#!/usr/bin/env python

# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import re
import subprocess
import sys
from pathlib import Path

if __name__ not in ("__main__", "__mp_main__"):
    raise SystemExit(
        "This file is intended to be executed as an executable program. You cannot use "
        f"it as a module.To run this script, run the ./{__file__} command"
    )

SCRIPT_DIR = Path(__file__).resolve().parent
# We just check if the first line of the license is in the file. This is
# enough to check that the file is okay.
LICENSE_TEXT = (SCRIPT_DIR / "license-template.txt").read_text().splitlines()[0]

IGNORE_PATTERN = re.compile(
    # Exclude CI files.
    r"^\.(github)/"
    # Exclude images.
    r"|\.(?:png|jpg|jpeg|gif|ttf|woff|otf|eot|woff2|ico|svg)$"
    # Exclude playwright test assets folder.
    r"|e2e_playwright/test_assets/.*$"
    # Exclude js file we use for testing st.html.
    r"|^lib/tests/streamlit/elements/test_html\.js"
    # Exclude files, because they make it obvious which product they relate to.
    r"|(LICENSE|NOTICES|CODE_OF_CONDUCT\.md|README\.md|CONTRIBUTING\.md|SECURITY.md)$"
    # Exclude files, because they do not support comments
    r"|\.(json|prettierrc|nvmrc)$"
    # Exclude generated files, because they don't have any degree of creativity.
    r"|yarn\.lock$"
    # Exclude pytest config files, because they don't have any degree of creativity.
    r"|pytest\.ini$"
    # Exclude empty files, because they don't have any degree of creativity.
    r"|py\.typed$"
    # Exclude dev-tools configuration files, because they don't have any
    # degree of creativity.
    r"|^(\.dockerignore|\.editorconfig|\.gitignore|\.gitmodules)$"
    r"|^frontend/(\.dockerignore|\.eslintrc.js|\.prettierignore)$"
    r"|^lib/(\.coveragerc|\.dockerignore|MANIFEST\.in|mypy\.ini)$"
    r"|^lib/.*-requirements\.txt$"
    r"|^lib/min-constraints-gen\.txt"
    r"|\.isort\.cfg$"
    r"|\.credentials/\.gitignore$"
    r"|^frontend/app/performance/lighthouse/\.gitignore$"
    r"|^e2e_playwright/\.gitignore$"
    # Excluding test files, because adding headers may cause tests to fail.
    r"|/(fixtures|__snapshots__|test_data|data|test)/"
    # Exclude vendored files.
    r"|/vendor/|^vendor/|^component-lib/declarations/apache-arrow"
    r"|proto/streamlit/proto/openmetrics_data_model\.proto"
    # Exclude patch files.
    r"|\.patch$",
    re.IGNORECASE,
)


def main():
    git_files = sorted(
        subprocess.check_output(["git", "ls-files", "--no-empty-directory"])
        .decode()
        .strip()
        .splitlines()
    )

    invalid_files_count = 0
    for fileloc in git_files:
        if IGNORE_PATTERN.search(fileloc):
            continue
        filepath = Path(fileloc)
        # Exclude submodules
        if not filepath.is_file():
            continue

        try:
            file_content = filepath.read_text()
            if LICENSE_TEXT not in file_content:
                print("Found file without license header", fileloc)
                invalid_files_count += 1
        except:
            print(
                f"Failed to open the file: {fileloc}. Is it binary file?",
            )
            invalid_files_count += 1

    print("Invalid files count:", invalid_files_count)
    if invalid_files_count > 0:
        sys.exit(1)


main()


================================================
File: /scripts/cli_regression_tests.py
================================================
#!/usr/bin/env python

# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import os
import signal
import subprocess
from typing import Optional

import pytest

CONFIG_FILE_PATH: str
CREDENTIALS_FILE_PATH: str
REPO_ROOT: str
STREAMLIT_RELEASE_VERSION: Optional[str]


class TestCLIRegressions:
    """Suite of CLI regression tests to be run against a release build of the Streamlit library.

    Before running, ensure that you have:
        - An isolated environment with Streamlit installed in production mode (not development) as
          well as pytest. This can include the current version, nightly, or local build/wheel, like
          one of the following:
                pip install streamlit-nightly=[nightly tag]
                pip install lib/dist/<WHEEL_FILE>
                pip install streamlit
        - The STREAMLIT_RELEASE_VERSION environment variable must be set, such as:
                export STREAMLIT_RELEASE_VERSION=1.5.1

    You can then run the tests from the root of the Streamlit repository using one of the following:
            pytest scripts/cli_regression_tests.py
            make cli-regression-tests

    This test suite makes use of Python's built-in assert statement. Note that assertions in the
    form of `assert <expression>` use Pytest's assertion introspection. In some cases, a more clear
    error message is specified manually by using `assert <expression>, <message>`. See
    https://docs.pytest.org/en/7.0.x/how-to/assert.html#assert-details for more details.
    """

    @pytest.fixture(scope="module", autouse=True)
    def setup(self):
        # ---- Initialization
        global CONFIG_FILE_PATH
        CONFIG_FILE_PATH = os.path.expanduser("~/.streamlit/config.toml")

        global CREDENTIALS_FILE_PATH
        CREDENTIALS_FILE_PATH = os.path.expanduser("~/.streamlit/credentials.toml")

        global REPO_ROOT
        REPO_ROOT = os.getcwd()

        global STREAMLIT_RELEASE_VERSION
        STREAMLIT_RELEASE_VERSION = os.environ.get("STREAMLIT_RELEASE_VERSION", None)

        # Ensure that there aren't any previously stored credentials
        if os.path.exists(CREDENTIALS_FILE_PATH):
            os.remove(CREDENTIALS_FILE_PATH)

        yield  # Run tests

        # ---- Tear Down
        # Remove testing credentials
        if os.path.exists(CREDENTIALS_FILE_PATH):
            os.remove(CREDENTIALS_FILE_PATH)

        if os.path.exists(CONFIG_FILE_PATH):
            os.remove(CONFIG_FILE_PATH)

        self.run_command("streamlit cache clear")

    def parameterize(self, params):
        return params.split(" ")

    def read_process_output(self, proc, num_lines_to_read):
        num_lines_read = 0
        output = ""

        while num_lines_read < num_lines_to_read:
            output += proc.stdout.readline().decode("UTF-8")
            num_lines_read += 1

        return output

    def run_command(self, command):
        return subprocess.check_output(self.parameterize(command)).decode("UTF-8")

    def run_single_proc(self, command, num_lines_to_read=4):
        proc = subprocess.Popen(
            command,
            shell=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            preexec_fn=os.setpgrp,
        )

        output = self.read_process_output(proc, num_lines_to_read)

        try:
            os.kill(os.getpgid(proc.pid), signal.SIGTERM)
        except ProcessLookupError:
            # The process may have exited already. If so, we don't need to do anything
            pass

        return output

    def run_double_proc(
        self, command_one, command_two, wait_in_seconds=2, num_lines_to_read=4
    ):
        proc_one = subprocess.Popen(
            command_one,
            shell=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            preexec_fn=os.setpgrp,
        )

        # Getting the output from process one ensures the process started first
        output_one = self.read_process_output(proc_one, num_lines_to_read)

        proc_two = subprocess.Popen(
            command_two,
            shell=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            preexec_fn=os.setpgrp,
        )

        output_two = self.read_process_output(proc_two, num_lines_to_read)

        try:
            os.killpg(os.getpgid(proc_one.pid), signal.SIGKILL)
            os.killpg(os.getpgid(proc_two.pid), signal.SIGKILL)
        except ProcessLookupError:
            # The process may have exited already. If so, we don't need to do anything
            pass

        return output_one, output_two

    @pytest.mark.skipif(
        bool(os.environ.get("SKIP_VERSION_CHECK", False)) == True,
        reason="Skip version verification when `SKIP_VERSION_CHECK` env var is set",
    )
    def test_streamlit_version(self):
        assert (
            STREAMLIT_RELEASE_VERSION != None and STREAMLIT_RELEASE_VERSION != ""
        ), "You must set the $STREAMLIT_RELEASE_VERSION env variable"
        assert (
            STREAMLIT_RELEASE_VERSION in self.run_command("streamlit version")
        ), f"Package version does not match the desired version of {STREAMLIT_RELEASE_VERSION}"

    def test_streamlit_activate(self):
        process = subprocess.Popen(
            "streamlit activate", stdin=subprocess.PIPE, shell=True
        )
        process.stdin.write(b"regressiontest@streamlit.io\n")  # type: ignore
        process.stdin.flush()  # type: ignore
        process.communicate()

        with open(CREDENTIALS_FILE_PATH) as f:
            assert (
                "regressiontest@streamlit.io" in f.read()
            ), "Email address was not found in the credentials file"

    def test_port_reassigned(self):
        """When starting a new Streamlit session, it will run on port 8501 by default. If 8501 is
        not available, it will use the next available port.
        """

        out_one, out_two = self.run_double_proc(
            f"streamlit run --server.headless=true {REPO_ROOT}/e2e_playwright/st_file_uploader.py",
            f"streamlit run --server.headless=true {REPO_ROOT}/e2e_playwright/st_file_uploader.py",
        )

        assert ":8501" in out_one, f"Incorrect port. See output:\n{out_one}"
        assert ":8502" in out_two, f"Incorrect port. See output:\n{out_two}"

    def test_conflicting_port(self):
        out_one, out_two = self.run_double_proc(
            f"streamlit run --server.headless=true {REPO_ROOT}/e2e_playwright/st_file_uploader.py",
            f"streamlit run --server.headless=true --server.port=8501 {REPO_ROOT}/e2e_playwright/st_file_uploader.py",
        )

        assert ":8501" in out_one, f"Incorrect port. See output:\n{out_one}"
        assert (
            "Port 8501 is already in use" in out_two
        ), f"Incorrect conflict. See output:\n{out_one}"

    def test_cli_defined_port(self):
        out = self.run_single_proc(
            f"streamlit run --server.headless=true --server.port=9999 {REPO_ROOT}/e2e_playwright/st_file_uploader.py",
        )

        assert ":9999" in out, f"Incorrect port. See output:\n{out}"

    def test_config_toml_defined_port(self):
        with open(CONFIG_FILE_PATH, "w") as file:
            file.write("[server]\n  port=8888")

        out = self.run_single_proc(
            f"streamlit run --server.headless=true {REPO_ROOT}/e2e_playwright/st_file_uploader.py",
        )

        assert ":8888" in out, f"Incorrect port. See output:\n{out}"


================================================
File: /scripts/cli_smoke_tests.py
================================================
#!/usr/bin/env python

# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import subprocess
import sys

import click


def main():
    standard_cli = ["streamlit", "test", "prog_name"]
    if not _can_run_streamlit(standard_cli):
        sys.exit("Failed to run `streamlit test prog_name`")

    # When calling from module, the called argv[0] is updated by
    # __main__.py to be "streamlit" instead of "__main__.py".
    # If this doesn't occur, an assert stops execution of the program.
    module_cli = ["python", "-m", "streamlit", "test", "prog_name"]
    if not _can_run_streamlit(module_cli):
        sys.exit("Failed to run `python -m streamlit test prog_name`")

    # Invoking streamlit via `python -m streamlit.cli <command>` is a method
    # that we previously accidentally supported, but we decided that we should
    # only keep official support for the similar `python -m streamlit <command>`
    # invocation.
    unsupported_module_cli = ["python", "-m", "streamlit.cli", "test", "prog_name"]
    if _can_run_streamlit(unsupported_module_cli):
        sys.exit("`python -m streamlit.cli test prog_name` should not run")

    click.secho("CLI smoke tests succeeded!", fg="green", bold=True)


def _can_run_streamlit(command_list):
    result = subprocess.run(command_list, stdout=subprocess.DEVNULL)
    return result.returncode == 0


if __name__ == "__main__":
    main()


================================================
File: /scripts/create_release.py
================================================
#!/usr/bin/env python
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Create a release using Github API"""

import os

import requests


def create_release():
    """Create a release from the Git Tag"""

    tag = os.getenv("GIT_TAG")
    access_token = os.getenv("GH_TOKEN")

    if not tag:
        raise Exception("Unable to retrieve GIT_TAG environment variable")

    url = "https://api.github.com/repos/streamlit/streamlit/releases"
    header = {"Authorization": f"token {access_token}"}

    # Get the latest release tag to compare against
    response = requests.get(f"{url}/latest", headers=header)
    previous_tag_name = None
    if response.status_code == 200:
        previous_tag_name = response.json()["tag_name"]
    else:
        raise Exception(f"Unable get the latest release: {response.text}")

    # Generate the automated release notes
    payload = {"tag_name": tag, "previous_tag_name": previous_tag_name}
    response = requests.post(f"{url}/generate-notes", json=payload, headers=header)
    body = None
    if response.status_code == 200:
        body = response.json()["body"]
    else:
        raise Exception(f"Unable generate the latest release notes: {response.text}")

    # Create the release with the generated release notes
    payload = {"tag_name": tag, "name": tag, "body": body}
    response = requests.post(url, json=payload, headers=header)

    if response.status_code == 201:
        print(f"Successfully created Release {tag}")
    else:
        raise Exception(f"Unable to create release, HTTP response: {response.text}")


def main():
    create_release()


if __name__ == "__main__":
    main()


================================================
File: /scripts/create_release_branch.sh
================================================
#!/bin/sh
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

set -euo pipefail

VERSION=$1
VERSION_BRANCH="release/${VERSION}"

git switch --create "$VERSION_BRANCH"
python scripts/update_version.py "$VERSION"
git commit --all --message="Up version to ${VERSION}"
git push origin "$VERSION_BRANCH"


================================================
File: /scripts/ensure_relative_imports.sh
================================================
#!/bin/bash

# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# Function to search for the string recursively in .ts and .js files
search_files() {
    local folder="$1"
    local search_string="$2"

    echo "Searching for $search_string within the $folder folder..."
    # Use find to recursively search for .ts and .js files in the folder
    while IFS= read -r -d '' file; do
        # Check if the file has a .ts or .js extension
        if [[ "$file" == *.ts || "$file" == *.js ]]; then
            # Check if the search string does not exist in the file
            if grep -q "$search_string" "$file"; then
                echo "The string '$search_string' found in: $file"
                exit 1
            fi
        fi
    done < <(find "$folder" -type f -print0)
    echo "Done!"
}

# Set the folder path and the search string
folder_path="frontend/lib/dist"
search_string="@streamlit/lib/src"

# Call the function to search for the string in .ts and .js files
search_files "$folder_path" "$search_string"


================================================
File: /scripts/get_min_versions.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

# This script should be invoked using `make gen-min-dep-constraints`.
# It has the precondition that you must have installed streamlit locally since
# you last updated its dependencies, which the make command takes care of.

# based on https://stackoverflow.com/a/59711270
import pkg_resources

package = pkg_resources.working_set.find(pkg_resources.Requirement.parse("streamlit"))

oldest_dependencies = []

for requirement in package.requires():  # type: ignore
    dependency = requirement.project_name
    if requirement.extras:
        dependency += "[" + ",".join(requirement.extras) + "]"
    # We will see both the lower bound and upper bound parts of each requriment
    # So we ignore the ones that aren't the lower bound.
    for comparator, version in requirement.specs:
        if comparator == "==":
            if len(requirement.specs) != 1:
                raise ValueError(f"Invalid dependency: {requirement}")
            dependency += "==" + version
        elif comparator == "<=":
            if len(requirement.specs) != 2:
                raise ValueError(f"Invalid dependency: {requirement}")
        elif comparator == ">=":
            dependency += "==" + version

    oldest_dependencies.append(dependency)

for dependency in sorted(oldest_dependencies):
    print(dependency)


================================================
File: /scripts/get_release_branch.py
================================================
#!/usr/bin/env python
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Retrieve the branch name from the release PR"""

import requests


# Assumes there is only one open pull request with a release/ branch
def check_for_release_pr(pull):
    label = pull["head"]["label"]

    if label.find("release/") != -1:
        return pull["head"]["ref"]


def get_release_branch():
    """Retrieve the release branch from the release PR"""

    url = "https://api.github.com/repos/streamlit/streamlit/pulls"
    response = requests.get(url).json()

    # Response is in an array, must map over each pull (dict)
    for pull in response:
        ref = check_for_release_pr(pull)
        if ref != None:
            return ref


def main():
    print(get_release_branch())


if __name__ == "__main__":
    main()


================================================
File: /scripts/license-template.txt
================================================
Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)

Licensed under the Apache License, Version 2.0 (the "License");
you may not use this file except in compliance with the License.
You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

Unless required by applicable law or agreed to in writing, software
distributed under the License is distributed on an "AS IS" BASIS,
WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
See the License for the specific language governing permissions and
limitations under the License.


================================================
File: /scripts/pypi_nightly_create_tag.py
================================================
#!/usr/bin/env python

# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Create a tag for the PYPI nightly version

Increment the version number, add a dev suffix and add todays date
"""

from datetime import datetime

import packaging.version
import pytz
from packaging.version import Version

PYPI_STREAMLIT_URL = "https://pypi.org/pypi/streamlit/json"


def get_latest_streamlit_version() -> Version:
    """Request the latest streamlit version string from PyPI.

    NB: this involves a network call, so it could raise an error
    or take a long time.

    Parameters
    ----------
    timeout : float or None
        The request timeout.

    Returns
    -------
    str
        The version string for the latest version of streamlit
        on PyPI.

    """
    import requests

    rsp = requests.get(PYPI_STREAMLIT_URL)
    try:
        version_str = rsp.json()["info"]["version"]
    except Exception as e:
        raise RuntimeError("Got unexpected response from PyPI", e)
    return Version(version_str)


def create_tag():
    """Create tag with updated version, a suffix and date."""

    # Get latest version
    current_version = get_latest_streamlit_version()

    # Update micro
    version_with_inc_micro = (
        current_version.major,
        current_version.minor,
        current_version.micro + 1,
    )

    # Append todays date
    version_with_date = (
        ".".join([str(x) for x in version_with_inc_micro])
        + ".dev"
        + datetime.now(pytz.timezone("US/Pacific")).strftime("%Y%m%d")
    )

    # Verify if version is PEP440 compliant.
    packaging.version.Version(version_with_date)

    return version_with_date


if __name__ == "__main__":
    tag = create_tag()

    # Print so we can access the tag in the shell
    print(tag)


================================================
File: /scripts/run_bare_execution_tests.py
================================================
#!/usr/bin/env python

# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Runs all the scripts in the e2e_playwright folder in "bare" mode - that is,
using `python [script]` as opposed to `streamlit run [script]`.

If any script exits with a non-zero status, this will also exit
with a non-zero status.
"""

import multiprocessing
import os
import subprocess
import sys
from multiprocessing import Lock
from multiprocessing.pool import ThreadPool
from typing import Set

import click

# Where we expect to find the example files.
E2E_DIR = "e2e_playwright"

# the hostframe_app.py script does not work because without a script_context
# the navigation function will raise an exception when trying some non-existing page properties.
EXCLUDED_FILENAMES: Set[str] = set(["compilation_error_dialog.py", "hostframe_app.py"])

# Since there is not DISPLAY set (and since Streamlit is not actually running
# and fixing Matplotlib in these tests), we set the MPL backend to something
# that doesn't require a display.
os.environ["MPLBACKEND"] = "Agg"


def _command_to_string(command):
    return " ".join(command) if isinstance(command, list) else command


def _get_filenames(folder):
    folder_path = os.path.abspath(folder)
    return [
        os.path.join(folder_path, filename)
        for filename in sorted(os.listdir(folder_path))
        if filename.endswith(".py")
        and not filename.endswith("_test.py")
        and filename not in EXCLUDED_FILENAMES
    ]


def run_commands(section_header, commands):
    """Run a list of commands, displaying them within the given section."""

    pool = ThreadPool(processes=max(1, multiprocessing.cpu_count() - 1))
    lock = Lock()
    failed_commands = []

    def process_command(arg):
        i, command = arg

        # Display the status.
        click.secho(
            f"\nRunning {section_header} {i + 1}/{len(commands)} : {_command_to_string(command)}",
            bold=True,
        )

        # Run the command.
        result = subprocess.call(
            command.split(" "), stdout=subprocess.DEVNULL, stderr=None
        )
        if result != 0:
            with lock:
                failed_commands.append(command)

    pool.map(process_command, enumerate(commands))
    return failed_commands


def main():
    filenames = _get_filenames(E2E_DIR)
    commands = [f"python {filename}" for filename in filenames]
    failed = run_commands("bare scripts", commands)

    if len(failed) == 0:
        click.secho("All scripts succeeded!", fg="green", bold=True)
        sys.exit(0)
    else:
        click.secho(
            "\n".join(_command_to_string(command) for command in failed), fg="red"
        )
        click.secho(f"\n{ len(failed)} failed scripts", fg="red", bold=True)
        sys.exit(-1)


if __name__ == "__main__":
    main()


================================================
File: /scripts/run_in_subdirectory.py
================================================
#!/usr/bin/env python
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import subprocess
import sys
import textwrap
from pathlib import Path
from typing import List, Tuple

if __name__ not in ("__main__", "__mp_main__"):
    raise SystemExit(
        "This file is intended to be executed as an executable program. You cannot use "
        "it as a module.To run this script, run the ./{__file__} command"
    )


def is_relative_to(path: Path, *other):
    """Return True if the path is relative to another path or False.

    This function is backported from Python 3.9 - Path.relativeto.
    """
    try:
        path.relative_to(*other)
        return True
    except ValueError:
        return False


def display_usage():
    prog = Path(__file__).name
    print(
        textwrap.dedent(
            f"""\
    usage: {prog} [-h] SUBDIRECTORY ARGS [ARGS ...]

    Runs the program in a subdirectory and fix paths in arguments.

    example:

    When this program is executed with the following command:
       {prog} frontend/ yarn eslint frontend/src/index.ts
    Then the command will be executed:
        yarn eslint src/index.ts
    and the current working directory will be set to frontend/

    positional arguments:
      SUBDIRECTORY  subdirectory within which the subprocess will be executed
      ARGS  sequence of program arguments

    optional arguments:
      -h, --help    show this help message and exit\
    """
        )
    )


def parse_args() -> Tuple[str, List[str]]:
    if len(sys.argv) == 2 and sys.argv[1] in ("-h", "--help"):
        display_usage()
        sys.exit(0)
    if len(sys.argv) < 3:
        print("Missing arguments")
        display_usage()
        sys.exit(1)
    print(sys.argv)

    return sys.argv[1], sys.argv[2:]


def fix_arg(subdirectory: str, arg: str) -> str:
    arg_path = Path(arg)
    if not (arg_path.exists() and is_relative_to(arg_path, subdirectory)):
        return arg
    return str(arg_path.relative_to(subdirectory))


def try_as_shell(fixed_args: List[str], subdirectory: str):
    # Windows doesn't know how to run "yarn" using the CreateProcess
    # WINAPI because it's looking for an executable, and yarn is a node script.
    # Yarn happens to be the only thing currently run with this patching script,
    # so add a fall-back which tries to run the requested command in a shell
    # if directly calling the process doesn't work.

    print("Direct call failed, trying as shell command:")
    shell_cmd = " ".join(fixed_args)
    print(shell_cmd)
    try:
        subprocess.run(shell_cmd, cwd=subdirectory, check=True, shell=True)
    except subprocess.CalledProcessError as ex:
        sys.exit(ex.returncode)


def main():
    subdirectory, subprocess_args = parse_args()

    fixed_args = [fix_arg(subdirectory, arg) for arg in subprocess_args]
    try:
        subprocess.run(fixed_args, cwd=subdirectory, check=True)
    except subprocess.CalledProcessError as ex:
        sys.exit(ex.returncode)
    except FileNotFoundError:
        if "win32" in sys.platform:
            try_as_shell(fixed_args, subdirectory)
        else:
            sys.exit(1)


main()


================================================
File: /scripts/slack_notifications.py
================================================
#!/usr/bin/env python
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Send slack notifications"""

import os
import sys

import requests


def send_notification():
    """Create a slack message"""

    webhook = os.getenv("SLACK_WEBHOOK")

    if not webhook:
        raise Exception("Unable to retrieve SLACK_WEBHOOK")

    nightly_slack_messages = {
        "tag": "to create a tag",
        "python": "on python tests",
        "js": "on javascript tests",
        "py_prod": "on python prod dependencies test",
        "playwright": "on playwright tests",
        "build": "to release",
    }

    run_id = os.getenv("RUN_ID")
    workflow = sys.argv[1]
    message_key = sys.argv[2]
    payload = None

    if workflow == "nightly":
        failure = nightly_slack_messages[message_key]
        payload = {
            "text": f":blobonfire: Nightly build failed {failure} - <https://github.com/streamlit/streamlit/actions/runs/{run_id}|Link to run>"
        }

    if workflow == "candidate":
        if message_key == "success":
            payload = {"text": ":rocket: Release Candidate was successful!"}
        else:
            payload = {
                "text": f":blobonfire: Release Candidate failed - <https://github.com/streamlit/streamlit/actions/runs/{run_id}|Link to run>"
            }

    if workflow == "release":
        if message_key == "success":
            payload = {"text": ":rocket: Release was successful!"}
        else:
            payload = {
                "text": f":blobonfire: Release failed - <https://github.com/streamlit/streamlit/actions/runs/{run_id}|Link to run>"
            }

    if payload:
        response = requests.post(webhook, json=payload)

        if response.status_code != 200:
            raise Exception(
                f"Unable to send slack message, HTTP response: {response.text}"
            )


def main():
    send_notification()


if __name__ == "__main__":
    main()


================================================
File: /scripts/update_e2e_snapshots.py
================================================
#!/usr/bin/env python
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Update e2e snapshots."""

import os
import sys
import subprocess
import requests
import tempfile
import shutil
import zipfile
import argparse
from typing import Any, Dict, List
import time


SNAPSHOT_UPDATE_FOLDER = "snapshot-updates"
GITHUB_OWNER = "streamlit"
GITHUB_REPO = "streamlit"
GITHUB_WORKFLOW_FILE_NAME = "playwright.yml"
GITHUB_WORKFLOW_FILE_NAME_CHANGED_FILES = "playwright-changed-files.yml"
PLAYWRIGHT_RESULT_ARTIFACT_NAME = "playwright_test_results"
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
E2E_SNAPSHOTS_DIR = os.path.join(BASE_DIR, "e2e_playwright", "__snapshots__")


def get_token_from_credential_manager() -> str:
    """Get the GitHub token from the git credential manager.
    The token can also be provided via the --token argument.
    """
    cmd = ["git", "credential", "fill"]
    input_data = "protocol=https\nhost=github.com\n\n"
    result = subprocess.run(
        cmd, input=input_data, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True
    )
    if result.returncode != 0:
        print(
            f"Error getting credentials from git credential manager: {result.stderr.strip()}"
        )
        return ""
    output = result.stdout
    # Parse the output to get the token
    for line in output.splitlines():
        if line.startswith("password="):
            return line[len("password=") :]
    return ""


def get_last_commit_sha() -> str:
    """Get the last commit SHA of the local branch."""
    cmd = ["git", "rev-parse", "HEAD"]
    result = subprocess.run(
        cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True
    )
    if result.returncode != 0:
        raise Exception(f"Error getting last commit SHA: {result.stderr.strip()}")
    return result.stdout.strip()


def get_latest_workflow_run(
    owner: str, repo: str, workflow_file_name: str, commit_sha: str, token: str
) -> Dict[str, Any]:
    """Get the latest workflow run for a given workflow file name and commit SHA."""
    url = f"https://api.github.com/repos/{owner}/{repo}/actions/workflows/{workflow_file_name}/runs"
    params = {"head_sha": commit_sha}
    headers = {
        "Accept": "application/vnd.github.v3+json",
        "Authorization": f"token {token}",
    }
    response = requests.get(url, headers=headers, params=params)
    if response.status_code != 200:
        raise Exception(
            f"Error getting workflow runs: {response.status_code} {response.text}"
        )
    data = response.json()
    runs = data.get("workflow_runs", [])
    if not runs:
        print(
            f"No workflow runs found for {workflow_file_name} with head SHA {commit_sha}"
        )
        sys.exit(1)
    # Assuming the latest one is the first in the list
    return runs[0]  # type: ignore


def wait_for_workflow_completion(
    owner: str, repo: str, workflow_file_name: str, commit_sha: str, token: str
) -> Dict[str, Any]:
    """Wait for the workflow to complete, checking every few seconds."""
    while True:
        workflow_run = get_latest_workflow_run(
            owner, repo, workflow_file_name, commit_sha, token
        )
        status = workflow_run.get("status")
        conclusion = workflow_run.get("conclusion")

        if status == "completed":
            if conclusion == "failure":
                # Only failed runs are expected to have updated snapshots.
                return workflow_run
            else:
                print(
                    f"The latest workflow run completed with status: {conclusion}. "
                    "The snapshot update is only working on failed runs."
                )
                sys.exit(1)
        print(
            f"Workflow is still {status}. Waiting 60 seconds before checking again..."
        )
        time.sleep(60)


def get_artifacts(
    owner: str, repo: str, run_id: int, token: str
) -> List[Dict[str, Any]]:
    """Get the artifacts for a given workflow run ID."""
    url = f"https://api.github.com/repos/{owner}/{repo}/actions/runs/{run_id}/artifacts"
    headers = {
        "Accept": "application/vnd.github.v3+json",
        "Authorization": f"token {token}",
    }
    response = requests.get(url, headers=headers)
    if response.status_code != 200:
        raise Exception(
            f"Error getting artifacts: {response.status_code} {response.text}"
        )
    data = response.json()
    artifacts = data.get("artifacts", [])
    return artifacts  # type: ignore


def download_artifact(artifact_url: str, token: str, download_path: str) -> None:
    """Download an artifact from a given URL."""
    headers = {
        "Accept": "application/vnd.github.v3+json",
        "Authorization": f"token {token}",
    }
    response = requests.get(artifact_url, headers=headers, stream=True)
    if response.status_code != 200:
        raise Exception(
            f"Error downloading artifact: {response.status_code} {response.text}"
        )

    with open(download_path, "wb") as f:
        for chunk in response.iter_content(chunk_size=8192):
            f.write(chunk)


def extract_and_merge_snapshots(zip_path: str, destination_folder: str) -> None:
    """Extract and merge the 'snapshot-updates/' folder from an artifact into the destination folder."""
    with zipfile.ZipFile(zip_path, "r") as zip_ref:
        namelist = zip_ref.namelist()
        snapshot_files = [
            name for name in namelist if name.startswith(SNAPSHOT_UPDATE_FOLDER)
        ]
        if not snapshot_files:
            print(f"'{SNAPSHOT_UPDATE_FOLDER}' folder not found in the artifact.")
            sys.exit(1)
        # Extract the 'snapshot-updates/' folder to a temp directory
        temp_extract_dir = tempfile.mkdtemp()
        for file in snapshot_files:
            zip_ref.extract(file, temp_extract_dir)
        # Merge the extracted files into the destination folder
        source_folder = os.path.join(temp_extract_dir, SNAPSHOT_UPDATE_FOLDER)
        if not os.path.exists(destination_folder):
            os.makedirs(destination_folder)
        copy_tree(source_folder, destination_folder)
        # Clean up temp directory
        shutil.rmtree(temp_extract_dir)


def copy_tree(src: str, dst: str) -> None:
    """Copy a directory tree from src to dst."""
    for root, _, files in os.walk(src):
        rel_path = os.path.relpath(root, src)
        dest_dir = os.path.join(dst, rel_path)
        if not os.path.exists(dest_dir):
            os.makedirs(dest_dir)
        for file in files:
            src_file = os.path.join(root, file)
            dst_file = os.path.join(dest_dir, file)
            shutil.copy2(src_file, dst_file)


def main() -> None:
    parser = argparse.ArgumentParser(description="Download GitHub Action Artifact")
    parser.add_argument(
        "--token",
        required=False,
        help="GitHub Personal Access Token (only requires the repo/public_repo scope)",
    )
    parser.add_argument(
        "--changed",
        action="store_true",
        help="Only update snapshots for changed files",
    )
    args = parser.parse_args()
    token = args.token

    if not token:
        print(
            "GitHub token not provided via argument. Attempting to retrieve it from the Git credential manager..."
        )
        token = get_token_from_credential_manager()
        if not token:
            # Add interactive prompt for token
            try:
                token = input(
                    "Please enter your GitHub Personal Access Token (only requires the repo/public_repo scope): "
                ).strip()
            except (KeyboardInterrupt, EOFError):
                token = None

            if not token:
                print(
                    "GitHub token is required. Please provide it via --token or configure your git credential manager."
                )
                sys.exit(1)
        else:
            print("Token retrieved from git credential manager.")

    print("Retrieving latest workflow run...")

    try:
        commit_sha = get_last_commit_sha()
        print(f"Current head SHA: {commit_sha}")

        # Wait for the workflow to complete with status 'failure'
        workflow_file_name = (
            GITHUB_WORKFLOW_FILE_NAME_CHANGED_FILES
            if args.changed
            else GITHUB_WORKFLOW_FILE_NAME
        )
        workflow_run = wait_for_workflow_completion(
            GITHUB_OWNER, GITHUB_REPO, workflow_file_name, commit_sha, token
        )
        run_id = workflow_run["id"]
        print(f"Found completed workflow run with ID: {run_id}")

        # Get artifacts for this run
        artifacts = get_artifacts(GITHUB_OWNER, GITHUB_REPO, run_id, token)
        if not artifacts:
            print(f"No artifacts found for workflow run with ID {run_id}")
            sys.exit(1)
        # Find the correct artifact:
        artifact = next(
            (a for a in artifacts if a["name"] == PLAYWRIGHT_RESULT_ARTIFACT_NAME), None
        )

        if not artifact:
            print(
                f"Artifact '{PLAYWRIGHT_RESULT_ARTIFACT_NAME}' not found in workflow run with ID {run_id}"
            )
            sys.exit(1)
        artifact_id = artifact["id"]
        print(f"Found artifact ID: {artifact_id}")

        # Download the artifact
        download_url = artifact["archive_download_url"]
        with tempfile.TemporaryDirectory() as temp_dir:
            zip_path = os.path.join(temp_dir, "artifact.zip")
            print(f"Downloading artifact to {zip_path}")
            download_artifact(download_url, token, zip_path)

            # Extract and merge 'snapshot-updates' folder
            print(
                f"Extracting '{SNAPSHOT_UPDATE_FOLDER}' and merging into {E2E_SNAPSHOTS_DIR}"
            )
            extract_and_merge_snapshots(zip_path, E2E_SNAPSHOTS_DIR)

        print("Artifact downloaded and snapshots merged successfully.")

    except Exception as e:
        print(f"Error: {e}")
        sys.exit(1)


if __name__ == "__main__":
    main()


================================================
File: /scripts/update_emojis.py
================================================
#!/usr/bin/env python

# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Update the list of emojis in `lib/streamlit/emojis.py.

This script requires the emoji package to be installed: pip install emoji.
"""

import os
import re

from emoji.unicode_codes import EMOJI_DATA
from streamlit.emojis import ALL_EMOJIS

BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
EMOJI_SET_REGEX = re.compile(r"### EMOJIS START ###(.+?)### EMOJIS END ###", re.DOTALL)
EMOJIS_SCRIPT_PATH = os.path.join(BASE_DIR, "lib", "streamlit", "emojis.py")

emoji_unicodes = set(EMOJI_DATA.keys())

print(f"Existing emoji collection: {len(ALL_EMOJIS)}")
print(f"New emoji collection:  {len(emoji_unicodes)}")

generated_code = f"""### EMOJIS START ###
ALL_EMOJIS = {{{", ".join([f'"{emoji}"' for emoji in sorted(emoji_unicodes)])}}}
### EMOJIS END ###"""

with open(EMOJIS_SCRIPT_PATH, "r") as file:
    script_content = file.read()

updated_script_content = re.sub(EMOJI_SET_REGEX, generated_code, script_content)

with open(EMOJIS_SCRIPT_PATH, "w") as file:
    file.write(updated_script_content)


================================================
File: /scripts/update_material_icon_font_and_names.py
================================================
#!/usr/bin/env python

# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Update the list of material icon names in `lib/streamlit/material_icon_names.py.
and download the latest material symbols font file to
./frontend/app/src/assets/fonts/MaterialSymbols/MaterialSymbols-Rounded.woff2
"""

import os
import re
import sys
import urllib.request
import requests

from streamlit.material_icon_names import ALL_MATERIAL_ICONS

MATERIAL_ICONS_CODEPOINTS_URL = "https://raw.githubusercontent.com/google/material-design-icons/master/variablefont/MaterialSymbolsRounded%5BFILL%2CGRAD%2Copsz%2Cwght%5D.codepoints"
MATERIAL_ICONS_FONT_URL = (
    "https://fonts.googleapis.com/css2?family=Material+Symbols+Rounded"
)
BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
NAMES_SET_REGEX = re.compile(
    r"### MATERIAL ICON NAMES START ###(.+?)### MATERIAL ICON NAMES END ###", re.DOTALL
)

FONT_FILE_URL_REGEX = (
    r"url\((https://fonts\.gstatic\.com/s/materialsymbolsrounded/[^\)]+)\)"
)

NAMES_MODULE_PATH = os.path.join(BASE_DIR, "lib", "streamlit", "material_icon_names.py")
FONT_FILE_PATH = os.path.join(
    BASE_DIR,
    "frontend",
    "app",
    "src",
    "assets",
    "fonts",
    "MaterialSymbols",
    "MaterialSymbols-Rounded.woff2",
)


# Fetch the content from the URL
with urllib.request.urlopen(MATERIAL_ICONS_CODEPOINTS_URL) as response:
    content = response.read().decode("utf-8")

# Split the content by lines
lines = content.splitlines()

# Create a set to store unique names
icon_names = set()

# Extract the first word from each line and add it to the set
for line in lines:
    name = line.split()[0]
    icon_names.add(name)

print(f"Existing number of icon names: {len(ALL_MATERIAL_ICONS)}")
print(f"New number of icon names:  {len(icon_names)}")
print(f"New icon names:  {icon_names.difference(ALL_MATERIAL_ICONS)}")


generated_code = f"""### MATERIAL ICON NAMES START ###
ALL_MATERIAL_ICONS = {{{", ".join([f'"{icon_name}"' for icon_name in sorted(icon_names)])}}}
### MATERIAL ICON NAMES END ###"""

with open(NAMES_MODULE_PATH, "r") as file:
    script_content = file.read()

updated_script_content = re.sub(NAMES_SET_REGEX, generated_code, script_content)

with open(NAMES_MODULE_PATH, "w") as file:
    file.write(updated_script_content)

# Fetch the content from the URL
# We use custom User-Agent header here to get .woff2 font instead of .ttf
response = requests.get(
    MATERIAL_ICONS_FONT_URL,
    headers={
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 14_7_1) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.4.1 Safari/605.1.15"
    },
)


# Search for the font file URL in the response
match = re.search(FONT_FILE_URL_REGEX, response.text)

font_url = None

if match:
    font_url = match.group(1)
    print("Extracted URL:", font_url)
else:
    print("URL not found")
    sys.exit(1)

# Download the font file from the URL
if font_url is not None:
    font_file = requests.get(font_url)
    with open(FONT_FILE_PATH, "wb") as file:
        file.write(font_file.content)
        print("Font file downloaded and replaced successfully")
else:
    print("Font file not downloaded")
    sys.exit(1)


================================================
File: /scripts/update_name.py
================================================
#!/usr/bin/env python

# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Update project name across the entire repo.

The streamlit-nightly CI job uses this to set the project name to "streamlit-nightly".
"""

import fileinput
import os
import re
import sys
from typing import Dict

BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))

# A dict of [filename:regex]. For each filename, we modify all lines
# matched by the regex.
#
# Regexes should start with a "<pre_match>" named group and end with a
# "<post_match>" named group. Text between these pre- and post-match
# groups will be replaced with the specified project_name text.
FILES_AND_REGEXES = {
    "lib/setup.py": r"(?P<pre_match>.*name=\").*(?P<post_match>\")",
    "lib/streamlit/version.py": r"(?P<pre_match>.*_version\(\").*(?P<post_match>\"\)$)",
}


def update_files(project_name: str, files: Dict[str, str]) -> None:
    """Update files with new project name."""
    for filename, regex in files.items():
        filename = os.path.join(BASE_DIR, filename)
        matched = False
        pattern = re.compile(regex)
        for line in fileinput.input(filename, inplace=True):
            line = line.rstrip()
            if pattern.match(line):
                line = re.sub(
                    regex, rf"\g<pre_match>{project_name}\g<post_match>", line
                )
                matched = True
            print(line)
        if not matched:
            raise Exception(f'In file "{filename}", did not find regex "{regex}"')


def main() -> None:
    if len(sys.argv) != 2:
        raise Exception(f'Specify project name, e.g: "{sys.argv[0]} streamlit-nightly"')
    project_name = sys.argv[1]
    update_files(project_name, FILES_AND_REGEXES)


if __name__ == "__main__":
    main()


================================================
File: /scripts/update_version.py
================================================
#!/usr/bin/env python

# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Update version number across the entire repo.

If the current version is 0.15.2 and I wanted to create a release for
local development, ie make a wheel file and make either a conda or pex
package to test on OSX or linux.  What should I call the next version?

If its a patch change, then only the third number being edited. If
its a minor change then its the second number.  In this example, we're
doing a patch change.

The public released dev version would be
0.15.3-dev0

For local development it would be
0.15.3-dev0+USERNAME0

If you iterate your local dev version it would then be
0.15.3-dev0+USERNAME1

You then release it for testing.
0.15.3-dev0

Someone finds a bug so you release a new internal version for testing.
0.15.3-dev1+USERNAME0

Then we can go to alpha, rc1, rc2, etc. but eventually its
0.15.3
"""

import fileinput
import os
import re
import sys

import packaging.version
import semver

BASE_DIR = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))

# Warning: Advanced regex foo.
# If another file has a version number that needs updating, add it here.
# These regex's are super greedy in that it actually matches everything
# but the version number so we can throw any valid PEP440 version in
# there.
PYTHON = {"lib/setup.py": r"(?P<pre>.*VERSION = \").*(?P<post>\"  # PEP-440$)"}

# This regex captures the "version": field in a JSON-like structure
# allowing for any amount of whitespace before the "version": field.
NODE_ROOT = {"frontend/package.json": r'(?P<pre>^ \s*"version": ").*(?P<post>",$)'}
NODE_APP = {"frontend/app/package.json": r'(?P<pre>^ \s*"version": ").*(?P<post>",$)'}
NODE_LIB = {"frontend/lib/package.json": r'(?P<pre>^ \s*"version": ").*(?P<post>",$)'}

# This regex captures the "@streamlit/lib": field in a JSON-like structure
# allowing for any amount of whitespace before the "version": field.
NODE_APP_ST_LIB = {
    "frontend/app/package.json": r'(?P<pre>^ \s*"@streamlit/lib": ").*(?P<post>",$)'
}


def verify_pep440(version):
    """Verify if version is PEP440 compliant.

    https://github.com/pypa/packaging/blob/16.7/packaging/version.py#L191

    We might need pre, post, alpha, rc in the future so might as well
    use an object that does all that.  This verifies its a valid
    version.
    """

    try:
        return packaging.version.Version(version)
    except packaging.version.InvalidVersion as e:
        raise (e)


def verify_semver(version):
    """Verify if version is compliant with semantic versioning.

    https://semver.org/
    """

    try:
        return str(semver.Version.parse(version))
    except ValueError as e:
        raise (e)


def update_files(data, version):
    """Update files with new version number."""

    for filename, regex in data.items():
        filename = os.path.join(BASE_DIR, filename)
        matched = False
        pattern = re.compile(regex)
        for line in fileinput.input(filename, inplace=True):
            if pattern.match(line.rstrip()):
                matched = True
            line = re.sub(regex, r"\g<pre>%s\g<post>" % version, line.rstrip())
            print(line)
        if not matched:
            raise Exception('In file "%s", did not find regex "%s"' % (filename, regex))


def main():
    """Run main loop."""

    if len(sys.argv) != 2:
        e = Exception(
            'Specify semvver version as an argument, e.g.: "%s 1.2.3"' % sys.argv[0]
        )
        raise (e)

    # We need two flavors of the version - one that's semver-compliant for Node, one that's
    # PEP440-compliant for Python. We allow for the incoming version to be either semver-compliant
    # PEP440-compliant.
    # - `verify_pep440` automatically converts semver to PEP440-compliant
    pep440_version = verify_pep440(sys.argv[1])

    # - Attempt to convert to semver-compliant. If a failure occurs, manually attempt to convert.
    semver_version = None
    try:
        semver_version = verify_semver(sys.argv[1])
    except ValueError:
        semver_version = verify_semver(
            sys.argv[1].replace("rc", "-rc.").replace(".dev", "-dev")
        )

    update_files(PYTHON, pep440_version)
    update_files(NODE_ROOT, semver_version)
    update_files(NODE_APP, semver_version)
    update_files(NODE_LIB, semver_version)
    update_files(NODE_APP_ST_LIB, semver_version)


if __name__ == "__main__":
    main()


================================================
File: /.github/CODEOWNERS
================================================
# We need to take additional care when making changes to Python dependencies
# to ensure that Streamlit works with as wide a range of packages/package
# versions as possible.
lib/setup.py @streamlit/open-source-release-team

# `audit_frontend_dependencies` ensures that the libraries we ship
# with our frontend code don't violate Snowflake open source policy.
scripts/audit_frontend_licenses.py @streamlit/open-source-release-team

# Ensure changes to our GitHub Actions and related files are reviewed by
# someone closely familiar with how our CI works.
.github/ @streamlit/open-source-release-team @mayagbarnes

# Changes to the following files/directories are likely to have backwards
# compatibility implications for platforms that host Streamlit apps, so we need
# to be extra-careful with these.
proto/ @streamlit/open-source-release-team
lib/streamlit/web/server/server.py @streamlit/open-source-release-team
frontend/lib/src/DefaultStreamlitEndpoints.ts @streamlit/open-source-release-team


================================================
File: /.github/codeql-config.yml
================================================
queries:
  # Details on CodeQL's query packs refer to : https://docs.github.com/en/code-security/code-scanning/automatically-scanning-your-code-for-vulnerabilities-and-errors/configuring-code-scanning#using-queries-in-ql-packs
  - uses: security-and-quality
query-filters:
  - exclude:
      id: py/ineffectual-statement
  - exclude:
      id: py/import-and-import-from
  - exclude:
      id: py/cyclic-import
  - exclude:
      id: py/unsafe-cyclic-import
paths:
  - lib/streamlit
  - frontend/lib/src
  - frontend/app/src
paths-ignore:
  - "frontend/lib/src/vendor/**"
  - "frontend/app/src/vendor/**"
  - "lib/streamlit/vendor/**"


================================================
File: /.github/dependabot.yml
================================================
version: 2
updates:
  # Keep package.json (& lockfiles) up to date as soon as
  # new versions are published to the npm registry
  - package-ecosystem: "npm"
    directory: "/frontend"
    schedule:
      interval: "daily"
    # Pause Dependabot updates. Security updates are unaffected
    open-pull-requests-limit: 0

    labels:
      - "change:chore"
      - "impact:internal"

  # Keep Pipfile up to date
  - package-ecosystem: "pip"
    directory: "/lib"
    schedule:
      interval: "daily"
    # Pause Dependabot updates. Security updates are unaffected
    open-pull-requests-limit: 0

    labels:
      - "change:chore"
      - "impact:internal"

  # Maintain dependencies in GitHub Actions workflows
  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: "weekly"


================================================
File: /.github/pull_request_template.md
================================================
## Describe your changes

## GitHub Issue Link (if applicable)

## Testing Plan

- Explanation of why no additional tests are needed
- Unit Tests (JS and/or Python)
- E2E Tests
- Any manual testing needed?

---

**Contribution License Agreement**

By submitting this pull request you agree that all contributions to this project are made under the Apache 2.0 license.


================================================
File: /.github/release.yml
================================================
changelog:
  exclude:
    labels:
      - impact:internal
  categories:
    - title: Breaking Changes 🛠
      labels:
        - change:breaking
    - title: New Features 🎉
      labels:
        - change:feature
    - title: Bug Fixes 🐛
      labels:
        - change:bugfix
    - title: Other Changes
      labels:
        - impact:users


================================================
File: /.github/repo_meta.yaml
================================================
# point_of_contact: the owner of this repository, can be a GitHub user or GitHub team
point_of_contact: "@sfc-gh-kmcgrady"

# production: whether this repository meets the criteria for being "production"
production: true

# distributed: whether any source code in this repository is distributed directly to customers (e.g. driver and frontend software)
distributed: true

# modified: whether any open source dependencies in this repository have been modified
modified: false

# release_branches: list of release branch patterns, exact matches or regex is acceptable
release_branches:
  - develop
  - release\/*

# code_owners_file_present: whether there is a CODEOWNERS file in this repository
code_owners_file_present: true

# jira_project_issue_type: the jira issuetype used to raise issues related to this repository in the STREAMLIT Jira project
jira_project_issue_type: Bug

# jira_area: the jira area that raised issues should use
jira_area: Streamlit


================================================
File: /.github/ISSUE_TEMPLATE/bug_report.yml
================================================
name: 🐛 Bug report
description: Submit a bug report to help us improve Streamlit
labels: ["type:bug", "status:needs-triage"]
body:
  - type: markdown
    attributes:
      value: |
        Thanks for taking the time to report this problem!
        We really appreciate the community's efforts to improve Streamlit.

        If you are not sure whether you have found a bug, please consider asking in our [community forum](https://discuss.streamlit.io/) first.
  - type: checkboxes
    attributes:
      label: Checklist
      description: Please confirm and check all the following options.
      options:
        - label: I have searched the [existing issues](https://github.com/streamlit/streamlit/issues) for similar issues.
          required: true
        - label: I added a very descriptive title to this issue.
          required: true
        - label: I have provided sufficient information below to help reproduce this issue.
          required: true
  - type: textarea
    attributes:
      label: Summary
      description: Type here a clear and concise description of the problem. Aim for 2-3 sentences.
    validations:
      required: true
  - type: textarea
    attributes:
      label: Reproducible Code Example
      render: Python
      description: |
        If applicable, please provide a [self-contained minimal code example](https://stackoverflow.com/help/minimal-reproducible-example) that reproduces the problem you ran into.
        If we can copy it, run it, and see it right away, there's a much higher chance we will be able to help you.
      placeholder: |
        import streamlit as st

        st.write("Hello World")
    validations:
      required: false
  - type: textarea
    attributes:
      label: Steps To Reproduce
      description: Please provide the steps we should take to reproduce the bug.
      placeholder: |
        1. Go to '...'
        2. Click on '....'
        3. Scroll down to '....'
        4. See error
    validations:
      required: false
  - type: textarea
    attributes:
      label: Expected Behavior
      description: Explain what you expect to happen when you go through the steps above, assuming there were no bugs.
    validations:
      required: false
  - type: textarea
    attributes:
      label: Current Behavior
      placeholder: |
        Error message:
        ```
        streamlit.errors.StreamlitAPIException ...
        ```
      description: |
        Explain the buggy behavior you experience when you go through the steps above.
        If you have error messages or stack traces please provide them here as well.
        If applicable, add screenshots to help explain your problem.

        _Tip: You can attach images or log files by clicking this area to highlight it and then dragging files in._
    validations:
      required: false
  - type: checkboxes
    attributes:
      label: Is this a regression?
      description: Did this use to work the way you expected in the past?
      options:
        - label: Yes, this used to work in a previous version.
          required: false
  - type: textarea
    attributes:
      label: Debug info
      description: |
        Please share some system information related to the environment your app is running in.

        Example:
          - **Streamlit version**: 1.13.0 _(get it with `$ streamlit version`)_
          - **Python version**: 3.9 _(get it with `$ python --version`)_
          - **Operating System**: MacOs 12.6
          - **Browser**: Chrome
      value: |
        - Streamlit version:
        - Python version:
        - Operating System:
        - Browser:
    validations:
      required: false
  - type: textarea
    attributes:
      label: Additional Information
      description: |
        Links? References? Anything that will give us more context about the issue you are encountering!
        For example, did this bug come from https://discuss.streamlit.io or another site? Link the original source here!

        _Tip: You can attach images or log files by clicking this area to highlight it and then dragging files in._
    validations:
      required: false


================================================
File: /.github/ISSUE_TEMPLATE/config.yml
================================================
blank_issues_enabled: false
contact_links:
  - name: 📚 Documentation request
    url: https://github.com/streamlit/docs/issues/new/choose
    about: Let us know how our docs could be better
  - name: 📖 Streamlit documentation
    url: https://docs.streamlit.io/
    about: Learn more about how to use Streamlit
  - name: ❓ Anything else?
    url: https://discuss.streamlit.io/
    about: Ask usage questions on the Streamlit community forum


================================================
File: /.github/ISSUE_TEMPLATE/feature_request.yml
================================================
name: ✨ Feature request
description: Suggest a feature or enhancement for Streamlit
labels: ["type:enhancement"]
body:
  - type: markdown
    attributes:
      value: |
        Thanks for taking the time to suggest a feature or enhancement for Streamlit!
        We really appreciate the community's efforts to improve Streamlit ❤️
  - type: checkboxes
    attributes:
      label: Checklist
      description: Please confirm and check all the following options.
      options:
        - label: I have searched the [existing issues](https://github.com/streamlit/streamlit/issues) for similar feature requests.
          required: true
        - label: I added a descriptive title and summary to this issue.
          required: true
  - type: textarea
    attributes:
      label: Summary
      description: Type here a clear and concise description of the feature or enhancement request. Aim for 2-3 sentences.
    validations:
      required: true
  - type: textarea
    attributes:
      label: Why?
      description: Please outline the problem, motivation, or use case related to this feature request.
      placeholder: |
        I'm always frustrated when ...
    validations:
      required: false
  - type: textarea
    attributes:
      label: How?
      description: |
        Please describe the solution or implementation you'd like to see. This might include suggestions for `st` commands, new parameters, or UI mockups.
        Don't worry if you don't have a clear solution in mind; any input helps!
      placeholder: |
        Introduce a new command called `st.foo` with the following set of parameters...
    validations:
      required: false
  - type: textarea
    attributes:
      label: Additional Context
      description: |
        Links? References? Anything that will give us more context about the feature request here!
        For example, did this feature request come from https://discuss.streamlit.io or another site? Link the original source here!

        _Tip: You can attach images by clicking this area to highlight it and then dragging files in._
    validations:
      required: false


================================================
File: /.github/ISSUE_TEMPLATE/thank_streamlit_team.yml
================================================
name: 🙏 Thank the Streamlit team!
description: Have some kind words to share with the Streamlit team? We'd love to hear them!
labels: ["type:kudos"]
body:
  - type: textarea
    attributes:
      label: Message
      description: Type your message to the Streamlit team here
    validations:
      required: false


================================================
File: /.github/actions/branch/action.yml
================================================
name: "Set BRANCH env variable"

# Using an action to process user input (branch name) as an argument
# is the recommended approach for mitigating script injection attacks.
# It is not vulnerable to injection attacks, as the context value is not used
# to generate a shell script, but is instead passed to the action as an argument
# https://docs.github.com/en/actions/security-guides/security-hardening-for-github-actions#good-practices-for-mitigating-script-injection-attacks

inputs:
  branch:
    description: "Name of the branch"

runs:
  using: composite
  steps:
    - name: Set BRANCH
      env:
        BRANCH_NAME: ${{ inputs.branch }}
      run: echo "BRANCH=$BRANCH_NAME" >> $GITHUB_ENV
      shell: bash --login -eo pipefail {0}


================================================
File: /.github/actions/build_info/action.yml
================================================
name: Build info
description: Sets common builds variables that are needed for other build steps

inputs:
  force-canary:
    description: |
      Forces the current build to be canary.
      Canary builds test all Python versions and do not use constraints.
    required: false
    default: "false"

outputs:
  PYTHON_VERSIONS:
    description: |
      Python versions for which tests will be run.
      The oldest version is replaced by the literal "min" and
      the newest is replaced by the literal "max".
    value: ${{ steps.build_info.outputs.PYTHON_VERSIONS }}
  PYTHON_MIN_VERSION:
    description: Oldest version of Python supported by Streamlit
    value: ${{ steps.build_info.outputs.PYTHON_MIN_VERSION }}
  PYTHON_MAX_VERSION:
    description: Latest version of Python supported by Streamlit
    value: ${{ steps.build_info.outputs.PYTHON_MAX_VERSION }}
  USE_CONSTRAINTS_FILE:
    description: Whether to use a constraint file to install Python dependencies
    value: ${{ steps.build_info.outputs.USE_CONSTRAINTS_FILE }}

runs:
  using: composite
  steps:
    - name: Set Python version vars
      id: build_info
      run: ./.github/scripts/build_info.py
      env:
        GITHUB_CONTEXT: ${{ toJson(github) }}
        GITHUB_INPUTS: ${{ toJson(inputs) }}
      shell: bash


================================================
File: /.github/actions/make_init/action.yml
================================================
name: "Setup Virtual Env"
description: Sets up virtualenv + React; compiles protobuf

inputs:
  use_cached_venv:
    description: "Use Cached Virtual Env"
    default: "true"

# There is an altered copy of these steps inlined in the python_min_deps
# workflow. If you make changes to this action, apply them there too if appropriate.
runs:
  using: composite
  steps:
    - name: Setup Node
      uses: actions/setup-node@v4
      with:
        node-version-file: ".nvmrc"
        cache: "yarn"
        cache-dependency-path: "**/yarn.lock"
    - name: Initialize React
      run: |
        # Create the cache directory if it does not exist.
        mkdir -p $(yarn cache dir)
        make react-init
      shell: bash
    # We require protoc >= 3.20, but Ubuntu 22.04 - the OS that these Github
    # Actions are running as of 2024.06.04 - doesn't have recent versions
    # of protoc in its package repository. To work around this, we
    # install the latest version from the protobuf release page.
    - name: Install `protoc` binary
      run: |
        PROTOC_VERSION=26.1
        curl -OL https://github.com/protocolbuffers/protobuf/releases/download/v${PROTOC_VERSION}/protoc-${PROTOC_VERSION}-linux-x86_64.zip
        sudo unzip -o protoc-${PROTOC_VERSION}-linux-x86_64.zip -d /usr/local bin/protoc
        sudo unzip -o protoc-${PROTOC_VERSION}-linux-x86_64.zip -d /usr/local 'include/*'
        sudo ln -s /usr/local/bin/protoc /usr/bin/protoc
        # Print out your System's protoc version:
        protoc --version
      shell: bash
    # Combine hashes of the Python interpreter, Pipfile, and today's
    # date into a file whose hash will key the Python virtualenv.
    #
    # This means that our virtualenv cache will expire each day. We do
    # this because we are not using a lockfile to pin dependencies -
    # instead, each time Github Actions rebuilds the virtualenv, it uses the
    # latest compatible version of each dependency (which mirrors what
    # happens when a user installs Streamlit locally). So we expire our
    # virtualenv cache daily to prevent it from getting far out of sync
    # with what a fresh Streamlit installation would look like.
    - if: inputs.use_cached_venv == 'true'
      name: Create Python environment cache key
      run: |
        md5sum $(which python) > $GITHUB_WORKSPACE/python_cache_key.md5
        md5sum lib/dev-requirements.txt >> $GITHUB_WORKSPACE/python_cache_key.md5
        md5sum lib/test-requirements.txt >> $GITHUB_WORKSPACE/python_cache_key.md5
        md5sum lib/setup.py >> $GITHUB_WORKSPACE/python_cache_key.md5
        md5sum Makefile >> $GITHUB_WORKSPACE/python_cache_key.md5
        date +%F >> $GITHUB_WORKSPACE/python_cache_key.md5
      shell: bash
    - if: inputs.use_cached_venv == 'true'
      name: Restore virtualenv from cache
      id: cache-virtualenv
      uses: actions/cache@v4
      with:
        path: venv
        key: v1-python-venv-${{ hashFiles('**/python_cache_key.md5') }}
    - if: steps.cache-virtualenv.outputs.cache-hit != 'true'
      name: Create Virtual Env
      run: |
        python -m venv venv
        source venv/bin/activate
        pip install --upgrade pip
        pip install uv
        make python-init
      shell: bash
    - name: Activate virtualenv
      run: echo "${{ github.workspace }}/venv/bin" >> $GITHUB_PATH
      shell: bash
    - name: Show environment info
      run: |
        echo "Show environment info"
        echo "Python version:"
        python --version
        echo "Installed dependencies:"
        python -m pip list
      shell: bash
    - name: Generate Protobufs
      run: make protobuf
      shell: bash


================================================
File: /.github/actions/preview_branch/action.yml
================================================
name: "Set PREVIEW_BRANCH & BRANCH env variables"

# Using an action to process user input (branch name) as an argument
# is the recommended approach for mitigating script injection attacks.
# It is not vulnerable to injection attacks, as the context value is not used
# to generate a shell script, but is instead passed to the action as an argument
# https://docs.github.com/en/actions/security-guides/security-hardening-for-github-actions#good-practices-for-mitigating-script-injection-attacks

inputs:
  pull_request_number:
    description: "Pull request number"
  ref_type:
    description: "The type of Git ref object created in the repository. Can be either branch or tag"
  branch:
    description: "Name of the branch"

runs:
  using: composite
  steps:
    - name: Set PREVIEW_BRANCH & BRANCH
      env:
        PR_NUMBER: ${{ inputs.pull_request_number }}
        REF_TYPE: ${{ inputs.ref_type }}
        BRANCH_NAME: ${{ inputs.branch }}
      run: |
        echo "PREVIEW_BRANCH=$(
          if [[ -n "$PR_NUMBER" ]]
          then
            echo "pr-$PR_NUMBER"
          elif [[ "$REF_TYPE" == 'branch' ]]
          then
            echo "$BRANCH_NAME-preview"
          elif [[ "$REF_TYPE" == 'tag' ]]
          then
            echo "tag-$BRANCH_NAME"
          else
            echo "main-preview"
          fi
        )" >> $GITHUB_ENV
        echo "BRANCH=$BRANCH_NAME" >> $GITHUB_ENV
      shell: bash


================================================
File: /.github/scripts/build_info.py
================================================
#!/usr/bin/env python
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
"""
Generates variables that are needed to execute the Github Action build.

The description of the variables is in the
`.github/actions/build_info/action.yml` file, but variables are also available
in other contexts.

Variables are saved in 3 places to handle 3 use cases:
- The file specified by the GITHUB_OUTPUT environment variable, which
  means the values will be available in the GitHub expression.
  This allows us to have values when communicating between jobs.
  For details, see:
  https://docs.github.com/en/actions/using-workflows/workflow-commands-for-github-actions#setting-an-output-parameter
- The file specified by the GITHUB_ENV environment variable, which
  means the values will be available for other tools run in the following step
  of the same job as environment variable.
  For details, see:
  https://docs.github.com/en/actions/using-workflows/workflow-commands-for-github-actions#setting-an-environment-variable
- The standard output, which means the values will be available in the GitHub logs,
  making troubleshooting easier.
"""

from __future__ import annotations

import enum
import fnmatch
import json
import os
import subprocess
import sys

if __name__ not in ("__main__", "__mp_main__"):
    raise SystemExit(
        "This file is intended to be executed as an executable program. You cannot use "
        f"it as a module. To run this script, run the ./{__file__} command"
    )

GITHUB_CONTEXT_ENV_VAR = "GITHUB_CONTEXT"
GITHUB_INPUTS_ENV_VAR = "GITHUB_INPUTS"
GITHUB_OUTPUT_ENV_VAR = "GITHUB_OUTPUT"
GITHUB_ENV_ENV_VAR = "GITHUB_ENV"

REQUIRED_ENV_VAR = (
    [
        GITHUB_CONTEXT_ENV_VAR,
        GITHUB_INPUTS_ENV_VAR,
        GITHUB_OUTPUT_ENV_VAR,
        GITHUB_ENV_ENV_VAR,
    ]
    if "CI" in os.environ
    else [GITHUB_CONTEXT_ENV_VAR]
)
# The walrus operator requires Python 3.8 or newer
if missing_envs := [
    env_var for env_var in REQUIRED_ENV_VAR if env_var not in os.environ
]:
    raise SystemExit(f"Missing environment variables: {', '.join(missing_envs)}")


FILES_WITH_PYTHON_DEPENDENCIES = [
    "lib/dev-requirements.txt",
    "lib/test-requirements*.txt",
    "lib/setup.py",
]
# +1 to make range inclusive.
ALL_PYTHON_VERSIONS = [f"3.{d}" for d in range(9, 13 + 1)]
PYTHON_MIN_VERSION = ALL_PYTHON_VERSIONS[0]
PYTHON_MAX_VERSION = ALL_PYTHON_VERSIONS[-1]

# To avoid the need to update the protected branch, we replace the boundary
# values with fixed literal. We map it to real values in the Github workflow.
ALL_PYTHON_VERSIONS[0] = "min"
ALL_PYTHON_VERSIONS[-1] = "max"

LABEL_FULL_MATRIX = "dev:full-matrix"
LABEL_UPGRADE_DEPENDENCIES = "dev:upgrade-dependencies"

GITHUB_CONTEXT = json.loads(os.environ[GITHUB_CONTEXT_ENV_VAR])
GITHUB_EVENT = GITHUB_CONTEXT["event"]
GITHUB_EVENT_NAME = GITHUB_CONTEXT["event_name"]


class GithubEvent(enum.Enum):
    PULL_REQUEST = "pull_request"
    PUSH = "push"
    SCHEDULE = "schedule"


def get_changed_files() -> list[str]:
    """
    Checks the modified files in the last commit.

    Note that GITHUB_SHA for pull_request event is the last merge commit of the pull
    request merge branch, which means that the last commit for a pull request always
    lists all files modified by PR.

    This script required the repository to have at least two recent commits checked
    out, which means that Github Action actions/checkout must set the a parameter
    fetch-depth to a value equal or greater than 2.

    Example:

      - name: Checkout Streamlit code
        uses: actions/checkout@v3
        with:
          fetch-depth: 2
    """
    git_output = subprocess.check_output(
        [
            "git",
            "diff-tree",
            "--no-commit-id",
            "--name-only",
            "-r",
            "HEAD^",
            "HEAD",
        ]
    )
    return [line for line in git_output.decode().splitlines() if line]


def get_current_pr_labels() -> list[str]:
    """
    Returns a list of all tags associated with the current PR.

    Note that this function works only when the current event is `pull_request`.
    """
    if GITHUB_EVENT_NAME != GithubEvent.PULL_REQUEST.value:
        raise Exception(
            f"Invalid github event. "
            f"Current value: {GITHUB_EVENT_NAME}. "
            f"Expected state: {GithubEvent.PULL_REQUEST.value}"
        )
    return [label["name"] for label in GITHUB_EVENT["pull_request"].get("labels", [])]


def get_changed_python_dependencies_files() -> list[str]:
    """
    Gets a list of files that contain Python dependency definitions and have
    been modified.
    """
    changed_files = get_changed_files()
    changed_dependencies_files = sorted(
        path
        for pattern in FILES_WITH_PYTHON_DEPENDENCIES
        for path in fnmatch.filter(changed_files, pattern)
    )
    return changed_dependencies_files


def check_if_pr_has_label(label: str, action: str) -> bool:
    """
    Checks if the PR has the given label.

    The function works for all GitHub events, but returns false
    for any event that is not a PR.
    """
    if GITHUB_EVENT_NAME == GithubEvent.PULL_REQUEST.value:
        pr_labels = get_current_pr_labels()
        if label in pr_labels:
            print(f"PR has the following labels: {pr_labels}")
            print(f"{action}, because PR has {label !r} label.")
            return True
    return False


def get_github_input(input_key: str) -> str | None:
    """
    Get additional data that the script expects to use during runtime.

    For details, see: https://docs.github.com/en/actions/creating-actions/metadata-syntax-for-github-actions#inputs
    """
    if GITHUB_INPUTS_ENV_VAR not in os.environ:
        return None
    inputs = json.loads(os.environ[GITHUB_INPUTS_ENV_VAR]) or {}
    input_value = inputs.get(input_key)
    return input_value


def is_canary_build() -> bool:
    """
    Checks whether current build is canary.

    Canary builds are tested on all Python versions and do not use constraints.
    Non-canary builds are tested by default on the oldest and latest Python versions
    and use constraints files by default.

    The behavior depends on what event triggered the current GitHub Action build to run.

    For pull_request event, we return true when Python dependencies have been modified
    In other case, we return false.

    For push event, we return true when the default branch is checked. In other case,
    we return false.

    For scheduled event, we always return true.

    For other events, we return false

    Build canary can be enforced by workflow inputs parameter e.g. all "Build Release"
    workflows trigger canary builds.
    """
    force_canary_input = get_github_input("force-canary") or "false"
    if force_canary_input.lower() == "true":
        print("Current build is canary, because it is enforced by input")
        return True
    if GITHUB_EVENT_NAME == GithubEvent.PULL_REQUEST.value:
        changed_dependencies_files = get_changed_python_dependencies_files()
        if changed_dependencies_files:
            print(f"{len(changed_dependencies_files)} files changed in this build.")
            print(
                "Current build is canary, "
                "because the following files have been modified:"
            )
            print("- " + "- ".join(changed_dependencies_files))
            return True
        return False
    elif GITHUB_EVENT_NAME == GithubEvent.PUSH.value:
        default_branch = GITHUB_EVENT["repository"]["default_branch"]
        is_default_branch = (
            GITHUB_CONTEXT["ref_type"] == "branch"
            and default_branch == GITHUB_CONTEXT["ref_name"]
        )
        if is_default_branch:
            print(
                "Current build is canary, "
                f"because the default branch ({default_branch!r}) is checked."
            )
            return True
        return False
    elif GITHUB_EVENT_NAME == GithubEvent.SCHEDULE.value:
        print(
            "Current build is canary, "
            f"because current github event name is {GITHUB_EVENT_NAME!r}"
        )
        return True

    print(
        "Current build is NOT canary, "
        f"because current github event name is {GITHUB_EVENT_NAME!r}"
    )
    return False


def get_output_variables() -> dict[str, str]:
    """
    Compute build variables.
    """
    canary_build = is_canary_build()
    python_versions = (
        ALL_PYTHON_VERSIONS
        if canary_build
        or check_if_pr_has_label(
            LABEL_FULL_MATRIX, "All Python versions will be tested"
        )
        else [ALL_PYTHON_VERSIONS[0], ALL_PYTHON_VERSIONS[-1]]
    )
    use_constraints_file = not (
        canary_build
        or check_if_pr_has_label(
            LABEL_UPGRADE_DEPENDENCIES, "Latest dependencies will be used"
        )
    )
    variables = {
        "PYTHON_MIN_VERSION": PYTHON_MIN_VERSION,
        "PYTHON_MAX_VERSION": PYTHON_MAX_VERSION,
        "PYTHON_VERSIONS": json.dumps(python_versions),
        "USE_CONSTRAINTS_FILE": str(use_constraints_file).lower(),
    }
    # Environment variables can be overridden at job level and we don't want
    # to change them then.
    for key, value in variables.copy().items():
        variables[key] = os.environ.get(key, value)
    return variables


def save_output_variables(variables: dict[str, str]) -> None:
    """
    Saves build variables
    """
    print("Saving output variables")
    with open(
        os.environ.get(GITHUB_ENV_ENV_VAR, "/dev/null"), "w+"
    ) as github_env_file, open(
        os.environ.get(GITHUB_OUTPUT_ENV_VAR, "/dev/null"), "w+"
    ) as github_output_file:
        for target_file in [sys.stdout, github_env_file, github_output_file]:
            for name, value in variables.items():
                target_file.write(f"{name}={value}\n")
            target_file.flush()


def main() -> None:
    print(f"Current github event name: {GITHUB_EVENT_NAME!r}")
    output_variables = get_output_variables()
    save_output_variables(output_variables)


main()


================================================
File: /.github/workflows/cli-regression.yml
================================================
name: CLI Regression

on:
  push:
    branches:
      - "develop"
  pull_request:
    types: [opened, synchronize, reopened]

# Avoid duplicate workflows on same branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  cli-regression:
    runs-on: ubuntu-latest

    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout Streamlit code
        uses: actions/checkout@v4
        with:
          persist-credentials: false
          submodules: "recursive"
          fetch-depth: 2
      - name: Set Python version vars
        uses: ./.github/actions/build_info
      - name: Set up Python ${{ env.PYTHON_MAX_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: "${{ env.PYTHON_MAX_VERSION }}"
      - name: Setup virtual env
        uses: ./.github/actions/make_init
      - name: Build Package - Fast
        timeout-minutes: 120
        run: |
          sudo apt install rsync
          make package
      - name: Run CLI regression tests
        run: |
          export SKIP_VERSION_CHECK=true; make cli-regression-tests


================================================
File: /.github/workflows/codeql-analysis.yml
================================================
name: "CodeQL"

on:
  push:
    branches: ["develop"]
  pull_request:
    # The branches below must be a subset of the branches above
    branches: ["develop"]
  schedule:
    - cron: "22 19 * * 6"

jobs:
  codeql-analysis:
    name: Analyze
    runs-on: ubuntu-latest
    permissions:
      actions: read
      contents: read
      security-events: write

    strategy:
      fail-fast: false
      matrix:
        language: ["javascript", "python"]

    steps:
      - name: Checkout Streamlit code
        uses: actions/checkout@v4
        with:
          persist-credentials: false
          submodules: "recursive"
          fetch-depth: 2
      # Initializes the CodeQL tools for scanning.
      - name: Initialize CodeQL
        uses: github/codeql-action/init@v3
        with:
          languages: ${{ matrix.language }}
          config-file: ./.github/codeql-config.yml
      - name: Perform CodeQL Analysis
        uses: github/codeql-action/analyze@v3
        with:
          category: "/language:${{matrix.language}}"


================================================
File: /.github/workflows/community-voting.yml
================================================
# This workflow automatically comments on issues labeled with 'type:enhancement' or 'type:bug'
# and adds a thumbs-up reaction to the issue to encourage community voting.

name: Community Voting
on:
  issues:
    types:
      - labeled
jobs:
  add-enhancement-comment:
    if: github.event.label.name == 'type:enhancement'
    runs-on: ubuntu-latest
    permissions:
      issues: write
    steps:
      - name: Add comment to issue
        run: gh issue comment ${{ github.event.issue.html_url }} --body "$ISSUE_BODY"
        env:
          GH_TOKEN: ${{ github.token }}
          ISSUE_BODY: |
            **To help Streamlit prioritize this feature, react with a 👍 (thumbs up emoji) to the initial post.**

            Your vote helps us identify which enhancements matter most to our users.

            ![Visits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2Fstreamlit%2Fstreamlit%2Fissues%2F${{ github.event.issue.number }}&title=visits&edge_flat=false)
      - name: Upvote issue
        uses: aidan-mundy/react-to-issue@b2a9194cf1ea483d633bc2834ed6c4c41c2a45f0
        with:
          issue-number: ${{ github.event.issue.number }}
          reactions: "+1"
  add-bug-comment:
    if: github.event.label.name == 'type:bug'
    runs-on: ubuntu-latest
    permissions:
      issues: write
    steps:
      - name: Add comment to issue
        run: gh issue comment ${{ github.event.issue.html_url }} --body "$ISSUE_BODY"
        env:
          GH_TOKEN: ${{ github.token }}
          ISSUE_BODY: |
            **If this issue affects you, please react with a 👍 (thumbs up emoji) to the initial post.**

            Your feedback helps us prioritize which bugs to investigate and address first.

            ![Visits](https://hits.seeyoufarm.com/api/count/incr/badge.svg?url=https%3A%2F%2Fgithub.com%2Fstreamlit%2Fstreamlit%2Fissues%2F${{ github.event.issue.number }}&title=visits&edge_flat=false)
      - name: Upvote issue
        uses: aidan-mundy/react-to-issue@b2a9194cf1ea483d633bc2834ed6c4c41c2a45f0
        with:
          issue-number: ${{ github.event.issue.number }}
          reactions: "+1"


================================================
File: /.github/workflows/component-template-e2e-tests.yml
================================================
name: Component-template Repo E2E Tests

on:
  push:
    branches:
      - "develop"
  pull_request:
    types: [opened, synchronize, reopened]

jobs:
  component-template-e2e-tests:
    runs-on: ubuntu-latest-8-cores
    steps:
      - name: Checkout Streamlit code
        uses: actions/checkout@v4
        with:
          persist-credentials: false
          submodules: "recursive"
          fetch-depth: 2

      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: "19.x"
          cache: "yarn"
          cache-dependency-path: "component-lib/yarn.lock"

      - name: Set Python version vars
        uses: ./.github/actions/build_info

      - name: Set up Python ${{ env.PYTHON_MAX_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: "${{ env.PYTHON_MAX_VERSION }}"

      - name: Setup virtual env
        uses: ./.github/actions/make_init

      - name: Run make develop
        run: make develop

      - name: Build Package
        timeout-minutes: 120
        run: make package

      - name: Return path to Streamlit wheel
        id: streamlit_wheel
        shell: bash
        run: |
          streamlit_wheel=$(find "./lib/dist" -maxdepth 1 -name '*.whl')
          streamlit_wheel=$(readlink -e "${streamlit_wheel}")
          echo "output_file=${streamlit_wheel}" >> $GITHUB_OUTPUT

      - name: Install node dependencies for streamlit-component-lib
        working-directory: component-lib
        shell: bash
        run: yarn install

      - name: Build streamlit-component-lib package
        working-directory: component-lib
        shell: bash
        run: yarn run build && npm pack

      - name: Return path to Component Library
        working-directory: component-lib
        id: component_library
        shell: bash
        run: |
          component_lib_tar_gz=$(find "./" -maxdepth 1 -name 'streamlit-component-lib-*.tgz')
          component_lib_tar_gz=$(readlink -e "${component_lib_tar_gz}")
          echo "output_file=${component_lib_tar_gz}" >> $GITHUB_OUTPUT

      - name: Checkout streamlit/component-template
        uses: actions/checkout@v4
        with:
          persist-credentials: false
          repository: streamlit/component-template
          path: ./component-template

      - name: Build components wheels
        uses: ./component-template/.github/actions/build_component_wheels
        id: component_wheels
        with:
          custom_streamlit_component_lib_file: >-
            ${{ steps.component_library.outputs.output_file }}

      - name: Run E2E tests
        uses: ./component-template/.github/actions/run_e2e
        with:
          python_version: ${{ env.PYTHON_MAX_VERSION }}
          streamlit_wheel_file: ${{ steps.streamlit_wheel.outputs.output_file }}


================================================
File: /.github/workflows/conda-build.yml
================================================
name: Snowpark Conda Build Test

on:
  push:
    branches:
      - "develop"
  pull_request:
    types: [opened, synchronize, reopened]

# Avoid duplicate workflows on same branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  build-snowpark-conda-package:
    runs-on: ubuntu-latest

    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout Streamlit code
        uses: actions/checkout@v4
        with:
          persist-credentials: false
          submodules: "recursive"
          fetch-depth: 2
      - name: Set build config env vars
        uses: ./.github/actions/build_info
      - name: Set up Python 3.12
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"
      - name: Setup virtual env
        uses: ./.github/actions/make_init
      - name: Install conda and conda-build
        env:
          MINICONDA_RELEASE: "Miniconda3-py312_24.1.2-0-Linux-x86_64"
        run: |
          curl -sO "https://repo.anaconda.com/miniconda/${MINICONDA_RELEASE}.sh"
          bash "${MINICONDA_RELEASE}.sh" -b
          conda install conda-build
      - name: Build Snowpark Conda Package - Fast
        timeout-minutes: 120
        run: |
          sudo apt install rsync
          conda config --set conda_build.pkg_format 2
          SNOWPARK_CONDA_BUILD=1 make conda-package


================================================
File: /.github/workflows/enforce-pre-commit.yml
================================================
name: Enforce Pre-Commit Hooks

on:
  push:
    branches:
      - "develop"
  pull_request:
    types: [opened, synchronize, reopened]
  # Allows workflow to be called from other workflows
  workflow_call:
    inputs:
      ref:
        required: true
        type: string

# Avoid duplicate workflows on same branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}-enforce-pre-commit
  cancel-in-progress: true

jobs:
  enforce-pre-commit:
    runs-on: ubuntu-latest

    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout Streamlit code
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref }}
          persist-credentials: false
          submodules: "recursive"
          fetch-depth: 2
      - name: Set Python version vars
        uses: ./.github/actions/build_info
      - name: Set up Python ${{ env.PYTHON_MAX_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: "${{ env.PYTHON_MAX_VERSION }}"
      - name: Restore pre-commit cache
        id: cache-pre-commit
        uses: actions/cache@v4
        with:
          path: ~/.cache/pre-commit
          key: v1-pre-commit-${{ env.pythonLocation }}-${{ hashFiles('**/.pre-commit-config.yaml') }}
      - name: Install pre-commit
        run: |
          pip install pre-commit
          pre-commit install-hooks
        shell: bash
      - name: Install prettier
        run: cd frontend && yarn install
      - name: Run pre-commit hooks
        run: PRE_COMMIT_NO_CONCURRENCY=true pre-commit run --show-diff-on-failure --color=always --all-files


================================================
File: /.github/workflows/ensure-relative-imports.yml
================================================
name: Ensure Relative Imports in Frontend

on:
  push:
    branches:
      - "develop"
  pull_request:
    types: [opened, synchronize, reopened]
  # Allows workflow to be called from other workflows
  workflow_call:
    inputs:
      ref:
        required: true
        type: string

# Avoid duplicate workflows on same branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}-ensure-relative-imports
  cancel-in-progress: true

jobs:
  ensure-relative-imports:
    runs-on: ubuntu-latest

    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout Streamlit code
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref }}
          persist-credentials: false
          submodules: "recursive"
          fetch-depth: 2
      - name: Set Python version vars
        uses: ./.github/actions/build_info
      - name: Set up Python ${{ env.PYTHON_MAX_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: "${{ env.PYTHON_MAX_VERSION }}"
      - name: Setup virtual env
        uses: ./.github/actions/make_init
      - name: Run make develop
        run: make develop
      - name: Run make protobuf
        run: make protobuf
      - name: Run make frontend-lib-prod
        run: make frontend-lib-prod
      - name: Ensure relative imports exist in the @streamlit/lib/dist folder
        run: make ensure-relative-imports


================================================
File: /.github/workflows/js-tests.yml
================================================
name: Javascript Unit Tests

on:
  push:
    branches:
      - "develop"
  pull_request:
    types: [opened, synchronize, reopened]
  # Allows workflow to be called from other workflows
  workflow_call:
    inputs:
      ref:
        required: true
        type: string

# Avoid duplicate workflows on same branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}-javascript
  cancel-in-progress: true

jobs:
  js-unit-tests:
    runs-on: ubuntu-latest

    defaults:
      run:
        shell: bash
    steps:
      - name: Checkout Streamlit code
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref }}
          persist-credentials: false
          submodules: "recursive"
          fetch-depth: 2
      - name: Set Python version vars
        uses: ./.github/actions/build_info
      - name: Set up Python ${{ env.PYTHON_MAX_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: "${{ env.PYTHON_MAX_VERSION }}"
      - name: Setup virtual env
        uses: ./.github/actions/make_init
      - name: Run make develop
        run: make develop
      - name: Run make protobuf
        run: make protobuf
      - name: Run make frontend-lib
        run: make frontend-lib
      - name: Audit frontend licenses
        run: ./scripts/audit_frontend_licenses.py
      - name: Run type checks
        run: make tstypecheck
      - name: Run linters
        run: make jslint
      - name: Validate NOTICES
        run: |
          # Run `make notices`. If it results in changes, warn the user and fail.
          make notices

          git_status=$(git status --porcelain -- NOTICES)
          if [[ -n $git_status ]]; then
            echo "::error::The NOTICES file is out of date! Please run \`make notices\` and commit the result."
            echo "::group::git diff NOTICES"
            git diff NOTICES
            echo "::endgroup::"
            exit 1
          else
            echo "NOTICES is up to date."
          fi
      - name: Run frontend tests
        run: make jstestcoverage
      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage_report_vitest
          path: |
            frontend/lib/coverage
            frontend/app/coverage
          retention-days: 7

  components-lib-tests:
    runs-on: ubuntu-latest

    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout Streamlit code
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref }}
          persist-credentials: false
          submodules: "recursive"
          fetch-depth: 2
      - name: Setup Node
        uses: actions/setup-node@v4
        with:
          node-version: "20.x"
          cache: "yarn"
          cache-dependency-path: "component-lib/yarn.lock"
      - name: Install node dependencies
        working-directory: component-lib
        run: yarn install
      - name: Run frontend tests
        working-directory: component-lib
        run: yarn test
      - name: Build package
        working-directory: component-lib
        run: yarn build


================================================
File: /.github/workflows/nightly.yml
================================================
name: Nightly Build

on:
  schedule:
    # Run job at 10.30pm PST or 11.30pm PDT
    - cron: "30 6 * * *"

jobs:
  create-nightly-tag:
    runs-on: ubuntu-latest

    if: github.repository == 'streamlit/streamlit'

    defaults:
      run:
        shell: bash

    permissions:
      # Additional permission needed to generate tag
      contents: write

    outputs:
      TAG: ${{ steps.create_tag.outputs.tag }}

    steps:
      - name: Checkout Streamlit code
        uses: actions/checkout@v4
        with:
          submodules: "recursive"
          # Save the access token to the local git config, so
          # later git commands can work.
          persist-credentials: true
          fetch-depth: 2
      - name: Set Python version vars
        uses: ./.github/actions/build_info
      - name: Set up Python ${{ env.PYTHON_MAX_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: "${{ env.PYTHON_MAX_VERSION }}"
      - name: Setup virtual env
        uses: ./.github/actions/make_init
      - name: Run make develop
        run: make develop
      - name: Create tag
        id: create_tag
        run: |
          git config --global user.email "core+streamlitbot-github@streamlit.io"
          git config --global user.name "Streamlit Bot"

          TAG="$(./scripts/pypi_nightly_create_tag.py)"
          echo "tag=$TAG" >> $GITHUB_OUTPUT

          ./scripts/update_version.py $TAG
          ./scripts/update_name.py streamlit-nightly

          git add lib/setup.py frontend/package.json lib/streamlit/__init__.py lib/streamlit/version.py

          git commit -m "Update version and project name in files"

          git tag -a $TAG -m "Streamlit nightly $TAG"
          git push origin $TAG
      - if: ${{ failure() }}
        name: Nightly Tag Failure Slack Message
        env:
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
          RUN_ID: ${{ github.run_id }}
        run: python scripts/slack_notifications.py nightly tag

  run-python-tests:
    needs: create-nightly-tag
    permissions:
      # Pass additional permission needed to upload constraints
      contents: write
    uses: ./.github/workflows/python-tests.yml
    with:
      ref: ${{needs.create-nightly-tag.outputs.tag}}
    secrets:
      SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
      SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}

  run-javascript-tests:
    needs: create-nightly-tag
    uses: ./.github/workflows/js-tests.yml
    with:
      ref: ${{needs.create-nightly-tag.outputs.tag}}

  run-playwright-tests:
    uses: ./.github/workflows/playwright.yml
    with:
      ref: ${{needs.create-nightly-tag.outputs.tag}}

  performance-lighthouse:
    uses: ./.github/workflows/performance-lighthouse.yml
    with:
      ref: ${{needs.create-nightly-tag.outputs.tag}}
      externalCall: true

  test-status-notification:
    runs-on: ubuntu-latest

    if: ${{ always() }}
    # By default, jobs listed in needs must all complete successfully for the dependent job to run. always() conditional
    # added as we'd like this job to run whether or not tests pass & slack us regarding failing tests.
    needs:
      - create-nightly-tag
      - run-python-tests
      - run-javascript-tests
      - run-playwright-tests

    env:
      SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
      RUN_ID: ${{ github.run_id }}

    steps:
      - name: Checkout Streamlit code
        uses: actions/checkout@v4
        with:
          ref: ${{ needs.create-nightly-tag.outputs.tag }}
          persist-credentials: false
          submodules: "recursive"
      - if: ${{ needs.run-python-tests.result == 'failure' }}
        run: python scripts/slack_notifications.py nightly python
      - if: ${{ needs.run-javascript-tests.result == 'failure' }}
        run: python scripts/slack_notifications.py nightly js
      - if: ${{ needs.run-playwright-tests.result == 'failure' }}
        run: python scripts/slack_notifications.py nightly playwright

  create-nightly-build:
    runs-on: ubuntu-latest

    # Tag creation & tests must all complete successfully for nightly build job to run.
    needs:
      - create-nightly-tag
      - run-python-tests
      - run-javascript-tests
      - run-playwright-tests
    permissions:
      id-token: write

    defaults:
      run:
        shell: bash

    outputs:
      enable-setup: ${{ steps.exports.outputs.enable-setup }}
      s3-url: ${{ steps.exports.outputs.s3-url }}

    environment: nightly

    steps:
      - name: Checkout Streamlit code
        uses: actions/checkout@v4
        with:
          ref: ${{ needs.create-nightly-tag.outputs.tag }}
          # Save the access token to the local git config, so
          # later git commands can work.
          persist-credentials: true
          submodules: "recursive"
      - name: Set Python version vars
        uses: ./.github/actions/build_info
      - name: Set up Python ${{ env.PYTHON_MAX_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: "${{ env.PYTHON_MAX_VERSION }}"
      - name: Setup virtual env
        uses: ./.github/actions/make_init
      - name: Run make develop
        run: make develop
      - name: Verify git tag vs. version
        env:
          TAG: ${{ needs.create-nightly-tag.outputs.tag }}
        run: |
          cd lib
          python setup.py verify
      - name: Build Package
        timeout-minutes: 120
        run: |
          sudo apt update
          sudo apt install rsync
          make package
      - name: Store Whl File
        uses: actions/upload-artifact@v4
        with:
          name: whl_file
          path: lib/dist/*.whl
      - name: Upload wheel to S3
        id: exports
        env:
          AWS_DEFAULT_REGION: us-west-2
          AWS_ACCESS_KEY_ID: ${{ secrets.CORE_PREVIEWS_S3_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.CORE_PREVIEWS_S3_SECRET_KEY }}
        run: |
          # Install awscli via pip/uv:
          uv pip install awscli

          cd lib/dist
          export WHEELFILE="$(ls -t *.whl | head -n 1)"

          aws s3 cp "${WHEELFILE}" s3://core-previews/nightly-preview/ --acl public-read
          S3_URL="https://core-previews.s3-us-west-2.amazonaws.com/nightly-preview/${WHEELFILE}"

          echo -e "Wheel file download link: ${S3_URL}"

          cd ../..
          # env variables don't carry over between gh action jobs
          echo "enable-setup=${{ env.AWS_ACCESS_KEY_ID != '' }}" >> $GITHUB_OUTPUT
          echo "s3-url=${S3_URL}" >> $GITHUB_OUTPUT
      - name: Upload to PyPI
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          packages-dir: lib/dist/
      - if: ${{ failure() }}
        name: Nightly Build Failure Slack Message
        env:
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
          RUN_ID: ${{ github.run_id }}
        run: python scripts/slack_notifications.py nightly build

  setup-nightly-preview:
    runs-on: ubuntu-latest

    needs: [create-nightly-tag, create-nightly-build]
    if: needs.create-nightly-build.outputs.enable-setup == 'true'

    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout Core Previews Repo
        uses: actions/checkout@v4
        with:
          repository: streamlit/core-previews
          # The default GITHUB_TOKEN is scoped only to the triggering streamlit/streamlit repo.
          # Accessing streamlit/core-previews repo requires a separate auth token.
          token: ${{ secrets.CORE_PREVIEWS_REPO_TOKEN }}
          # Save the access token to the local git config, so
          # later git commands can work.
          persist-credentials: true
      - name: Setup preview repo
        env:
          NIGHTLY_TAG: ${{ needs.create-nightly-tag.outputs.tag }}
          S3_URL: ${{ needs.create-nightly-build.outputs.s3-url }}
        run: |
          git config --global user.email "core+streamlitbot-github@streamlit.io"
          git config --global user.name "Streamlit Bot"
          git branch -D nightly-preview &>/dev/null || true
          git checkout -b nightly-preview

          echo "$S3_URL" >> requirements.txt

          git add .
          git commit -m "Nightly Preview: ${NIGHTLY_TAG}"
          git push -f origin nightly-preview


================================================
File: /.github/workflows/performance-lighthouse.yml
================================================
name: Performance - Lighthouse

on:
  pull_request:
    types: [opened, synchronize, reopened, labeled, unlabeled]
  # Allows workflow to be called from other workflows
  workflow_call:
    inputs:
      ref:
        required: true
        type: string
      externalCall:
        description: "To distinguish workflow_call from regular push"
        type: boolean
        required: false
        default: false

# Avoid duplicate workflows on same branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}-performance-lighthouse
  cancel-in-progress: true

jobs:
  performance-lighthouse:
    # Only run this job if the PR has the label 'perf:lighthouse' or if it's been called by another workflow
    # See https://github.com/actions/runner/discussions/1884 for discussion on why `externalCall` is used
    if: contains(github.event.pull_request.labels.*.name, 'perf:lighthouse') || inputs.externalCall
    runs-on: ubuntu-latest

    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout Streamlit code
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref }}
          persist-credentials: false
          submodules: "recursive"
          fetch-depth: 2
      - name: Set Python version vars
        uses: ./.github/actions/build_info
      - name: Set up Python ${{ env.PYTHON_MAX_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: "${{ env.PYTHON_MAX_VERSION }}"
      - name: Setup virtual env
        uses: ./.github/actions/make_init
      - name: Run make frontend
        run: make frontend
      - name: Run Performance Lighthouse
        run: make performance-lighthouse
      - name: Set MY_DATE_TIME env var
        run: echo "MY_DATE_TIME=$(date +'%Y%m%d%H%M%S')" >> $GITHUB_ENV
      - name: Upload artifacts
        uses: actions/upload-artifact@v4
        with:
          name: performance_lighthouse_${{ env.MY_DATE_TIME }}
          path: frontend/app/performance/lighthouse/reports


================================================
File: /.github/workflows/playwright-changed-files.yml
================================================
name: Playwright E2E Tests - Changed Files

on:
  pull_request:
    types: [opened, synchronize, reopened]

# Avoid duplicate workflows on same branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}-playwright-changed-files
  cancel-in-progress: true

jobs:
  playwright-e2e-tests-changed-files:
    runs-on: ubuntu-latest-8-cores

    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout Streamlit code
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref }}
          persist-credentials: false
          submodules: "recursive"
          fetch-depth: 2
      - name: Get changed files
        id: changed-files
        uses: tj-actions/changed-files@v45
        with:
          path: e2e_playwright
          # Exclude all files in custom_components folder as they require external dependencies
          files: |
            **/*_test.py
            !custom_components/**
      - name: Check changed files
        id: check_changed_files
        env:
          CHANGED_FILES: ${{ steps.changed-files.outputs.all_changed_files }}
          CHANGED_FILES_COUNT: ${{ steps.changed-files.outputs.all_changed_files_count }}
        run: |
          echo "Changed files count: ${CHANGED_FILES_COUNT}"
          echo "$CHANGED_FILES"
          if [[ "${CHANGED_FILES_COUNT}" -gt 5 || "${CHANGED_FILES_COUNT}" -lt 1 ]]; then
            # We limit the workflow to a max of 5 changed files, since otherwise it would
            # take too long and would not provide any benefit compared to the main playwright
            # workflow.
            echo "This workflow only supports between 1-5 changed files. Otherwise its skipping running the tests.";
            echo "run_tests=false" >> $GITHUB_OUTPUT
          else
            echo "run_tests=true" >> $GITHUB_OUTPUT
          fi
      - name: Use output
        run: |
          echo "The output value is: ${{ steps.check_changed_files.outputs.run_tests }}"
      - name: Set Python version vars
        uses: ./.github/actions/build_info
      - name: Set up Python ${{ env.PYTHON_MAX_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: "${{ env.PYTHON_MAX_VERSION }}"
      - if: steps.check_changed_files.outputs.run_tests == 'true'
        name: Setup virtual env
        uses: ./.github/actions/make_init
      - if: steps.check_changed_files.outputs.run_tests == 'true'
        name: Install playwright
        run: python -m playwright install --with-deps
      - if: steps.check_changed_files.outputs.run_tests == 'true'
        name: Run make frontend-build-with-profiler
        run: make frontend-build-with-profiler
      - if: steps.check_changed_files.outputs.run_tests == 'true'
        name: Run changed playwright tests
        run: |
          cd e2e_playwright;
          rm -rf ./test-results;
          pytest ${{ steps.changed-files.outputs.all_changed_files }} --browser webkit --browser chromium --browser firefox --video retain-on-failure --screenshot only-on-failure --full-page-screenshot --tracing retain-on-failure --output ./test-results/ --cov=streamlit --cov-report=html -n auto --durations=5 -r aR -v
      - name: Upload failed test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: playwright_test_results
          path: e2e_playwright/test-results
      - name: Upload performance results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: playwright_performance_results
          path: e2e_playwright/performance-results

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage_report_e2e
          path: e2e_playwright/htmlcov
          retention-days: 7


================================================
File: /.github/workflows/playwright-custom-components.yml
================================================
name: Playwright E2E Tests - Custom Components

on:
  push:
    branches:
      - "develop"
  pull_request:
    types: [opened, synchronize, reopened]
  # Allows workflow to be called from other workflows
  workflow_call:
    inputs:
      ref:
        required: true
        type: string

# Avoid duplicate workflows on same branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}-playwright-custom-component
  cancel-in-progress: true

jobs:
  playwright-e2e-tests-custom-components:
    runs-on: ubuntu-latest
    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout Streamlit code
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref }}
          persist-credentials: false
          submodules: "recursive"
          fetch-depth: 2
      - name: Set Python version vars
        uses: ./.github/actions/build_info
      - name: Set up Python ${{ env.PYTHON_MAX_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: "${{ env.PYTHON_MAX_VERSION }}"
      - name: Setup virtual env
        uses: ./.github/actions/make_init
      - name: Install playwright
        run: python -m playwright install --with-deps
      - name: Run make frontend
        run: make frontend
      - name: Run make playwright-custom-components
        run: make playwright-custom-components
      - name: Upload failed test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: playwright_test_results
          path: e2e_playwright/test-results


================================================
File: /.github/workflows/playwright-performance.yml
================================================
name: Playwright E2E Tests - Performance

on:
  push:
    branches:
      - "develop"
  pull_request:
    types: [opened, synchronize, reopened]
  # Allows workflow to be called from other workflows
  workflow_call:
    inputs:
      ref:
        required: true
        type: string

# Avoid duplicate workflows on same branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}-playwright-performance
  cancel-in-progress: true

jobs:
  playwright-performance:
    runs-on: ubuntu-latest-8-cores

    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout Streamlit code
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref }}
          persist-credentials: false
          submodules: "recursive"
          fetch-depth: 2
      - name: Set Python version vars
        uses: ./.github/actions/build_info
      - name: Set up Python ${{ env.PYTHON_MAX_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: "${{ env.PYTHON_MAX_VERSION }}"
      - name: Setup virtual env
        uses: ./.github/actions/make_init
      - name: Install playwright
        run: python -m playwright install --with-deps
      - name: Run make frontend-build-with-profiler
        run: make frontend-build-with-profiler
      - name: Run make playwright-performance
        run: make playwright-performance
      - name: Upload failed test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: playwright_test_results
          path: e2e_playwright/test-results
      - name: Upload performance results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: playwright_performance_results
          path: e2e_playwright/performance-results


================================================
File: /.github/workflows/playwright.yml
================================================
name: Playwright E2E Tests

on:
  push:
    branches:
      - "develop"
  pull_request:
    types: [opened, synchronize, reopened]
  # Allows workflow to be called from other workflows
  workflow_call:
    inputs:
      ref:
        required: true
        type: string

# Avoid duplicate workflows on same branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}-playwright
  cancel-in-progress: true

jobs:
  playwright-e2e-tests:
    runs-on: ubuntu-latest-32-cores

    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout Streamlit code
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref }}
          persist-credentials: false
          submodules: "recursive"
          fetch-depth: 2
      - name: Set Python version vars
        uses: ./.github/actions/build_info
      - name: Set up Python ${{ env.PYTHON_MAX_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: "${{ env.PYTHON_MAX_VERSION }}"
      - name: Setup virtual env
        uses: ./.github/actions/make_init
      - name: Install playwright
        run: python -m playwright install --with-deps
      - name: Run make frontend-build-with-profiler
        run: make frontend-build-with-profiler
      - name: Run make playwright
        run: make playwright
      - name: Upload failed test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: playwright_test_results
          path: e2e_playwright/test-results
      - name: Upload performance results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: playwright_performance_results
          path: e2e_playwright/performance-results


================================================
File: /.github/workflows/pr-preview.yml
================================================
name: PR Preview

on:
  push:
    branches:
      - "develop"
  pull_request:
    types: [opened, synchronize, reopened]

# Avoid duplicate workflows on same branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  upload-whl:
    runs-on: ubuntu-latest

    permissions:
      contents: read # This is required for actions/checkout
      statuses: write # This is required for "Set S3 URL as Github status" step

    defaults:
      run:
        shell: bash

    outputs:
      enable-setup: ${{ steps.exports.outputs.enable-setup }}
      preview-branch: ${{ steps.exports.outputs.preview-branch }}
      s3-url: ${{ steps.exports.outputs.s3-url }}

    steps:
      - name: Checkout Streamlit code
        uses: actions/checkout@v4
        with:
          persist-credentials: false
          submodules: "recursive"
          fetch-depth: 2
      - name: Set Python version vars
        uses: ./.github/actions/build_info
      - name: Set up Python ${{ env.PYTHON_MAX_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: "${{ env.PYTHON_MAX_VERSION }}"
      - name: Setup virtual env
        uses: ./.github/actions/make_init
      - name: Create Wheel File
        timeout-minutes: 120
        run: |
          sudo apt update
          sudo apt install rsync
          make package
      - name: Store Whl File
        uses: actions/upload-artifact@v4
        with:
          name: whl_file
          path: lib/dist/*.whl
      # Uses action to safely process user input (branch name) to prevent script injection attacks
      - name: Set Environment Variables
        uses: ./.github/actions/preview_branch
        with:
          pull_request_number: ${{ github.event.pull_request.number }}
          ref_type: ${{ github.ref_type }}
          branch: ${{ github.ref_name }}
      - if: ${{ env.AWS_ACCESS_KEY_ID != '' }}
        name: Upload wheel to S3
        id: exports
        env:
          BRANCH: ${{ env.BRANCH }}
          PREVIEW_BRANCH: ${{ env.PREVIEW_BRANCH }}
          AWS_DEFAULT_REGION: us-west-2
          AWS_ACCESS_KEY_ID: ${{ secrets.CORE_PREVIEWS_S3_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.CORE_PREVIEWS_S3_SECRET_KEY }}
        # To create a consistent location for the release/demo whl file, we need a
        # stagnent version number (streamlit-11.11.11)
        run: |
          # Install awscli via pip/uv:
          uv pip install awscli

          cd lib/dist
          export WHEELFILE="$(ls -t *.whl | head -n 1)"

          if [ "${BRANCH}" = "release/demo" ]
          then
            aws s3 cp "${WHEELFILE}" s3://core-previews/${PREVIEW_BRANCH}/streamlit-11.11.11-py2.py3-none-any.whl --acl public-read
            S3_URL="https://core-previews.s3-us-west-2.amazonaws.com/${PREVIEW_BRANCH}/streamlit-11.11.11-py2.py3-none-any.whl"
          else
            aws s3 cp "${WHEELFILE}" s3://core-previews/${PREVIEW_BRANCH}/ --acl public-read
            S3_URL="https://core-previews.s3-us-west-2.amazonaws.com/${PREVIEW_BRANCH}/${WHEELFILE}"
          fi
          echo -e "Wheel file download link: ${S3_URL}"

          cd ../..
          # env variables don't carry over between gh action jobs
          echo "enable-setup=${{ env.AWS_ACCESS_KEY_ID != '' }}" >> $GITHUB_OUTPUT
          echo "preview-branch=$PREVIEW_BRANCH" >> $GITHUB_OUTPUT
          echo "s3-url=${S3_URL}" >> $GITHUB_OUTPUT
      - if: steps.exports.outputs.enable-setup == 'true' && success() && github.repository == 'streamlit/streamlit' && github.event_name == 'pull_request' && github.event.sender.type == 'User'
        name: Set S3 URL as Github Status
        uses: actions/github-script@v7
        env:
          S3_URL: ${{ steps.exports.outputs.s3-url }}
        with:
          script: |
            const { sha } = context.payload.pull_request.head
            // For API documentation, see:
            // https://docs.github.com/en/rest/commits/statuses?apiVersion=2022-11-28#create-a-commit-status
            await github.request(`POST /repos/streamlit/streamlit/statuses/{sha}`, {
              owner: 'streamlit',
              repo: 'streamlit',
              sha,
              state: 'success',
              target_url: process.env.S3_URL,
              context: 'Wheel ready!'
            })

  setup-preview:
    runs-on: ubuntu-latest

    needs: upload-whl
    if: needs.upload-whl.outputs.enable-setup == 'true'

    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout Core Previews Repo
        uses: actions/checkout@v4
        with:
          repository: streamlit/core-previews
          # The default GITHUB_TOKEN is scoped only to the triggering streamlit/streamlit repo.
          # Accessing streamlit/core-previews repo requires a separate auth token.
          token: ${{ secrets.CORE_PREVIEWS_REPO_TOKEN }}
          # Save the access token to the local git config, so
          # later git commands can work.
          persist-credentials: true
      - name: Setup preview repo
        env:
          PREVIEW_BRANCH: ${{ needs.upload-whl.outputs.preview-branch }}
          S3_URL: ${{ needs.upload-whl.outputs.s3-url }}
        run: |
          git config --global user.email "core+streamlitbot-github@streamlit.io"
          git config --global user.name "Streamlit Bot"
          git branch -D "$PREVIEW_BRANCH" &>/dev/null || true
          git checkout -b "$PREVIEW_BRANCH"

          echo "$S3_URL" >> requirements.txt

          git add .
          git commit -m "Prepare core preview: ${PREVIEW_BRANCH}"
          git push -f origin ${PREVIEW_BRANCH}
      - name: Ready to deploy!
        env:
          PREVIEW_BRANCH: ${{ needs.upload-whl.outputs.preview-branch }}
        run: |
          echo -e "https://share.streamlit.io/deploy?repository=streamlit/core-previews&branch=${PREVIEW_BRANCH}&mainModule=E2E_Tester_🧪.py"


================================================
File: /.github/workflows/python-bare-executions.yml
================================================
name: Python Bare Execution Tests

on:
  push:
    branches:
      - "develop"
  pull_request:
    types: [opened, synchronize, reopened]
  # Allows workflow to be called from other workflows
  workflow_call:
    inputs:
      ref:
        required: true
        type: string

# Avoid duplicate workflows on same branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}-bare-executions
  cancel-in-progress: true

jobs:
  py-bare-executions:
    runs-on: ubuntu-latest

    defaults:
      run:
        shell: bash

    steps:
      - name: Checkout Streamlit code
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref }}
          persist-credentials: false
          submodules: "recursive"
          fetch-depth: 2
      - name: Set Python version vars
        uses: ./.github/actions/build_info
      - name: Set up Python ${{ env.PYTHON_MAX_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: "${{ env.PYTHON_MAX_VERSION }}"
      - name: Setup virtual env
        uses: ./.github/actions/make_init
      - name: Run Bare Execution Tests
        run: make bare-execution-tests


================================================
File: /.github/workflows/python-min-deps.yml
================================================
name: Python Minimum Dependency Versions

on:
  push:
    branches:
      - "develop"
  pull_request:
    types: [opened, synchronize, reopened]
  # Allows workflow to be called from other workflows
  workflow_call:
    inputs:
      ref:
        required: true
        type: string

# Avoid duplicate workflows on same branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}-python-min
  cancel-in-progress: true

defaults:
  run:
    shell: bash

env:
  FORCE_COLOR: "1"

jobs:
  py-min-deps-test:
    # The min pillow version we support in Streamlit cannot be installed on
    # Ubuntu 24 -> thats why we use Ubuntu 22.04 here instead.
    runs-on: ubuntu-22.04

    strategy:
      fail-fast: false

    env:
      PYTHON_VERSION: "${{needs.build_info.outputs.PYTHON_MIN_VERSION}}"

    steps:
      - name: Checkout Streamlit code
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref }}
          persist-credentials: false
          submodules: "recursive"
          fetch-depth: 2
      - name: Set Python version vars
        uses: ./.github/actions/build_info
      - name: Set up Python ${{ env.PYTHON_MIN_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: "${{ env.PYTHON_MIN_VERSION }}"
      - name: Setup virtual env
        uses: ./.github/actions/make_init
        with:
          use_cached_venv: false
      - name: Install min dependencies (force reinstall)
        run: uv pip install -r lib/min-constraints-gen.txt --force-reinstall
      - name: Generate Protobufs
        run: make protobuf
      - name: Make local modules visible
        run: uv pip install --editable ./lib --no-deps
      - name: Run Python Tests
        run: make pytest
      - name: CLI Smoke Tests
        run: make cli-smoke-tests
      - name: Validate min-constraints-gen
        run: |
          make gen-min-dep-constraints

          git_status=$(git status --porcelain -- lib/min-constraints-gen.txt)
          if [[ -n $git_status ]]; then
            echo "::error::The min constraints file is out of date! Please run \`make gen-min-dep-constraints\` and commit the result."
            echo "::group::git diff lib/min-constraints-gen.txt"
            git diff lib/min-constraints-gen.txt
            echo "::endgroup::"
            exit 1
          else
            echo "min constraints file is up to date."
          fi


================================================
File: /.github/workflows/python-tests.yml
================================================
name: Python Unit Tests

on:
  push:
    branches:
      - "develop"
  pull_request:
    types: [opened, synchronize, reopened]
  # Allows workflow to be called from other workflows
  workflow_call:
    inputs:
      ref:
        required: true
        type: string
      force-canary:
        description: |
          Forces the current build to be canary.
          Canary builds test all Python versions and do not use constraints.
        default: false
        type: boolean
      constraints-branch:
        description: "The name of the branch from which the constraints files will be downloaded or compared with."
        default: "constraints-develop"
        type: string
    secrets:
      SNOWFLAKE_ACCOUNT:
        description: "Snowflake account passed from caller workflows for snowflake integration tests"
        required: true
      SNOWFLAKE_PASSWORD:
        description: "Snowflake account password passed from caller workflows for snowflake integration tests"
        required: true

# Avoid duplicate workflows on same branch
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}-python
  cancel-in-progress: true

defaults:
  run:
    shell: bash

env:
  FORCE_COLOR: "1"

jobs:
  build_info:
    runs-on: ubuntu-latest

    name: "Build info"

    steps:
      - name: Checkout Streamlit code
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref }}
          persist-credentials: false
          submodules: "recursive"
          fetch-depth: 2
      - name: Set Python version vars
        id: build_info
        uses: ./.github/actions/build_info
        with:
          force-canary: ${{ inputs.force-canary || false }}

    outputs:
      PYTHON_VERSIONS: ${{ steps.build_info.outputs.PYTHON_VERSIONS }}
      PYTHON_MIN_VERSION: ${{ steps.build_info.outputs.PYTHON_MIN_VERSION }}
      PYTHON_MAX_VERSION: ${{ steps.build_info.outputs.PYTHON_MAX_VERSION }}
      USE_CONSTRAINTS_FILE: ${{ steps.build_info.outputs.USE_CONSTRAINTS_FILE }}

  py-unit-tests:
    needs:
      - build_info

    runs-on: ubuntu-latest

    strategy:
      fail-fast: false
      matrix:
        python_version: "${{ fromJson(needs.build_info.outputs.PYTHON_VERSIONS) }}"

    env:
      PYTHON_VERSION: >-
        ${{
          (
            matrix.python_version == 'min' && needs.build_info.outputs.PYTHON_MIN_VERSION ||
            (matrix.python_version == 'max' && needs.build_info.outputs.PYTHON_MAX_VERSION || matrix.python_version)
          )
        }}
      USE_CONSTRAINTS_FILE: "${{ fromJson(needs.build_info.outputs.USE_CONSTRAINTS_FILE )}}"
      CONSTRAINTS_BRANCH: ${{ inputs.constraints-branch || 'constraints-develop' }}

    steps:
      - name: Checkout Streamlit code
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref }}
          persist-credentials: false
          submodules: "recursive"

      - name: Set up Python ${{ env.PYTHON_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      - name: Setup virtual env
        uses: ./.github/actions/make_init
      - name: Run make develop
        run: make develop
      - name: Run Linters
        run: make pylint
        env:
          RUFF_OUTPUT_FORMAT: github
      - name: Run Type Checkers
        run: make mypy
      - name: Run Python Tests
        run: make pytest
      - name: CLI Smoke Tests
        run: make cli-smoke-tests
      - name: Set CONSTRAINTS_FILE env variable
        if: ${{ always() }}
        run: |
          mkdir -p /tmp/constraints
          echo "CONSTRAINTS_FILE=/tmp/constraints/constraints-${PYTHON_VERSION}.txt" >> $GITHUB_ENV
      - name: Generate constraint file for Python ${{ env.PYTHON_VERSION }}
        if: ${{ always() }}
        run: |
          pip freeze | grep -v "\-e git" | tee "${CONSTRAINTS_FILE}"
      - name: Diff constraint file
        if: ${{ always() }}
        run: |
          CONSTRAINT_URL="https://raw.githubusercontent.com/${GITHUB_REPOSITORY}/${CONSTRAINTS_BRANCH}/constraints-${PYTHON_VERSION}.txt"
          diff -y <(echo "Old"; curl -s "${CONSTRAINT_URL}") <(echo "New"; cat "${CONSTRAINTS_FILE}") || true
      - name: Upload constraints file
        uses: actions/upload-artifact@v4
        with:
          name: constraints-${{ matrix.python_version }}
          path: ${{ env.CONSTRAINTS_FILE }}
          if-no-files-found: error
      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage_report_${{ matrix.python_version }}
          path: lib/htmlcov
          retention-days: 7

  py-updated-constraints:
    needs:
      - py-unit-tests
    permissions:
      # Additional permission needed to upload constraints
      contents: write

    runs-on: ubuntu-latest
    if: |
      github.repository == 'streamlit/streamlit' && (
      (github.event_name == 'push' && github.ref_name == 'develop') ||
      (github.event_name == 'schedule')
      )

    name: Upload constraints

    env:
      TARGET_BRANCH: constraints-${{ github.ref_name }}

    steps:
      - name: Checkout branch "${{ env.TARGET_BRANCH }}"
        uses: actions/checkout@v4
        with:
          ref: ${{ env.TARGET_BRANCH }}
          # Save the access token to the local git config, so
          # later git commands can work.
          persist-credentials: true

      - uses: actions/download-artifact@v4
        with:
          path: .
          pattern: constraints-*
          merge-multiple: true

      - name: Commit and push constraint files
        run: |
          git add .
          git config --local user.email "core+streamlitbot-github@streamlit.io"
          git config --local user.name "Automated GitHub Actions commit"
          if ! git diff --cached --color --exit-code --ignore-matching-lines="^#.*"
          then
            git commit --all --message "Updating constraints. Github run id:${GITHUB_RUN_ID}

            This update in constraints is automatically committed by the CI based on
            '${GITHUB_REF}' in the '${GITHUB_REPOSITORY}' repository with commit sha ${GITHUB_SHA}.

            The action that build those constraints can be found at https://github.com/${GITHUB_REPOSITORY}/actions/runs/${GITHUB_RUN_ID}/
            "
            git push "origin" "HEAD:${TARGET_BRANCH}";
          else
            echo "No changes"
          fi
        env:
          TARGET_BRANCH: constraints-${{ github.ref_name }}

  py-integration-tests:
    needs:
      - build_info

    runs-on: ubuntu-latest

    # Runs triggered by PRs from forks or by dependabot won't run this job, since that PR wouldn't have secrets access
    # See: https://docs.github.com/en/code-security/dependabot/working-with-dependabot/automating-dependabot-with-github-actions
    # Runs triggered by Release/RC are workflow_dispatch events ; Nightly is a schedule event
    if: |
      github.repository == 'streamlit/streamlit' && (
      (github.event_name == 'pull_request' && github.event.pull_request.head.repo.full_name == github.repository && github.actor != 'dependabot[bot]') ||
      (github.event_name == 'push') ||
      (github.event_name == 'workflow_dispatch') ||
      (github.event_name == 'schedule')
      )

    env:
      USE_CONSTRAINTS_FILE: "${{ fromJson(needs.build_info.outputs.USE_CONSTRAINTS_FILE )}}"
      CONSTRAINTS_BRANCH: ${{ inputs.constraints-branch || 'constraints-develop' }}

    steps:
      - name: Checkout Streamlit code
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.ref }}
          persist-credentials: false
          submodules: "recursive"
      - name: Set up Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
      - name: Setup virtual env
        uses: ./.github/actions/make_init
        with:
          # Deactivate usage of cached venv to avoid inferring with the Python 3.11
          # unit test job. The key generation for the cache resolves to the same key,
          # which might cause some unexpected issues with dependencies.
          use_cached_venv: false
      - name: Run make develop
        run: make develop
      - name: Install integration dependencies
        run: uv pip install -r lib/integration-requirements.txt --force-reinstall
      - name: Run Python integration tests
        run: make pytest-integration
        env:
          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage_report_integration
          path: lib/htmlcov
          retention-days: 7


================================================
File: /.github/workflows/release.yml
================================================
name: Build Release

on:
  # Manual Trigger GH CLI -> gh workflow run release.yml --ref <tag>
  workflow_dispatch:

jobs:
  run-python-tests:
    uses: ./.github/workflows/python-tests.yml
    with:
      ref: ${{ github.ref_name }}
    secrets:
      SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
      SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
    permissions:
      # Permission needed to upload constraints file
      contents: write

  run-javascript-tests:
    uses: ./.github/workflows/js-tests.yml
    with:
      ref: ${{ github.ref_name }}

  run-playwright-tests:
    uses: ./.github/workflows/playwright.yml
    with:
      ref: ${{ github.ref_name }}

  build-release:
    runs-on: ubuntu-latest

    needs:
      - run-python-tests
      - run-javascript-tests
      - run-playwright-tests

    defaults:
      run:
        shell: bash

    permissions:
      # Additional permission needed to generate release
      contents: write
      id-token: write

    env:
      # Name of the tag
      GIT_TAG: ${{ github.ref_name }}
      # The owner and repository name
      GH_REPO: ${{ github.repository }}
      # A branch with constraints files on the basis of which
      # the tag will be created.
      CONSTRAINTS_BRANCH: constraints-release
      # The name of the tag that contains the constraints files
      # for the current release
      CONSTRAINTS_TAG: constraints/${{ github.ref_name }}
      # We don't want to use constraints files because they might not exist yet.
      USE_CONSTRAINTS_FILE: "false"

    environment: release

    steps:
      - name: Checkout Streamlit code
        uses: actions/checkout@v4
        with:
          ref: ${{ github.ref_name }}
          # Save the access token to the local git config, so
          # later git commands can work.
          persist-credentials: true
          submodules: "recursive"
          fetch-depth: 2
      - name: Set Python version vars
        uses: ./.github/actions/build_info
      - name: Set up Python ${{ env.PYTHON_MAX_VERSION }}
        uses: actions/setup-python@v5
        with:
          python-version: "${{ env.PYTHON_MAX_VERSION }}"
      - name: Look up the related GitHub PR branch name
        # Need GH Token to use gh api
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          pip install requests
          echo "GH_PR_BRANCH=$(python scripts/get_release_branch.py)" >> $GITHUB_ENV
      - name: Ensure release branch corresponding to this tag exists
        env:
          GH_PR_BRANCH: ${{ env.GH_PR_BRANCH }}
        run: |
          BRANCH_VERSION=$(echo "$GH_PR_BRANCH" | sed 's/release\///' )
          if [ "$BRANCH_VERSION" != "$GIT_TAG" ]
          then
            echo "ERROR: release branch corresponding to this tag does not exist."
            exit 1
          fi
      - name: Setup virtual env
        uses: ./.github/actions/make_init
      - name: Set release version from tag name
        env:
          GIT_TAG: ${{ env.GIT_TAG }}
        run: echo "STREAMLIT_RELEASE_VERSION=$GIT_TAG" >> $GITHUB_ENV
      - name: Create Package
        timeout-minutes: 120
        run: |
          sudo apt install rsync
          make package
      - name: Store Package
        uses: actions/upload-artifact@v4
        with:
          name: Release
          path: lib/dist
      - name: Upload to PyPI
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          packages-dir: lib/dist/
      - name: Create GitHub Release
        env:
          GIT_TAG: ${{ env.GIT_TAG }}
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          python scripts/create_release.py

      - name: Checkout branch "${{ env.CONSTRAINTS_BRANCH }}"
        uses: actions/checkout@v4
        with:
          ref: ${{ env.CONSTRAINTS_BRANCH }}
          # Save the access token to the local git config, so
          # later git commands can work.
          persist-credentials: true
          path: constraints
      - uses: actions/download-artifact@v4
        with:
          path: constraints
          pattern: constraints-*
          merge-multiple: true
      - name: Commit and push constraint files as tag
        run: |
          cd constraints;
          git add .
          git config --local user.email "core+streamlitbot-github@streamlit.io"
          git config --local user.name "Streamlit Bot"
          if ! git diff --cached --color --exit-code --ignore-matching-lines="^#.*"
          then
            git commit --all --message "Updating constraints. Github run id:${GITHUB_RUN_ID}

            This update in constraints is automatically committed by the CI based on
            '${GITHUB_REF}' in the '${GITHUB_REPOSITORY}' repository with commit sha ${GITHUB_SHA}.

            The action that build those constraints can be found at https://github.com/${GITHUB_REPOSITORY}/actions/runs/${GITHUB_RUN_ID}/
            "
          else
            echo "No changes"
          fi
          git tag "${CONSTRAINTS_TAG}"
          git push origin "${CONSTRAINTS_TAG}";
          git push origin "${CONSTRAINTS_BRANCH}";

      - name: Successful Release Slack Message
        if: ${{ success() }}
        env:
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
          RUN_ID: ${{ github.run_id }}
        run: python scripts/slack_notifications.py release success
      - name: Failed Release Slack Message
        if: ${{ failure() }}
        env:
          SLACK_WEBHOOK: ${{ secrets.SLACK_WEBHOOK }}
          RUN_ID: ${{ github.run_id }}
        run: python scripts/slack_notifications.py release failure


================================================
File: /.github/workflows/require-labels.yml
================================================
name: Pull Request Labels

on:
  pull_request:
    types: [opened, labeled, unlabeled, synchronize]

jobs:
  security-assessment:
    runs-on: ubuntu-latest

    permissions:
      pull-requests: read

    steps:
      # v2=7b0461786d3bd0c6a8487e9b57814ba3e2c00227
      - uses: mheap/github-action-required-labels@388fd6af37b34cdfe5a23b37060e763217e58b03
        with:
          mode: exactly
          count: 1
          labels: "security-assessment-completed"
  do-not-merge-guardrail:
    runs-on: ubuntu-latest

    permissions:
      pull-requests: read

    steps:
      # v2=7b0461786d3bd0c6a8487e9b57814ba3e2c00227
      - uses: mheap/github-action-required-labels@388fd6af37b34cdfe5a23b37060e763217e58b03
        with:
          mode: exactly
          count: 0
          labels: "do-not-merge"
  change-description:
    runs-on: ubuntu-latest

    permissions:
      pull-requests: read

    steps:
      # v2=7b0461786d3bd0c6a8487e9b57814ba3e2c00227
      - uses: mheap/github-action-required-labels@388fd6af37b34cdfe5a23b37060e763217e58b03
        with:
          mode: exactly
          count: 1
          labels: "change:feature,change:bugfix,change:refactor,change:chore,change:docs,change:other"
  impact-defined:
    runs-on: ubuntu-latest

    permissions:
      pull-requests: read

    steps:
      # v2=7b0461786d3bd0c6a8487e9b57814ba3e2c00227
      - uses: mheap/github-action-required-labels@388fd6af37b34cdfe5a23b37060e763217e58b03
        with:
          mode: exactly
          count: 1
          labels: "impact:users,impact:internal"


================================================
File: /.github/workflows/semgrep.yml
================================================
---
name: Run Semgrep Checks

on:
  pull_request:
    branches: [develop]

permissions:
  contents: read

jobs:
  run-semgrep-reusable-workflow:
    uses: snowflakedb/reusable-workflows/.github/workflows/semgrep-v2.yml@main
    secrets:
      token: ${{ secrets.SEMGREP_APP_TOKEN }}


