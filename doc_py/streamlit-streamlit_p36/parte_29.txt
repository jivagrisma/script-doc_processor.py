    def test_only_path_pathlib(self):
        """Succeed when a path is provided via Path."""

        def isdir(path):
            return path == PATH or path == os.path.abspath(PATH)

        with mock.patch(
            "streamlit.components.v1.component_registry.os.path.isdir",
            side_effect=isdir,
        ):
            component = components.declare_component("test", path=Path(PATH))

        self.assertEqual(PATH, component.path)
        self.assertIsNone(component.url)

        self.assertEqual(
            ComponentRegistry.instance().get_component_path(component.name),
            component.abspath,
        )

    def test_only_url(self):
        """Succeed when a URL is provided."""
        component = components.declare_component("test", url=URL)
        self.assertEqual(URL, component.url)
        self.assertIsNone(component.path)

        self.assertEqual(
            ComponentRegistry.instance().get_component_path("components_test"),
            component.abspath,
        )

    def test_path_and_url(self):
        """Fail if path AND url are provided."""
        with pytest.raises(StreamlitAPIException) as exception_message:
            components.declare_component("test", path=PATH, url=URL)
        self.assertEqual(
            "Either 'path' or 'url' must be set, but not both.",
            str(exception_message.value),
        )

    def test_no_path_and_no_url(self):
        """Fail if neither path nor url is provided."""
        with pytest.raises(StreamlitAPIException) as exception_message:
            components.declare_component("test", path=None, url=None)
        self.assertEqual(
            "Either 'path' or 'url' must be set, but not both.",
            str(exception_message.value),
        )

    def test_module_name_not_none(self):
        caller_frame = inspect.currentframe()
        self.assertIsNotNone(caller_frame)
        module_name = _get_module_name(caller_frame=caller_frame)

        component = components.declare_component("test", url=URL)
        self.assertEqual(
            ComponentRegistry.instance().get_module_name(component.name),
            module_name,
        )

    def test_get_registered_components(self):
        component1 = components.declare_component("test1", url=URL)
        component2 = components.declare_component("test2", url=URL)
        component3 = components.declare_component("test3", url=URL)
        expected_registered_component_names = {
            component1.name,
            component2.name,
            component3.name,
        }

        registered_components = ComponentRegistry.instance().get_components()
        self.assertEqual(
            len(registered_components),
            3,
        )
        registered_component_names = {
            component.name for component in registered_components
        }
        self.assertSetEqual(
            registered_component_names, expected_registered_component_names
        )

    def test_when_registry_not_explicitly_initialized_return_defaultregistry(self):
        ComponentRegistry._instance = None
        components.declare_component("test", url=URL)
        self.assertIsInstance(ComponentRegistry.instance(), LocalComponentRegistry)


class ComponentRegistryTest(unittest.TestCase):
    """Test component registration."""

    def setUp(self) -> None:
        config = RuntimeConfig(
            script_path="mock/script/path.py",
            command_line=None,
            component_registry=LocalComponentRegistry(),
            media_file_storage=MemoryMediaFileStorage("/mock/media"),
            uploaded_file_manager=MemoryUploadedFileManager("/mock/upload"),
        )
        self.runtime = Runtime(config)

    def tearDown(self) -> None:
        Runtime._instance = None

    def test_register_component_with_path(self):
        """Registering a component should associate it with its path."""
        test_path = "/a/test/component/directory"

        def isdir(path):
            return path == test_path

        registry = ComponentRegistry.instance()
        with mock.patch(
            "streamlit.components.types.base_custom_component.os.path.isdir",
            side_effect=isdir,
        ):
            registry.register_component(
                CustomComponent("test_component", path=test_path)
            )

        self.assertEqual(test_path, registry.get_component_path("test_component"))

    def test_register_component_no_path(self):
        """It's not an error to register a component without a path."""
        registry = ComponentRegistry.instance()

        # Return None when the component hasn't been registered
        self.assertIsNone(registry.get_component_path("test_component"))

        # And also return None when the component doesn't have a path
        registry.register_component(
            CustomComponent("test_component", url="http://not.a.url")
        )
        self.assertIsNone(registry.get_component_path("test_component"))

    def test_register_invalid_path(self):
        """We raise an exception if a component is registered with a
        non-existent path.
        """
        test_path = "/a/test/component/directory"

        registry = ComponentRegistry.instance()
        with self.assertRaises(StreamlitAPIException) as ctx:
            registry.register_component(CustomComponent("test_component", test_path))
        self.assertIn("No such component directory", str(ctx.exception))

    def test_register_duplicate_path(self):
        """It's not an error to re-register a component.
        (This can happen during development).
        """
        test_path_1 = "/a/test/component/directory"
        test_path_2 = "/another/test/component/directory"

        def isdir(path):
            return path in (test_path_1, test_path_2)

        registry = ComponentRegistry.instance()
        with mock.patch(
            "streamlit.components.types.base_custom_component.os.path.isdir",
            side_effect=isdir,
        ):
            registry.register_component(CustomComponent("test_component", test_path_1))
            registry.register_component(CustomComponent("test_component", test_path_1))
            self.assertEqual(test_path_1, registry.get_component_path("test_component"))

            registry.register_component(CustomComponent("test_component", test_path_2))
            self.assertEqual(test_path_2, registry.get_component_path("test_component"))


class InvokeComponentTest(DeltaGeneratorTestCase):
    """Test invocation of a custom component object."""

    def setUp(self):
        super().setUp()
        self.test_component = components.declare_component("test", url=URL)

    def test_only_json_args(self):
        """Test that component with only json args is marshalled correctly."""
        self.test_component(foo="bar")
        proto = self.get_delta_from_queue().new_element.component_instance

        self.assertEqual(self.test_component.name, proto.component_name)
        self.assertJSONEqual(
            {"foo": "bar", "key": None, "default": None}, proto.json_args
        )
        self.assertEqual("[]", str(proto.special_args))

    def test_only_df_args(self):
        """Test that component with only dataframe args is marshalled correctly."""
        raw_data = {
            "First Name": ["Jason", "Molly"],
            "Last Name": ["Miller", "Jacobson"],
            "Age": [42, 52],
        }
        df = pd.DataFrame(raw_data, columns=["First Name", "Last Name", "Age"])
        self.test_component(df=df)
        proto = self.get_delta_from_queue().new_element.component_instance

        self.assertEqual(self.test_component.name, proto.component_name)
        self.assertJSONEqual({"key": None, "default": None}, proto.json_args)
        self.assertEqual(1, len(proto.special_args))
        self.assertEqual(_serialize_dataframe_arg("df", df), proto.special_args[0])

    def test_only_list_args(self):
        """Test that component with only list args is marshalled correctly."""
        self.test_component(data=["foo", "bar", "baz"])
        proto = self.get_delta_from_queue().new_element.component_instance
        self.assertJSONEqual(
            {"data": ["foo", "bar", "baz"], "key": None, "default": None},
            proto.json_args,
        )
        self.assertEqual("[]", str(proto.special_args))

    def test_no_args(self):
        """Test that component with no args is marshalled correctly."""
        self.test_component()
        proto = self.get_delta_from_queue().new_element.component_instance

        self.assertEqual(self.test_component.name, proto.component_name)
        self.assertJSONEqual({"key": None, "default": None}, proto.json_args)
        self.assertEqual("[]", str(proto.special_args))

    def test_bytes_args(self):
        self.test_component(foo=b"foo", bar=b"bar")
        proto = self.get_delta_from_queue().new_element.component_instance
        self.assertJSONEqual({"key": None, "default": None}, proto.json_args)
        self.assertEqual(2, len(proto.special_args))
        self.assertEqual(
            _serialize_bytes_arg("foo", b"foo"),
            proto.special_args[0],
        )
        self.assertEqual(
            _serialize_bytes_arg("bar", b"bar"),
            proto.special_args[1],
        )

    def test_mixed_args(self):
        """Test marshalling of a component with varied arg types."""
        df = pd.DataFrame(
            {
                "First Name": ["Jason", "Molly"],
                "Last Name": ["Miller", "Jacobson"],
                "Age": [42, 52],
            },
            columns=["First Name", "Last Name", "Age"],
        )
        self.test_component(string_arg="string", df_arg=df, bytes_arg=b"bytes")
        proto = self.get_delta_from_queue().new_element.component_instance

        self.assertEqual(self.test_component.name, proto.component_name)
        self.assertJSONEqual(
            {"string_arg": "string", "key": None, "default": None},
            proto.json_args,
        )
        self.assertEqual(2, len(proto.special_args))
        self.assertEqual(_serialize_dataframe_arg("df_arg", df), proto.special_args[0])
        self.assertEqual(
            _serialize_bytes_arg("bytes_arg", b"bytes"), proto.special_args[1]
        )

    def test_duplicate_key(self):
        """Two components with the same `key` should throw DuplicateWidgetID exception"""
        self.test_component(foo="bar", key="baz")

        with self.assertRaises(DuplicateWidgetID):
            self.test_component(key="baz")

    def test_key_sent_to_frontend(self):
        """We send the 'key' param to the frontend (even if it's None)."""
        # Test a string key
        self.test_component(key="baz")
        proto = self.get_delta_from_queue().new_element.component_instance
        self.assertJSONEqual({"key": "baz", "default": None}, proto.json_args)

        # Test an empty key
        self.test_component()
        proto = self.get_delta_from_queue().new_element.component_instance
        self.assertJSONEqual({"key": None, "default": None}, proto.json_args)

    def test_widget_id_with_key(self):
        """UNLIKE OTHER WIDGET TYPES, a component with a user-supplied `key` will have a stable widget ID
        even when the component's other parameters change.

        This is important because a component's iframe gets unmounted and remounted - wiping all its
        internal state - when the component's ID changes. We want to be able to pass new data to a
        component's frontend without causing a remount.
        """

        # Create a component instance with a key and some custom data
        self.test_component(key="key", some_data=345)
        proto1 = self.get_delta_from_queue().new_element.component_instance
        self.assertJSONEqual(
            {"key": "key", "default": None, "some_data": 345}, proto1.json_args
        )

        # Clear some ScriptRunCtx data so that we can re-register the same component
        # without getting a DuplicateWidgetID error
        self.script_run_ctx.widget_user_keys_this_run.clear()
        self.script_run_ctx.widget_ids_this_run.clear()

        # Create a second component instance with the same key, and different custom data
        self.test_component(key="key", some_data=678, more_data="foo")
        proto2 = self.get_delta_from_queue().new_element.component_instance
        self.assertJSONEqual(
            {"key": "key", "default": None, "some_data": 678, "more_data": "foo"},
            proto2.json_args,
        )

        # The two component instances should have the same ID, *despite having different
        # data passed to them.*
        self.assertEqual(proto1.id, proto2.id)

    def test_widget_id_without_key(self):
        """Like all other widget types, two component instances with different data parameters,
        and without a specified `key`, will have different widget IDs.
        """

        # Create a component instance without a key and some custom data
        self.test_component(some_data=345)
        proto1 = self.get_delta_from_queue().new_element.component_instance
        self.assertJSONEqual(
            {"key": None, "default": None, "some_data": 345}, proto1.json_args
        )

        # Create a second component instance with different custom data
        self.test_component(some_data=678)
        proto2 = self.get_delta_from_queue().new_element.component_instance
        self.assertJSONEqual(
            {"key": None, "default": None, "some_data": 678}, proto2.json_args
        )

        # The two component instances should have different IDs (just like any other widget would).
        self.assertNotEqual(proto1.id, proto2.id)

    def test_simple_default(self):
        """Test the 'default' param with a JSON value."""
        return_value = self.test_component(default="baz")
        self.assertEqual("baz", return_value)

        proto = self.get_delta_from_queue().new_element.component_instance
        self.assertJSONEqual({"key": None, "default": "baz"}, proto.json_args)

    def test_bytes_default(self):
        """Test the 'default' param with a bytes value."""
        return_value = self.test_component(default=b"bytes")
        self.assertEqual(b"bytes", return_value)

        proto = self.get_delta_from_queue().new_element.component_instance
        self.assertJSONEqual({"key": None}, proto.json_args)
        self.assertEqual(
            _serialize_bytes_arg("default", b"bytes"),
            proto.special_args[0],
        )

    def test_df_default(self):
        """Test the 'default' param with a DataFrame value."""
        df = pd.DataFrame(
            {
                "First Name": ["Jason", "Molly"],
                "Last Name": ["Miller", "Jacobson"],
                "Age": [42, 52],
            },
            columns=["First Name", "Last Name", "Age"],
        )
        return_value = self.test_component(default=df)
        self.assertTrue(df.equals(return_value), "df != return_value")

        proto = self.get_delta_from_queue().new_element.component_instance
        self.assertJSONEqual({"key": None}, proto.json_args)
        self.assertEqual(
            _serialize_dataframe_arg("default", df),
            proto.special_args[0],
        )

    def test_on_change_handler(self):
        """Test the 'on_change' callback param."""

        # we use a list here so that we can update it in the lambda; we cannot assign a variable there.
        callback_call_value = []
        expected_element_value = "Called with foo"

        def create_on_change_handler(some_arg: str):
            return lambda: callback_call_value.append("Called with " + some_arg)

        return_value = self.test_component(
            key="key", default="baz", on_change=create_on_change_handler("foo")
        )
        self.assertEqual("baz", return_value)

        proto = self.get_delta_from_queue().new_element.component_instance
        self.assertJSONEqual({"key": "key", "default": "baz"}, proto.json_args)
        current_widget_states = self.script_run_ctx.session_state.get_widget_states()
        new_widget_state = WidgetState()
        # copy the custom components state and update the value
        new_widget_state.CopyFrom(current_widget_states[0])
        # update the widget's value so that the rerun will execute the callback
        new_widget_state.json_value = '{"key": "key", "default": "baz2"}'
        self.script_run_ctx.session_state.on_script_will_rerun(
            WidgetStates(widgets=[new_widget_state])
        )
        self.assertEqual(callback_call_value[0], expected_element_value)

    def assertJSONEqual(self, a, b):
        """Asserts that two JSON dicts are equal. If either arg is a string,
        it will be first converted to a dict with json.loads()."""
        # Ensure both objects are dicts.
        dict_a = a if isinstance(a, dict) else json.loads(a)
        dict_b = b if isinstance(b, dict) else json.loads(b)
        self.assertEqual(dict_a, dict_b)

    def test_outside_form(self):
        """Test that form id is marshalled correctly outside of a form."""

        self.test_component()

        proto = self.get_delta_from_queue().new_element.component_instance
        self.assertEqual(proto.form_id, "")

    @patch("streamlit.runtime.Runtime.exists", MagicMock(return_value=True))
    def test_inside_form(self):
        """Test that form id is marshalled correctly inside of a form."""

        with st.form("foo"):
            self.test_component()

        # 2 elements will be created: form block, widget
        self.assertEqual(len(self.get_all_deltas_from_queue()), 2)

        form_proto = self.get_delta_from_queue(0).add_block
        component_instance_proto = self.get_delta_from_queue(
            1
        ).new_element.component_instance
        self.assertEqual(component_instance_proto.form_id, form_proto.form.form_id)


class IFrameTest(DeltaGeneratorTestCase):
    def test_iframe(self):
        """Test components.iframe"""
        components.iframe("http://not.a.url", width=200, scrolling=True)

        el = self.get_delta_from_queue().new_element
        self.assertEqual(el.iframe.src, "http://not.a.url")
        self.assertEqual(el.iframe.srcdoc, "")
        self.assertEqual(el.iframe.width, 200)
        self.assertTrue(el.iframe.has_width)
        self.assertTrue(el.iframe.scrolling)

    def test_html(self):
        """Test components.html"""
        html = r"<html><body>An HTML string!</body></html>"
        components.html(html, width=200, scrolling=True)

        el = self.get_delta_from_queue().new_element
        self.assertEqual(el.iframe.src, "")
        self.assertEqual(el.iframe.srcdoc, html)
        self.assertEqual(el.iframe.width, 200)
        self.assertTrue(el.iframe.has_width)
        self.assertTrue(el.iframe.scrolling)


class AlternativeComponentRegistryTest(unittest.TestCase):
    """Test alternative component registry initialization."""

    class AlternativeComponentRegistry(BaseComponentRegistry):
        def __init__(self):
            """Dummy implementation"""
            pass

        def register_component(self, component: BaseCustomComponent) -> None:
            return None

        def get_component_path(self, name: str) -> str | None:
            return None

        def get_module_name(self, name: str) -> str | None:
            return None

        def get_component(self, name: str) -> BaseCustomComponent | None:
            return None

        def get_components(self) -> list[BaseCustomComponent]:
            return []

    def setUp(self) -> None:
        super().setUp()
        registry = AlternativeComponentRegistryTest.AlternativeComponentRegistry()
        # ComponentRegistry.initialize(registry)
        self.assertEqual(ComponentRegistry.instance(), registry)
        self.assertIsInstance(
            registry, AlternativeComponentRegistryTest.AlternativeComponentRegistry
        )


================================================
File: /lib/tests/streamlit/config_option_test.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import annotations

import unittest

import pytest
from parameterized import parameterized

from streamlit.config_option import ConfigOption


class ConfigOptionTest(unittest.TestCase):
    @parameterized.expand(
        [
            ("missingKey",),
            (".missingSection",),
            ("has spaces",),
            ("_.key"),
            ("section.v_1_name"),
        ]
    )
    def test_invalid_key(self, key):
        with pytest.raises(AssertionError) as e:
            ConfigOption(key)
        self.assertEqual('Key "%s" has invalid format.' % key, str(e.value))

    @parameterized.expand(
        [
            ("section.name", "section", "name"),
            ("section.numbered12", "section", "numbered12"),
            ("numbered1.allowCaps", "numbered1", "allowCaps"),
            ("allowCaps.numbered2", "allowCaps", "numbered2"),
        ]
    )
    def test_valid_keys(self, key, section, name):
        c = ConfigOption(key)
        self.assertEqual(section, c.section)
        self.assertEqual(name, c.name)

    def test_constructor_default_values(self):
        key = "mysection.myName"
        c = ConfigOption(key)
        self.assertEqual("mysection", c.section)
        self.assertEqual("myName", c.name)
        self.assertEqual(None, c.description)
        self.assertEqual("visible", c.visibility)

    def test_call(self):
        key = "mysection.myName"
        c = ConfigOption(key)

        @c
        def someRandomFunction():
            """Random docstring."""
            pass

        self.assertEqual("Random docstring.", c.description)
        self.assertEqual(someRandomFunction._get_val_func, c._get_val_func)

    def test_call_assert(self):
        key = "mysection.myName"
        c = ConfigOption(key)

        with pytest.raises(AssertionError) as e:

            @c
            def someRandomFunction():
                pass

        self.assertEqual(
            "Complex config options require doc strings for their description.",
            str(e.value),
        )

    def test_value(self):
        my_value = "myValue"

        key = "mysection.myName"
        c = ConfigOption(key)

        @c
        def someRandomFunction():
            """Random docstring."""
            return my_value

        self.assertEqual(my_value, c.value)

    def test_set_value(self):
        my_value = "myValue"
        where_defined = "im defined here"

        key = "mysection.myName"
        c = ConfigOption(key)
        c.set_value(my_value, where_defined)

        self.assertEqual(my_value, c.value)
        self.assertEqual(where_defined, c.where_defined)

    def test_deprecated_expired(self):
        my_value = "myValue"
        where_defined = "im defined here"

        key = "mysection.myName"

        c = ConfigOption(
            key,
            deprecated=True,
            deprecation_text="dep text",
            expiration_date="2000-01-01",
        )

        # Expired options behave like deprecated options
        # just a slightly different text.
        c.set_value(my_value, where_defined)

        self.assertTrue(c.is_expired())

    def test_deprecated_unexpired(self):
        my_value = "myValue"
        where_defined = "im defined here"

        key = "mysection.myName"

        c = ConfigOption(
            key,
            deprecated=True,
            deprecation_text="dep text",
            expiration_date="2100-01-01",
        )

        c.set_value(my_value, where_defined)

        self.assertFalse(c.is_expired())

    def test_replaced_by_unexpired(self):
        c = ConfigOption(
            "mysection.oldName",
            description="My old description",
            replaced_by="mysection.newName",
            expiration_date="2100-01-01",
        )

        self.assertTrue(c.deprecated)
        self.assertFalse(c.is_expired())

    def test_replaced_by_expired(self):
        c = ConfigOption(
            "mysection.oldName",
            description="My old description",
            replaced_by="mysection.newName",
            expiration_date="2000-01-01",
        )

        self.assertTrue(c.deprecated)
        self.assertTrue(c.is_expired())


================================================
File: /lib/tests/streamlit/config_test.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Config System Unittest."""

from __future__ import annotations

import copy
import os
import sys
import textwrap
import unittest
from unittest.mock import MagicMock, mock_open, patch

import pytest
from parameterized import parameterized

from streamlit import config, env_util
from streamlit.config import ShowErrorDetailsConfigOptions
from streamlit.config_option import ConfigOption
from streamlit.errors import StreamlitAPIException

SECTION_DESCRIPTIONS = copy.deepcopy(config._section_descriptions)
CONFIG_OPTIONS = copy.deepcopy(config._config_options)


class ConfigTest(unittest.TestCase):
    """Test the config system."""

    def setUp(self):
        self.patches = [
            patch.object(
                config, "_section_descriptions", new=copy.deepcopy(SECTION_DESCRIPTIONS)
            ),
            patch.object(config, "_config_options", new=copy.deepcopy(CONFIG_OPTIONS)),
            patch.dict(os.environ),
        ]

        for p in self.patches:
            p.start()

    def tearDown(self):
        for p in self.patches:
            p.stop()

        config._delete_option("_test.tomlTest")

    def test_set_user_option_scriptable(self):
        """Test that scriptable options can be set from API."""
        # This is set in lib/tests/conftest.py to off
        self.assertEqual(
            ShowErrorDetailsConfigOptions.FULL,
            config.get_option("client.showErrorDetails"),
        )

        try:
            # client.showErrorDetails can be set after run starts.
            config.set_user_option(
                "client.showErrorDetails", ShowErrorDetailsConfigOptions.STACKTRACE
            )
            self.assertEqual(
                ShowErrorDetailsConfigOptions.STACKTRACE,
                config.get_option("client.showErrorDetails"),
            )
        finally:
            # Restore original value
            config.set_user_option(
                "client.showErrorDetails", ShowErrorDetailsConfigOptions.FULL
            )

    def test_set_user_option_unscriptable(self):
        """Test that unscriptable options cannot be set with st.set_option."""
        # This is set in lib/tests/conftest.py to off
        self.assertEqual(True, config.get_option("server.enableCORS"))

        with self.assertRaises(StreamlitAPIException):
            config.set_user_option("server.enableCORS", False)

    def test_simple_config_option(self):
        """Test creating a simple (constant) config option."""
        # Create the config option.
        config_option = ConfigOption(
            "_test.simpleParam", description="Simple config option.", default_val=12345
        )

        # Test that it works.
        assert config_option.key == "_test.simpleParam"
        assert config_option.section == "_test"
        assert config_option.name == "simpleParam"
        assert config_option.description == "Simple config option."
        assert config_option.where_defined == ConfigOption.DEFAULT_DEFINITION
        assert config_option.value == 12345
        assert config_option.env_var == "STREAMLIT__TEST_SIMPLE_PARAM"
        assert not config_option.multiple

    def test_multiple_config_option(self):
        """Test creating a multiple value config option."""
        config_option = ConfigOption(
            "_test.simpleParam",
            description="Simple config option.",
            default_val=[12345],
        )

        assert config_option.key == "_test.simpleParam"
        assert config_option.section == "_test"
        assert config_option.name == "simpleParam"
        assert config_option.description == "Simple config option."
        assert config_option.where_defined == ConfigOption.DEFAULT_DEFINITION
        assert config_option.value == [12345]
        assert config_option.env_var == "STREAMLIT__TEST_SIMPLE_PARAM"
        assert config_option.multiple

    def test_complex_config_option(self):
        """Test setting a complex (functional) config option."""

        # Create the config option.
        @ConfigOption("_test.complexParam")
        def config_option():
            """Complex config option."""
            return 12345

        # Test that it works.
        self.assertEqual(config_option.key, "_test.complexParam")
        self.assertEqual(config_option.section, "_test")
        self.assertEqual(config_option.name, "complexParam")
        self.assertEqual(config_option.description, "Complex config option.")
        self.assertEqual(config_option.where_defined, ConfigOption.DEFAULT_DEFINITION)
        self.assertEqual(config_option.value, 12345)
        self.assertEqual(config_option.env_var, "STREAMLIT__TEST_COMPLEX_PARAM")

    def test_complex_config_option_must_have_doc_strings(self):
        """Test that complex config options use funcs with doc stringsself.

        This is because the doc string forms the option's description.
        """
        with self.assertRaises(AssertionError):

            @ConfigOption("_test.noDocString")
            def no_doc_string():
                pass

    def test_invalid_config_name(self):
        """Test setting an invalid config section."""
        with self.assertRaises(AssertionError):
            ConfigOption("_test.myParam.")

    def test_invalid_config_section(self):
        """Test setting an invalid config section."""
        with self.assertRaises(AssertionError):
            config._create_option("mySection.myParam")

    def test_cannot_overwrite_config_section(self):
        """Test overwriting a config section using _create_section."""
        with self.assertRaises(AssertionError):
            config._create_section("_test2", "A test section.")
            config._create_section("_test2", "A test section.")

    def test_cannot_overwrite_config_key(self):
        """Test overwriting a config option using _create_option."""
        with self.assertRaises(AssertionError):
            config._create_option("_test.overwriteKey")
            config._create_option("_test.overwriteKey")

    def test_param_names_are_camel_case(self):
        """Test that param names must be camelCase.

        Note the exception is the "_test" section which is used
        for unit testing.
        """
        with self.assertRaises(AssertionError):
            config._create_option("_test.snake_case")

    def test_get_set_and_complex_config_options(self):
        """Verify that changing one option changes another, dependent one.

        This also implicitly tests simple and complex ConfigOptions as well as
        get_option() and set_option().
        """
        # Some useful variables.
        DUMMY_VAL_1, DUMMY_VAL_2, DUMMY_VAL_3 = "Steven", "Vincent", "Buscemi"

        # Set up both options.
        config._create_option(
            "_test.independentOption",
            description="This option can change at will",
            default_val=DUMMY_VAL_1,
        )

        @config._create_option("_test.dependentOption")
        def _test_dependent_option():
            """Depend on the value of _test.independentOption."""
            return config.get_option("_test.independentOption")

        config.get_config_options(force_reparse=True)

        # Check that the default values are good.
        self.assertEqual(config.get_option("_test.independentOption"), DUMMY_VAL_1)
        self.assertEqual(config.get_option("_test.dependentOption"), DUMMY_VAL_1)
        self.assertEqual(
            config.get_where_defined("_test.independentOption"),
            ConfigOption.DEFAULT_DEFINITION,
        )
        self.assertEqual(
            config.get_where_defined("_test.dependentOption"),
            ConfigOption.DEFAULT_DEFINITION,
        )

        # Override the independent option. Both update!
        config.set_option("_test.independentOption", DUMMY_VAL_2)
        self.assertEqual(config.get_option("_test.independentOption"), DUMMY_VAL_2)
        self.assertEqual(config.get_option("_test.dependentOption"), DUMMY_VAL_2)
        self.assertEqual(
            config.get_where_defined("_test.independentOption"), config._USER_DEFINED
        )
        self.assertEqual(
            config.get_where_defined("_test.dependentOption"),
            ConfigOption.DEFAULT_DEFINITION,
        )

        # Override the dependent option. Only that updates!
        config.set_option("_test.dependentOption", DUMMY_VAL_3)
        self.assertEqual(config.get_option("_test.independentOption"), DUMMY_VAL_2)
        self.assertEqual(config.get_option("_test.dependentOption"), DUMMY_VAL_3)
        self.assertEqual(
            config.get_where_defined("_test.independentOption"), config._USER_DEFINED
        )
        self.assertEqual(
            config.get_where_defined("_test.dependentOption"), config._USER_DEFINED
        )

    def test_parsing_toml(self):
        """Test config._update_config_with_toml()."""
        # Some useful variables.
        DUMMY_VAL_1, DUMMY_VAL_2 = "Christopher", "Walken"
        DUMMY_DEFINITION = "<test definition>"

        # Create a dummy default option.
        config._create_option(
            "_test.tomlTest",
            description="This option tests the TOML parser.",
            default_val=DUMMY_VAL_1,
        )
        config.get_config_options(force_reparse=True)
        self.assertEqual(config.get_option("_test.tomlTest"), DUMMY_VAL_1)
        self.assertEqual(
            config.get_where_defined("_test.tomlTest"), ConfigOption.DEFAULT_DEFINITION
        )

        # Override it with some TOML
        NEW_TOML = (
            """
            [_test]
            tomlTest="%s"
        """
            % DUMMY_VAL_2
        )
        config._update_config_with_toml(NEW_TOML, DUMMY_DEFINITION)
        self.assertEqual(config.get_option("_test.tomlTest"), DUMMY_VAL_2)
        self.assertEqual(config.get_where_defined("_test.tomlTest"), DUMMY_DEFINITION)

    def test_parsing_env_vars_in_toml(self):
        """Test that environment variables get parsed in the TOML file."""
        # Some useful variables.
        DEFAULT_VAL, DESIRED_VAL = "Christopher", "Walken"
        DUMMY_DEFINITION = "<test definition>"

        # Create a dummy default option.
        config._create_option(
            "_test.tomlTest",
            description="This option tests the TOML parser.",
            default_val=DEFAULT_VAL,
        )
        config.get_config_options(force_reparse=True)
        self.assertEqual(config.get_option("_test.tomlTest"), DEFAULT_VAL)
        self.assertEqual(
            config.get_where_defined("_test.tomlTest"), ConfigOption.DEFAULT_DEFINITION
        )

        os.environ["TEST_ENV_VAR"] = DESIRED_VAL

        # Override it with some TOML
        NEW_TOML = """
            [_test]
            tomlTest="env:TEST_ENV_VAR"
        """
        config._update_config_with_toml(NEW_TOML, DUMMY_DEFINITION)
        self.assertEqual(config.get_option("_test.tomlTest"), DESIRED_VAL)
        self.assertEqual(config.get_where_defined("_test.tomlTest"), DUMMY_DEFINITION)

    def test_parsing_sensitive_options(self):
        """Test config._update_config_with_sensitive_env_var()."""
        # Some useful variables.
        DUMMY_VAL_1, DUMMY_VAL_2 = "Adam", "Malysz"

        # Create a dummy default option.
        config._create_option(
            "_test.sensitiveTest",
            description="This sensitive option tests the config parser.",
            default_val=DUMMY_VAL_1,
            sensitive=True,
        )
        config.get_config_options(force_reparse=True)
        self.assertEqual(config.get_option("_test.sensitiveTest"), DUMMY_VAL_1)
        self.assertEqual(
            config.get_where_defined("_test.sensitiveTest"),
            ConfigOption.DEFAULT_DEFINITION,
        )
        with patch.dict(os.environ, STREAMLIT__TEST_SENSITIVE_TEST=DUMMY_VAL_2):
            config.get_config_options(force_reparse=True)
            self.assertEqual(config.get_option("_test.sensitiveTest"), DUMMY_VAL_2)
            self.assertEqual(
                config.get_where_defined("_test.sensitiveTest"),
                config._DEFINED_BY_ENV_VAR,
            )

    def test_delete_option(self):
        # Create a dummy default option.
        config._create_option(
            "_test.testDeleteOption",
            description="This option tests the _delete_option function.",
            default_val="delete me!",
        )
        config.get_config_options(force_reparse=True)
        self.assertEqual(config.get_option("_test.testDeleteOption"), "delete me!")

        config._delete_option("_test.testDeleteOption")

        with pytest.raises(RuntimeError) as e:
            config.get_option("_test.testDeleteOption")
        self.assertEqual(
            str(e.value), 'Config key "_test.testDeleteOption" not defined.'
        )

        config._delete_option("_test.testDeleteOption")

    def test_multiple_value_option(self):
        option = config._create_option(
            "_test.testMultipleValueOption",
            description="This option tests multiple values for an option",
            default_val=["Option 1", "Option 2"],
        )

        assert option.multiple
        config.get_config_options(force_reparse=True)
        assert config.get_option("_test.testMultipleValueOption") == [
            "Option 1",
            "Option 2",
        ]

    def test_sections_order(self):
        sections = sorted(
            [
                "_test",
                "browser",
                "client",
                "theme",
                "global",
                "logger",
                "magic",
                "mapbox",
                "runner",
                "secrets",
                "server",
                "ui",
            ]
        )
        keys = sorted(config._section_descriptions.keys())
        self.assertEqual(sections, keys)

    def test_config_option_keys(self):
        config_options = sorted(
            [
                "browser.gatherUsageStats",
                "browser.serverAddress",
                "browser.serverPort",
                "client.showErrorDetails",
                "client.showSidebarNavigation",
                "client.toolbarMode",
                "theme.base",
                "theme.primaryColor",
                "theme.backgroundColor",
                "theme.secondaryBackgroundColor",
                "theme.textColor",
                "theme.font",
                "global.appTest",
                "global.developmentMode",
                "global.disableWidgetStateDuplicationWarning",
                "global.e2eTest",
                "global.maxCachedMessageAge",
                "global.minCachedMessageSize",
                "global.showWarningOnDirectExecution",
                "global.storeCachedForwardMessagesInMemory",
                "global.suppressDeprecationWarnings",
                "global.unitTest",
                "logger.enableRich",
                "logger.level",
                "logger.messageFormat",
                "runner.enforceSerializableSessionState",
                "runner.magicEnabled",
                "runner.postScriptGC",
                "runner.fastReruns",
                "runner.enumCoercion",
                "magic.displayRootDocString",
                "magic.displayLastExprIfNoSemicolon",
                "mapbox.token",
                "secrets.files",
                "server.baseUrlPath",
                "server.enableCORS",
                "server.cookieSecret",
                "server.scriptHealthCheckEnabled",
                "server.enableWebsocketCompression",
                "server.enableXsrfProtection",
                "server.fileWatcherType",
                "server.folderWatchBlacklist",
                "server.headless",
                "server.address",
                "server.allowRunOnSave",
                "server.port",
                "server.runOnSave",
                "server.maxUploadSize",
                "server.maxMessageSize",
                "server.enableStaticServing",
                "server.enableArrowTruncation",
                "server.sslCertFile",
                "server.sslKeyFile",
                "server.disconnectedSessionTTL",
                "ui.hideTopBar",
            ]
        )
        keys = sorted(config._config_options.keys())
        self.assertEqual(config_options, keys)

    def test_check_conflicts_server_port(self):
        config._set_option("global.developmentMode", True, "test")
        config._set_option("server.port", 1234, "test")
        with pytest.raises(AssertionError) as e:
            config._check_conflicts()
        self.assertEqual(
            str(e.value),
            "server.port does not work when global.developmentMode is true.",
        )

    @patch("streamlit.logger.get_logger")
    def test_check_conflicts_server_csrf(self, get_logger):
        config._set_option("server.enableXsrfProtection", True, "test")
        config._set_option("server.enableCORS", True, "test")
        mock_logger = get_logger()
        config._check_conflicts()
        mock_logger.warning.assert_called_once()

    def test_check_conflicts_browser_serverport(self):
        config._set_option("global.developmentMode", True, "test")
        config._set_option("browser.serverPort", 1234, "test")
        with pytest.raises(AssertionError) as e:
            config._check_conflicts()
        self.assertEqual(
            str(e.value),
            "browser.serverPort does not work when global.developmentMode is true.",
        )

    def test_maybe_convert_to_number(self):
        self.assertEqual(1234, config._maybe_convert_to_number("1234"))
        self.assertEqual(1234.5678, config._maybe_convert_to_number("1234.5678"))
        self.assertEqual("1234.5678ex", config._maybe_convert_to_number("1234.5678ex"))

    def test_maybe_read_env_variable(self):
        self.assertEqual(
            "env:RANDOM_TEST", config._maybe_read_env_variable("env:RANDOM_TEST")
        )
        os.environ["RANDOM_TEST"] = "1234"
        self.assertEqual(1234, config._maybe_read_env_variable("env:RANDOM_TEST"))

    def test_update_config_with_toml(self):
        self.assertEqual(
            ShowErrorDetailsConfigOptions.FULL,
            config.get_option("client.showErrorDetails"),
        )
        toml = textwrap.dedent(
            """
           [client]
           showErrorDetails = "type"
        """
        )
        config._update_config_with_toml(toml, "test")
        self.assertEqual(
            ShowErrorDetailsConfigOptions.TYPE,
            config.get_option("client.showErrorDetails"),
        )

    def test_set_option(self):
        with self.assertLogs(logger="streamlit.config", level="WARNING") as cm:
            config._set_option("not.defined", "no.value", "test")
        # cm.output is a list of messages and there shouldn't be any other messages besides one created by this test
        self.assertIn(
            '"not.defined" is not a valid config option. If you previously had this config option set, it may have been removed.',
            cm.output[0],
        )

        config._set_option("browser.gatherUsageStats", "test", "test")
        self.assertEqual("test", config.get_option("browser.gatherUsageStats"))

    def test_is_manually_set(self):
        config._set_option("browser.serverAddress", "some.bucket", "test")
        self.assertEqual(True, config.is_manually_set("browser.serverAddress"))

        config._set_option("browser.serverAddress", "some.bucket", "<default>")
        self.assertEqual(False, config.is_manually_set("browser.serverAddress"))

    def test_is_unset(self):
        config._set_option("browser.serverAddress", "some.bucket", "test")
        self.assertEqual(False, config._is_unset("browser.serverAddress"))

        config._set_option("browser.serverAddress", "some.bucket", "<default>")
        self.assertEqual(True, config._is_unset("browser.serverAddress"))

    def test_get_where_defined(self):
        config._set_option("browser.serverAddress", "some.bucket", "test")
        self.assertEqual("test", config.get_where_defined("browser.serverAddress"))

        with pytest.raises(RuntimeError) as e:
            config.get_where_defined("doesnt.exist")
        self.assertEqual(str(e.value), 'Config key "doesnt.exist" not defined.')

    def test_get_option(self):
        config._set_option("browser.serverAddress", "some.bucket", "test")
        self.assertEqual("some.bucket", config.get_option("browser.serverAddress"))

        with pytest.raises(RuntimeError) as e:
            config.get_option("doesnt.exist")
        self.assertEqual(str(e.value), 'Config key "doesnt.exist" not defined.')

    def test_get_options_for_section(self):
        config._set_option("theme.primaryColor", "000000", "test")
        config._set_option("theme.font", "serif", "test")

        expected = {
            "base": None,
            "primaryColor": "000000",
            "secondaryBackgroundColor": None,
            "backgroundColor": None,
            "textColor": None,
            "font": "serif",
        }
        self.assertEqual(config.get_options_for_section("theme"), expected)

    def test_browser_server_port(self):
        # developmentMode must be False for server.port to be modified
        config.set_option("global.developmentMode", False)
        config.set_option("server.port", 1234)
        self.assertEqual(1234, config.get_option("browser.serverPort"))

    def test_server_headless_via_atom_plugin(self):
        os.environ["IS_RUNNING_IN_STREAMLIT_EDITOR_PLUGIN"] = "True"

        self.assertEqual(True, config.get_option("server.headless"))

        del os.environ["IS_RUNNING_IN_STREAMLIT_EDITOR_PLUGIN"]

    def test_server_headless(self):
        orig_display = None
        if "DISPLAY" in os.environ.keys():
            orig_display = os.environ["DISPLAY"]
            del os.environ["DISPLAY"]

        orig_is_linux_or_bsd = env_util.IS_LINUX_OR_BSD
        env_util.IS_LINUX_OR_BSD = True

        self.assertEqual(True, config.get_option("server.headless"))

        env_util.IS_LINUX_OR_BSD = orig_is_linux_or_bsd
        if orig_display:
            os.environ["DISPLAY"] = orig_display

    def test_global_dev_mode(self):
        config.set_option("global.developmentMode", True)
        self.assertEqual(True, config.get_option("global.developmentMode"))

    def test_global_log_level_debug(self):
        config.set_option("global.developmentMode", True)
        self.assertEqual("debug", config.get_option("logger.level"))

    def test_global_log_level(self):
        config.set_option("global.developmentMode", False)
        self.assertEqual("info", config.get_option("logger.level"))

    @parameterized.expand(
        [
            (CONFIG_OPTIONS, True),
            (CONFIG_OPTIONS, False),
            (None, False),
            (None, True),
        ]
    )
    def test_on_config_parsed(self, config_options, connect_signal):
        """Tests to make sure callback is handled properly based upon
        _config_file_has_been_parsed and connect_signal."""

        mock_callback = MagicMock(return_value=None)

        with patch.object(config, "_config_options", new=config_options), patch.object(
            config._on_config_parsed, "connect"
        ) as patched_connect, patch.object(
            config._on_config_parsed, "disconnect"
        ) as patched_disconnect:
            mock_callback.reset_mock()
            disconnect_callback = config.on_config_parsed(mock_callback, connect_signal)

            if connect_signal:
                patched_connect.assert_called_once()
                mock_callback.assert_not_called()
            elif config_options:
                patched_connect.assert_not_called()
                mock_callback.assert_called_once()
            else:
                patched_connect.assert_called_once()
                mock_callback.assert_not_called()

            disconnect_callback()
            patched_disconnect.assert_called_once()

    def test_secret_files_default_values(self):
        """Verify that we're looking for secrets.toml in the right place."""
        if "win32" not in sys.platform:
            # conftest.py sets the HOME envvar to "/mock/home/folder".
            expected_global_path = "/mock/home/folder/.streamlit/secrets.toml"
        else:
            # On windows systems, HOME does not work so we look in the user's directory instead.
            expected_global_path = os.path.join(
                os.path.expanduser("~"), ".streamlit", "secrets.toml"
            )
        self.assertEqual(
            [
                expected_global_path,
                os.path.abspath("./.streamlit/secrets.toml"),
            ],
            config.get_option("secrets.files"),
        )


class ConfigLoadingTest(unittest.TestCase):
    """Tests that involve loading the config.toml file."""

    def setUp(self):
        self.patches = [
            patch.object(
                config, "_section_descriptions", new=copy.deepcopy(SECTION_DESCRIPTIONS)
            ),
            patch.object(config, "_config_options", new=None),
        ]

        for p in self.patches:
            p.start()

    def tearDown(self):
        for p in self.patches:
            p.stop()

    def test_missing_config(self):
        """Test that we can initialize our config even if the file is missing."""
        with patch("streamlit.config.os.path.exists") as path_exists:
            path_exists.return_value = False
            config.get_config_options()

            self.assertEqual(True, config.get_option("browser.gatherUsageStats"))
            self.assertIsNone(config.get_option("theme.font"))

    def test_load_global_config(self):
        """Test that ~/.streamlit/config.toml is read."""
        global_config = """
        [theme]
        base = "dark"
        font = "sans serif"
        """
        global_config_path = "/mock/home/folder/.streamlit/config.toml"

        open_patch = patch("streamlit.config.open", mock_open(read_data=global_config))
        # patch streamlit.*.os.* instead of os.* for py35 compat
        makedirs_patch = patch("streamlit.config.os.makedirs")
        makedirs_patch.return_value = True
        pathexists_patch = patch("streamlit.config.os.path.exists")
        pathexists_patch.side_effect = lambda path: path == global_config_path

        with open_patch, makedirs_patch, pathexists_patch:
            config.get_config_options()

            self.assertEqual("sans serif", config.get_option("theme.font"))
            self.assertIsNone(config.get_option("theme.textColor"))

    def test_load_local_config(self):
        """Test that $CWD/.streamlit/config.toml is read, even
        if ~/.streamlit/config.toml is missing.
        """

        local_config = """
        [theme]
        base = "light"
        textColor = "#FFFFFF"
        """

        local_config_path = os.path.join(os.getcwd(), ".streamlit/config.toml")

        open_patch = patch("streamlit.config.open", mock_open(read_data=local_config))
        # patch streamlit.*.os.* instead of os.* for py35 compat
        makedirs_patch = patch("streamlit.config.os.makedirs")
        makedirs_patch.return_value = True
        pathexists_patch = patch("streamlit.config.os.path.exists")
        pathexists_patch.side_effect = lambda path: path == local_config_path

        with open_patch, makedirs_patch, pathexists_patch:
            config.get_config_options()

            self.assertEqual("#FFFFFF", config.get_option("theme.textColor"))
            self.assertIsNone(config.get_option("theme.font"))

    def test_load_global_local_config(self):
        """Test that $CWD/.streamlit/config.toml gets overlaid on
        ~/.streamlit/config.toml at parse time.
        """

        global_config = """
        [theme]
        base = "dark"
        font = "sans serif"
        """

        local_config = """
        [theme]
        base = "light"
        textColor = "#FFFFFF"
        """

        global_config_path = "/mock/home/folder/.streamlit/config.toml"
        local_config_path = os.path.join(os.getcwd(), ".streamlit/config.toml")

        global_open = mock_open(read_data=global_config)
        local_open = mock_open(read_data=local_config)
        open = mock_open()
        open.side_effect = [global_open.return_value, local_open.return_value]

        open_patch = patch("streamlit.config.open", open)
        # patch streamlit.*.os.* instead of os.* for py35 compat
        makedirs_patch = patch("streamlit.config.os.makedirs")
        makedirs_patch.return_value = True
        pathexists_patch = patch("streamlit.config.os.path.exists")
        pathexists_patch.side_effect = lambda path: path in [
            global_config_path,
            local_config_path,
        ]

        with open_patch, makedirs_patch, pathexists_patch:
            config.get_config_options()

            # theme.base set in both local and global
            self.assertEqual("light", config.get_option("theme.base"))

            # theme.font is set in global, and not in local
            self.assertEqual("sans serif", config.get_option("theme.font"))

            # theme.textColor is set in local and not in global
            self.assertEqual("#FFFFFF", config.get_option("theme.textColor"))

    def test_load_global_local_flag_config(self):
        """Test that CLI flags have higher priority than both
        ~/.streamlit/config.toml and $CWD/.streamlit/config.toml at parse time.
        """

        global_config = """
        [theme]
        base = "dark"
        font = "sans serif"
        textColor = "#FFFFFF"
        """

        local_config = """
        [theme]
        base = "light"
        font = "serif"
        """

        global_config_path = "/mock/home/folder/.streamlit/config.toml"
        local_config_path = os.path.join(os.getcwd(), ".streamlit/config.toml")

        global_open = mock_open(read_data=global_config)
        local_open = mock_open(read_data=local_config)
        open = mock_open()
        open.side_effect = [global_open.return_value, local_open.return_value]

        open_patch = patch("streamlit.config.open", open)
        # patch streamlit.*.os.* instead of os.* for py35 compat
        makedirs_patch = patch("streamlit.config.os.makedirs")
        makedirs_patch.return_value = True
        pathexists_patch = patch("streamlit.config.os.path.exists")
        pathexists_patch.side_effect = lambda path: path in [
            global_config_path,
            local_config_path,
        ]

        with open_patch, makedirs_patch, pathexists_patch:
            config.get_config_options(options_from_flags={"theme.font": "monospace"})

            self.assertEqual("light", config.get_option("theme.base"))
            self.assertEqual("#FFFFFF", config.get_option("theme.textColor"))
            self.assertEqual("monospace", config.get_option("theme.font"))

    def test_upload_file_default_values(self):
        self.assertEqual(200, config.get_option("server.maxUploadSize"))

    def test_max_message_size_default_values(self):
        self.assertEqual(200, config.get_option("server.maxMessageSize"))

    def test_config_options_removed_on_reparse(self):
        """Test that config options that are removed in a file are also removed
        from our _config_options dict."""

        global_config_path = "/mock/home/folder/.streamlit/config.toml"
        makedirs_patch = patch("streamlit.config.os.makedirs")
        makedirs_patch.return_value = True
        pathexists_patch = patch("streamlit.config.os.path.exists")
        pathexists_patch.side_effect = lambda path: path == global_config_path

        global_config = """
        [theme]
        base = "dark"
        font = "sans serif"
        """
        open_patch = patch("streamlit.config.open", mock_open(read_data=global_config))

        with open_patch, makedirs_patch, pathexists_patch:
            config.get_config_options()

            self.assertEqual("dark", config.get_option("theme.base"))
            self.assertEqual("sans serif", config.get_option("theme.font"))

        global_config = """
        [theme]
        base = "dark"
        """
        open_patch = patch("streamlit.config.open", mock_open(read_data=global_config))

        with open_patch, makedirs_patch, pathexists_patch:
            config.get_config_options(force_reparse=True)

            self.assertEqual("dark", config.get_option("theme.base"))
            self.assertEqual(None, config.get_option("theme.font"))

    @patch("streamlit.logger.get_logger")
    def test_config_options_warn_on_server_change(self, get_logger):
        """Test that a warning is logged if a user changes a config file in the
        server section."""

        global_config_path = "/mock/home/folder/.streamlit/config.toml"
        makedirs_patch = patch("streamlit.config.os.makedirs")
        makedirs_patch.return_value = True
        pathexists_patch = patch("streamlit.config.os.path.exists")
        pathexists_patch.side_effect = lambda path: path == global_config_path
        mock_logger = get_logger()

        global_config = """
        [server]
        address = "localhost"
        """
        open_patch = patch("streamlit.config.open", mock_open(read_data=global_config))

        with open_patch, makedirs_patch, pathexists_patch:
            config.get_config_options()

        global_config = """
        [server]
        address = "streamlit.io"
        """
        open_patch = patch("streamlit.config.open", mock_open(read_data=global_config))

        with open_patch, makedirs_patch, pathexists_patch:
            config.get_config_options(force_reparse=True)

        mock_logger.warning.assert_any_call(
            "An update to the [server] config option section was detected."
            " To have these changes be reflected, please restart streamlit."
        )


================================================
File: /lib/tests/streamlit/config_util_test.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Config Util Unittest."""

from __future__ import annotations

import copy
import re
import textwrap
import unittest
from unittest.mock import patch

from parameterized import parameterized

from streamlit import config, config_util
from streamlit.config_option import ConfigOption

CONFIG_OPTIONS_TEMPLATE = config._config_options_template
CONFIG_SECTION_DESCRIPTIONS = copy.deepcopy(config._section_descriptions)


def create_config_options(overrides):
    config_options = copy.deepcopy(CONFIG_OPTIONS_TEMPLATE)
    for opt_name, opt_val in overrides.items():
        config_options[opt_name].set_value(opt_val, "test")
    return config_options


class ConfigUtilTest(unittest.TestCase):
    def test_clean(self):
        result = config_util._clean(" clean    this         text  ")
        self.assertEqual(" clean this text ", result)

    def test_clean_empty_string(self):
        result = config_util._clean("")
        self.assertEqual("", result)

    def test_clean_paragraphs(self):
        # from https://www.lipsum.com/
        input = textwrap.dedent(
            """
            Lorem              ipsum dolor sit amet,
            consectetur adipiscing elit.

               Curabitur ac fermentum eros.

            Maecenas                   libero est,
                    ultricies
            eget ligula eget,    """
        )

        truth = [
            "Lorem ipsum dolor sit amet,\nconsectetur adipiscing elit.",
            " Curabitur ac fermentum eros.",
            "Maecenas libero est,\n ultricies\neget ligula eget, ",
        ]

        result = config_util._clean_paragraphs(input)
        self.assertEqual(truth, result)

    def test_clean_paragraphs_empty_string(self):
        result = config_util._clean_paragraphs("")
        self.assertEqual([""], result)

    @patch("click.secho")
    def test_default_config_options_commented_out(self, patched_echo):
        config_options = create_config_options(
            {
                "server.address": "example.com",  # overrides default
                "server.port": 8501,  # explicitly set to default
            }
        )

        config_util.show_config(CONFIG_SECTION_DESCRIPTIONS, config_options)

        [(args, _)] = patched_echo.call_args_list
        # Remove the ascii escape sequences used to color terminal output.
        output = re.compile(r"\x1b[^m]*m").sub("", args[0])
        lines = set(output.split("\n"))

        # Config options not explicitly set should be commented out.
        assert "# runOnSave = false" in lines

        # Config options explicitly set should *not* be commented out, even if
        # they are set to their default values.
        assert 'address = "example.com"' in lines
        assert "port = 8501" in lines

    @patch("click.secho")
    def test_ui_section_hidden(self, patched_echo):
        config_options = create_config_options({})

        config_util.show_config(CONFIG_SECTION_DESCRIPTIONS, config_options)

        [(args, _)] = patched_echo.call_args_list
        # Remove the ascii escape sequences used to color terminal output.
        output = re.compile(r"\x1b[^m]*m").sub("", args[0])
        lines = set(output.split("\n"))

        assert "[ui]" not in lines
        assert "# hideTopBar = false" not in lines

    @parameterized.expand(
        [
            # Nothing changed.
            (
                {
                    "mapbox.token": "shhhhhhh",
                    "server.address": "localhost",
                },
                {
                    "mapbox.token": "shhhhhhh",
                    "server.address": "localhost",
                },
                False,
            ),
            # A non-server config option changed.
            (
                {
                    "mapbox.token": "shhhhhhh",
                    "server.address": "localhost",
                },
                {
                    "mapbox.token": "SHHHHHHH!!!!!! >:(",
                    "server.address": "localhost",
                },
                False,
            ),
            # A server config option changed.
            (
                {
                    "mapbox.token": "shhhhhhh",
                    "server.address": "localhost",
                },
                {
                    "mapbox.token": "shhhhhhh",
                    "server.address": "streamlit.io",
                },
                True,
            ),
        ]
    )
    def test_server_option_changed(self, old, new, changed):
        old_options = create_config_options(old)
        new_options = create_config_options(new)
        self.assertEqual(
            config_util.server_option_changed(old_options, new_options), changed
        )

    @patch("click.secho")
    def test_newlines_preserved_in_description(self, patched_echo):
        config_options = {
            "server.customOption": ConfigOption(
                key="server.customOption",
                description="""
                    This option has multiple lines.
                    Each line should be preserved.
                    Even this one.
                """,
                default_val="default",
                type_=str,
            )
        }

        config_util.show_config(CONFIG_SECTION_DESCRIPTIONS, config_options)

        [(args, _)] = patched_echo.call_args_list
        # Remove the ascii escape sequences used to color terminal output.
        output = re.compile(r"\x1b[^m]*m").sub("", args[0])
        lines = set(output.split("\n"))

        assert "# This option has multiple lines." in lines
        assert "# Each line should be preserved." in lines
        assert "# Even this one." in lines

    @patch("click.secho")
    def test_omits_empty_lines_at_description_start(self, patched_echo):
        config_options = {
            "server.customOption": ConfigOption(
                key="server.customOption",
                description="""

                    This option's description starts from third line.
                    All preceding empty lines should be removed.
                """,
                default_val="default",
                type_=str,
            )
        }

        config_util.show_config(CONFIG_SECTION_DESCRIPTIONS, config_options)

        [(args, _)] = patched_echo.call_args_list
        # Remove the ascii escape sequences used to color terminal output.
        output = re.compile(r"\x1b[^m]*m").sub("", args[0])
        lines = output.split("\n")
        description_index = lines.index(
            "# This option's description starts from third line."
        )

        assert (
            description_index > 1
        ), "Description should not be at the start of the output"
        assert (
            lines[description_index - 1].strip() == ""
        ), "Preceding line should be empty (this line separates config options)"
        assert (
            lines[description_index - 2].strip() != ""
        ), "The line before the preceding line should not be empty (this is the section header)"

    @patch("click.secho")
    def test_description_appears_before_option(self, patched_echo):
        config_options = {
            "server.customOption": ConfigOption(
                key="server.customOption",
                description="This option's description should appear before the option.",
                default_val="default",
                type_=str,
            )
        }

        config_util.show_config(CONFIG_SECTION_DESCRIPTIONS, config_options)

        [(args, _)] = patched_echo.call_args_list
        # Remove the ascii escape sequences used to color terminal output.
        output = re.compile(r"\x1b[^m]*m").sub("", args[0])
        lines = output.split("\n")

        # Find the index of the description and the option in the output.
        description_index = lines.index(
            "# This option's description should appear before the option."
        )
        option_index = lines.index('# customOption = "default"')

        # Assert that the description appears before the option.
        self.assertLess(description_index, option_index)

    @patch("click.secho")
    def test_show_config_section_formatting(self, patched_echo):
        config_options = create_config_options({"server.address": "localhost"})
        config_util.show_config(CONFIG_SECTION_DESCRIPTIONS, config_options)

        [(args, _)] = patched_echo.call_args_list
        output = re.compile(r"\x1b[^m]*m").sub("", args[0])
        lines = output.split("\n")

        self.assertIn("[server]", lines)

    @patch("click.secho")
    def test_show_config_hidden_option(self, patched_echo):
        config_options = {
            "server.hiddenOption": ConfigOption(
                key="server.hiddenOption",
                description="This is a hidden option.",
                default_val="default",
                type_=str,
                visibility="hidden",
            )
        }
        config_util.show_config(CONFIG_SECTION_DESCRIPTIONS, config_options)

        [(args, _)] = patched_echo.call_args_list
        output = re.compile(r"\x1b[^m]*m").sub("", args[0])
        lines = output.split("\n")

        self.assertNotIn("# This is a hidden option.", lines)


================================================
File: /lib/tests/streamlit/data_test_cases.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import annotations

import array
import enum
import random
from collections import (
    ChainMap,
    Counter,
    OrderedDict,
    UserDict,
    UserList,
    defaultdict,
    deque,
)
from dataclasses import dataclass
from datetime import date
from types import MappingProxyType
from typing import Any, Literal, NamedTuple, TypedDict

import numpy as np
import pandas as pd
import pyarrow as pa

from streamlit.dataframe_util import DataFormat, is_pandas_version_less_than
from tests.streamlit.data_mocks.dask_mocks import DataFrame as DaskDataFrame
from tests.streamlit.data_mocks.dask_mocks import Index as DaskIndex
from tests.streamlit.data_mocks.dask_mocks import Series as DaskSeries
from tests.streamlit.data_mocks.modin_mocks import DataFrame as ModinDataFrame
from tests.streamlit.data_mocks.modin_mocks import Series as ModinSeries
from tests.streamlit.data_mocks.pyspark_connect_mocks import (
    DataFrame as PySparkConnectDataFrame,
)
from tests.streamlit.data_mocks.pyspark_mocks import DataFrame as PySparkDataFrame
from tests.streamlit.data_mocks.ray_mocks import Dataset as RayDataset
from tests.streamlit.data_mocks.ray_mocks import (
    MaterializedDataset as RayMaterializedDataset,
)
from tests.streamlit.data_mocks.snowpandas_mocks import DataFrame as SnowpandasDataFrame
from tests.streamlit.data_mocks.snowpandas_mocks import Index as SnowpandasIndex
from tests.streamlit.data_mocks.snowpandas_mocks import Series as SnowpandasSeries
from tests.streamlit.data_mocks.snowpark_mocks import DataFrame as SnowparkDataFrame
from tests.streamlit.data_mocks.snowpark_mocks import Row as SnowparkRow
from tests.streamlit.data_mocks.snowpark_mocks import Table as SnowparkTable

np.random.seed(0)
random.seed(0)


class CaseMetadata(NamedTuple):
    # The expected number of rows
    expected_rows: int
    # The expected number of columns (doesn't include index columns)
    expected_cols: int
    # The expected data format
    expected_data_format: DataFormat
    # The expected sequence when the data is converted to a sequence
    # If None, the sequence is not checked.
    expected_sequence: list[Any]
    # The expected command used when the data is written via `st.write`
    expected_write_command: Literal[
        "markdown", "dataframe", "json", "help", "write_stream"
    ]
    # Whether the data structure is unevaluated and will be truncated
    # if it is too large.
    is_unevaluated: bool
    # The expected return type of the data when it is
    # returned from the `st.data_editor` function.
    expected_type: type | None = None


@dataclass
class ElementDataClass:
    name: str
    is_widget: bool
    usage: float


class ElementNamedTuple(NamedTuple):
    name: str
    is_widget: bool
    usage: float


class ElementTypedDict(TypedDict):
    name: str
    is_widget: bool
    usage: float


class UserDictExample(UserDict):  # type: ignore
    pass


class TestObject:
    def __str__(self):
        return "TestObject"


class CustomDataframe:
    """A dummy dataframe-like class that supports the dataframe interchange protocol
    (__dataframe__ method).
    """

    def __init__(self, data: pd.DataFrame):
        self._data: pd.DataFrame = data

    def __dataframe__(self, allow_copy: bool = True):
        return self._data.__dataframe__(allow_copy=allow_copy)


class StrTestEnum(str, enum.Enum):
    NUMBER_INPUT = "st.number_input"
    TEXT_AREA = "st.text_area"
    TEXT_INPUT = "st.text_input"


class TestEnum(enum.Enum):
    NUMBER_INPUT = "st.number_input"
    TEXT_AREA = "st.text_area"
    TEXT_INPUT = "st.text_input"


def data_generator():
    yield "st.number_input"
    yield "st.text_area"
    yield "st.text_input"


SHARED_TEST_CASES: list[tuple[str, Any, CaseMetadata]] = [
    ###################################
    ####### Native Python Types #######
    ###################################
    (
        "None",
        None,
        CaseMetadata(0, 0, DataFormat.EMPTY, [], "markdown", False, pd.DataFrame),
    ),
    (
        "Empty list",
        [],
        CaseMetadata(0, 0, DataFormat.LIST_OF_VALUES, [], "json", False),
    ),
    (
        "Empty tuple",
        (),
        CaseMetadata(0, 0, DataFormat.TUPLE_OF_VALUES, [], "markdown", False),
    ),
    (
        "Empty dict",
        {},
        CaseMetadata(0, 0, DataFormat.KEY_VALUE_DICT, [], "json", False),
    ),
    (
        "Empty set",
        set(),
        CaseMetadata(0, 0, DataFormat.SET_OF_VALUES, [], "markdown", False),
    ),
    (
        "List[str]",
        ["st.text_area", "st.number_input", "st.text_input"],
        CaseMetadata(
            3,
            1,
            DataFormat.LIST_OF_VALUES,
            ["st.text_area", "st.number_input", "st.text_input"],
            "json",
            False,
        ),
    ),
    (
        "List[int]",
        [1, 2, 3],
        CaseMetadata(3, 1, DataFormat.LIST_OF_VALUES, [1, 2, 3], "json", False),
    ),
    (
        "List[float]",
        [1.1, 2.2, 3.3],
        CaseMetadata(3, 1, DataFormat.LIST_OF_VALUES, [1.1, 2.2, 3.3], "json", False),
    ),
    (
        "List[bool]",
        [True, False, True],
        CaseMetadata(
            3, 1, DataFormat.LIST_OF_VALUES, [True, False, True], "json", False
        ),
    ),
    (
        "List[None]",
        [None, None, None],
        CaseMetadata(
            3, 1, DataFormat.LIST_OF_VALUES, [None, None, None], "json", False
        ),
    ),
    (
        "List[date]",
        [date(2020, 1, 1), date(2020, 1, 2), date(2020, 1, 3)],
        CaseMetadata(
            3,
            1,
            DataFormat.LIST_OF_VALUES,
            [date(2020, 1, 1), date(2020, 1, 2), date(2020, 1, 3)],
            "json",
            False,
        ),
    ),
    (
        "Set[str]",
        # Set does not have a stable order across different Python version.
        # Therefore, we are only testing this with one item.
        {"st.number_input", "st.number_input"},  # noqa: B033
        CaseMetadata(
            1, 1, DataFormat.SET_OF_VALUES, ["st.number_input"], "markdown", False
        ),
    ),
    (
        "Tuple[str]",
        ("st.text_area", "st.number_input", "st.text_input"),
        CaseMetadata(
            3,
            1,
            DataFormat.TUPLE_OF_VALUES,
            ["st.text_area", "st.number_input", "st.text_input"],
            "markdown",
            False,
        ),
    ),
    (
        "Frozenset[str]",
        # Set does not have a stable order across different Python version.
        # Therefore, we are only testing this with one item.
        frozenset({"st.number_input", "st.number_input"}),  # noqa: B033
        CaseMetadata(
            1,
            1,
            DataFormat.SET_OF_VALUES,
            ["st.number_input"],
            "markdown",
            False,
            set,
        ),
    ),
    (
        "Empty frozenset",
        frozenset(),
        CaseMetadata(0, 0, DataFormat.SET_OF_VALUES, [], "markdown", False, set),
    ),
    (
        "Range",
        range(3),
        CaseMetadata(
            3, 1, DataFormat.LIST_OF_VALUES, [0, 1, 2], "markdown", False, list
        ),
    ),
    (
        "Dict Keys",
        {
            "st.number_input": "number",
            "st.text_area": "text",
            "st.text_input": "text",
        }.keys(),
        CaseMetadata(
            3,
            1,
            DataFormat.LIST_OF_VALUES,
            ["st.number_input", "st.text_area", "st.text_input"],
            "json",
            False,
            list,
        ),
    ),
    (
        "Dict Values",
        {
            "st.number_input": "number",
            "st.text_area": "text",
            "st.text_input": "text",
        }.values(),
        CaseMetadata(
            3,
            1,
            DataFormat.LIST_OF_VALUES,
            ["number", "text", "text"],
            "json",
            False,
            list,
        ),
    ),
    (
        "Dict Items",
        {
            "st.number_input": "number",
            "st.text_area": "text",
            "st.text_input": "text",
        }.items(),
        CaseMetadata(
            3,
            2,
            DataFormat.LIST_OF_ROWS,
            [
                ("st.number_input", "number"),
                ("st.text_area", "text"),
                ("st.text_input", "text"),
            ],
            "json",
            False,
            list,
        ),
    ),
    (
        "collections.OrderedDict",
        OrderedDict(
            [
                ("st.number_input", "number"),
                ("st.text_area", "text"),
            ]
        ),
        CaseMetadata(
            2,
            1,
            DataFormat.KEY_VALUE_DICT,
            ["st.number_input", "st.text_area"],
            "json",
            False,
            dict,
        ),
    ),
    (
        "collections.defaultdict",
        defaultdict(
            lambda: "Not Present",
            {"st.text_area": "widget", "st.markdown": "element"},
        ),
        CaseMetadata(
            2,
            1,
            DataFormat.KEY_VALUE_DICT,
            ["st.text_area", "st.markdown"],
            "json",
            False,
            dict,
        ),
    ),
    (
        "collections.Counter",
        Counter({"st.number_input": 4, "st.text_area": 2}),
        CaseMetadata(
            2,
            1,
            DataFormat.KEY_VALUE_DICT,
            ["st.number_input", "st.text_area"],
            "json",
            False,
            dict,
        ),
    ),
    (
        "collections.deque",
        deque(["st.number_input", "st.text_area", "st.text_input"]),
        CaseMetadata(
            3,
            1,
            DataFormat.LIST_OF_VALUES,
            ["st.number_input", "st.text_area", "st.text_input"],
            "markdown",
            False,
            list,
        ),
    ),
    (
        "collections.ChainMap",
        ChainMap(
            {"st.number_input": "number", "st.text_area": "text"},
            {"st.text_input": "text"},
        ),
        CaseMetadata(
            3,
            1,
            DataFormat.KEY_VALUE_DICT,
            ["st.number_input", "st.text_area", "st.text_input"],
            "json",
            False,
            dict,
        ),
    ),
    (
        "collections.UserList",
        UserList(["st.number_input", "st.text_area", "st.text_input"]),
        CaseMetadata(
            3,
            1,
            DataFormat.LIST_OF_VALUES,
            ["st.number_input", "st.text_area", "st.text_input"],
            "json",
            False,
            list,
        ),
    ),
    (
        "Dataclass",
        ElementDataClass("st.number_input", is_widget=True, usage=0.32),
        CaseMetadata(
            3,
            1,
            DataFormat.KEY_VALUE_DICT,
            ["st.number_input", True, 0.32],
            "help",
            False,
            dict,
        ),
    ),
    (
        "TypedDict",
        ElementTypedDict(name="st.number_input", is_widget=True, usage=0.32),
        CaseMetadata(
            3,
            1,
            DataFormat.KEY_VALUE_DICT,
            ["name", "is_widget", "usage"],
            "json",
            False,
            dict,
        ),
    ),
    (
        "NamedTuple",
        ElementNamedTuple("st.number_input", is_widget=True, usage=0.32),
        CaseMetadata(
            3,
            1,
            DataFormat.KEY_VALUE_DICT,
            ["st.number_input", True, 0.32],
            "json",
            False,
            dict,
        ),
    ),
    (
        "String Enum",
        StrTestEnum,
        CaseMetadata(
            3,
            1,
            DataFormat.LIST_OF_VALUES,
            ["st.number_input", "st.text_area", "st.text_input"],
            "help",
            False,
            list,
        ),
    ),
    (
        "Enum",
        TestEnum,
        CaseMetadata(
            3,
            1,
            DataFormat.LIST_OF_VALUES,
            [TestEnum.NUMBER_INPUT, TestEnum.TEXT_AREA, TestEnum.TEXT_INPUT],
            "help",
            False,
            list,
        ),
    ),
    (
        "Generator Function",
        data_generator,
        CaseMetadata(
            3,
            1,
            DataFormat.UNKNOWN,
            ["st.number_input", "st.text_area", "st.text_input"],
            "write_stream",
            True,
        ),
    ),
    (
        "Empty column value mapping",
        {"name": [], "type": []},
        CaseMetadata(
            0, 2, DataFormat.COLUMN_VALUE_MAPPING, ["name", "type"], "json", False
        ),
    ),
    (
        "array.array",
        array.array("i", [1, 2, 3]),
        CaseMetadata(
            3, 1, DataFormat.LIST_OF_VALUES, [1, 2, 3], "markdown", False, list
        ),
    ),
    (
        "MappingProxyType",
        MappingProxyType({"st.text_area": "widget", "st.markdown": "element"}),
        CaseMetadata(
            2,
            1,
            DataFormat.KEY_VALUE_DICT,
            ["st.text_area", "st.markdown"],
            "json",
            False,
            dict,
        ),
    ),
    (
        "UserDict",
        UserDictExample({"st.text_area": "widget", "st.markdown": "element"}),
        CaseMetadata(
            2,
            1,
            DataFormat.KEY_VALUE_DICT,
            ["st.text_area", "st.markdown"],
            "json",
            False,
            dict,
        ),
    ),
    (
        "List of rows",  # List[list[scalar]]
        [["st.text_area", "widget"], ["st.markdown", "element"]],
        CaseMetadata(
            2,
            2,
            DataFormat.LIST_OF_ROWS,
            [["st.text_area", "widget"], ["st.markdown", "element"]],
            "json",
            False,
        ),
    ),
    (
        "List of records",  # List[Dict[str, Scalar]]
        [
            {"name": "st.text_area", "type": "widget"},
            {"name": "st.markdown", "type": "element"},
        ],
        CaseMetadata(
            2,
            2,
            DataFormat.LIST_OF_RECORDS,
            [
                {"name": "st.text_area", "type": "widget"},
                {"name": "st.markdown", "type": "element"},
            ],
            "json",
            False,
        ),
    ),
    (
        "Column-index mapping",  # ({column: {index: value}})
        {
            "type": {"st.text_area": "widget", "st.markdown": "element"},
            "usage": {"st.text_area": 4.92, "st.markdown": 47.22},
        },
        CaseMetadata(
            2,
            2,
            DataFormat.COLUMN_INDEX_MAPPING,
            ["type", "usage"],
            "json",
            False,
        ),
    ),
    (
        "Column-value mapping",  # ({column: List[values]}})
        {
            "name": ["st.text_area", "st.markdown"],
            "type": ["widget", "element"],
        },
        CaseMetadata(
            2,
            2,
            DataFormat.COLUMN_VALUE_MAPPING,
            ["name", "type"],
            "json",
            False,
        ),
    ),
    (
        "Column-series mapping",  # ({column: Series(values)})
        {
            "name": pd.Series(["st.text_area", "st.markdown"], name="name"),
            "type": pd.Series(["widget", "element"], name="type"),
        },
        CaseMetadata(
            2,
            2,
            DataFormat.COLUMN_SERIES_MAPPING,
            ["name", "type"],
            "dataframe",
            False,
        ),
    ),
    (
        "Key-value dict",  # ({index: value})
        {"st.text_area": "widget", "st.markdown": "element"},
        CaseMetadata(
            2,
            1,
            DataFormat.KEY_VALUE_DICT,
            ["st.text_area", "st.markdown"],
            "json",
            False,
        ),
    ),
    ###################################
    ########## Pandas Types ###########
    ###################################
    (
        "Empty pd.Dataframe",
        pd.DataFrame(),
        CaseMetadata(0, 0, DataFormat.PANDAS_DATAFRAME, [], "dataframe", False),
    ),
    (
        "Empty pd.Dataframe with columns",
        pd.DataFrame(
            columns=["name", "type"], index=pd.RangeIndex(start=0, step=1)
        ),  # Explicitly set the range index to have the same behavior across versions
        CaseMetadata(0, 2, DataFormat.PANDAS_DATAFRAME, [], "dataframe", False),
    ),
    (
        "pd.Dataframe",
        pd.DataFrame(["st.text_area", "st.markdown"]),
        CaseMetadata(
            2,
            1,
            DataFormat.PANDAS_DATAFRAME,
            ["st.text_area", "st.markdown"],
            "dataframe",
            False,
        ),
    ),
    (
        "pd.Series[str]",
        pd.Series(
            ["st.text_area", "st.number_input", "st.text_input"],
            name="widgets",
        ),
        CaseMetadata(
            3,
            1,
            DataFormat.PANDAS_SERIES,
            ["st.text_area", "st.number_input", "st.text_input"],
            "dataframe",
            False,
        ),
    ),
    (
        "pd.Index",
        pd.Index(["st.text_area", "st.markdown"]),
        CaseMetadata(
            2,
            1,
            DataFormat.PANDAS_INDEX,
            ["st.text_area", "st.markdown"],
            "dataframe",
            False,
            pd.DataFrame,
        ),
    ),
    (
        "Pandas Styler",
        pd.DataFrame(["st.text_area", "st.markdown"]).style,
        CaseMetadata(
            2,
            1,
            DataFormat.PANDAS_STYLER,
            ["st.text_area", "st.markdown"],
            "dataframe",
            False,
            pd.DataFrame,
        ),
    ),
    (
        "pd.array",
        pd.array(["st.number_input", "st.text_area", "st.text_input"]),
        CaseMetadata(
            3,
            1,
            DataFormat.PANDAS_ARRAY,
            ["st.number_input", "st.text_area", "st.text_input"],
            "dataframe",
            False,
            pd.DataFrame,
        ),
    ),
    (
        "pd.DatetimeIndex",
        pd.DatetimeIndex(["1/1/2020 10:00:00+00:00", "2/1/2020 11:00:00+00:00"]),
        CaseMetadata(
            2,
            1,
            DataFormat.PANDAS_INDEX,
            [
                pd.Timestamp("2020-01-01 10:00:00+0000", tz="UTC"),
                pd.Timestamp("2020-02-01 11:00:00+0000", tz="UTC"),
            ],
            "dataframe",
            False,
            pd.DataFrame,
        ),
    ),
    (
        "pd.RangeIndex",
        pd.RangeIndex(start=0, stop=3, step=1),
        CaseMetadata(
            3, 1, DataFormat.PANDAS_INDEX, [0, 1, 2], "dataframe", False, pd.DataFrame
        ),
    ),
    ###################################
    ########### Numpy Types ###########
    ###################################
    (
        "Empty np.array",
        # For unknown reasons, pd.DataFrame initializes empty numpy arrays with a single column
        np.ndarray(0),
        CaseMetadata(0, 1, DataFormat.NUMPY_LIST, [], "dataframe", False),
    ),
    (
        "np.array[str]",
        np.array(["st.text_area", "st.number_input", "st.text_input"]),
        CaseMetadata(
            3,
            1,
            DataFormat.NUMPY_LIST,
            ["st.text_area", "st.number_input", "st.text_input"],
            "dataframe",
            False,
        ),
    ),
    (
        "np.array[int]",
        np.array([1, 2, 3]),
        CaseMetadata(3, 1, DataFormat.NUMPY_LIST, [1, 2, 3], "dataframe", False),
    ),
    (
        "np.array[list[scalar]]",
        np.array(
            [
                ["st.text_area", "widget"],
                ["st.markdown", "element"],
            ]
        ),
        CaseMetadata(
            2,
            2,
            DataFormat.NUMPY_MATRIX,
            ["st.text_area", "st.markdown"],
            "dataframe",
            False,
        ),
    ),
    (
        "np.array[list[str]]",  # numpy matrix
        np.array(
            [
                ["st.text_area", "widget"],
                ["st.markdown", "element"],
            ]
        ),
        CaseMetadata(
            2,
            2,
            DataFormat.NUMPY_MATRIX,
            ["st.text_area", "st.markdown"],
            "dataframe",
            False,
        ),
    ),
    ###################################
    ########## Pyarrow Types ##########
    ###################################
    (
        "Pyarrow Table",
        pa.Table.from_pandas(pd.DataFrame(["st.text_area", "st.markdown"])),
        CaseMetadata(
            2,
            1,
            DataFormat.PYARROW_TABLE,
            ["st.text_area", "st.markdown"],
            "dataframe",
            False,
        ),
    ),
    (
        "Pyarrow Array",
        pa.array(["st.number_input", "st.text_area", "st.text_input"]),
        CaseMetadata(
            3,
            1,
            DataFormat.PYARROW_ARRAY,
            ["st.number_input", "st.text_area", "st.text_input"],
            "dataframe",
            False,
        ),
    ),
    ###################################
    ##### Snowflake Types (Mocks) #####
    ###################################
    (
        "Snowpark DataFrame",
        SnowparkDataFrame(
            pd.DataFrame(
                [
                    {"name": "st.text_area", "type": "widget"},
                    {"name": "st.markdown", "type": "element"},
                ]
            )
        ),
        CaseMetadata(
            2,
            2,
            DataFormat.SNOWPARK_OBJECT,
            ["st.text_area", "st.markdown"],
            "dataframe",
            True,
            pd.DataFrame,
        ),
    ),
    (
        "Snowpark Table",
        SnowparkTable(
            pd.DataFrame(
                [
                    {"name": "st.text_area", "type": "widget"},
                    {"name": "st.markdown", "type": "element"},
                ]
            )
        ),
        CaseMetadata(
            2,
            2,
            DataFormat.SNOWPARK_OBJECT,
            ["st.text_area", "st.markdown"],
            "dataframe",
            True,
            pd.DataFrame,
        ),
    ),
    (
        "Snowpark Row List",
        [
            SnowparkRow({"name": "st.text_area", "type": "widget"}),
            SnowparkRow({"name": "st.markdown", "type": "element"}),
            SnowparkRow({"name": "st.text_input", "type": "text"}),
        ],
        CaseMetadata(
            3,
            2,
            DataFormat.SNOWPARK_OBJECT,
            ["st.text_area", "st.markdown", "st.text_input"],
            "dataframe",
            False,
            pd.DataFrame,
        ),
    ),
    (
        "Snowpandas DataFrame",
        SnowpandasDataFrame(
            pd.DataFrame(
                [
                    {"name": "st.text_area", "type": "widget"},
                    {"name": "st.markdown", "type": "element"},
                ]
            )
        ),
        CaseMetadata(
            2,
            2,
            DataFormat.SNOWPANDAS_OBJECT,
            ["st.text_area", "st.markdown"],
            "dataframe",
            True,
            pd.DataFrame,
        ),
    ),
    (
        "Snowpandas Series",
        SnowpandasSeries(pd.Series(["st.text_area", "st.markdown"])),
        CaseMetadata(
            2,
            1,
            DataFormat.SNOWPANDAS_OBJECT,
            ["st.text_area", "st.markdown"],
            "dataframe",
            True,
            pd.DataFrame,
        ),
    ),
    (
        "Snowpandas Index",
        SnowpandasIndex(
            pd.Index(["st.text_area", "st.markdown"]),
        ),
        CaseMetadata(
            2,
            1,
            DataFormat.SNOWPANDAS_OBJECT,
            ["st.text_area", "st.markdown"],
            "dataframe",
            True,
            pd.DataFrame,
        ),
    ),
    (
        "Modin DataFrame",
        ModinDataFrame(
            pd.DataFrame(
                [
                    {"name": "st.text_area", "type": "widget"},
                    {"name": "st.markdown", "type": "element"},
                ]
            )
        ),
        CaseMetadata(
            2,
            2,
            DataFormat.MODIN_OBJECT,
            ["st.text_area", "st.markdown"],
            "dataframe",
            True,
            pd.DataFrame,
        ),
    ),
    (
        "Modin Series",
        ModinSeries(pd.Series(["st.text_area", "st.markdown"])),
        CaseMetadata(
            2,
            1,
            DataFormat.MODIN_OBJECT,
            ["st.text_area", "st.markdown"],
            "dataframe",
            True,
            pd.DataFrame,
        ),
    ),
    ###################################
    ##### External Types (Mocks) ######
    ###################################
    (
        "Pyspark DataFrame",
        PySparkDataFrame(
            pd.DataFrame(
                [
                    {"name": "st.text_area", "type": "widget"},
                    {"name": "st.markdown", "type": "element"},
                ]
            )
        ),
        CaseMetadata(
            2,
            2,
            DataFormat.PYSPARK_OBJECT,
            ["st.text_area", "st.markdown"],
            "dataframe",
            True,
            pd.DataFrame,
        ),
    ),
    (
        "Pyspark Connect DataFrame",
        PySparkConnectDataFrame(
            pd.DataFrame(
                [
                    {"name": "st.text_area", "type": "widget"},
                    {"name": "st.markdown", "type": "element"},
                ]
            )
        ),
        CaseMetadata(
            2,
            2,
            DataFormat.PYSPARK_OBJECT,
            ["st.text_area", "st.markdown"],
            "dataframe",
            True,
            pd.DataFrame,
        ),
    ),
    (
        "Dask DataFrame",
        DaskDataFrame(
            pd.DataFrame(
                [
                    {"name": "st.text_area", "type": "widget"},
                    {"name": "st.markdown", "type": "element"},
                ]
            )
        ),
        CaseMetadata(
            2,
            2,
            DataFormat.DASK_OBJECT,
            ["st.text_area", "st.markdown"],
            "dataframe",
            True,
            pd.DataFrame,
        ),
    ),
    (
        "Dask Series",
        DaskSeries(pd.Series(["st.text_area", "st.markdown"])),
        CaseMetadata(
            2,
            1,
            DataFormat.DASK_OBJECT,
            ["st.text_area", "st.markdown"],
            "dataframe",
            True,
            pd.DataFrame,
        ),
    ),
    (
        "Dask Index",
        DaskIndex(
            pd.Index(["st.text_area", "st.markdown"]),
        ),
        CaseMetadata(
            2,
            1,
            DataFormat.DASK_OBJECT,
            ["st.text_area", "st.markdown"],
            "dataframe",
            True,
            pd.DataFrame,
        ),
    ),
    (
        "Ray Dataset",
        RayDataset(
            pd.DataFrame(
                [
                    {"name": "st.text_area", "type": "widget"},
                    {"name": "st.markdown", "type": "element"},
                ]
            )
        ),
        CaseMetadata(
            2,
            2,
            DataFormat.RAY_DATASET,
            ["st.text_area", "st.markdown"],
            "dataframe",
            True,
            pd.DataFrame,
        ),
    ),
    (
        "Ray Materialized Dataset",
        RayMaterializedDataset(
            pd.DataFrame(
                [
                    {"name": "st.text_area", "type": "widget"},
                    {"name": "st.markdown", "type": "element"},
                ]
            )
        ),
        CaseMetadata(
            2,
            2,
            DataFormat.RAY_DATASET,
            ["st.text_area", "st.markdown"],
            "dataframe",
            True,
            pd.DataFrame,
        ),
    ),
]

###################################
###### Dataframe Interchange ######
###################################
if is_pandas_version_less_than("1.5.0") is False:
    SHARED_TEST_CASES.extend(
        [
            (
                "Dataframe-interchange compatible",
                CustomDataframe(
                    pd.DataFrame(
                        [
                            {"name": "st.text_area", "type": "widget"},
                            {"name": "st.markdown", "type": "element"},
                        ]
                    )
                ),
                CaseMetadata(
                    2,
                    2,
                    DataFormat.UNKNOWN,
                    ["st.text_area", "st.markdown"],
                    "dataframe",
                    False,
                    None,
                ),
            ),
        ]
    )

###################################
########### Polars Types ##########
###################################
try:
    import polars as pl

    SHARED_TEST_CASES.extend(
        [
            (
                "Polars DataFrame",
                pl.DataFrame(
                    [
                        {"name": "st.text_area", "type": "widget"},
                        {"name": "st.markdown", "type": "element"},
                    ]
                ),
                CaseMetadata(
                    2,
                    2,
                    DataFormat.POLARS_DATAFRAME,
                    ["st.text_area", "st.markdown"],
                    "dataframe",
                    False,
                ),
            ),
            (
                "Polars Series",
                pl.Series(["st.number_input", "st.text_area", "st.text_input"]),
                CaseMetadata(
                    3,
                    1,
                    DataFormat.POLARS_SERIES,
                    ["st.number_input", "st.text_area", "st.text_input"],
                    "dataframe",
                    False,
                ),
            ),
            (
                "Polars LazyFrame",
                pl.LazyFrame(
                    {
                        "name": ["st.text_area", "st.markdown"],
                        "type": ["widget", "element"],
                    }
                ),
                CaseMetadata(
                    2,
                    2,
                    DataFormat.POLARS_LAZYFRAME,
                    ["st.text_area", "st.markdown"],
                    "dataframe",
                    True,
                    pl.DataFrame,
                ),
            ),
        ]
    )
except ModuleNotFoundError:
    print("Polars not installed. Skipping Polars dataframe integration tests.")  # noqa: T201

###################################
########### Xarray Types ##########
###################################
try:
    import xarray as xr

    SHARED_TEST_CASES.extend(
        [
            (
                "Xarray Dataset",
                xr.Dataset.from_dataframe(
                    pd.DataFrame(
                        {
                            "name": ["st.text_area", "st.markdown"],
                            "type": ["widget", "element"],
                        }
                    )
                ),
                CaseMetadata(
                    2,
                    2,
                    DataFormat.XARRAY_DATASET,
                    ["name", "type"],
                    "dataframe",
                    False,
                ),
            ),
            (
                "Xarray DataArray",
                xr.DataArray.from_series(
                    pd.Series(
                        ["st.number_input", "st.text_area", "st.text_input"],
                        name="widgets",
                    )
                ),
                CaseMetadata(
                    3,
                    1,
                    DataFormat.XARRAY_DATA_ARRAY,
                    ["st.number_input", "st.text_area", "st.text_input"],
                    "dataframe",
                    False,
                ),
            ),
        ]
    )
except ModuleNotFoundError:
    print("Xarray not installed. Skipping Xarray dataframe integration tests.")  # noqa: T201

###################################
########## Pydantic Types #########
###################################
try:
    from pydantic import BaseModel

    class ElementPydanticModel(BaseModel):
        name: str
        is_widget: bool
        usage: float

    SHARED_TEST_CASES.extend(
        [
            (
                "Pydantic Model",
                ElementPydanticModel(
                    name="st.number_input", is_widget=True, usage=0.32
                ),
                CaseMetadata(
                    3,
                    1,
                    DataFormat.KEY_VALUE_DICT,
                    ["st.number_input", True, 0.32],
                    "json",
                    False,
                    dict,
                ),
            ),
        ]
    )
except ModuleNotFoundError:
    print("Pydantic not installed. Skipping Pydantic dataframe tests.")  # noqa: T201


================================================
File: /lib/tests/streamlit/dataframe_coercion_test.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Tests coercing various objects to DataFrames"""

from __future__ import annotations

import unittest

import numpy as np
import pandas as pd
import pyarrow as pa

from streamlit import dataframe_util


class DataFrameCoercionTest(unittest.TestCase):
    def test_dict_of_lists(self):
        """Test that a DataFrame can be constructed from a dict
        of equal-length lists
        """
        d = {"a": [1], "b": [2], "c": [3]}
        df = dataframe_util.convert_anything_to_pandas_df(d)
        self.assertEqual(type(df), pd.DataFrame)
        self.assertEqual(df.shape, (1, 3))

    def test_empty_numpy_array(self):
        """Test that a single-column empty DataFrame can be constructed
        from an empty numpy array.
        """
        arr = np.array([])
        df = dataframe_util.convert_anything_to_pandas_df(arr)
        self.assertEqual(type(df), pd.DataFrame)
        self.assertEqual(df.shape, (0, 1))

    def test_styler(self):
        """Test that a DataFrame can be constructed from a pandas.Styler"""
        d = {"a": [1], "b": [2], "c": [3]}
        styler = pd.DataFrame(d).style.format("{:.2%}")
        df = dataframe_util.convert_anything_to_pandas_df(styler)
        self.assertEqual(type(df), pd.DataFrame)
        self.assertEqual(df.shape, (1, 3))

    def test_pyarrow_table(self):
        """Test that a DataFrame can be constructed from a pyarrow.Table"""
        d = {"a": [1], "b": [2], "c": [3]}
        table = pa.Table.from_pandas(pd.DataFrame(d))
        df = dataframe_util.convert_anything_to_pandas_df(table)
        self.assertEqual(type(df), pd.DataFrame)
        self.assertEqual(df.shape, (1, 3))


================================================
File: /lib/tests/streamlit/dataframe_util_test.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import annotations

import enum
import unittest
from datetime import date
from decimal import Decimal
from typing import Any
from unittest.mock import patch

import numpy as np
import pandas as pd
import pyarrow as pa
import pytest
from pandas.api.types import infer_dtype
from parameterized import parameterized

import streamlit as st
from streamlit import dataframe_util
from tests.delta_generator_test_case import DeltaGeneratorTestCase
from tests.streamlit.data_mocks.snowpandas_mocks import DataFrame as SnowpandasDataFrame
from tests.streamlit.data_mocks.snowpandas_mocks import Index as SnowpandasIndex
from tests.streamlit.data_mocks.snowpandas_mocks import Series as SnowpandasSeries
from tests.streamlit.data_mocks.snowpark_mocks import DataFrame as SnowparkDataFrame
from tests.streamlit.data_mocks.snowpark_mocks import Row as SnowparkRow
from tests.streamlit.data_test_cases import (
    SHARED_TEST_CASES,
    CaseMetadata,
    TestObject,
)
from tests.testutil import create_snowpark_session, patch_config_options


class DataframeUtilTest(unittest.TestCase):
    def test_convert_pandas_df_to_arrow_bytes(self):
        df1 = pd.DataFrame(["foo", "bar"])
        df2 = pd.DataFrame(df1.dtypes)

        try:
            dataframe_util.convert_pandas_df_to_arrow_bytes(df2)
        except Exception as ex:
            self.fail(f"Converting dtype dataframes to Arrow should not fail: {ex}")

    @parameterized.expand(
        SHARED_TEST_CASES,
    )
    def test_convert_anything_to_pandas_df(
        self,
        name: str,
        input_data: Any,
        metadata: CaseMetadata,
    ):
        """Test that `convert_anything_to_pandas_df` correctly converts
        a variety of types to a DataFrame.
        """
        converted_df = dataframe_util.convert_anything_to_pandas_df(input_data)
        self.assertIsInstance(converted_df, pd.DataFrame)
        self.assertEqual(converted_df.shape[0], metadata.expected_rows)
        self.assertEqual(converted_df.shape[1], metadata.expected_cols)

    @parameterized.expand(
        SHARED_TEST_CASES,
    )
    def test_unevaluated_dataframe_handling(
        self,
        name: str,
        input_data: Any,
        metadata: CaseMetadata,
    ):
        """Test that unevaluated data objects are correctly detected and
        handled by limiting the number of rows to be displayed.
        """
        with patch("streamlit.dataframe_util._show_data_information") as mock:
            if metadata.is_unevaluated:
                assert dataframe_util.is_unevaluated_data_object(input_data) is True
                converted_df = dataframe_util.convert_anything_to_pandas_df(
                    input_data, max_unevaluated_rows=1
                )
                assert isinstance(converted_df, pd.DataFrame)
                assert converted_df.shape[0] <= 1
                mock.assert_called_once()
            else:
                assert dataframe_util.is_unevaluated_data_object(input_data) is False
                converted_df = dataframe_util.convert_anything_to_pandas_df(
                    input_data, max_unevaluated_rows=1
                )
                assert converted_df.shape[0] == metadata.expected_rows
                mock.assert_not_called()

    def test_convert_anything_to_pandas_df_ensure_copy(self):
        """Test that `convert_anything_to_pandas_df` creates a copy of the original
        dataframe if `ensure_copy` is True.
        """
        orginal_df = pd.DataFrame(
            {
                "integer": [1, 2, 3],
                "float": [1.0, 2.1, 3.2],
                "string": ["foo", "bar", None],
            },
            index=[1.0, "foo", 3],
        )

        converted_df = dataframe_util.convert_anything_to_pandas_df(
            orginal_df, ensure_copy=True
        )
        # Apply a change
        converted_df["integer"] = [4, 5, 6]
        # Ensure that the original dataframe is not changed
        self.assertEqual(orginal_df["integer"].to_list(), [1, 2, 3])

        converted_df = dataframe_util.convert_anything_to_pandas_df(
            orginal_df, ensure_copy=False
        )
        # Apply a change
        converted_df["integer"] = [4, 5, 6]
        # The original dataframe should be changed here since ensure_copy is False
        self.assertEqual(orginal_df["integer"].to_list(), [4, 5, 6])

    def test_convert_anything_to_pandas_df_supports_key_value_dicts(self):
        """Test that `convert_anything_to_pandas_df` correctly converts
        key-value dicts to a dataframe.
        """
        data = {"a": 1, "b": 2}
        df = dataframe_util.convert_anything_to_pandas_df(data)
        pd.testing.assert_frame_equal(
            df, pd.DataFrame.from_dict(data, orient="index", columns=["value"])
        )

    def test_convert_anything_to_pandas_df_converts_stylers(self):
        """Test that `convert_anything_to_pandas_df` correctly converts Stylers to DF,
        without cloning the data.
        """
        original_df = pd.DataFrame(
            {
                "integer": [1, 2, 3],
                "float": [1.0, 2.1, 3.2],
                "string": ["foo", "bar", None],
            },
            index=[1.0, "foo", 3],
        )

        original_styler = original_df.style.highlight_max(axis=0)

        out = dataframe_util.convert_anything_to_pandas_df(original_styler)
        self.assertNotEqual(id(original_styler), id(out))
        self.assertEqual(id(original_df), id(out))
        pd.testing.assert_frame_equal(original_df, out)

    def test_convert_anything_to_pandas_df_converts_stylers_and_clones_data(self):
        """Test that `convert_anything_to_pandas_df` correctly converts Stylers to DF, cloning the data."""
        original_df = pd.DataFrame(
            {
                "integer": [1, 2, 3],
                "float": [1.0, 2.1, 3.2],
                "string": ["foo", "bar", None],
            },
            index=[1.0, "foo", 3],
        )

        original_styler = original_df.style.highlight_max(axis=0)

        out = dataframe_util.convert_anything_to_pandas_df(
            original_styler, ensure_copy=True
        )
        self.assertNotEqual(id(original_styler), id(out))
        self.assertNotEqual(id(original_df), id(out))
        pd.testing.assert_frame_equal(original_df, out)

    def test_convert_anything_to_pandas_df_calls_to_pandas_when_available(self):
        class DataFrameIsh:
            def to_pandas(self):
                return pd.DataFrame([])

        converted = dataframe_util.convert_anything_to_pandas_df(DataFrameIsh())
        assert isinstance(converted, pd.DataFrame)
        assert converted.empty

    @parameterized.expand(
        SHARED_TEST_CASES,
    )
    def test_convert_anything_to_arrow_bytes(
        self,
        name: str,
        input_data: Any,
        metadata: CaseMetadata,
    ):
        """Test that `convert_anything_to_arrow_bytes` correctly converts
        a variety of types to Arrow bytes.
        """
        converted_bytes = dataframe_util.convert_anything_to_arrow_bytes(input_data)
        self.assertIsInstance(converted_bytes, bytes)

        # Load bytes back into a DataFrame and check the shape.
        reconstructed_df = dataframe_util.convert_arrow_bytes_to_pandas_df(
            converted_bytes
        )
        self.assertEqual(reconstructed_df.shape[0], metadata.expected_rows)
        self.assertEqual(reconstructed_df.shape[1], metadata.expected_cols)

    @parameterized.expand(
        [
            # Complex numbers:
            (pd.Series([1 + 2j, 3 + 4j, 5 + 6 * 1j], dtype=np.complex64), True),
            (pd.Series([1 + 2j, 3 + 4j, 5 + 6 * 1j], dtype=np.complex128), True),
            # Mixed-integer types:
            (pd.Series([1, 2, "3"]), True),
            # Mixed:
            (pd.Series([1, 2.1, "3", True]), True),
            # Frozenset:
            (pd.Series([frozenset([1, 2]), frozenset([3, 4])]), True),
            # Dicts:
            (pd.Series([{"a": 1}, {"b": 2}]), True),
            # Complex types:
            (pd.Series([TestObject(), TestObject()]), True),
            # Supported types:
            (pd.Series([1, 2, 3]), False),
            (pd.Series([1, 2, 3.0]), False),
            (pd.Series(["foo", "bar"]), False),
            (pd.Series([True, False, None]), False),
            (pd.Series(["foo", "bar", None]), False),
            (pd.Series([[1, 2], [3, 4]]), False),
            (pd.Series(["a", "b", "c", "a"], dtype="category"), False),
            (pd.Series([date(2020, 1, 1), date(2020, 1, 2)]), False),
            (pd.Series([Decimal("1.1"), Decimal("2.2")]), False),
            (pd.Series([np.timedelta64(1, "D"), np.timedelta64(2, "D")]), False),
            (pd.Series([pd.Timedelta("1 days"), pd.Timedelta("2 days")]), False),
        ]
    )
    def test_is_colum_type_arrow_incompatible(
        self, column: pd.Series, incompatible: bool
    ):
        self.assertEqual(
            dataframe_util.is_colum_type_arrow_incompatible(column),
            incompatible,
            f"Expected {column} to be {'incompatible' if incompatible else 'compatible'} with Arrow.",
        )

    @parameterized.expand(
        [
            # Complex numbers:
            (pd.Series([1 + 2j, 3 + 4j, 5 + 6 * 1j]), True),
            # Mixed-integer types:
            (pd.Series([1, 2, "3"]), True),
            # Mixed:
            (pd.Series([1, 2.1, "3", True]), True),  # Frozenset:
            (pd.Series([frozenset([1, 2]), frozenset([3, 4])]), True),
            # Dicts:
            (pd.Series([{"a": 1}, {"b": 2}]), True),
            # Complex types:
            (pd.Series([TestObject(), TestObject()]), True),
            # Supported types:
            (pd.Series([1, 2, 3]), False),
            (pd.Series([1, 2, 3.0]), False),
            (pd.Series(["foo", "bar"]), False),
            (pd.Series([True, False, None]), False),
            (pd.Series(["foo", "bar", None]), False),
            (pd.Series([[1, 2], [3, 4]]), False),
            (pd.Series(["a", "b", "c", "a"], dtype="category"), False),
            (pd.Series([date(2020, 1, 1), date(2020, 1, 2)]), False),
            (pd.Series([Decimal("1.1"), Decimal("2.2")]), False),
            (pd.Series([pd.Timedelta("1 days"), pd.Timedelta("2 days")]), False),
            (pd.Series([np.timedelta64(1, "D"), np.timedelta64(2, "D")]), False),
        ]
    )
    def test_fix_arrow_incompatible_column_types(
        self, column: pd.Series, incompatible: bool
    ):
        """Test that `fix_arrow_incompatible_column_types` correctly fixes
        columns containing unsupported types by converting them to string and
        leaves supported columns unchanged.
        """
        df = pd.DataFrame({"c1": column})
        fixed_df = dataframe_util.fix_arrow_incompatible_column_types(df)
        col_dtype = fixed_df["c1"].dtype
        inferred_type = infer_dtype(fixed_df["c1"])

        if incompatible:
            # Column should have been converted to string.
            self.assertIsInstance(col_dtype, pd.StringDtype)
            self.assertEqual(inferred_type, "string")
        else:
            # Column should have the original type.
            self.assertEqual(col_dtype, df["c1"].dtype)
            self.assertEqual(inferred_type, infer_dtype(df["c1"]))

    def test_fix_no_columns(self):
        """Test that `fix_arrow_incompatible_column_types` does not
        modify a DataFrame if all columns are compatible with Arrow.
        """

        df = pd.DataFrame(
            {
                "integer": [1, 2, 3],
                "float": [1.1, 2.2, 3.3],
                "string": ["foo", "bar", None],
                "boolean": [True, False, None],
            }
        )

        fixed_df = dataframe_util.fix_arrow_incompatible_column_types(df)
        pd.testing.assert_frame_equal(df, fixed_df)

    def test_fix_mixed_column_types(self):
        """Test that `fix_arrow_incompatible_column_types` correctly fixes
        columns containing mixed types by converting them to string.
        """
        df = pd.DataFrame(
            {
                "mixed-integer": [1, "foo", 3],
                "mixed": [1.0, "foo", 3],
                "integer": [1, 2, 3],
                "float": [1.0, 2.1, 3.2],
                "string": ["foo", "bar", None],
            },
            index=[1.0, "foo", 3],
        )

        fixed_df = dataframe_util.fix_arrow_incompatible_column_types(df)

        # Check dtypes
        self.assertIsInstance(fixed_df["mixed-integer"].dtype, pd.StringDtype)
        self.assertIsInstance(fixed_df["mixed"].dtype, pd.StringDtype)
        self.assertTrue(pd.api.types.is_integer_dtype(fixed_df["integer"].dtype))
        self.assertTrue(pd.api.types.is_float_dtype(fixed_df["float"].dtype))
        self.assertTrue(pd.api.types.is_object_dtype(fixed_df["string"].dtype))
        self.assertEqual(fixed_df.index.dtype.kind, "O")

        # Check inferred types:
        self.assertEqual(infer_dtype(fixed_df["mixed-integer"]), "string")
        self.assertEqual(infer_dtype(fixed_df["mixed"]), "string")
        self.assertEqual(infer_dtype(fixed_df["integer"]), "integer")
        self.assertEqual(infer_dtype(fixed_df["float"]), "floating")
        self.assertEqual(infer_dtype(fixed_df["string"]), "string")
        self.assertEqual(infer_dtype(fixed_df.index), "string")

    def test_data_frame_with_unsupported_column_types(self):
        """Test that `data_frame_to_bytes` correctly handles dataframes
        with unsupported column types by converting those types to string.
        """
        df = pd.DataFrame(
            {
                "mixed-integer": [1, "foo", 3],
                "mixed": [1.0, "foo", 3],
                "complex": [1 + 2j, 3 + 4j, 5 + 6 * 1j],
                "integer": [1, 2, 3],
                "float": [1.0, 2.1, 3.2],
                "string": ["foo", "bar", None],
            },
            index=[1.0, "foo", 3],
        )

        try:
            dataframe_util.convert_pandas_df_to_arrow_bytes(df)
        except Exception as ex:
            self.fail(
                "No exception should have been thrown here. "
                f"Unsupported types of this dataframe should have been automatically fixed: {ex}"
            )

    def test_is_pandas_data_object(self):
        """Test that `is_pandas_data_object` correctly detects pandas data objects."""
        assert dataframe_util.is_pandas_data_object(pd.DataFrame()) is True
        assert dataframe_util.is_pandas_data_object(pd.Series()) is True
        assert dataframe_util.is_pandas_data_object(pd.Index(["a", "b"])) is True
        assert dataframe_util.is_pandas_data_object(pd.array(["a", "b"])) is True
        assert dataframe_util.is_pandas_data_object(["a", "b"]) is False

    def test_is_snowpandas_data_object(self):
        df = pd.DataFrame([1, 2, 3])

        self.assertFalse(dataframe_util.is_snowpandas_data_object(df))

        # Our mock objects should be detected as snowpandas data objects:
        self.assertTrue(
            dataframe_util.is_snowpandas_data_object(SnowpandasDataFrame(df))
        )
        self.assertTrue(dataframe_util.is_snowpandas_data_object(SnowpandasSeries(df)))
        self.assertTrue(dataframe_util.is_snowpandas_data_object(SnowpandasIndex(df)))

    def test_is_snowpark_row_list(self):
        class DummyClass:
            """DummyClass for testing purposes"""

        # empty list should not be snowpark dataframe
        self.assertFalse(dataframe_util.is_snowpark_row_list([]))

        # list with items should not be snowpark dataframe
        self.assertFalse(
            dataframe_util.is_snowpark_row_list(
                [
                    "any text",
                ]
            )
        )
        self.assertFalse(
            dataframe_util.is_snowpark_row_list(
                [
                    123,
                ]
            )
        )
        self.assertFalse(
            dataframe_util.is_snowpark_row_list(
                [
                    DummyClass(),
                ]
            )
        )

        # list with SnowparkRow should be SnowparkDataframe
        self.assertTrue(
            dataframe_util.is_snowpark_row_list(
                [
                    SnowparkRow({"col1": 1, "col2": "foo"}),
                    SnowparkRow({"col1": 2, "col2": "bar"}),
                ]
            )
        )

    def test_is_snowpark_dataframe(self):
        df = pd.DataFrame(
            {
                "mixed-integer": [1, "foo", 3],
                "mixed": [1.0, "foo", 3],
                "complex": [1 + 2j, 3 + 4j, 5 + 6 * 1j],
                "integer": [1, 2, 3],
                "float": [1.0, 2.1, 3.2],
                "string": ["foo", "bar", None],
            },
            index=[1.0, "foo", 3],
        )

        # pandas dataframe should not be SnowparkDataFrame
        self.assertFalse(dataframe_util.is_snowpark_data_object(df))

        # if snowflake.snowpark.dataframe.DataFrame def is_snowpark_data_object should return true
        self.assertTrue(dataframe_util.is_snowpark_data_object(SnowparkDataFrame(df)))

    def test_verify_sqlite3_integration(self):
        """Verify that sqlite3 cursor can be used as a data source."""
        import sqlite3

        con = sqlite3.connect("file::memory:")
        cur = con.cursor()
        cur.execute("CREATE TABLE movie(title, year, score)")
        cur.execute("""
            INSERT INTO movie VALUES
                ('Monty Python and the Holy Grail', 1975, 8.2),
                ('And Now for Something Completely Different', 1971, 7.5)
        """)
        con.commit()
        db_cursor = cur.execute("SELECT * FROM movie")
        assert dataframe_util.is_dbapi_cursor(db_cursor) is True
        assert (
            dataframe_util.determine_data_format(db_cursor)
            is dataframe_util.DataFormat.DBAPI_CURSOR
        )
        converted_df = dataframe_util.convert_anything_to_pandas_df(db_cursor)
        assert isinstance(
            converted_df,
            pd.DataFrame,
        )
        assert converted_df.shape == (2, 3)
        con.close()

    @pytest.mark.require_integration
    def test_verify_duckdb_db_api_integration(self):
        """Test that duckdb cursor can be used as a data source.

        https://duckdb.org/docs/api/python/dbapi
        """
        import duckdb

        con = duckdb.connect(database=":memory:")
        con.execute(
            "CREATE TABLE items (item VARCHAR, value DECIMAL(10, 2), count INTEGER)"
        )
        con.execute("INSERT INTO items VALUES ('jeans', 20.0, 1), ('hammer', 42.2, 2)")
        con.execute("SELECT * FROM items")

        assert dataframe_util.is_dbapi_cursor(con) is True
        assert (
            dataframe_util.determine_data_format(con)
            is dataframe_util.DataFormat.DBAPI_CURSOR
        )
        converted_df = dataframe_util.convert_anything_to_pandas_df(con)
        assert isinstance(
            converted_df,
            pd.DataFrame,
        )
        assert converted_df.shape == (2, 3)
        con.close()

    @pytest.mark.require_integration
    def test_verify_duckdb_relational_api_integration(self):
        """Test that duckdb relational API can be used as a data source.

        https://duckdb.org/docs/api/python/relational_api
        """
        import duckdb

        items = pd.DataFrame([["foo", 1], ["bar", 2]], columns=["name", "value"])
        db_relation = duckdb.sql("SELECT * from items")
        assert dataframe_util.is_duckdb_relation(db_relation) is True
        assert (
            dataframe_util.determine_data_format(db_relation)
            is dataframe_util.DataFormat.DUCKDB_RELATION
        )
        converted_df = dataframe_util.convert_anything_to_pandas_df(db_relation)
        assert isinstance(
            converted_df,
            pd.DataFrame,
        )
        assert converted_df.shape == items.shape

    @pytest.mark.require_integration
    def test_verify_snowpark_integration(self):
        """Integration test snowpark object handling.
        This is in addition to the tests using the mocks to verify that
        the latest version of the library is still supported.
        """
        with create_snowpark_session() as snowpark_session:
            snowpark_df = snowpark_session.sql("SELECT 40+2 as COL1")

            assert dataframe_util.is_snowpark_data_object(snowpark_df) is True
            assert isinstance(
                dataframe_util.convert_anything_to_pandas_df(snowpark_df),
                pd.DataFrame,
            )

            snowpark_cached_result = snowpark_session.sql(
                "SELECT 40+2 as COL1"
            ).cache_result()
            assert (
                dataframe_util.is_snowpark_data_object(snowpark_cached_result) is True
            )
            assert isinstance(
                dataframe_util.convert_anything_to_pandas_df(snowpark_cached_result),
                pd.DataFrame,
            )

            snowpark_row_list = snowpark_session.sql("SELECT 40+2 as COL1").collect()
            assert dataframe_util.is_snowpark_row_list(snowpark_row_list) is True
            assert isinstance(
                dataframe_util.convert_anything_to_pandas_df(snowpark_row_list),
                pd.DataFrame,
            )

    @pytest.mark.require_integration
    def test_verify_dask_integration(self):
        """Integration test dask object handling.

        This is in addition to the tests using the mocks to verify that
        the latest version of the library is still supported.
        """
        import dask

        dask_df = dask.datasets.timeseries()

        assert dataframe_util.is_dask_object(dask_df) is True
        assert isinstance(
            dataframe_util.convert_anything_to_pandas_df(dask_df),
            pd.DataFrame,
        )

        dask_series = dask_df["x"]
        assert dataframe_util.is_dask_object(dask_series) is True
        assert isinstance(
            dataframe_util.convert_anything_to_pandas_df(dask_series),
            pd.DataFrame,
        )

        dask_index = dask_df.index
        assert dataframe_util.is_dask_object(dask_index) is True
        assert isinstance(
            dataframe_util.convert_anything_to_pandas_df(dask_index),
            pd.DataFrame,
        )

    @pytest.mark.require_integration
    def test_verify_ray_integration(self):
        """Integration test ray object handling.

        This is in addition to the tests using the mocks to verify that
        the latest version of the library is still supported.
        """
        import ray

        df = pd.DataFrame({"a": [1, 2, 3], "b": [4, 5, 6]})
        ray_dataset = ray.data.from_pandas(df)

        assert dataframe_util.is_ray_dataset(ray_dataset) is True
        assert isinstance(
            dataframe_util.convert_anything_to_pandas_df(ray_dataset),
            pd.DataFrame,
        )

    @parameterized.expand(
        SHARED_TEST_CASES,
    )
    def test_determine_data_format(
        self,
        name: str,
        input_data: Any,
        metadata: CaseMetadata,
    ):
        """Test that `determine_data_format` correctly determines the
        data format of a variety of data structures/types.
        """
        data_format = dataframe_util.determine_data_format(input_data)
        self.assertEqual(
            data_format,
            metadata.expected_data_format,
            f"{str(input_data)} is expected to be {metadata.expected_data_format} but was {data_format}.",
        )

    @parameterized.expand(
        SHARED_TEST_CASES,
    )
    def test_convert_pandas_df_to_data_format(
        self,
        name: str,
        input_data: Any,
        metadata: CaseMetadata,
    ):
        """Test that `convert_pandas_df_to_data_format` correctly converts a
        DataFrame to the specified data format.
        """
        converted_df = dataframe_util.convert_anything_to_pandas_df(input_data)
        self.assertEqual(converted_df.shape[0], metadata.expected_rows)
        self.assertEqual(converted_df.shape[1], metadata.expected_cols)

        if metadata.expected_data_format == dataframe_util.DataFormat.UNKNOWN:
            with self.assertRaises(ValueError):
                dataframe_util.convert_pandas_df_to_data_format(
                    converted_df, metadata.expected_data_format
                )
            # We don't have to do any other tests for unknown data formats.
        else:
            converted_data = dataframe_util.convert_pandas_df_to_data_format(
                converted_df, metadata.expected_data_format
            )

            self.assertEqual(
                type(converted_data),
                type(input_data)
                if metadata.expected_type is None
                else metadata.expected_type,
            )

            if isinstance(converted_data, pd.DataFrame):
                self.assertEqual(converted_data.shape[0], metadata.expected_rows)
                self.assertEqual(converted_data.shape[1], metadata.expected_cols)
            elif (
                # Sets in python are unordered, so we can't compare them this way.
                metadata.expected_data_format != dataframe_util.DataFormat.SET_OF_VALUES
                and metadata.expected_type is None
            ):
                self.assertEqual(str(converted_data), str(input_data))
                pd.testing.assert_frame_equal(
                    converted_df,
                    dataframe_util.convert_anything_to_pandas_df(converted_data),
                )

    def test_convert_pandas_df_to_data_format_with_unknown_data_format(self):
        """Test that `convert_df_to_data_format` raises a ValueError when
        passed an unknown data format.
        """
        with self.assertRaises(ValueError):
            dataframe_util.convert_pandas_df_to_data_format(
                pd.DataFrame({"a": [1, 2, 3]}), dataframe_util.DataFormat.UNKNOWN
            )

    def test_convert_df_with_missing_values(self):
        """Test that `convert_df_to_data_format` correctly converts
        all types of missing values to None.
        """

        # Add dataframe with different missing values:
        df = pd.DataFrame(
            {
                "missing": [None, pd.NA, np.nan, pd.NaT],
            }
        )

        self.assertEqual(
            dataframe_util.convert_pandas_df_to_data_format(
                df, dataframe_util.DataFormat.LIST_OF_VALUES
            ),
            [None, None, None, None],
        )
        self.assertEqual(
            dataframe_util.convert_pandas_df_to_data_format(
                df, dataframe_util.DataFormat.TUPLE_OF_VALUES
            ),
            (None, None, None, None),
        )
        self.assertEqual(
            dataframe_util.convert_pandas_df_to_data_format(
                df, dataframe_util.DataFormat.SET_OF_VALUES
            ),
            {None},
        )
        self.assertEqual(
            dataframe_util.convert_pandas_df_to_data_format(
                df, dataframe_util.DataFormat.LIST_OF_ROWS
            ),
            [
                [None],
                [None],
                [None],
                [None],
            ],
        )
        self.assertEqual(
            dataframe_util.convert_pandas_df_to_data_format(
                df, dataframe_util.DataFormat.LIST_OF_RECORDS
            ),
            [
                {"missing": None},
                {"missing": None},
                {"missing": None},
                {"missing": None},
            ],
        )
        self.assertEqual(
            dataframe_util.convert_pandas_df_to_data_format(
                df, dataframe_util.DataFormat.COLUMN_VALUE_MAPPING
            ),
            {
                "missing": [None, None, None, None],
            },
        )
        self.assertEqual(
            dataframe_util.convert_pandas_df_to_data_format(
                df, dataframe_util.DataFormat.COLUMN_INDEX_MAPPING
            ),
            {"missing": {0: None, 1: None, 2: None, 3: None}},
        )
        self.assertEqual(
            dataframe_util.convert_pandas_df_to_data_format(
                df, dataframe_util.DataFormat.KEY_VALUE_DICT
            ),
            {0: None, 1: None, 2: None, 3: None},
        )

    def test_convert_anything_to_sequence_object_is_indexable(self):
        l1 = ["a", "b", "c"]
        l2 = dataframe_util.convert_anything_to_list(l1)

        # Assert that l1 was shallow copied into l2.
        self.assertFalse(l1 is l2)
        self.assertEqual(l1, l2)

    def test_convert_anything_to_sequence_object_not_indexable(self):
        converted_list = dataframe_util.convert_anything_to_list({"a", "b", "c"})
        self.assertIn("a", converted_list)
        self.assertIn("b", converted_list)
        self.assertIn("c", converted_list)

    def test_convert_anything_to_sequence_enum_is_indexable(self):
        """Test Enums are indexable"""

        class Opt(enum.Enum):
            OPT1 = 1
            OPT2 = 2

        class StrOpt(str, enum.Enum):
            OPT1 = "a"
            OPT2 = "b"

        converted_list = dataframe_util.convert_anything_to_list(Opt)
        self.assertEqual(list(Opt), converted_list)

        converted_list = dataframe_util.convert_anything_to_list(StrOpt)
        self.assertEqual(list(StrOpt), converted_list)

    @parameterized.expand(
        SHARED_TEST_CASES,
    )
    def test_convert_anything_to_sequence(
        self,
        name: str,
        input_data: Any,
        metadata: CaseMetadata,
    ):
        """Test that `convert_anything_to_sequence` correctly converts
        a variety of types to a sequence.
        """
        converted_sequence = dataframe_util.convert_anything_to_list(input_data)

        # We convert to a set for the check since some of the formats don't
        # have a guaranteed order.
        assert {str(item) for item in converted_sequence} == {
            str(item) for item in metadata.expected_sequence
        }
        # Check that it is a new object and not the same as the input:
        assert converted_sequence is not input_data


class TestArrowTruncation(DeltaGeneratorTestCase):
    """Test class for the automatic arrow truncation feature."""

    @patch_config_options(
        {"server.maxMessageSize": 3, "server.enableArrowTruncation": True}
    )
    def test_truncate_larger_table(self):
        """Test that `_maybe_truncate_table` correctly truncates a table that is
        larger than the max message size.
        """
        col_data = list(range(200000))
        original_df = pd.DataFrame(
            {
                "col 1": col_data,
                "col 2": col_data,
                "col 3": col_data,
            }
        )

        original_table = pa.Table.from_pandas(original_df)
        truncated_table = dataframe_util._maybe_truncate_table(
            pa.Table.from_pandas(original_df)
        )
        # Should be under the configured 3MB limit:
        self.assertLess(truncated_table.nbytes, 3 * int(1e6))

        # Test that the table should have been truncated
        self.assertLess(truncated_table.nbytes, original_table.nbytes)
        self.assertLess(truncated_table.num_rows, original_table.num_rows)

        # Test that it prints out a caption test:
        el = self.get_delta_from_queue().new_element
        self.assertIn("due to data size limitations", el.markdown.body)
        self.assertTrue(el.markdown.is_caption)

    @patch_config_options(
        {"server.maxMessageSize": 3, "server.enableArrowTruncation": True}
    )
    def test_dont_truncate_smaller_table(self):
        """Test that `_maybe_truncate_table` doesn't truncate smaller tables."""
        col_data = list(range(100))
        original_df = pd.DataFrame(
            {
                "col 1": col_data,
                "col 2": col_data,
                "col 3": col_data,
            }
        )

        original_table = pa.Table.from_pandas(original_df)
        truncated_table = dataframe_util._maybe_truncate_table(
            pa.Table.from_pandas(original_df)
        )

        # Test that the tables are the same:
        self.assertEqual(truncated_table.nbytes, original_table.nbytes)
        self.assertEqual(truncated_table.num_rows, original_table.num_rows)

    @patch_config_options({"server.enableArrowTruncation": False})
    def test_dont_truncate_if_deactivated(self):
        """Test that `_maybe_truncate_table` doesn't do anything
        when server.enableArrowTruncation is decatived
        """
        col_data = list(range(200000))
        original_df = pd.DataFrame(
            {
                "col 1": col_data,
                "col 2": col_data,
                "col 3": col_data,
            }
        )

        original_table = pa.Table.from_pandas(original_df)
        truncated_table = dataframe_util._maybe_truncate_table(
            pa.Table.from_pandas(original_df)
        )

        # Test that the tables are the same:
        self.assertEqual(truncated_table.nbytes, original_table.nbytes)
        self.assertEqual(truncated_table.num_rows, original_table.num_rows)

    @patch_config_options(
        {"server.maxMessageSize": 3, "server.enableArrowTruncation": True}
    )
    def test_st_dataframe_truncates_data(self):
        """Test that `st.dataframe` truncates the data if server.enableArrowTruncation==True."""
        col_data = list(range(200000))
        original_df = pd.DataFrame(
            {
                "col 1": col_data,
                "col 2": col_data,
                "col 3": col_data,
            }
        )
        original_table = pa.Table.from_pandas(original_df)
        st.dataframe(original_df)
        el = self.get_delta_from_queue().new_element
        # Test that table bytes should be smaller than the full table
        self.assertLess(len(el.arrow_data_frame.data), original_table.nbytes)
        # Should be under the configured 3MB limit:
        self.assertLess(len(el.arrow_data_frame.data), 3 * int(1e6))

        # Test that it prints out a caption test:
        el = self.get_delta_from_queue(-2).new_element
        self.assertIn("due to data size limitations", el.markdown.body)
        self.assertTrue(el.markdown.is_caption)


================================================
File: /lib/tests/streamlit/delta_generator_singletons_test.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import unittest

import streamlit as st
from streamlit.delta_generator import DeltaGenerator
from streamlit.delta_generator_singletons import (
    context_dg_stack,
    get_default_dg_stack_value,
    get_dg_singleton_instance,
    get_last_dg_added_to_context_stack,
)
from streamlit.proto.RootContainer_pb2 import RootContainer


class DeltaGeneratorSingletonsTest(unittest.TestCase):
    def test_get_last_dg_added_to_context_stack(self):
        last_dg_added_to_context_stack = get_last_dg_added_to_context_stack()
        assert last_dg_added_to_context_stack is None

        sidebar = st.sidebar
        with sidebar:
            last_dg_added_to_context_stack = get_last_dg_added_to_context_stack()
            assert sidebar == last_dg_added_to_context_stack
        last_dg_added_to_context_stack = get_last_dg_added_to_context_stack()
        assert sidebar != last_dg_added_to_context_stack

    def test_context_dg_stack(self):
        dg_stack = context_dg_stack.get()
        assert get_default_dg_stack_value() == dg_stack
        assert len(dg_stack) == 1

        new_dg = DeltaGenerator(
            root_container=RootContainer.MAIN,
            parent=get_dg_singleton_instance().main_dg,
        )
        token = context_dg_stack.set(context_dg_stack.get() + (new_dg,))

        # get the updated dg_stack for current context
        dg_stack = context_dg_stack.get()
        assert len(dg_stack) == 2

        # reset for the other tests
        context_dg_stack.reset(token)
        dg_stack = context_dg_stack.get()
        assert len(dg_stack) == 1


class DeltaGeneratorSingletonsVariablesAreInitializedTest(unittest.TestCase):
    """dg variables are initialized by Streamlit.__init__.py"""

    def test_main_dg_is_initialized(self):
        assert get_dg_singleton_instance().main_dg is not None

    def test_sidebar_dg_is_initialized(self):
        assert get_dg_singleton_instance().sidebar_dg is not None

    def test_event_dg_is_initialized(self):
        assert get_dg_singleton_instance().event_dg is not None

    def test_bottom_dg_is_initialized(self):
        assert get_dg_singleton_instance().bottom_dg is not None

    def test_create_status_container_is_initialized(self):
        assert get_dg_singleton_instance().status_container_cls is not None

    def test_create_dialog_is_initialized(self):
        assert get_dg_singleton_instance().dialog_container_cls is not None


================================================
File: /lib/tests/streamlit/delta_generator_test.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""DeltaGenerator Unittest."""

from __future__ import annotations

import asyncio
import functools
import inspect
import json
import logging
import re
import threading
import unittest
from copy import deepcopy
from unittest.mock import MagicMock, patch

import pytest
from parameterized import parameterized

import streamlit as st
import streamlit.delta_generator as delta_generator
import streamlit.runtime.state.widgets as w
from streamlit.cursor import LockedCursor, make_delta_path
from streamlit.delta_generator import DeltaGenerator
from streamlit.delta_generator_singletons import get_dg_singleton_instance
from streamlit.elements.lib.utils import compute_and_register_element_id
from streamlit.errors import (
    StreamlitAPIException,
    StreamlitDuplicateElementId,
    StreamlitDuplicateElementKey,
)
from streamlit.logger import get_logger
from streamlit.proto.Empty_pb2 import Empty as EmptyProto
from streamlit.proto.RootContainer_pb2 import RootContainer
from streamlit.proto.Text_pb2 import Text as TextProto
from streamlit.runtime.scriptrunner import add_script_run_ctx, get_script_run_ctx
from tests.delta_generator_test_case import DeltaGeneratorTestCase
from tests.streamlit.streamlit_test import ELEMENT_COMMANDS


def identity(x):
    return x


register_widget = functools.partial(
    w.register_widget, deserializer=lambda x, s: x, serializer=identity
)


class RunWarningTest(unittest.TestCase):
    @patch("streamlit.runtime.Runtime.exists", MagicMock(return_value=False))
    def test_run_warning_presence(self):
        """Using Streamlit without `streamlit run` produces a warning."""
        with self.assertLogs("streamlit", level=logging.WARNING) as logs:
            delta_generator._use_warning_has_been_displayed = False
            st.write("Using delta generator")
            output = "".join(logs.output)
            # Warning produced exactly once
            self.assertEqual(len(re.findall(r"streamlit run", output)), 1)

    @patch("streamlit.runtime.Runtime.exists", MagicMock(return_value=True))
    def test_run_warning_absence(self):
        """Using Streamlit through the CLI results in a Runtime being instantiated,
        so it produces no usage warning."""
        with self.assertLogs("streamlit", level=logging.WARNING) as logs:
            delta_generator._use_warning_has_been_displayed = False
            st.write("Using delta generator")
            # assertLogs is being used as a context manager, but it also checks
            # that some log output was captured, so we have to let it capture something
            get_logger("root").warning("irrelevant warning so assertLogs passes")
            self.assertNotRegex("".join(logs.output), r"streamlit run")

    def test_public_api(self):
        """Test that we don't accidentally remove (or add) symbols
        to the public `DeltaGenerator` API.
        """
        api = {
            name
            for name, _ in inspect.getmembers(DeltaGenerator)
            if not name.startswith("_")
        }
        expected_api = ELEMENT_COMMANDS.copy()

        # Remove commands that are only exposed in the top-level namespace (st.*)
        # and cannot be called on a DeltaGenerator object.
        expected_api = expected_api - {
            "spinner",
            "dialog",
            "experimental_dialog",
            "echo",
            "logo",
            "login",
            "logout",
        }

        # Add public commands that only exist in the delta generator:
        expected_api = expected_api.union({"add_rows", "id", "dg"})

        self.assertEqual(api, expected_api)


class DeltaGeneratorTest(DeltaGeneratorTestCase):
    """Test streamlit.delta_generator methods."""

    def test_nonexistent_method(self):
        with self.assertRaises(Exception) as ctx:
            st.sidebar.non_existing()

        self.assertEqual(
            str(ctx.exception), "`non_existing()` is not a valid Streamlit command."
        )

    def test_sidebar_nonexistent_method(self):
        with self.assertRaises(Exception) as ctx:
            st.sidebar.echo()

        self.assertEqual(
            str(ctx.exception),
            "Method `echo()` does not exist for `st.sidebar`. "
            "Did you mean `st.echo()`?",
        )

    def set_widget_requires_args(self):
        st.text_input()
        c = self.get_delta_from_queue().new_element.exception
        self.assertEqual(c.type, "TypeError")

    def test_duplicate_widget_id_error(self):
        """Multiple widgets with the same generated key should report an error."""
        widgets = {
            "button": lambda key=None: st.button("", key=key),
            "button_group": lambda key=None: st.feedback("thumbs", key=key),
            "checkbox": lambda key=None: st.checkbox("", key=key),
            "multiselect": lambda key=None: st.multiselect("", options=[1, 2], key=key),
            "radio": lambda key=None: st.radio("", options=[1, 2], key=key),
            "selectbox": lambda key=None: st.selectbox("", options=[1, 2], key=key),
            "slider": lambda key=None: st.slider("", key=key),
            "text_area": lambda key=None: st.text_area("", key=key),
            "text_input": lambda key=None: st.text_input("", key=key),
            "time_input": lambda key=None: st.time_input("", key=key),
            "date_input": lambda key=None: st.date_input("", key=key),
            "number_input": lambda key=None: st.number_input("", key=key),
        }

        for _, create_widget in widgets.items():
            create_widget()
            with self.assertRaises(StreamlitDuplicateElementId):
                # Test creating a widget with a duplicate c
                # raises an exception.
                create_widget()

        for widget_type, create_widget in widgets.items():
            # widgets with keys are distinct from the unkeyed ones created above
            create_widget(widget_type)
            with self.assertRaises(StreamlitDuplicateElementKey):
                # Test creating a widget with a duplicate key
                # raises an exception.
                create_widget(widget_type)

    def test_duplicate_widget_id_error_when_user_key_specified(self):
        """Multiple widgets with the different generated key, but same user specified
        key should report an error.
        """

        widgets = {
            "button": lambda key=None, label="": st.button(label=label, key=key),
            "checkbox": lambda key=None, label="": st.checkbox(label=label, key=key),
            "feedback": lambda key=None, label="": st.feedback(
                options="thumbs", key=key
            ),
            "multiselect": lambda key=None, label="": st.multiselect(
                label=label, options=[1, 2], key=key
            ),
            "radio": lambda key=None, label="": st.radio(
                label=label, options=[1, 2], key=key
            ),
            "selectbox": lambda key=None, label="": st.selectbox(
                label=label, options=[1, 2], key=key
            ),
            "slider": lambda key=None, label="": st.slider(label=label, key=key),
            "text_area": lambda key=None, label="": st.text_area(label=label, key=key),
            "text_input": lambda key=None, label="": st.text_input(
                label=label, key=key
            ),
            "time_input": lambda key=None, label="": st.time_input(
                label=label, key=key
            ),
            "date_input": lambda key=None, label="": st.date_input(
                label=label, key=key
            ),
            "number_input": lambda key=None, label="": st.number_input(
                label=label, key=key
            ),
        }

        for widget_type, create_widget in widgets.items():
            user_key = widget_type
            create_widget(label="LABEL_A", key=user_key)
            with self.assertRaises(StreamlitDuplicateElementKey):
                # We specify different labels for widgets, so auto-generated keys
                # (widget_ids) will be different.
                # Test creating a widget with a different auto-generated key but same
                # user specified key raises an exception.
                create_widget(label="LABEL_B", key=user_key)


class DeltaGeneratorClassTest(DeltaGeneratorTestCase):
    """Test DeltaGenerator Class."""

    def test_constructor(self):
        """Test default DeltaGenerator()."""
        dg = DeltaGenerator()
        self.assertFalse(dg._cursor.is_locked)
        self.assertEqual(dg._cursor.index, 0)

    def test_constructor_with_id(self):
        """Test DeltaGenerator() with an id."""
        cursor = LockedCursor(root_container=RootContainer.MAIN, index=1234)
        dg = DeltaGenerator(root_container=RootContainer.MAIN, cursor=cursor)
        self.assertTrue(dg._cursor.is_locked)
        self.assertEqual(dg._cursor.index, 1234)

    def test_can_deepcopy_delta_generators(self):
        cursor = LockedCursor(root_container=RootContainer.MAIN, index=1234)
        dg1 = DeltaGenerator(root_container=RootContainer.MAIN, cursor=cursor)
        dg2 = deepcopy(dg1)

        self.assertEqual(dg1._root_container, dg2._root_container)
        self.assertIsNone(dg1._parent)
        self.assertIsNone(dg2._parent)
        self.assertEqual(dg1._block_type, dg2._block_type)

        # Check that the internals of the Cursors look the same. Note the cursors
        # themselves will be different objects so won't compare equal.
        c1 = dg1._cursor
        c2 = dg2._cursor
        self.assertIsInstance(c1, LockedCursor)
        self.assertIsInstance(c2, LockedCursor)
        self.assertEqual(c1._root_container, c2._root_container)
        self.assertEqual(c1._index, c2._index)
        self.assertEqual(c1._parent_path, c2._parent_path)
        self.assertEqual(c1._props, c2._props)

    def test_enqueue_null(self):
        # Test "Null" Delta generators
        dg = DeltaGenerator(root_container=None)
        new_dg = dg._enqueue("empty", EmptyProto())
        self.assertEqual(dg, new_dg)

    @parameterized.expand([(RootContainer.MAIN,), (RootContainer.SIDEBAR,)])
    def test_enqueue(self, container):
        dg = DeltaGenerator(root_container=container)
        self.assertEqual(0, dg._cursor.index)
        self.assertEqual(container, dg._root_container)

        test_data = "some test data"
        text_proto = TextProto()
        text_proto.body = test_data
        new_dg = dg._enqueue("text", text_proto)

        self.assertNotEqual(dg, new_dg)
        self.assertEqual(1, dg._cursor.index)
        self.assertEqual(container, new_dg._root_container)

        delta = self.get_delta_from_queue()
        element = delta.new_element
        self.assertEqual(delta.fragment_id, "")
        self.assertEqual(element.text.body, test_data)

    def test_enqueue_same_id(self):
        cursor = LockedCursor(root_container=RootContainer.MAIN, index=123)
        dg = DeltaGenerator(root_container=RootContainer.MAIN, cursor=cursor)
        self.assertEqual(123, dg._cursor.index)

        test_data = "some test data"
        text_proto = TextProto()
        text_proto.body = test_data
        new_dg = dg._enqueue("text", text_proto)

        self.assertEqual(dg._cursor, new_dg._cursor)

        msg = self.get_message_from_queue()
        # The last element in delta_path is the delta's index in its container.
        self.assertEqual(
            make_delta_path(RootContainer.MAIN, (), 123), msg.metadata.delta_path
        )
        self.assertEqual(msg.delta.new_element.text.body, test_data)

    def test_enqueue_adds_fragment_id_to_delta_if_set(self):
        ctx = get_script_run_ctx()
        ctx.current_fragment_id = "my_fragment_id"

        dg = DeltaGenerator(root_container=RootContainer.MAIN)
        dg._enqueue("text", TextProto())

        delta = self.get_delta_from_queue()
        self.assertEqual(delta.fragment_id, "my_fragment_id")

    def test_enqueue_explodes_if_fragment_writes_to_sidebar(self):
        ctx = get_script_run_ctx()
        ctx.current_fragment_id = "my_fragment_id"
        ctx.fragment_ids_this_run = ["my_fragment_id"]

        exc = "is not supported"
        with pytest.raises(StreamlitAPIException, match=exc):
            get_dg_singleton_instance().sidebar_dg._enqueue("text", TextProto())

    def test_enqueue_can_write_to_container_in_sidebar(self):
        ctx = get_script_run_ctx()
        ctx.current_fragment_id = "my_fragment_id"
        ctx.fragment_ids_this_run = ["my_fragment_id"]

        get_dg_singleton_instance().sidebar_dg.container().write("Hello world")

        deltas = self.get_all_deltas_from_queue()
        assert [d.fragment_id for d in deltas] == ["my_fragment_id", "my_fragment_id"]


class DeltaGeneratorContainerTest(DeltaGeneratorTestCase):
    """Test DeltaGenerator Container."""

    def test_container(self):
        container = st.container()

        self.assertIsInstance(container, DeltaGenerator)
        self.assertFalse(container._cursor.is_locked)

    def test_container_paths(self):
        level3 = st.container().container().container()
        level3.markdown("hi")
        level3.markdown("bye")

        msg = self.get_message_from_queue()
        self.assertEqual(
            make_delta_path(RootContainer.MAIN, (0, 0, 0), 1), msg.metadata.delta_path
        )


class DeltaGeneratorColumnsTest(DeltaGeneratorTestCase):
    """Test DeltaGenerator Columns."""

    def test_equal_columns(self):
        for column in st.columns(4):
            self.assertIsInstance(column, DeltaGenerator)
            self.assertFalse(column._cursor.is_locked)

    def test_variable_columns(self):
        weights = [3, 1, 4, 1, 5, 9]
        sum_weights = sum(weights)
        st.columns(weights)

        for idx, weight in enumerate(weights):
            # Pull the delta from the back of the queue, using negative index
            delta = self.get_delta_from_queue(idx - len(weights))
            self.assertEqual(delta.add_block.column.weight, weight / sum_weights)

    def test_bad_columns_negative_int(self):
        with self.assertRaises(StreamlitAPIException):
            st.columns(-1337)

    def test_bad_columns_single_float(self):
        with self.assertRaises(TypeError):
            st.columns(6.28)

    def test_bad_columns_list_negative_value(self):
        with self.assertRaises(StreamlitAPIException):
            st.columns([5, 6, -1.2])

    def test_bad_columns_list_int_zero_value(self):
        with self.assertRaises(StreamlitAPIException):
            st.columns([5, 0, 1])

    def test_bad_columns_list_float_zero_value(self):
        with self.assertRaises(StreamlitAPIException):
            st.columns([5.0, 0.0, 1.0])

    def test_two_levels_of_columns_does_not_raise_any_exception(self):
        level1, _ = st.columns(2)
        try:
            _, _ = level1.columns(2)
        except StreamlitAPIException:
            self.fail("Error, one level of nested columns should be allowed!")

    def test_three_levels_of_columns_raise_streamlit_api_exception(self):
        level1, _ = _ = st.columns(2)
        level2, _ = level1.columns(2)
        exc = "Columns can only be placed inside other columns up to one level of nesting."
        with pytest.raises(StreamlitAPIException, match=exc):
            _, _ = level2.columns(2)

    def test_one_level_of_columns_is_allowed_in_the_sidebar(self):
        try:
            with st.sidebar:
                _, _ = st.columns(2)
        except StreamlitAPIException:
            self.fail("Error, 1 level column should be allowed in the sidebar!")

    def test_two_levels_of_columns_in_the_sidebar_raise_streamlit_api_exception(self):
        exc = "Columns cannot be placed inside other columns in the sidebar. This is only possible in the main area of the app."
        with pytest.raises(StreamlitAPIException, match=exc):
            with st.sidebar:
                col1, _ = st.columns(2)
                _, _ = col1.columns(2)


class DeltaGeneratorExpanderTest(DeltaGeneratorTestCase):
    def test_nested_expanders(self):
        level1 = st.expander("level 1")
        with self.assertRaises(StreamlitAPIException):
            level1.expander("level 2")


class DeltaGeneratorWithTest(DeltaGeneratorTestCase):
    """Test the `with DG` feature"""

    def test_with(self):
        # Same as test_container_paths, but using `with` syntax
        level3 = st.container().container().container()
        with level3:
            st.markdown("hi")
            st.markdown("bye")

        msg = self.get_message_from_queue()
        self.assertEqual(
            make_delta_path(RootContainer.MAIN, (0, 0, 0), 1), msg.metadata.delta_path
        )

        # Now we're out of the `with` block, commands should use the main dg
        st.markdown("outside")

        msg = self.get_message_from_queue()
        self.assertEqual(
            make_delta_path(RootContainer.MAIN, (), 1), msg.metadata.delta_path
        )

    def test_nested_with(self):
        with st.container():
            with st.container():
                st.markdown("Level 2 with")
                msg = self.get_message_from_queue()
                self.assertEqual(
                    make_delta_path(RootContainer.MAIN, (0, 0), 0),
                    msg.metadata.delta_path,
                )

            st.markdown("Level 1 with")
            msg = self.get_message_from_queue()
            self.assertEqual(
                make_delta_path(RootContainer.MAIN, (0,), 1),
                msg.metadata.delta_path,
            )

    def test_threads_with(self):
        """
        Tests that with statements work correctly when multiple threads are involved.

        The test sequence is as follows:

              Main Thread       |       Worker Thread
        -----------------------------------------------------
        with container1:        |
                                | with container2:
        st.markdown("Object 1") |
                                | st.markdown("Object 2")


        We check that Object1 is created in container1 and object2 is created in container2.
        """
        container1 = st.container()
        container2 = st.container()

        with_1 = threading.Event()
        with_2 = threading.Event()
        object_1 = threading.Event()

        def thread():
            with_1.wait()
            with container2:
                with_2.set()
                object_1.wait()

                st.markdown("Object 2")
                msg = self.get_message_from_queue()
                self.assertEqual(
                    make_delta_path(RootContainer.MAIN, (1,), 0),
                    msg.metadata.delta_path,
                )

        worker_thread = threading.Thread(target=thread)
        add_script_run_ctx(worker_thread)
        worker_thread.start()

        with container1:
            with_1.set()
            with_2.wait()

            st.markdown("Object in container 1")
            msg = self.get_message_from_queue()
            self.assertEqual(
                make_delta_path(RootContainer.MAIN, (0,), 0),
                msg.metadata.delta_path,
            )

            object_1.set()
            worker_thread.join()

    def test_asyncio_with(self):
        """
        Tests that with statements work correctly when multiple async tasks are involved.

        The test sequence is as follows:

              Task 1             |       Task 2
        -----------------------------------------------------
        with container1:
        asyncio.create_task()   ->
                                 | st.markdown("Object 1a")
                                 | with container2:
        st.markdown("Object 1b") |
                                 | st.markdown("Object 2")

        In this scenario, Task 2 should inherit the container1 context from Task 1 when it is created, so Objects 1a and 1b
        will both go in container 1, and object 2 will go in container 2.
        """
        container1 = st.container()
        container2 = st.container()

        with_2 = asyncio.Event()
        object_1 = asyncio.Event()

        async def task1():
            with container1:
                task = asyncio.create_task(task2())

                await with_2.wait()

                st.markdown("Object 1b")
                msg = self.get_message_from_queue()
                self.assertEqual(
                    make_delta_path(RootContainer.MAIN, (0,), 1),
                    msg.metadata.delta_path,
                )

                object_1.set()
                await task

        async def task2():
            st.markdown("Object 1a")
            msg = self.get_message_from_queue()
            self.assertEqual(
                make_delta_path(RootContainer.MAIN, (0,), 0),
                msg.metadata.delta_path,
            )

            with container2:
                with_2.set()
                st.markdown("Object 2")
                msg = self.get_message_from_queue()
                self.assertEqual(
                    make_delta_path(RootContainer.MAIN, (1,), 0),
                    msg.metadata.delta_path,
                )

                await object_1.wait()

        asyncio.get_event_loop().run_until_complete(task1())


class DeltaGeneratorWriteTest(DeltaGeneratorTestCase):
    """Test DeltaGenerator Text, Alert, Json, and Markdown Classes."""

    def test_json_list(self):
        """Test Text.JSON list."""
        json_data = [5, 6, 7, 8]

        st.json(json_data)

        json_string = json.dumps(json_data)

        element = self.get_delta_from_queue().new_element
        self.assertEqual(json_string, element.json.body)

    def test_json_tuple(self):
        """Test Text.JSON tuple."""
        json_data = (5, 6, 7, 8)

        st.json(json_data)

        json_string = json.dumps(json_data)

        element = self.get_delta_from_queue().new_element
        self.assertEqual(json_string, element.json.body)

    def test_json_object(self):
        """Test Text.JSON object."""
        json_data = {"key": "value"}

        # Testing python object
        st.json(json_data)

        json_string = json.dumps(json_data)

        element = self.get_delta_from_queue().new_element
        self.assertEqual(json_string, element.json.body)
        self.assertEqual(True, element.json.expanded)

    def test_json_string(self):
        """Test Text.JSON string."""
        json_string = '{"key": "value"}'

        # Testing JSON string
        st.json(json_string)

        element = self.get_delta_from_queue().new_element
        self.assertEqual(json_string, element.json.body)

    def test_json_unserializable(self):
        """Test Text.JSON with unserializable object."""
        obj = json  # Modules aren't serializable.

        # Testing unserializable object.
        st.json(obj)

        element = self.get_delta_from_queue().new_element

        # validate a substring since repr for a module may contain an installation-specific path
        self.assertTrue(element.json.body.startswith("\"<module 'json'"))

    def test_json_not_expanded_arg(self):
        """Test st.json expanded arg."""
        json_data = {"key": "value"}

        # Testing python object
        st.json(json_data, expanded=False)

        json_string = json.dumps(json_data)

        element = self.get_delta_from_queue().new_element
        self.assertEqual(json_string, element.json.body)
        self.assertEqual(False, element.json.expanded)

    def test_json_not_mutates_data_containing_sets(self):
        """Test st.json do not mutate data containing sets,
        pass a dict-containing-a-set to st.json; ensure that it's not mutated
        """
        json_data = {"some_set": {"a", "b"}}
        self.assertIsInstance(json_data["some_set"], set)

        st.json(json_data)
        self.assertIsInstance(json_data["some_set"], set)

    def test_st_json_set_is_serialized_as_list(self):
        """Test st.json serializes set as list"""
        json_data = {"a", "b", "c", "d"}
        st.json(json_data)
        element = self.get_delta_from_queue().new_element
        parsed_element = json.loads(element.json.body)
        self.assertIsInstance(parsed_element, list)
        for el in json_data:
            self.assertIn(el, parsed_element)

    def test_st_json_serializes_sets_inside_iterables_as_lists(self):
        """Test st.json serializes sets inside iterables as lists"""
        json_data = {"some_set": {"a", "b"}}
        st.json(json_data)
        element = self.get_delta_from_queue().new_element
        parsed_element = json.loads(element.json.body)
        set_as_list = parsed_element.get("some_set")
        self.assertIsInstance(set_as_list, list)
        self.assertSetEqual(json_data["some_set"], set(set_as_list))

    def test_st_json_generator_is_serialized_as_string(self):
        """Test st.json serializes generator as string"""
        json_data = (c for c in "foo")
        st.json(json_data)
        element = self.get_delta_from_queue().new_element
        parsed_element = json.loads(element.json.body)
        self.assertIsInstance(parsed_element, str)
        self.assertIn("generator", parsed_element)

    def test_markdown(self):
        """Test Markdown element."""
        test_string = "    data         "

        st.markdown(test_string)

        element = self.get_delta_from_queue().new_element
        self.assertEqual("data", element.markdown.body)

        test_string = "    <a#data>data</a>   "
        st.markdown(test_string)
        element = self.get_delta_from_queue().new_element

        assert element.markdown.body.startswith("<a#data>")

    def test_empty(self):
        """Test Empty."""
        st.empty()

        element = self.get_delta_from_queue().new_element
        self.assertEqual(element.empty, EmptyProto())


class AutogeneratedWidgetIdTests(DeltaGeneratorTestCase):
    def test_ids_are_equal_when_inputs_are_equal(self):
        with self.assertRaises(StreamlitDuplicateElementId):
            compute_and_register_element_id(
                "text_input",
                label="Label #1",
                default="Value #1",
                user_key=None,
                form_id=None,
            )

            compute_and_register_element_id(
                "text_input",
                label="Label #1",
                default="Value #1",
                user_key=None,
                form_id=None,
            )

    def test_duplicated_key_is_raised(self):
        with self.assertRaises(StreamlitDuplicateElementKey):
            compute_and_register_element_id(
                "text_input",
                label="Label #1",
                default="Value #1",
                user_key="some_key1",
                form_id=None,
            )

            compute_and_register_element_id(
                "text_input",
                label="Label #2",
                default="Value #1",
                user_key="some_key1",
                form_id=None,
            )

    def test_ids_are_diff_when_labels_are_diff(self):
        id1 = compute_and_register_element_id(
            "text_input",
            label="Label #1",
            default="Value #1",
            user_key=None,
            form_id=None,
        )
        id2 = compute_and_register_element_id(
            "text_input",
            label="Label #2",
            default="Value #1",
            user_key=None,
            form_id=None,
        )

        assert id1 != id2

    def test_ids_are_diff_when_types_are_diff(self):
        id1 = compute_and_register_element_id(
            "text_input",
            label="Label #1",
            default="Value #1",
            user_key=None,
            form_id=None,
        )
        id2 = compute_and_register_element_id(
            "text_area",
            label="Label #1",
            default="Value #1",
            user_key=None,
            form_id=None,
        )
        assert id1 != id2


class KeyWidgetIdTests(DeltaGeneratorTestCase):
    def test_ids_are_diff_when_keys_are_diff(self):
        id1 = compute_and_register_element_id(
            "text_input",
            user_key="some_key1",
            label="Label #1",
            default="Value #1",
            form_id=None,
        )

        id2 = compute_and_register_element_id(
            "text_input",
            user_key="some_key2",
            label="Label #1",
            default="Value #1",
            form_id=None,
        )

        assert id1 != id2


class DeltaGeneratorImageTest(DeltaGeneratorTestCase):
    """Test DeltaGenerator Images"""

    def test_image_from_url(self):
        """Tests dg.image with single and multiple image URLs"""

        url = "https://streamlit.io/an_image.png"
        caption = "ahoy!"

        # single URL
        st.image(url, caption=caption, width=200)
        element = self.get_delta_from_queue().new_element
        self.assertEqual(element.imgs.width, 200)
        self.assertEqual(len(element.imgs.imgs), 1)
        self.assertEqual(element.imgs.imgs[0].url, url)
        self.assertEqual(element.imgs.imgs[0].caption, caption)

        # multiple URLs
        st.image([url] * 5, caption=[caption] * 5, width=200)
        element = self.get_delta_from_queue().new_element
        self.assertEqual(len(element.imgs.imgs), 5)
        self.assertEqual(element.imgs.imgs[4].url, url)
        self.assertEqual(element.imgs.imgs[4].caption, caption)

    def test_unequal_images_and_captions_error(self):
        """Tests that the number of images and captions must match, or
        an exception is generated"""

        url = "https://streamlit.io/an_image.png"
        caption = "ahoy!"

        with self.assertRaises(Exception) as ctx:
            st.image([url] * 5, caption=[caption] * 2)
        self.assertTrue("Cannot pair 2 captions with 5 images." in str(ctx.exception))


================================================
File: /lib/tests/streamlit/deprecation_util_test.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import annotations

import unittest
from unittest.mock import Mock, patch

from streamlit.deprecation_util import (
    deprecate_func_name,
    deprecate_obj_name,
    show_deprecation_warning,
)
from tests.testutil import patch_config_options


class DeprecationUtilTest(unittest.TestCase):
    @patch("streamlit.deprecation_util._LOGGER")
    @patch("streamlit.warning")
    def test_show_deprecation_warning(self, mock_warning: Mock, mock_logger: Mock):
        """show_deprecation_warning logs warnings always, and prints to the browser only
        if config.client.showErrorDetails is True.
        """
        message = (
            "We regret the bother, but it's been fated:\n"
            "the function you called is DEPRECATED."
        )

        # config.client.showErrorDetails=True: log AND show in browser
        with patch_config_options({"client.showErrorDetails": True}):
            show_deprecation_warning(message)
            mock_logger.warning.assert_called_once_with(message)
            mock_warning.assert_called_once_with(message)

        mock_logger.reset_mock()
        mock_warning.reset_mock()

        # config.client.showErrorDetails=False: log, but DON'T show in browser
        with patch_config_options({"client.showErrorDetails": False}):
            show_deprecation_warning(message)
            mock_logger.warning.assert_called_once_with(message)
            mock_warning.assert_not_called()

    @patch("streamlit.deprecation_util.show_deprecation_warning")
    def test_deprecate_func_name(self, mock_show_warning: Mock):
        def multiply(a, b):
            return a * b

        beta_multiply = deprecate_func_name(multiply, "beta_multiply", "1980-01-01")

        self.assertEqual(beta_multiply(3, 2), 6)

        expected_warning = (
            "Please replace `st.beta_multiply` with `st.multiply`.\n\n"
            "`st.beta_multiply` will be removed after 1980-01-01."
        )
        mock_show_warning.assert_called_once_with(expected_warning)

    @patch("streamlit.deprecation_util.show_deprecation_warning")
    def test_deprecate_func_name_with_override(self, mock_show_warning: Mock):
        def multiply(a, b):
            return a * b

        beta_multiply = deprecate_func_name(
            multiply, "beta_multiply", "1980-01-01", name_override="mul"
        )

        self.assertEqual(beta_multiply(3, 2), 6)

        expected_warning = (
            "Please replace `st.beta_multiply` with `st.mul`.\n\n"
            "`st.beta_multiply` will be removed after 1980-01-01."
        )
        mock_show_warning.assert_called_once_with(expected_warning)

    @patch("streamlit.deprecation_util.show_deprecation_warning")
    def test_deprecate_obj_name(self, mock_show_warning: Mock):
        """Test that we override dunder methods."""

        class DictClass(dict):
            pass

        beta_dict = deprecate_obj_name(
            DictClass(), "beta_dict", "my_dict", "1980-01-01"
        )

        beta_dict["foo"] = "bar"
        self.assertEqual(beta_dict["foo"], "bar")
        self.assertEqual(len(beta_dict), 1)
        self.assertEqual(list(beta_dict), ["foo"])

        expected_warning = (
            "Please replace `st.beta_dict` with `st.my_dict`.\n\n"
            "`st.beta_dict` will be removed after 1980-01-01."
        )

        # We only show the warning a single time for a given object.
        mock_show_warning.assert_called_once_with(expected_warning)

    @patch("streamlit.deprecation_util.show_deprecation_warning")
    def test_deprecate_obj_name_no_st_prefix(self, mock_show_warning: Mock):
        class DictClass(dict):
            pass

        beta_dict = deprecate_obj_name(
            DictClass(),
            "beta_dict",
            "my_dict",
            "1980-01-01",
            include_st_prefix=False,
        )

        beta_dict["foo"] = "bar"
        self.assertEqual(beta_dict["foo"], "bar")
        self.assertEqual(len(beta_dict), 1)
        self.assertEqual(list(beta_dict), ["foo"])

        expected_warning = (
            "Please replace `beta_dict` with `my_dict`.\n\n"
            "`beta_dict` will be removed after 1980-01-01."
        )

        # We only show the warning a single time for a given object.
        mock_show_warning.assert_called_once_with(expected_warning)


================================================
File: /lib/tests/streamlit/element_mocks.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import annotations

from typing import Any, Callable

import altair as alt
import matplotlib.pyplot as plt
import pandas as pd
import plotly.express as px
import pydeck as pdk

import streamlit as st
from streamlit.type_util import is_altair_version_less_than

_CHART_DATA = pd.DataFrame(
    {
        "col1": [1, 2, 3],
        "col2": [3, 2, 1],
    }
)

ELEMENT_PRODUCER = Callable[[], Any]

H3_HEX_DATA = [
    {"hex": "88283082b9fffff", "count": 10},
    {"hex": "88283082d7fffff", "count": 50},
    {"hex": "88283082a9fffff", "count": 100},
]
df = pd.DataFrame(H3_HEX_DATA)

WIDGET_ELEMENTS: list[tuple[str, ELEMENT_PRODUCER]] = [
    # buttons
    ("button", lambda: st.button("Click me")),
    ("download_button", lambda: st.download_button("Download me", b"")),
    (
        "form_submit_button",
        # Form submit button doesn't work in the context of the test
        # since it requires to be wrapped in a form. Therefore,
        # we are just using a text input as a proxy for the form submit button.
        lambda: st.text_input("Write me"),
    ),
    # checkboxes
    ("checkbox", lambda: st.checkbox("Check me")),
    ("pills", lambda: st.pills("Some pills", ["a", "b", "c"])),
    (
        "segmented_control",
        lambda: st.segmented_control("Some segments", ["a", "b", "c"]),
    ),
    ("toggle", lambda: st.toggle("Toggle me")),
    # arrows
    ("data_editor", lambda: st.data_editor(pd.DataFrame())),
    ("dataframe", lambda: st.dataframe(pd.DataFrame(), on_select="rerun")),
    # other widgets
    ("color_picker", lambda: st.color_picker("Pick a color")),
    # media manager
    ("audio_input", lambda: st.audio_input("Record me")),
    ("experimental_audio_input", lambda: st.experimental_audio_input("Record me")),
    ("camera_input", lambda: st.camera_input("Take a picture")),
    ("file_uploader", lambda: st.file_uploader("Upload me")),
    # selectors
    ("feedback", lambda: st.feedback()),
    ("multiselect", lambda: st.multiselect("Show me", ["a", "b", "c"])),
    ("number_input", lambda: st.number_input("Enter a number")),
    ("radio", lambda: st.radio("Choose me", ["a", "b", "c"])),
    ("slider", lambda: st.slider("Slide me")),
    ("selectbox", lambda: st.selectbox("Select me", ["a", "b", "c"])),
    ("select_slider", lambda: st.select_slider("Select me", ["a", "b", "c"])),
    # text_widgets
    ("text_area", lambda: st.text_area("Write me")),
    ("text_input", lambda: st.text_input("Write me")),
    ("chat_input", lambda: st.chat_input("Chat with me")),
    # time_widgets
    ("date_input", lambda: st.date_input("Pick a date")),
    ("time_input", lambda: st.time_input("Pick a time")),
    # hybrid-widgets
    (
        "altair_chart",
        lambda: (
            st.altair_chart(
                alt.Chart(pd.DataFrame({"a": ["A"], "b": [1]}))
                .mark_bar()
                .encode(x="a", y="b")
                .add_params(alt.selection_point()),
                on_select="rerun",
            )
            # altair with 'on_select' only works for versions >= 5.0.0
            if is_altair_version_less_than("5.0.0") is False
            else st.text_input("Write me")  # some other widget that raises an exception
        ),
    ),
    (
        "vega_lite_chart",
        lambda: (
            st.vega_lite_chart(
                {
                    "data": {"values": [{"a": "A", "b": "B"}]},
                    "mark": "rect",
                    "params": [{"name": "select", "select": "point"}],
                    "encoding": {
                        "x": {"field": "a", "type": "ordinal"},
                        "y": {"field": "b", "type": "quantitative"},
                    },
                },
                on_select="rerun",
            )
            # altair with 'on_select' only works for versions >= 5.0.0
            if is_altair_version_less_than("5.0.0") is False
            else st.text_input("Write me")  # some other widget that raises an exception
        ),
    ),
    (
        "plotly_chart",
        lambda: st.plotly_chart(px.line(pd.DataFrame()), on_select="rerun"),
    ),
    (
        "pydeck_chart",
        lambda: st.pydeck_chart(
            pdk.Deck(
                map_style="mapbox://styles/mapbox/outdoors-v12",
                initial_view_state=pdk.ViewState(
                    latitude=37.7749295,
                    longitude=-122.4194155,
                    zoom=11,
                    bearing=0,
                    pitch=30,
                ),
                layers=[
                    pdk.Layer(
                        "H3HexagonLayer",
                        df,
                        id="MyHexLayer",
                        pickable=True,
                        stroked=True,
                        filled=True,
                        get_hexagon="hex",
                        line_width_min_pixels=2,
                        get_fill_color="[120, count > 50 ? 255 : 0, 255]",
                    ),
                ],
            ),
            use_container_width=True,
            key="mocked_pydeck_chart",
            on_select="rerun",
            selection_mode="single-object",
        ),
    ),
]

NON_WIDGET_ELEMENTS: list[tuple[str, ELEMENT_PRODUCER]] = [
    # text elements
    ("header", lambda: st.header("Header")),
    ("title", lambda: st.title("Title")),
    ("subheader", lambda: st.subheader("Subheader")),
    ("caption", lambda: st.caption("Caption")),
    ("divider", lambda: st.divider()),
    ("text", lambda: st.text("Hello")),
    ("code", lambda: st.code("Hello")),
    ("html", lambda: st.html("Hello")),
    ("latex", lambda: st.latex("Hello")),
    ("markdown", lambda: st.markdown("Hello")),
    ("write", lambda: st.write("Hello")),
    ("write_stream", lambda: st.write_stream([])),
    # alerts
    ("error", lambda: st.error("Hello")),
    ("info", lambda: st.info("Hello")),
    ("success", lambda: st.success("Hello")),
    ("warning", lambda: st.warning("Hello")),
    ("exception", lambda: st.exception(Exception("Hello"))),
    # progress
    ("spinner", lambda: st.spinner("Hello")),
    ("toast", lambda: st.toast("Hello")),
    ("progress", lambda: st.progress(0.5)),
    ("balloons", lambda: st.balloons()),
    ("snow", lambda: st.snow()),
    # media
    ("audio", lambda: st.audio(b"")),
    ("video", lambda: st.video(b"")),
    (
        "image",
        lambda: st.image("https://streamlit.io/images/brand/streamlit-mark-color.png"),
    ),
    (
        "logo",
        lambda: st.logo("https://streamlit.io/images/brand/streamlit-mark-color.png"),
    ),
    # data elements
    ("json", lambda: st.json({})),
    ("metric", lambda: st.metric("Metric", 100)),
    ("dataframe", lambda: st.dataframe(pd.DataFrame())),
    ("table", lambda: st.table(pd.DataFrame())),
    # charts:
    ("line_chart", lambda: st.line_chart(_CHART_DATA)),
    ("area_chart", lambda: st.area_chart(_CHART_DATA)),
    ("bar_chart", lambda: st.bar_chart(_CHART_DATA)),
    ("scatter_chart", lambda: st.scatter_chart(_CHART_DATA)),
    (
        "altair_chart",
        lambda: (
            st.altair_chart(alt.Chart().mark_bar(), on_select="ignore")
            # altair with 'on_select' only works for versions >= 5.0.0
            if is_altair_version_less_than("5.0.0") is False
            else st.write("")
        ),
    ),
    (
        "vega_lite_chart",
        lambda: (
            st.vega_lite_chart({"mark": "rect"}, on_select="ignore")
            # altair with 'on_select' only works for versions >= 5.0.0
            if is_altair_version_less_than("5.0.0") is False
            else st.write("")
        ),
    ),
    (
        "plotly_chart",
        lambda: st.plotly_chart(px.line(_CHART_DATA), on_select="ignore"),
    ),
    ("pydeck_chart", lambda: st.pydeck_chart(pdk.Deck())),
    (
        "map",
        lambda: st.map(pd.DataFrame({"lat": [1, 2, 3], "lon": [3, 2, 1]})),
    ),
    (
        "graphviz_chart",
        lambda: st.graphviz_chart("""
    digraph {
        run -> intr
    }
    """),
    ),
    ("pyplot", lambda: st.pyplot(plt.figure())),
    (
        "bokeh_chart",
        lambda: (
            # Ignore bokeh chart since it requires outdated dependencies:
            st.write("")
        ),
    ),
    # utilities
    ("help", lambda: st.help("Hello")),
    ("echo", lambda: st.echo()),
    # other elements
    ("link_button", lambda: st.link_button("Link", "https://streamlit.io")),
    ("page_link", lambda: st.page_link("https://streamlit.io", label="Streamlit")),
]

CONTAINER_ELEMENTS: list[tuple[str, ELEMENT_PRODUCER]] = [
    ("container", lambda: st.container()),
    ("expander", lambda: st.expander("Expand me")),
    ("tabs", lambda: st.tabs(["Tab 1", "Tab 2"])),
    ("chat_message", lambda: st.chat_message("user")),
    ("popover", lambda: st.popover("Popover")),
    ("columns", lambda: st.columns(2)),
    ("status", lambda: st.status("Status")),
    ("form", lambda: st.form("Form")),
    ("empty", lambda: st.empty()),
    ("dialog", lambda: st.dialog("Dialog")),
    ("experimental_dialog", lambda: st.experimental_dialog("Dialog")),
]


================================================
File: /lib/tests/streamlit/error_util_test.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import annotations

import contextlib
import io
import unittest
from unittest.mock import patch

from streamlit.error_util import _print_rich_exception, handle_uncaught_app_exception
from tests import testutil


class ErrorUtilTest(unittest.TestCase):
    def test_handle_print_rich_exception(self):
        """Test if the print rich exception method is working fine."""

        with io.StringIO() as buf:
            # Capture stdout logs (rich logs to stdout)
            with contextlib.redirect_stdout(buf):
                _print_rich_exception(Exception("boom!"))
            # Capture the stdout output
            captured_output = buf.getvalue()

            assert "Exception:" in captured_output
            assert "boom!" in captured_output

    def test_handle_uncaught_app_exception_with_rich(self):
        """Test if the exception is logged with rich enabled and disabled."""
        exc = Exception("boom!")
        with testutil.patch_config_options({"logger.enableRich": True}):
            with io.StringIO() as buf:
                # Capture stdout logs (rich logs to stdout)
                with contextlib.redirect_stdout(buf):
                    handle_uncaught_app_exception(exc)
                # Capture the stdout output
                captured_output = buf.getvalue()

                assert "Exception:" in captured_output
                assert "boom!" in captured_output
                # Uncaught app exception is only used by the non-rich exception logging
                assert "Uncaught app exception" not in captured_output

        with testutil.patch_config_options({"logger.enableRich": False}):
            with io.StringIO() as buf:
                # Capture stdout logs
                with contextlib.redirect_stdout(buf):
                    handle_uncaught_app_exception(exc)
                # Capture the stdout output
                captured_output = buf.getvalue()

                # With rich deactivated, the exception is not logged to stdout
                assert "Exception:" not in captured_output
                assert "boom!" not in captured_output

    def test_handle_uncaught_app_exception_with_rich_doesnt_call_logger(self):
        """Test that if rich is enabled, the logger error is not used."""
        with testutil.patch_config_options({"logger.enableRich": True}):
            with patch("streamlit.error_util._LOGGER.error") as mock_logger:
                handle_uncaught_app_exception(Exception("boom!"))
                mock_logger.assert_not_called()

        with testutil.patch_config_options({"logger.enableRich": False}):
            with patch("streamlit.error_util._LOGGER.error") as mock_logger:
                handle_uncaught_app_exception(Exception("boom!"))
                mock_logger.assert_called_once()


================================================
File: /lib/tests/streamlit/file_uploader_utils_test.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
from __future__ import annotations

import unittest
from typing import Sequence

from parameterized import parameterized

from streamlit.elements.lib.file_uploader_utils import normalize_upload_file_type


class FileUploaderUtilsTest(unittest.TestCase):
    @parameterized.expand(
        [
            ("png", [".png"]),
            (["png", ".svg", "foo"], [".png", ".svg", ".foo"]),
            (["jpeg"], [".jpeg", ".jpg"]),
            (["png", ".jpg"], [".png", ".jpg", ".jpeg"]),
            ([".JpG"], [".jpg", ".jpeg"]),
        ]
    )
    def test_file_type(self, file_type: str | Sequence[str], expected: Sequence[str]):
        """Test that it can be called using string(s) for type parameter."""
        normalized = normalize_upload_file_type(file_type=file_type)
        self.assertEqual(normalized, expected)


================================================
File: /lib/tests/streamlit/file_util_test.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import annotations

import errno
import os
import unittest
from unittest.mock import MagicMock, mock_open, patch

import pytest

from streamlit import errors, file_util

FILENAME = "/some/cache/file"
mock_get_path = MagicMock(return_value=FILENAME)


class FileUtilTest(unittest.TestCase):
    def setUp(self):
        self.patch1 = patch("streamlit.file_util.os.stat")
        self.os_stat = self.patch1.start()

    def tearDown(self):
        self.patch1.stop()

    @patch("streamlit.file_util.get_streamlit_file_path", mock_get_path)
    @patch("streamlit.file_util.open", mock_open(read_data="data"))
    def test_streamlit_read(self):
        """Test streamlitfile_util.streamlit_read."""
        with file_util.streamlit_read(FILENAME) as input:
            data = input.read()
        self.assertEqual("data", data)

    @patch("streamlit.file_util.get_streamlit_file_path", mock_get_path)
    @patch("streamlit.file_util.open", mock_open(read_data=b"\xaa\xbb"))
    def test_streamlit_read_binary(self):
        """Test streamlitfile_util.streamlit_read."""
        with file_util.streamlit_read(FILENAME, binary=True) as input:
            data = input.read()
        self.assertEqual(b"\xaa\xbb", data)

    @patch("streamlit.file_util.get_streamlit_file_path", mock_get_path)
    @patch("streamlit.file_util.open", mock_open(read_data="data"))
    def test_streamlit_read_zero_bytes(self):
        """Test streamlitfile_util.streamlit_read."""
        self.os_stat.return_value.st_size = 0
        with pytest.raises(errors.Error) as e:
            with file_util.streamlit_read(FILENAME) as input:
                input.read()
        self.assertEqual(str(e.value), 'Read zero byte file: "/some/cache/file"')

    @patch("streamlit.file_util.get_streamlit_file_path", mock_get_path)
    def test_streamlit_write(self):
        """Test streamlitfile_util.streamlit_write."""

        dirname = os.path.dirname(file_util.get_streamlit_file_path(FILENAME))
        # patch streamlit.*.os.makedirs instead of os.makedirs for py35 compat
        with patch("streamlit.file_util.open", mock_open()) as open, patch(
            "streamlit.file_util.os.makedirs"
        ) as makedirs, file_util.streamlit_write(FILENAME) as output:
            output.write("some data")
            open().write.assert_called_once_with("some data")
            makedirs.assert_called_once_with(dirname, exist_ok=True)

    @patch("streamlit.file_util.get_streamlit_file_path", mock_get_path)
    @patch("streamlit.env_util.IS_DARWIN", True)
    def test_streamlit_write_exception(self):
        """Test streamlitfile_util.streamlit_write."""
        with patch("streamlit.file_util.open", mock_open()) as p, patch(
            "streamlit.file_util.os.makedirs"
        ):
            p.side_effect = OSError(errno.EINVAL, "[Errno 22] Invalid argument")
            with pytest.raises(errors.Error) as e, file_util.streamlit_write(
                FILENAME
            ) as output:
                output.write("some data")
            error_msg = (
                "Unable to write file: /some/cache/file\n"
                "Python is limited to files below 2GB on OSX. "
                "See https://bugs.python.org/issue24658"
            )
            self.assertEqual(str(e.value), error_msg)

    def test_get_project_streamlit_file_path(self):
        expected = os.path.join(
            os.getcwd(), file_util.CONFIG_FOLDER_NAME, "some/random/file"
        )

        self.assertEqual(
            expected, file_util.get_project_streamlit_file_path("some/random/file")
        )

        self.assertEqual(
            expected,
            file_util.get_project_streamlit_file_path("some", "random", "file"),
        )

    def test_get_app_static_dir(self):
        self.assertEqual(
            file_util.get_app_static_dir("/some_path/to/app/myapp.py"),
            "/some_path/to/app/static",
        )

    @patch("os.path.getsize", MagicMock(return_value=42))
    @patch(
        "os.walk",
        MagicMock(
            return_value=[
                ("dir1", [], ["file1", "file2", "file3"]),
                ("dir2", [], ["file4", "file5"]),
            ]
        ),
    )
    def test_get_directory_size(self):
        self.assertEqual(file_util.get_directory_size("the_dir"), 42 * 5)


class FileIsInFolderTest(unittest.TestCase):
    def test_file_in_folder(self):
        # Test with and without trailing slash
        ret = file_util.file_is_in_folder_glob("/a/b/c/foo.py", "/a/b/c/")
        self.assertTrue(ret)
        ret = file_util.file_is_in_folder_glob("/a/b/c/foo.py", "/a/b/c")
        self.assertTrue(ret)

    def test_file_in_subfolder(self):
        # Test with and without trailing slash
        ret = file_util.file_is_in_folder_glob("/a/b/c/foo.py", "/a")
        self.assertTrue(ret)
        ret = file_util.file_is_in_folder_glob("/a/b/c/foo.py", "/a/")
        self.assertTrue(ret)
        ret = file_util.file_is_in_folder_glob("/a/b/c/foo.py", "/a/b")
        self.assertTrue(ret)
        ret = file_util.file_is_in_folder_glob("/a/b/c/foo.py", "/a/b/")
        self.assertTrue(ret)

    def test_file_not_in_folder(self):
        # Test with and without trailing slash
        ret = file_util.file_is_in_folder_glob("/a/b/c/foo.py", "/d/e/f/")
        self.assertFalse(ret)
        ret = file_util.file_is_in_folder_glob("/a/b/c/foo.py", "/d/e/f")
        self.assertFalse(ret)

    def test_rel_file_not_in_folder(self):
        # Test with and without trailing slash
        ret = file_util.file_is_in_folder_glob("foo.py", "/d/e/f/")
        self.assertFalse(ret)
        ret = file_util.file_is_in_folder_glob("foo.py", "/d/e/f")
        self.assertFalse(ret)

    def test_file_in_folder_glob(self):
        ret = file_util.file_is_in_folder_glob("/a/b/c/foo.py", "**/c")
        self.assertTrue(ret)

    def test_file_not_in_folder_glob(self):
        ret = file_util.file_is_in_folder_glob("/a/b/c/foo.py", "**/f")
        self.assertFalse(ret)

    def test_rel_file_not_in_folder_glob(self):
        ret = file_util.file_is_in_folder_glob("foo.py", "**/f")
        self.assertFalse(ret)

    def test_rel_file_in_folder_glob(self):
        ret = file_util.file_is_in_folder_glob("foo.py", "")
        self.assertTrue(ret)


class FileInPythonPathTest(unittest.TestCase):
    @staticmethod
    def _make_it_absolute(path):
        # Use manual join instead of os.abspath to test against non normalized paths
        return os.path.join(os.getcwd(), path)

    def test_no_pythonpath(self):
        with patch("os.environ", {}):
            self.assertFalse(
                file_util.file_in_pythonpath(
                    self._make_it_absolute("../something/dir1/dir2/module")
                )
            )

    def test_empty_pythonpath(self):
        with patch("os.environ", {"PYTHONPATH": ""}):
            self.assertFalse(
                file_util.file_in_pythonpath(
                    self._make_it_absolute("something/dir1/dir2/module")
                )
            )

    def test_python_path_relative(self):
        with patch("os.environ", {"PYTHONPATH": "something"}):
            self.assertTrue(
                file_util.file_in_pythonpath(
                    self._make_it_absolute("something/dir1/dir2/module")
                )
            )
            self.assertFalse(
                file_util.file_in_pythonpath(
                    self._make_it_absolute("something_else/module")
                )
            )
            self.assertFalse(
                file_util.file_in_pythonpath(
                    self._make_it_absolute("../something/dir1/dir2/module")
                )
            )

    def test_python_path_absolute(self):
        with patch("os.environ", {"PYTHONPATH": self._make_it_absolute("something")}):
            self.assertTrue(
                file_util.file_in_pythonpath(
                    self._make_it_absolute("something/dir1/dir2/module")
                )
            )
            self.assertFalse(
                file_util.file_in_pythonpath(
                    self._make_it_absolute("something_else/module")
                )
            )
            self.assertFalse(
                file_util.file_in_pythonpath(
                    self._make_it_absolute("../something/dir1/dir2/module")
                )
            )

    def test_python_path_mixed(self):
        with patch(
            "os.environ",
            {
                "PYTHONPATH": os.pathsep.join(
                    [self._make_it_absolute("something"), "something"]
                )
            },
        ):
            self.assertTrue(
                file_util.file_in_pythonpath(
                    self._make_it_absolute("something/dir1/dir2/module")
                )
            )
            self.assertFalse(
                file_util.file_in_pythonpath(
                    self._make_it_absolute("something_else/module")
                )
            )

    def test_current_directory(self):
        with patch("os.environ", {"PYTHONPATH": "."}):
            self.assertTrue(
                file_util.file_in_pythonpath(
                    self._make_it_absolute("something/dir1/dir2/module")
                )
            )
            self.assertTrue(
                file_util.file_in_pythonpath(
                    self._make_it_absolute("something_else/module")
                )
            )
            self.assertFalse(
                file_util.file_in_pythonpath(
                    self._make_it_absolute("../something_else/module")
                )
            )

    def test_get_main_script_directory(self):
        """Test file_util.get_main_script_directory."""
        with patch("os.getcwd", return_value="/some/random"):
            self.assertEqual(
                file_util.get_main_script_directory("app.py"),
                "/some/random",
            )
            self.assertEqual(
                file_util.get_main_script_directory("./app.py"),
                "/some/random",
            )
            self.assertEqual(
                file_util.get_main_script_directory("../app.py"),
                "/some",
            )
            self.assertEqual(
                file_util.get_main_script_directory("/path/to/my/app.py"),
                "/path/to/my",
            )

    def test_normalize_path_join(self):
        """Test file_util.normalize_path_join."""
        self.assertEqual(
            file_util.normalize_path_join("/some", "random", "path"),
            "/some/random/path",
        )
        self.assertEqual(
            file_util.normalize_path_join("some", "random", "path"),
            "some/random/path",
        )
        self.assertEqual(
            file_util.normalize_path_join("/some", "random", "./path"),
            "/some/random/path",
        )
        self.assertEqual(
            file_util.normalize_path_join("some", "random", "./path"),
            "some/random/path",
        )
        self.assertEqual(
            file_util.normalize_path_join("/some", "random", "../path"),
            "/some/path",
        )
        self.assertEqual(
            file_util.normalize_path_join("some", "random", "../path"),
            "some/path",
        )
        self.assertEqual(
            file_util.normalize_path_join("/some", "random", "/path"),
            "/path",
        )
        self.assertEqual(
            file_util.normalize_path_join("some", "random", "/path"),
            "/path",
        )
        self.assertEqual(
            file_util.normalize_path_join("some", "random", "path", ".."),
            "some/random",
        )
        self.assertEqual(
            file_util.normalize_path_join("some", "random", "path", "../.."),
            "some",
        )


================================================
File: /lib/tests/streamlit/form_test.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Form unit tests."""

from __future__ import annotations

from unittest.mock import MagicMock, patch

from parameterized import parameterized

import streamlit as st
from streamlit.errors import StreamlitAPIException
from streamlit.runtime.state.session_state import RegisterWidgetResult
from tests.delta_generator_test_case import DeltaGeneratorTestCase

NO_FORM_ID = ""


@patch("streamlit.runtime.Runtime.exists", MagicMock(return_value=True))
class FormAssociationTest(DeltaGeneratorTestCase):
    """Tests for every flavor of form/deltagenerator association."""

    def _get_last_checkbox_form_id(self) -> str:
        """Return the form ID for the last checkbox delta that was enqueued."""
        last_delta = self.get_delta_from_queue()
        self.assertIsNotNone(last_delta)
        self.assertEqual("new_element", last_delta.WhichOneof("type"))
        self.assertEqual("checkbox", last_delta.new_element.WhichOneof("type"))
        return last_delta.new_element.checkbox.form_id

    def test_no_form(self):
        """By default, an element doesn't belong to a form."""
        st.checkbox("widget")
        self.assertEqual(NO_FORM_ID, self._get_last_checkbox_form_id())

    def test_implicit_form_parent(self):
        """Within a `with form` statement, any `st.foo` element becomes
        part of that form."""
        with st.form("form"):
            st.checkbox("widget")
        self.assertEqual("form", self._get_last_checkbox_form_id())

        # The sidebar, and any other DG parent created outside
        # the form, does not create children inside the form.
        with st.form("form2"):
            st.sidebar.checkbox("widget2")
        self.assertEqual(NO_FORM_ID, self._get_last_checkbox_form_id())

    def test_deep_implicit_form_parent(self):
        """Within a `with form` statement, any `st.foo` element becomes
        part of that form, regardless of how deeply nested the element is."""
        with st.form("form"):
            cols1 = st.columns(2)
            with cols1[0]:
                with st.container():
                    st.checkbox("widget")
        self.assertEqual("form", self._get_last_checkbox_form_id())

        # The sidebar, and any other DG parent created outside
        # the form, does not create children inside the form.
        with st.form("form2"):
            cols1 = st.columns(2)
            with cols1[0]:
                with st.container():
                    st.sidebar.checkbox("widget2")
        self.assertEqual(NO_FORM_ID, self._get_last_checkbox_form_id())

    def test_parent_created_inside_form(self):
        """If a parent DG is created inside a form, any children of
        that parent belong to the form."""
        with st.form("form"):
            with st.container():
                # Create a (deeply nested) column inside the form
                form_col = st.columns(2)[0]

                # Attach children to the column in various ways.
                # They'll all belong to the form.
                with form_col:
                    st.checkbox("widget1")
                    self.assertEqual("form", self._get_last_checkbox_form_id())

                    form_col.checkbox("widget2")
                    self.assertEqual("form", self._get_last_checkbox_form_id())

        form_col.checkbox("widget3")
        self.assertEqual("form", self._get_last_checkbox_form_id())

    def test_parent_created_outside_form(self):
        """If our parent was created outside a form, any children of
        that parent have no form, regardless of where they're created."""
        no_form_col = st.columns(2)[0]
        no_form_col.checkbox("widget1")
        self.assertEqual(NO_FORM_ID, self._get_last_checkbox_form_id())

        with st.form("form"):
            no_form_col.checkbox("widget2")
            self.assertEqual(NO_FORM_ID, self._get_last_checkbox_form_id())

            with no_form_col:
                st.checkbox("widget3")
                self.assertEqual(NO_FORM_ID, self._get_last_checkbox_form_id())

    def test_widget_created_directly_on_form_block(self):
        """Test that a widget can be created directly on a form block."""

        form = st.form("form")
        form.checkbox("widget")

        self.assertEqual("form", self._get_last_checkbox_form_id())

    def test_form_inside_columns(self):
        """Test that a form was successfully created inside a column."""

        col, _ = st.columns(2)

        with col:
            with st.form("form"):
                st.checkbox("widget")

        self.assertEqual("form", self._get_last_checkbox_form_id())

    def test_form_in_sidebar(self):
        """Test that a form was successfully created in the sidebar."""

        with st.sidebar.form("form"):
            st.checkbox("widget")

        self.assertEqual("form", self._get_last_checkbox_form_id())

    def test_dg_outside_form_but_element_inside(self):
        """Test that a widget doesn't belong to a form if its DG was created outside it."""

        empty = st.empty()
        with st.form("form"):
            empty.checkbox("widget")

        first_delta = self.get_delta_from_queue(0)
        self.assertEqual(NO_FORM_ID, first_delta.new_element.checkbox.form_id)

    def test_dg_inside_form_but_element_outside(self):
        """Test that a widget belongs to a form if its DG was created inside it."""

        with st.form("form"):
            empty = st.empty()
        empty.checkbox("widget")

        self.assertEqual("form", self._get_last_checkbox_form_id())

    def test_dg_and_element_inside_form(self):
        """Test that a widget belongs to a form if its DG was created inside it and then replaced."""

        with st.form("form"):
            empty = st.empty()
            empty.checkbox("widget")

        self.assertEqual("form", self._get_last_checkbox_form_id())


@patch("streamlit.runtime.Runtime.exists", MagicMock(return_value=True))
class FormMarshallingTest(DeltaGeneratorTestCase):
    """Test ability to marshall form protos."""

    def test_marshall_form(self):
        """Creating a form should result in the expected protobuf data."""

        # Test with clear_on_submit=True
        with st.form(key="foo", clear_on_submit=True):
            pass

        self.assertEqual(len(self.get_all_deltas_from_queue()), 1)
        form_proto = self.get_delta_from_queue(0).add_block
        self.assertEqual("foo", form_proto.form.form_id)
        self.assertEqual(True, form_proto.form.clear_on_submit)
        self.assertEqual(True, form_proto.form.enter_to_submit)
        self.assertEqual(True, form_proto.form.border)
        self.clear_queue()

        # Test with clear_on_submit=False
        with st.form(key="bar", clear_on_submit=False):
            pass

        self.assertEqual(len(self.get_all_deltas_from_queue()), 1)
        form_proto = self.get_delta_from_queue(0).add_block
        self.assertEqual("bar", form_proto.form.form_id)
        self.assertEqual(False, form_proto.form.clear_on_submit)

    def test_form_enter_to_submit(self):
        """Test that a form can be created with enter_to_submit=False."""

        # Test with enter_to_submit=False
        with st.form(key="foo", enter_to_submit=False):
            pass

        self.assertEqual(len(self.get_all_deltas_from_queue()), 1)
        form_proto = self.get_delta_from_queue(0).add_block
        self.assertEqual(False, form_proto.form.enter_to_submit)

    def test_form_without_border(self):
        """Test that a form can be created without a border."""

        # Test with clear_on_submit=True
        with st.form(key="foo", clear_on_submit=True, border=False):
            pass

        self.assertEqual(len(self.get_all_deltas_from_queue()), 1)
        form_proto = self.get_delta_from_queue(0).add_block
        self.assertEqual(False, form_proto.form.border)

    def test_multiple_forms_same_key(self):
        """Multiple forms with the same key are not allowed."""

        with self.assertRaises(StreamlitAPIException) as ctx:
            st.form(key="foo")
            st.form(key="foo")

        self.assertIn(
            "There are multiple identical forms with `key='foo'`", str(ctx.exception)
        )

    def test_multiple_forms_same_labels_different_keys(self):
        """Multiple forms with different keys are allowed."""

        try:
            st.form(key="foo")
            st.form(key="bar")

        except Exception:
            self.fail("Forms with same labels and different keys failed to create.")

    def test_form_in_form(self):
        """Test that forms cannot be nested in other forms."""

        with self.assertRaises(StreamlitAPIException) as ctx:
            with st.form("foo"):
                with st.form("bar"):
                    pass

        self.assertEqual(str(ctx.exception), "Forms cannot be nested in other forms.")

    def test_button_in_form(self):
        """Test that buttons are not allowed in forms."""

        with self.assertRaises(StreamlitAPIException) as ctx:
            with st.form("foo"):
                st.button("foo")

        self.assertIn(
            "`st.button()` can't be used in an `st.form()`", str(ctx.exception)
        )

    def test_form_block_data(self):
        """Test that a form creates a block element with correct data."""

        form_data = st.form(key="bar")._form_data
        self.assertEqual("bar", form_data.form_id)


@patch("streamlit.runtime.Runtime.exists", MagicMock(return_value=True))
class FormSubmitButtonTest(DeltaGeneratorTestCase):
    """Test form submit button."""

    def test_disabled_submit_button(self):
        """Test that a submit button can be disabled."""

        with st.form("foo"):
            st.form_submit_button(disabled=True)

        last_delta = self.get_delta_from_queue()
        self.assertEqual(True, last_delta.new_element.button.disabled)

    def test_submit_button_outside_form(self):
        """Test that a submit button is not allowed outside a form."""

        with self.assertRaises(StreamlitAPIException) as ctx:
            st.form_submit_button()

        self.assertIn(
            "`st.form_submit_button()` must be used inside an `st.form()`",
            str(ctx.exception),
        )

    def test_submit_button_inside_form(self):
        """Test that a submit button is allowed inside a form."""

        with st.form("foo"):
            st.form_submit_button()

        last_delta = self.get_delta_from_queue()
        self.assertEqual("foo", last_delta.new_element.button.form_id)

    def test_submit_button_called_directly_on_form_block(self):
        """Test that a submit button can be called directly on a form block."""

        form = st.form("foo")
        form.form_submit_button()

        last_delta = self.get_delta_from_queue()
        self.assertEqual("foo", last_delta.new_element.button.form_id)

    def test_submit_button_default_type(self):
        """Test that a submit button with no explicit type has default of "secondary"."""

        form = st.form("foo")
        form.form_submit_button()

        last_delta = self.get_delta_from_queue()
        self.assertEqual("secondary", last_delta.new_element.button.type)

    @parameterized.expand(["primary", "secondary", "tertiary"])
    def test_submit_button_types(self, type):
        """Test that a submit button can be called with different types."""

        form = st.form("foo")
        form.form_submit_button(type=type)

        last_delta = self.get_delta_from_queue()
        self.assertEqual(type, last_delta.new_element.button.type)

    def test_submit_button_emoji_icon(self):
        """Test that a submit button can be called with an emoji icon."""

        form = st.form("foo")
        form.form_submit_button(icon="⚡")

        last_delta = self.get_delta_from_queue()
        self.assertEqual("⚡", last_delta.new_element.button.icon)

    def test_submit_button_material_icon(self):
        """Test that a submit button can be called with a Material icon."""

        form = st.form("foo")
        form.form_submit_button(icon=":material/thumb_up:")

        last_delta = self.get_delta_from_queue()
        self.assertEqual(":material/thumb_up:", last_delta.new_element.button.icon)

    def test_submit_button_can_use_container_width_by_default(self):
        """Test that a submit button can be called with use_container_width=True."""

        form = st.form("foo")
        form.form_submit_button(type="primary", use_container_width=True)

        last_delta = self.get_delta_from_queue()
        self.assertTrue(last_delta.new_element.button.use_container_width)

    def test_submit_button_does_not_use_container_width_by_default(self):
        """Test that a submit button does not use_use_container width by default."""

        form = st.form("foo")
        form.form_submit_button(type="primary")

        last_delta = self.get_delta_from_queue()
        self.assertFalse(last_delta.new_element.button.use_container_width)

    def test_return_false_when_not_submitted(self):
        with st.form("form1"):
            submitted = st.form_submit_button("Submit")
            self.assertEqual(submitted, False)

    @patch(
        "streamlit.elements.widgets.button.register_widget",
        MagicMock(return_value=RegisterWidgetResult(True, False)),
    )
    def test_return_true_when_submitted(self):
        with st.form("form"):
            submitted = st.form_submit_button("Submit")
            self.assertEqual(submitted, True)

    def test_shows_cached_widget_replay_warning(self):
        """Test that a warning is shown when this widget is used inside a cached function."""

        @st.cache_data
        def cached_function():
            with st.form("form"):
                st.form_submit_button("Submit")

        cached_function()

        # The widget itself is still created, so we need to go back one element more:
        el = self.get_delta_from_queue(-2).new_element.exception
        self.assertEqual(el.type, "CachedWidgetWarning")
        self.assertTrue(el.is_warning)


@patch("streamlit.runtime.Runtime.exists", MagicMock(return_value=True))
class FormStateInteractionTest(DeltaGeneratorTestCase):
    def test_exception_for_callbacks_on_widgets(self):
        with self.assertRaises(StreamlitAPIException):
            with st.form("form"):
                st.radio("radio", ["a", "b", "c"], 0, on_change=lambda x: x)
                st.form_submit_button()

    def test_no_exception_for_callbacks_on_submit_button(self):
        with st.form("form"):
            st.radio("radio", ["a", "b", "c"], 0)
            st.form_submit_button(on_click=lambda x: x)


================================================
File: /lib/tests/streamlit/form_utils_test.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

import unittest

from streamlit.delta_generator import DeltaGenerator
from streamlit.delta_generator_singletons import (
    context_dg_stack,
    get_default_dg_stack_value,
)
from streamlit.elements.lib.form_utils import FormData, is_in_form
from streamlit.runtime import Runtime, RuntimeConfig


class FormUtilsTest(unittest.TestCase):
    def tearDown(self) -> None:
        super().tearDown()

        # reset context_dg_stack to clean state for other tests
        # that are executed in the same thread
        context_dg_stack.set(get_default_dg_stack_value())

    @classmethod
    def setUpClass(cls):
        super().setUpClass()
        config = RuntimeConfig(
            script_path="",
            command_line=None,
            media_file_storage=None,
            uploaded_file_manager=None,
        )
        # init runtime
        Runtime(config)

    @classmethod
    def tearDownClass(cls) -> None:
        super().tearDownClass()
        Runtime._instance = None

    def test_is_in_form_true_when_dg_has_formdata(self):
        dg = DeltaGenerator()
        dg._form_data = FormData("form_id")

        assert is_in_form(dg) is True

    def test_is_in_form_false_when_dg_has_no_formdata(self):
        dg = DeltaGenerator()

        assert is_in_form(dg) is False

    def test_is_in_form_true_when_dg_stack_has_form(self):
        form_dg = DeltaGenerator()
        form_dg._form_data = FormData("form_id")
        dg = DeltaGenerator()
        context_dg_stack.set((form_dg, dg))

        assert is_in_form(dg) is True

    def test_is_in_form_false_when_dg_stack_has_no_form(self):
        form_dg = DeltaGenerator()
        dg = DeltaGenerator()
        context_dg_stack.set((form_dg, dg))

        assert is_in_form(dg) is False

    def test_is_in_form_true_when_dg_has_form_parent(self):
        parent_dg = DeltaGenerator()
        parent_dg._form_data = FormData("form_id")
        dg = DeltaGenerator(parent=parent_dg)

        assert is_in_form(dg) is True

    def test_is_in_form_false_when_dg_has_no_form_parent(self):
        parent_dg = DeltaGenerator()
        dg = DeltaGenerator(parent=parent_dg)

        assert is_in_form(dg) is False


================================================
File: /lib/tests/streamlit/git_util_test.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import annotations

import unittest
from unittest.mock import patch

from git.exc import InvalidGitRepositoryError

from streamlit.git_util import GITHUB_HTTP_URL, GITHUB_SSH_URL, GitRepo


class GitUtilTest(unittest.TestCase):
    def test_https_url_check(self):
        # standard https url with and without .git
        self.assertRegex("https://github.com/username/repo.git", GITHUB_HTTP_URL)
        self.assertRegex("https://github.com/username/repo", GITHUB_HTTP_URL)

        # with www with and without .git
        self.assertRegex("https://www.github.com/username/repo.git", GITHUB_HTTP_URL)
        self.assertRegex("https://www.github.com/username/repo", GITHUB_HTTP_URL)

        # not http
        self.assertNotRegex("http://www.github.com/username/repo.git", GITHUB_HTTP_URL)

    def test_ssh_url_check(self):
        # standard ssh url
        self.assertRegex("git@github.com:username/repo.git", GITHUB_SSH_URL)

        # no .git
        self.assertRegex("git@github.com:username/repo", GITHUB_SSH_URL)

    def test_git_repo_invalid(self):
        with patch("git.Repo") as mock:
            mock.side_effect = InvalidGitRepositoryError("Not a git repo")
            repo = GitRepo(".")
            self.assertFalse(repo.is_valid())

    def test_old_git_version(self):
        """If the installed git is older than 2.7, certain repo operations
        prompt the user for credentials. We don't want to do this, so
        repo.is_valid() returns False for old gits.
        """
        with patch("git.repo.base.Repo.GitCommandWrapperType") as git_mock, patch(
            "streamlit.git_util.os"
        ):
            git_mock.return_value.version_info = (1, 6, 4)  # An old git version
            repo = GitRepo(".")
            self.assertFalse(repo.is_valid())
            self.assertEqual((1, 6, 4), repo.git_version)

    def test_git_repo_valid(self):
        with patch("git.repo.base.Repo.GitCommandWrapperType") as git_mock, patch(
            "streamlit.git_util.os"
        ):
            git_mock.return_value.version_info = (2, 20, 3)  # A recent git version
            repo = GitRepo(".")
            self.assertTrue(repo.is_valid())
            self.assertEqual((2, 20, 3), repo.git_version)

    def test_gitpython_not_installed(self):
        with patch.dict("sys.modules", {"git": None}):
            repo = GitRepo(".")
            self.assertFalse(repo.is_valid())


================================================
File: /lib/tests/streamlit/logger_test.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Logger Unittest."""

from __future__ import annotations

import logging
import unittest
from collections import OrderedDict
from unittest.mock import patch

import pytest
from parameterized import parameterized

from streamlit import config, logger

DUMMY_CONFIG_OPTIONS = OrderedDict()


class LoggerTest(unittest.TestCase):
    """Logger Unittest class."""

    # Need to fix this test:
    # https://trello.com/c/ZwNR7fWI
    # def test_set_log_level_by_name(self):
    #     """Test streamlit.logger.set_log_level."""
    #     data = {
    #         'critical': logging.CRITICAL,
    #         'error': logging.ERROR,
    #         'warning': logging.WARNING,
    #         'info': logging.INFO,
    #         'debug': logging.DEBUG,
    #     }
    #     for k, v in data.items():
    #         streamlit.logger.set_log_level(k)
    #         self.assertEqual(v, logging.getLogger().getEffectiveLevel())

    def test_set_log_level_by_constant(self):
        """Test streamlit.logger.set_log_level."""
        data = [
            logging.CRITICAL,
            logging.ERROR,
            logging.WARNING,
            logging.INFO,
            logging.DEBUG,
        ]
        for k in data:
            logger.set_log_level(k)
            self.assertEqual(k, logging.getLogger("streamlit").getEffectiveLevel())

    def test_set_log_level_error(self):
        """Test streamlit.logger.set_log_level."""
        with pytest.raises(SystemExit) as e:
            logger.set_log_level(90)
        self.assertEqual(e.type, SystemExit)
        self.assertEqual(e.value.code, 1)

    # Need to fix this test:
    # https://trello.com/c/ZwNR7fWI
    # def test_set_log_level_resets(self):
    #     """Test streamlit.logger.set_log_level."""
    #     streamlit.logger.set_log_level('debug')
    #     test1 = streamlit.logger.get_logger('test1')
    #     self.assertEqual(logging.DEBUG, test1.getEffectiveLevel())
    #
    #     streamlit.logger.set_log_level('warning')
    #     self.assertEqual(logging.WARNING, test1.getEffectiveLevel())
    #
    #     streamlit.logger.set_log_level('critical')
    #     test2 = streamlit.logger.get_logger('test2')
    #     self.assertEqual(logging.CRITICAL, test2.getEffectiveLevel())

    @parameterized.expand(
        [
            ("%(asctime)s.%(msecs)03d %(name)s: %(message)s", None),
            ("%(asctime)s.%(msecs)03d %(name)s: %(message)s", DUMMY_CONFIG_OPTIONS),
            (None, None),
            (None, DUMMY_CONFIG_OPTIONS),
        ]
    )
    def test_setup_log_formatter(self, messageFormat, config_options):
        """Test streamlit.logger.setup_log_formatter."""

        LOGGER = logger.get_logger("test")

        config._set_option("logger.messageFormat", messageFormat, "test")
        config._set_option("logger.level", logging.DEBUG, "test")

        with patch.object(config, "_config_options", new=config_options):
            logger.setup_formatter(LOGGER)
            self.assertEqual(len(LOGGER.handlers), 1)
            if config_options:
                self.assertEqual(
                    LOGGER.handlers[0].formatter._fmt, messageFormat or "%(message)s"
                )
            else:
                self.assertEqual(
                    LOGGER.handlers[0].formatter._fmt, logger.DEFAULT_LOG_MESSAGE
                )

    def test_init_tornado_logs(self):
        """Test streamlit.logger.init_tornado_logs."""
        logger.init_tornado_logs()
        loggers = [x for x in logger._loggers.keys() if "tornado." in x]
        truth = ["tornado.access", "tornado.application", "tornado.general"]
        self.assertEqual(sorted(truth), sorted(loggers))

    # Need to fix this test:
    # https://trello.com/c/ZwNR7fWI
    # def test_get_logger(self):
    #     """Test streamlit.logger.get_logger."""
    #     # Test that get_logger with no args, figures out its caller
    #     logger = streamlit.logger.get_logger()
    #     self.assertTrue('.logger_test' in streamlit.logger.LOGGERS.keys())


================================================
File: /lib/tests/streamlit/message_mocks.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Shared protobuf message mocking utilities."""

from __future__ import annotations

from typing import TYPE_CHECKING

from streamlit.cursor import make_delta_path
from streamlit.elements import arrow
from streamlit.proto.ForwardMsg_pb2 import ForwardMsg
from streamlit.proto.RootContainer_pb2 import RootContainer

if TYPE_CHECKING:
    from streamlit.elements.arrow import Data


def create_dataframe_msg(df: Data, id: int = 1) -> ForwardMsg:
    """Create a mock legacy_data_frame ForwardMsg."""
    msg = ForwardMsg()
    msg.metadata.delta_path[:] = make_delta_path(RootContainer.SIDEBAR, (), id)
    arrow.marshall(msg.delta.new_element.arrow_data_frame, df)
    return msg


def create_script_finished_message(
    status: ForwardMsg.ScriptFinishedStatus.ValueType,
) -> ForwardMsg:
    """Create a script_finished ForwardMsg."""
    msg = ForwardMsg()
    msg.script_finished = status
    return msg


================================================
File: /lib/tests/streamlit/net_util_test.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import annotations

import unittest

import requests
import requests_mock

from streamlit import net_util


class UtilTest(unittest.TestCase):
    def setUp(self):
        net_util._external_ip = None

    def test_get_external_ip(self):
        # Test success
        with requests_mock.mock() as m:
            m.get(net_util._AWS_CHECK_IP, text="1.2.3.4")
            self.assertEqual("1.2.3.4", net_util.get_external_ip())

        net_util._external_ip = None

        # Test failure
        with requests_mock.mock() as m:
            m.get(net_util._AWS_CHECK_IP, exc=requests.exceptions.ConnectTimeout)
            self.assertEqual(None, net_util.get_external_ip())

    def test_get_external_ip_use_http_by_default(self):
        with requests_mock.mock() as m:
            m.get(net_util._AWS_CHECK_IP, text="1.2.3.4")
            m.get(net_util._AWS_CHECK_IP_HTTPS, text="5.6.7.8")
            self.assertEqual("1.2.3.4", net_util.get_external_ip())
            self.assertEqual(m.call_count, 1)

    def test_get_external_ip_https_if_http_fails(self):
        with requests_mock.mock() as m:
            m.get(net_util._AWS_CHECK_IP, exc=requests.exceptions.ConnectTimeout)
            m.get(net_util._AWS_CHECK_IP_HTTPS, text="5.6.7.8")
            self.assertEqual("5.6.7.8", net_util.get_external_ip())
            self.assertEqual(m.call_count, 2)

    def test_get_external_ip_html(self):
        # This tests the case where the external URL returns a web page.
        # https://github.com/streamlit/streamlit/issues/554#issuecomment-604847244

        response_text = """
        <html>
            ... stuff
        </html>
        """

        with requests_mock.mock() as m:
            m.get(net_util._AWS_CHECK_IP, text=response_text)
            self.assertEqual(None, net_util.get_external_ip())

        net_util._external_ip = None


================================================
File: /lib/tests/streamlit/platform_test.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import annotations

from parameterized import parameterized

from streamlit.platform import post_parent_message
from tests.delta_generator_test_case import DeltaGeneratorTestCase


class PlatformTest(DeltaGeneratorTestCase):
    """Tests the platform module functions"""

    @parameterized.expand(["Hello", '{"name":"foo", "type":"bar"}'])
    def test_post_parent_message(self, message: str):
        post_parent_message(message)
        c = self.get_message_from_queue().parent_message
        self.assertEqual(c.message, message)


================================================
File: /lib/tests/streamlit/proto_compatibility_test.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import annotations

from google.protobuf.descriptor import FieldDescriptor
from parameterized import parameterized

from streamlit.proto.Alert_pb2 import Alert
from streamlit.proto.AppPage_pb2 import AppPage
from streamlit.proto.Common_pb2 import FileURLs, FileURLsRequest, FileURLsResponse
from streamlit.proto.Exception_pb2 import Exception as Exception_
from streamlit.proto.NewSession_pb2 import (
    Config,
    CustomThemeConfig,
    EnvironmentInfo,
    FontFace,
    FontSizes,
    Initialize,
    NewSession,
    Radii,
    UserInfo,
)
from streamlit.proto.ParentMessage_pb2 import ParentMessage
from streamlit.proto.SessionStatus_pb2 import SessionStatus

FD = FieldDescriptor


@parameterized.expand(
    [
        (
            AppPage,
            {
                ("page_script_hash", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("page_name", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("icon", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("is_default", FD.LABEL_OPTIONAL, FD.TYPE_BOOL),
                ("section_header", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("url_pathname", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
            },
        ),
        (
            NewSession,
            {
                ("initialize", FD.LABEL_OPTIONAL, FD.TYPE_MESSAGE),
                ("script_run_id", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("name", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("main_script_path", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("config", FD.LABEL_OPTIONAL, FD.TYPE_MESSAGE),
                ("custom_theme", FD.LABEL_OPTIONAL, FD.TYPE_MESSAGE),
                ("app_pages", FD.LABEL_REPEATED, FD.TYPE_MESSAGE),
                ("page_script_hash", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("fragment_ids_this_run", FD.LABEL_REPEATED, FD.TYPE_STRING),
                ("main_script_hash", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
            },
        ),
        (
            Initialize,
            {
                ("user_info", FD.LABEL_OPTIONAL, FD.TYPE_MESSAGE),
                ("environment_info", FD.LABEL_OPTIONAL, FD.TYPE_MESSAGE),
                ("session_status", FD.LABEL_OPTIONAL, FD.TYPE_MESSAGE),
                ("command_line", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("session_id", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("is_hello", FD.LABEL_OPTIONAL, FD.TYPE_BOOL),
            },
        ),
        (
            Config,
            {
                ("gather_usage_stats", FD.LABEL_OPTIONAL, FD.TYPE_BOOL),
                ("max_cached_message_age", FD.LABEL_OPTIONAL, FD.TYPE_INT32),
                ("mapbox_token", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("allow_run_on_save", FD.LABEL_OPTIONAL, FD.TYPE_BOOL),
                ("hide_top_bar", FD.LABEL_OPTIONAL, FD.TYPE_BOOL),
                ("hide_sidebar_nav", FD.LABEL_OPTIONAL, FD.TYPE_BOOL),
                ("toolbar_mode", FD.LABEL_OPTIONAL, FD.TYPE_ENUM),
            },
        ),
        (
            CustomThemeConfig,
            {
                ("primary_color", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("secondary_background_color", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("background_color", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("text_color", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("font", FD.LABEL_OPTIONAL, FD.TYPE_ENUM),
                ("base", FD.LABEL_OPTIONAL, FD.TYPE_ENUM),
                ("widget_background_color", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("widget_border_color", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("radii", FD.LABEL_OPTIONAL, FD.TYPE_MESSAGE),
                ("body_font", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("code_font", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("font_faces", FD.LABEL_REPEATED, FD.TYPE_MESSAGE),
                ("font_sizes", FD.LABEL_OPTIONAL, FD.TYPE_MESSAGE),
                ("skeleton_background_color", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
            },
        ),
        (
            FontFace,
            {
                ("url", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("family", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("weight", FD.LABEL_OPTIONAL, FD.TYPE_INT32),
                ("style", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
            },
        ),
        (
            Radii,
            {
                ("base_widget_radius", FD.LABEL_OPTIONAL, FD.TYPE_INT32),
                ("checkbox_radius", FD.LABEL_OPTIONAL, FD.TYPE_INT32),
            },
        ),
        (
            FontSizes,
            {
                ("tiny_font_size", FD.LABEL_OPTIONAL, FD.TYPE_INT32),
                ("small_font_size", FD.LABEL_OPTIONAL, FD.TYPE_INT32),
                ("base_font_size", FD.LABEL_OPTIONAL, FD.TYPE_INT32),
            },
        ),
        (
            UserInfo,
            {
                ("installation_id", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("installation_id_v3", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
            },
        ),
        (
            EnvironmentInfo,
            {
                ("streamlit_version", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("python_version", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
            },
        ),
        (
            SessionStatus,
            {
                ("run_on_save", FD.LABEL_OPTIONAL, FD.TYPE_BOOL),
                ("script_is_running", FD.LABEL_OPTIONAL, FD.TYPE_BOOL),
            },
        ),
    ]
)
def test_new_session_protos_stable(proto_class, expected_fields):
    d = proto_class.DESCRIPTOR

    assert {(f.name, f.label, f.type) for f in d.fields} == expected_fields


@parameterized.expand(
    [
        (
            FileURLsRequest,
            {
                ("request_id", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("file_names", FD.LABEL_REPEATED, FD.TYPE_STRING),
                ("session_id", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
            },
        ),
        (
            FileURLs,
            {
                ("file_id", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("upload_url", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("delete_url", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
            },
        ),
        (
            FileURLsResponse,
            {
                ("response_id", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
                ("file_urls", FD.LABEL_REPEATED, FD.TYPE_MESSAGE),
                ("error_msg", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
            },
        ),
    ]
)
def test_file_uploader_protos_stable(proto_class, expected_fields):
    d = proto_class.DESCRIPTOR

    assert {(f.name, f.label, f.type) for f in d.fields} == expected_fields


def test_alert_proto_stable():
    d = Alert.DESCRIPTOR

    assert {(f.name, f.label, f.type) for f in d.fields} == {
        ("body", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
        ("format", FD.LABEL_OPTIONAL, FD.TYPE_ENUM),
        ("icon", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
    }


def test_exception_proto_stable():
    d = Exception_.DESCRIPTOR

    assert {(f.name, f.label, f.type) for f in d.fields} == {
        ("type", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
        ("message", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
        ("message_is_markdown", FD.LABEL_OPTIONAL, FD.TYPE_BOOL),
        ("stack_trace", FD.LABEL_REPEATED, FD.TYPE_STRING),
        ("is_warning", FD.LABEL_OPTIONAL, FD.TYPE_BOOL),
    }


def test_parent_message_proto_stable():
    d = ParentMessage.DESCRIPTOR

    assert {(f.name, f.label, f.type) for f in d.fields} == {
        ("message", FD.LABEL_OPTIONAL, FD.TYPE_STRING),
    }


================================================
File: /lib/tests/streamlit/repr_test.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import annotations

import streamlit.util as util


def test_repr_simple_class():
    class Foo:
        def __init__(self, foo, bar=5):
            self.foo = foo
            self.bar = bar

        def __repr__(self):
            return util.repr_(self)

    foo = Foo("words")
    assert repr(foo) == "Foo(foo='words', bar=5)"


def test_repr_dict_class():
    class Foo:
        def __repr__(self):
            return util.repr_(self)

    foo = Foo()
    foo.bar = "bar"
    assert repr(foo) == "Foo(bar='bar')"


def test_repr_thread_class():
    import threading

    thread = threading.current_thread()
    # This should return a non empty string and not raise an exception.
    assert str(thread) is not None


================================================
File: /lib/tests/streamlit/source_util_test.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import annotations

import unittest
from pathlib import Path
from unittest.mock import MagicMock, patch

import pytest
from parameterized import parameterized

import streamlit.source_util as source_util
from streamlit.util import calc_md5


class PageHelperFunctionTests(unittest.TestCase):
    @parameterized.expand(
        [
            # Test that the page number is treated as the first sort key.
            ("/foo/01_bar.py", (1.0, "bar")),
            ("/foo/02-bar.py", (2.0, "bar")),
            ("/foo/03 bar.py", (3.0, "bar")),
            ("/foo/04 bar baz.py", (4.0, "bar baz")),
            ("/foo/05 -_- bar.py", (5.0, "bar")),
            # Test that sorting is not case-sensitive.
            ("/foo/06_BAR.py", (6.0, "bar")),
            # Test that the first sort key is float("inf") if there is no page
            # number.
            ("/foo/bar.py", (float("inf"), "bar")),
            ("/foo/bar baz.py", (float("inf"), "bar baz")),
        ]
    )
    def test_page_sort_key(self, path_str, expected):
        assert source_util.page_sort_key(Path(path_str)) == expected

    def test_page_sort_key_error(self):
        with pytest.raises(AssertionError) as e:
            source_util.page_sort_key(Path("/foo/bar/baz.rs"))

        assert str(e.value) == f"{Path('/foo/bar/baz.rs')} is not a Python file"

    @parameterized.expand(
        [
            # Test that the page number is removed as expected.
            ("/foo/01_bar.py", ("", "bar")),
            ("/foo/02-bar.py", ("", "bar")),
            ("/foo/03 bar.py", ("", "bar")),
            ("/foo/04 bar baz.py", ("", "bar_baz")),
            ("/foo/05 -_- bar.py", ("", "bar")),
            ("/foo/06 -_- 🎉bar.py", ("🎉", "bar")),
            ("/foo/07 -_- 🎉-_bar.py", ("🎉", "bar")),
            ("/foo/08 -_- 🎉 _ bar.py", ("🎉", "bar")),
            # Test cases with no page number.
            ("/foo/bar.py", ("", "bar")),
            ("/foo/bar baz.py", ("", "bar_baz")),
            ("/foo/😐bar baz.py", ("😐", "bar_baz")),
            ("/foo/😐_bar baz.py", ("😐", "bar_baz")),
            # Test that separator characters in the page name are removed as
            # as expected.
            ("/foo/1 - first page.py", ("", "first_page")),
            ("/foo/123_hairy_koala.py", ("", "hairy_koala")),
            (
                "/foo/123 wow_this_has a _lot_ _of  _ ___ separators.py",
                ("", "wow_this_has_a_lot_of_separators"),
            ),
            (
                "/foo/1-dashes in page-name stay.py",
                ("", "dashes_in_page-name_stay"),
            ),
            ("/foo/2 - 🙃second page.py", ("🙃", "second_page")),
            # Test other weirdness that might happen with numbers.
            ("12 monkeys.py", ("", "monkeys")),
            ("12 😰monkeys.py", ("😰", "monkeys")),
            ("_12 monkeys.py", ("", "12_monkeys")),
            ("_12 😰monkeys.py", ("", "12_😰monkeys")),
            ("_😰12 monkeys.py", ("😰", "12_monkeys")),
            ("123.py", ("", "123")),
            ("😰123.py", ("😰", "123")),
            # Test the default case for non-Python files.
            ("not_a_python_script.rs", ("", "")),
        ]
    )
    def test_page_icon_and_name(self, path_str, expected):
        assert source_util.page_icon_and_name(Path(path_str)) == expected

    @patch("streamlit.source_util._on_pages_changed", MagicMock())
    @patch("streamlit.source_util._cached_pages", new="Some pages")
    def test_invalidate_pages_cache(self):
        source_util.invalidate_pages_cache()

        assert source_util._cached_pages is None
        source_util._on_pages_changed.send.assert_called_once()

    @patch("streamlit.source_util._on_pages_changed", MagicMock())
    def test_register_pages_changed_callback(self):
        def callback():
            return None

        disconnect = source_util.register_pages_changed_callback(callback)

        source_util._on_pages_changed.connect.assert_called_once_with(
            callback, weak=False
        )

        disconnect()
        source_util._on_pages_changed.disconnect.assert_called_once_with(callback)


# NOTE: We write this test function using pytest conventions (as opposed to
# using unittest.TestCase like in the rest of the codebase) because the tmpdir
# pytest fixture is so useful for writing this test it's worth having the
# slight inconsistency.
@patch("streamlit.source_util._cached_pages", new=None)
def test_get_pages(tmpdir):
    # Write an empty string to create a file.
    tmpdir.join("streamlit_app.py").write("")

    pages_dir = tmpdir.mkdir("pages")
    pages = [
        # These pages are out of order so that we can check that they're sorted
        # in the assert below.
        "03_other_page.py",
        "04 last numbered page.py",
        "01-page.py",
        # This page should appear last since it doesn't have an integer prefix.
        "page.py",
        # This file shouldn't appear as a page because it's hidden.
        ".hidden_file.py",
        # This file shouldn't appear as a page because it's __init__.py, so also hidden.
        "__init__.py",
        # This shouldn't appear because it's not a Python file.
        "not_a_page.rs",
    ]
    for p in pages:
        pages_dir.join(p).write("")

    main_script_path = str(tmpdir / "streamlit_app.py")

    received_pages = source_util.get_pages(main_script_path)
    assert received_pages == {
        calc_md5(main_script_path): {
            "page_script_hash": calc_md5(main_script_path),
            "page_name": "streamlit_app",
            "script_path": main_script_path,
            "icon": "",
        },
        calc_md5(str(pages_dir / "01-page.py")): {
            "page_script_hash": calc_md5(str(pages_dir / "01-page.py")),
            "page_name": "page",
            "script_path": str(pages_dir / "01-page.py"),
            "icon": "",
        },
        calc_md5(str(pages_dir / "03_other_page.py")): {
            "page_script_hash": calc_md5(str(pages_dir / "03_other_page.py")),
            "page_name": "other_page",
            "script_path": str(pages_dir / "03_other_page.py"),
            "icon": "",
        },
        calc_md5(str(pages_dir / "04 last numbered page.py")): {
            "page_script_hash": calc_md5(str(pages_dir / "04 last numbered page.py")),
            "page_name": "last_numbered_page",
            "script_path": str(pages_dir / "04 last numbered page.py"),
            "icon": "",
        },
        calc_md5(str(pages_dir / "page.py")): {
            "page_script_hash": calc_md5(str(pages_dir / "page.py")),
            "page_name": "page",
            "script_path": str(pages_dir / "page.py"),
            "icon": "",
        },
    }


================================================
File: /lib/tests/streamlit/spinner_test.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import annotations

import time

from streamlit.elements.spinner import spinner
from tests.delta_generator_test_case import DeltaGeneratorTestCase


class SpinnerTest(DeltaGeneratorTestCase):
    def test_spinner(self):
        """Test st.spinner."""
        with spinner("some text"):
            # Without the timeout, the spinner is sometimes not available
            time.sleep(0.7)
            el = self.get_delta_from_queue().new_element
            self.assertEqual(el.spinner.text, "some text")
            self.assertFalse(el.spinner.cache)
        # Check if it gets reset to st.empty()
        last_delta = self.get_delta_from_queue()
        self.assertTrue(last_delta.HasField("new_element"))
        self.assertEqual(last_delta.new_element.WhichOneof("type"), "empty")
        self.assertFalse(el.spinner.show_time)

    def test_spinner_within_chat_message(self):
        """Test st.spinner in st.chat_message resets to empty container block."""
        import streamlit as st

        with st.chat_message("user"):
            with spinner("some text"):
                # Without the timeout, the spinner is sometimes not available
                time.sleep(0.7)
                el = self.get_delta_from_queue().new_element
                self.assertEqual(el.spinner.text, "some text")
                self.assertFalse(el.spinner.cache)
        # Check that the element gets reset to an empty container block:
        last_delta = self.get_delta_from_queue()
        self.assertTrue(last_delta.HasField("add_block"))
        # The block should have `allow_empty` set to false,
        # which means that it will be ignored on the frontend in case
        # it the container is empty. This is the desired behavior
        # for spinner
        self.assertFalse(last_delta.add_block.allow_empty)

    def test_spinner_for_caching(self):
        """Test st.spinner in cache functions."""
        with spinner("some text", _cache=True):
            # Without the timeout, the spinner is sometimes not available
            time.sleep(0.7)
            el = self.get_delta_from_queue().new_element
            self.assertEqual(el.spinner.text, "some text")
            self.assertTrue(el.spinner.cache)
        # Check if it gets reset to st.empty()
        last_delta = self.get_delta_from_queue()
        self.assertTrue(last_delta.HasField("new_element"))
        self.assertEqual(last_delta.new_element.WhichOneof("type"), "empty")

    def test_spinner_time(self):
        """Test st.spinner with show_time."""
        with spinner("some text", show_time=True):
            time.sleep(0.7)
            el = self.get_delta_from_queue().new_element
            self.assertEqual(el.spinner.text, "some text")
            self.assertTrue(el.spinner.show_time)
        # Check if it gets reset to st.empty()
        last_delta = self.get_delta_from_queue()
        self.assertTrue(last_delta.HasField("new_element"))
        self.assertEqual(last_delta.new_element.WhichOneof("type"), "empty")


================================================
File: /lib/tests/streamlit/stop_test.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

from __future__ import annotations

import streamlit as st
from streamlit.runtime.scriptrunner_utils.script_requests import ScriptRequestType
from tests.delta_generator_test_case import DeltaGeneratorTestCase


class StopTest(DeltaGeneratorTestCase):
    def test_stop(self):
        st.stop()
        assert self.script_run_ctx.script_requests._state == ScriptRequestType.STOP


================================================
File: /lib/tests/streamlit/streamlit_test.py
================================================
# Copyright (c) Streamlit Inc. (2018-2022) Snowflake Inc. (2022-2025)
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Streamlit Unit test."""

from __future__ import annotations

import os
import re
import subprocess
import sys
import tempfile
import unittest

import matplotlib

import streamlit as st
from streamlit import __version__
from tests.streamlit.element_mocks import (
    CONTAINER_ELEMENTS,
    NON_WIDGET_ELEMENTS,
    WIDGET_ELEMENTS,
)


def get_version():
    """Get version by parsing out setup.py."""
    dirname = os.path.dirname(__file__)
    base_dir = os.path.abspath(os.path.join(dirname, "../.."))
    pattern = re.compile(r"(?:.*VERSION = \")(?P<version>.*)(?:\"  # PEP-440$)")
    for line in open(os.path.join(base_dir, "setup.py")).readlines():
        m = pattern.match(line)
