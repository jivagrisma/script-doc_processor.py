   To cancel a running Task use the :meth:`cancel` method.  Calling it
   will cause the Task to throw a :exc:`CancelledError` exception into
   the wrapped coroutine.  If a coroutine is awaiting on a Future
   object during cancellation, the Future object will be cancelled.

   :meth:`cancelled` can be used to check if the Task was cancelled.
   The method returns ``True`` if the wrapped coroutine did not
   suppress the :exc:`CancelledError` exception and was actually
   cancelled.

   :class:`asyncio.Task` inherits from :class:`Future` all of its
   APIs except :meth:`Future.set_result` and
   :meth:`Future.set_exception`.

   An optional keyword-only *context* argument allows specifying a
   custom :class:`contextvars.Context` for the *coro* to run in.
   If no *context* is provided, the Task copies the current context
   and later runs its coroutine in the copied context.

   An optional keyword-only *eager_start* argument allows eagerly starting
   the execution of the :class:`asyncio.Task` at task creation time.
   If set to ``True`` and the event loop is running, the task will start
   executing the coroutine immediately, until the first time the coroutine
   blocks. If the coroutine returns or raises without blocking, the task
   will be finished eagerly and will skip scheduling to the event loop.

   .. versionchanged:: 3.7
      Added support for the :mod:`contextvars` module.

   .. versionchanged:: 3.8
      Added the *name* parameter.

   .. deprecated:: 3.10
      Deprecation warning is emitted if *loop* is not specified
      and there is no running event loop.

   .. versionchanged:: 3.11
      Added the *context* parameter.

   .. versionchanged:: 3.12
      Added the *eager_start* parameter.

   .. method:: done()

      Return ``True`` if the Task is *done*.

      A Task is *done* when the wrapped coroutine either returned
      a value, raised an exception, or the Task was cancelled.

   .. method:: result()

      Return the result of the Task.

      If the Task is *done*, the result of the wrapped coroutine
      is returned (or if the coroutine raised an exception, that
      exception is re-raised.)

      If the Task has been *cancelled*, this method raises
      a :exc:`CancelledError` exception.

      If the Task's result isn't yet available, this method raises
      an :exc:`InvalidStateError` exception.

   .. method:: exception()

      Return the exception of the Task.

      If the wrapped coroutine raised an exception that exception
      is returned.  If the wrapped coroutine returned normally
      this method returns ``None``.

      If the Task has been *cancelled*, this method raises a
      :exc:`CancelledError` exception.

      If the Task isn't *done* yet, this method raises an
      :exc:`InvalidStateError` exception.

   .. method:: add_done_callback(callback, *, context=None)

      Add a callback to be run when the Task is *done*.

      This method should only be used in low-level callback-based code.

      See the documentation of :meth:`Future.add_done_callback`
      for more details.

   .. method:: remove_done_callback(callback)

      Remove *callback* from the callbacks list.

      This method should only be used in low-level callback-based code.

      See the documentation of :meth:`Future.remove_done_callback`
      for more details.

   .. method:: get_stack(*, limit=None)

      Return the list of stack frames for this Task.

      If the wrapped coroutine is not done, this returns the stack
      where it is suspended.  If the coroutine has completed
      successfully or was cancelled, this returns an empty list.
      If the coroutine was terminated by an exception, this returns
      the list of traceback frames.

      The frames are always ordered from oldest to newest.

      Only one stack frame is returned for a suspended coroutine.

      The optional *limit* argument sets the maximum number of frames
      to return; by default all available frames are returned.
      The ordering of the returned list differs depending on whether
      a stack or a traceback is returned: the newest frames of a
      stack are returned, but the oldest frames of a traceback are
      returned.  (This matches the behavior of the traceback module.)

   .. method:: print_stack(*, limit=None, file=None)

      Print the stack or traceback for this Task.

      This produces output similar to that of the traceback module
      for the frames retrieved by :meth:`get_stack`.

      The *limit* argument is passed to :meth:`get_stack` directly.

      The *file* argument is an I/O stream to which the output
      is written; by default output is written to :data:`sys.stdout`.

   .. method:: get_coro()

      Return the coroutine object wrapped by the :class:`Task`.

      .. note::

         This will return ``None`` for Tasks which have already
         completed eagerly. See the :ref:`Eager Task Factory <eager-task-factory>`.

      .. versionadded:: 3.8

      .. versionchanged:: 3.12

         Newly added eager task execution means result may be ``None``.

   .. method:: get_context()

      Return the :class:`contextvars.Context` object
      associated with the task.

      .. versionadded:: 3.12

   .. method:: get_name()

      Return the name of the Task.

      If no name has been explicitly assigned to the Task, the default
      asyncio Task implementation generates a default name during
      instantiation.

      .. versionadded:: 3.8

   .. method:: set_name(value)

      Set the name of the Task.

      The *value* argument can be any object, which is then
      converted to a string.

      In the default Task implementation, the name will be visible
      in the :func:`repr` output of a task object.

      .. versionadded:: 3.8

   .. method:: cancel(msg=None)

      Request the Task to be cancelled.

      This arranges for a :exc:`CancelledError` exception to be thrown
      into the wrapped coroutine on the next cycle of the event loop.

      The coroutine then has a chance to clean up or even deny the
      request by suppressing the exception with a :keyword:`try` ...
      ... ``except CancelledError`` ... :keyword:`finally` block.
      Therefore, unlike :meth:`Future.cancel`, :meth:`Task.cancel` does
      not guarantee that the Task will be cancelled, although
      suppressing cancellation completely is not common and is actively
      discouraged.  Should the coroutine nevertheless decide to suppress
      the cancellation, it needs to call :meth:`Task.uncancel` in addition
      to catching the exception.

      .. versionchanged:: 3.9
         Added the *msg* parameter.

      .. versionchanged:: 3.11
         The ``msg`` parameter is propagated from cancelled task to its awaiter.

      .. _asyncio_example_task_cancel:

      The following example illustrates how coroutines can intercept
      the cancellation request::

          async def cancel_me():
              print('cancel_me(): before sleep')

              try:
                  # Wait for 1 hour
                  await asyncio.sleep(3600)
              except asyncio.CancelledError:
                  print('cancel_me(): cancel sleep')
                  raise
              finally:
                  print('cancel_me(): after sleep')

          async def main():
              # Create a "cancel_me" Task
              task = asyncio.create_task(cancel_me())

              # Wait for 1 second
              await asyncio.sleep(1)

              task.cancel()
              try:
                  await task
              except asyncio.CancelledError:
                  print("main(): cancel_me is cancelled now")

          asyncio.run(main())

          # Expected output:
          #
          #     cancel_me(): before sleep
          #     cancel_me(): cancel sleep
          #     cancel_me(): after sleep
          #     main(): cancel_me is cancelled now

   .. method:: cancelled()

      Return ``True`` if the Task is *cancelled*.

      The Task is *cancelled* when the cancellation was requested with
      :meth:`cancel` and the wrapped coroutine propagated the
      :exc:`CancelledError` exception thrown into it.

   .. method:: uncancel()

      Decrement the count of cancellation requests to this Task.

      Returns the remaining number of cancellation requests.

      Note that once execution of a cancelled task completed, further
      calls to :meth:`uncancel` are ineffective.

      .. versionadded:: 3.11

      This method is used by asyncio's internals and isn't expected to be
      used by end-user code.  In particular, if a Task gets successfully
      uncancelled, this allows for elements of structured concurrency like
      :ref:`taskgroups` and :func:`asyncio.timeout` to continue running,
      isolating cancellation to the respective structured block.
      For example::

        async def make_request_with_timeout():
            try:
                async with asyncio.timeout(1):
                    # Structured block affected by the timeout:
                    await make_request()
                    await make_another_request()
            except TimeoutError:
                log("There was a timeout")
            # Outer code not affected by the timeout:
            await unrelated_code()

      While the block with ``make_request()`` and ``make_another_request()``
      might get cancelled due to the timeout, ``unrelated_code()`` should
      continue running even in case of the timeout.  This is implemented
      with :meth:`uncancel`.  :class:`TaskGroup` context managers use
      :func:`uncancel` in a similar fashion.

      If end-user code is, for some reason, suppressing cancellation by
      catching :exc:`CancelledError`, it needs to call this method to remove
      the cancellation state.

      When this method decrements the cancellation count to zero,
      the method checks if a previous :meth:`cancel` call had arranged
      for :exc:`CancelledError` to be thrown into the task.
      If it hasn't been thrown yet, that arrangement will be
      rescinded (by resetting the internal ``_must_cancel`` flag).

   .. versionchanged:: 3.13
      Changed to rescind pending cancellation requests upon reaching zero.

   .. method:: cancelling()

      Return the number of pending cancellation requests to this Task, i.e.,
      the number of calls to :meth:`cancel` less the number of
      :meth:`uncancel` calls.

      Note that if this number is greater than zero but the Task is
      still executing, :meth:`cancelled` will still return ``False``.
      This is because this number can be lowered by calling :meth:`uncancel`,
      which can lead to the task not being cancelled after all if the
      cancellation requests go down to zero.

      This method is used by asyncio's internals and isn't expected to be
      used by end-user code.  See :meth:`uncancel` for more details.

      .. versionadded:: 3.11


================================================
File: /Doc/library/asyncio.rst
================================================
:mod:`!asyncio` --- Asynchronous I/O
====================================

.. module:: asyncio
   :synopsis: Asynchronous I/O.

-------------------------------

.. sidebar:: Hello World!

   ::

       import asyncio

       async def main():
           print('Hello ...')
           await asyncio.sleep(1)
           print('... World!')

       asyncio.run(main())

asyncio is a library to write **concurrent** code using
the **async/await** syntax.

asyncio is used as a foundation for multiple Python asynchronous
frameworks that provide high-performance network and web-servers,
database connection libraries, distributed task queues, etc.

asyncio is often a perfect fit for IO-bound and high-level
**structured** network code.

asyncio provides a set of **high-level** APIs to:

* :ref:`run Python coroutines <coroutine>` concurrently and
  have full control over their execution;

* perform :ref:`network IO and IPC <asyncio-streams>`;

* control :ref:`subprocesses <asyncio-subprocess>`;

* distribute tasks via :ref:`queues <asyncio-queues>`;

* :ref:`synchronize <asyncio-sync>` concurrent code;

Additionally, there are **low-level** APIs for
*library and framework developers* to:

* create and manage :ref:`event loops <asyncio-event-loop>`, which
  provide asynchronous APIs for :ref:`networking <loop_create_server>`,
  running :ref:`subprocesses <loop_subprocess_exec>`,
  handling :ref:`OS signals <loop_add_signal_handler>`, etc;

* implement efficient protocols using
  :ref:`transports <asyncio-transports-protocols>`;

* :ref:`bridge <asyncio-futures>` callback-based libraries and code
  with async/await syntax.

.. include:: ../includes/wasm-notavail.rst

.. _asyncio-cli:

.. rubric:: asyncio REPL

You can experiment with an ``asyncio`` concurrent context in the :term:`REPL`:

.. code-block:: pycon

   $ python -m asyncio
   asyncio REPL ...
   Use "await" directly instead of "asyncio.run()".
   Type "help", "copyright", "credits" or "license" for more information.
   >>> import asyncio
   >>> await asyncio.sleep(10, result='hello')
   'hello'

.. audit-event:: cpython.run_stdin "" ""

.. versionchanged:: 3.12.5 (also 3.11.10, 3.10.15, 3.9.20, and 3.8.20)
   Emits audit events.

.. versionchanged:: 3.13
   Uses PyREPL if possible, in which case :envvar:`PYTHONSTARTUP` is
   also executed. Emits audit events.

.. We use the "rubric" directive here to avoid creating
   the "Reference" subsection in the TOC.

.. rubric:: Reference

.. toctree::
   :caption: High-level APIs
   :maxdepth: 1

   asyncio-runner.rst
   asyncio-task.rst
   asyncio-stream.rst
   asyncio-sync.rst
   asyncio-subprocess.rst
   asyncio-queue.rst
   asyncio-exceptions.rst

.. toctree::
   :caption: Low-level APIs
   :maxdepth: 1

   asyncio-eventloop.rst
   asyncio-future.rst
   asyncio-protocol.rst
   asyncio-policy.rst
   asyncio-platforms.rst
   asyncio-extending.rst

.. toctree::
   :caption: Guides and Tutorials
   :maxdepth: 1

   asyncio-api-index.rst
   asyncio-llapi-index.rst
   asyncio-dev.rst

.. note::
   The source code for asyncio can be found in :source:`Lib/asyncio/`.


================================================
File: /Doc/library/asyncore.rst
================================================
:mod:`!asyncore` --- Asynchronous socket handler
================================================

.. module:: asyncore
   :synopsis: Removed in 3.12.
   :deprecated:

.. deprecated-removed:: 3.6 3.12

This module is no longer part of the Python standard library.
It was :ref:`removed in Python 3.12 <whatsnew312-removed>` after
being deprecated in Python 3.6.  The removal was decided in :pep:`594`.

Applications should use the :mod:`asyncio` module instead.

The last version of Python that provided the :mod:`!asyncore` module was
`Python 3.11 <https://docs.python.org/3.11/library/asyncore.html>`_.


================================================
File: /Doc/library/atexit.rst
================================================
:mod:`!atexit` --- Exit handlers
================================

.. module:: atexit
   :synopsis: Register and execute cleanup functions.

.. moduleauthor:: Skip Montanaro <skip.montanaro@gmail.com>
.. sectionauthor:: Skip Montanaro <skip.montanaro@gmail.com>

--------------

The :mod:`atexit` module defines functions to register and unregister cleanup
functions.  Functions thus registered are automatically executed upon normal
interpreter termination.  :mod:`atexit` runs these functions in the *reverse*
order in which they were registered; if you register ``A``, ``B``, and ``C``,
at interpreter termination time they will be run in the order ``C``, ``B``,
``A``.

**Note:** The functions registered via this module are not called when the
program is killed by a signal not handled by Python, when a Python fatal
internal error is detected, or when :func:`os._exit` is called.

**Note:** The effect of registering or unregistering functions from within
a cleanup function is undefined.

.. versionchanged:: 3.7
    When used with C-API subinterpreters, registered functions
    are local to the interpreter they were registered in.

.. function:: register(func, *args, **kwargs)

   Register *func* as a function to be executed at termination.  Any optional
   arguments that are to be passed to *func* must be passed as arguments to
   :func:`register`.  It is possible to register the same function and arguments
   more than once.

   At normal program termination (for instance, if :func:`sys.exit` is called or
   the main module's execution completes), all functions registered are called in
   last in, first out order.  The assumption is that lower level modules will
   normally be imported before higher level modules and thus must be cleaned up
   later.

   If an exception is raised during execution of the exit handlers, a traceback is
   printed (unless :exc:`SystemExit` is raised) and the exception information is
   saved.  After all exit handlers have had a chance to run, the last exception to
   be raised is re-raised.

   This function returns *func*, which makes it possible to use it as a
   decorator.

   .. warning::
       Starting new threads or calling :func:`os.fork` from a registered
       function can lead to race condition between the main Python
       runtime thread freeing thread states while internal :mod:`threading`
       routines or the new process try to use that state. This can lead to
       crashes rather than clean shutdown.

   .. versionchanged:: 3.12
       Attempts to start a new thread or :func:`os.fork` a new process
       in a registered function now leads to :exc:`RuntimeError`.

.. function:: unregister(func)

   Remove *func* from the list of functions to be run at interpreter shutdown.
   :func:`unregister` silently does nothing if *func* was not previously
   registered.  If *func* has been registered more than once, every occurrence
   of that function in the :mod:`atexit` call stack will be removed.  Equality
   comparisons (``==``) are used internally during unregistration, so function
   references do not need to have matching identities.


.. seealso::

   Module :mod:`readline`
      Useful example of :mod:`atexit` to read and write :mod:`readline` history
      files.


.. _atexit-example:

:mod:`atexit` Example
---------------------

The following simple example demonstrates how a module can initialize a counter
from a file when it is imported and save the counter's updated value
automatically when the program terminates without relying on the application
making an explicit call into this module at termination. ::

   try:
       with open('counterfile') as infile:
           _count = int(infile.read())
   except FileNotFoundError:
       _count = 0

   def incrcounter(n):
       global _count
       _count = _count + n

   def savecounter():
       with open('counterfile', 'w') as outfile:
           outfile.write('%d' % _count)

   import atexit

   atexit.register(savecounter)

Positional and keyword arguments may also be passed to :func:`register` to be
passed along to the registered function when it is called::

   def goodbye(name, adjective):
       print('Goodbye %s, it was %s to meet you.' % (name, adjective))

   import atexit

   atexit.register(goodbye, 'Donny', 'nice')
   # or:
   atexit.register(goodbye, adjective='nice', name='Donny')

Usage as a :term:`decorator`::

   import atexit

   @atexit.register
   def goodbye():
       print('You are now leaving the Python sector.')

This only works with functions that can be called without arguments.


================================================
File: /Doc/library/audioop.rst
================================================
:mod:`!audioop` --- Manipulate raw audio data
=============================================

.. module:: audioop
   :synopsis: Removed in 3.13.
   :deprecated:

.. deprecated-removed:: 3.11 3.13

This module is no longer part of the Python standard library.
It was :ref:`removed in Python 3.13 <whatsnew313-pep594>` after
being deprecated in Python 3.11.  The removal was decided in :pep:`594`.

The last version of Python that provided the :mod:`!audioop` module was
`Python 3.12 <https://docs.python.org/3.12/library/audioop.html>`_.


================================================
File: /Doc/library/audit_events.rst
================================================
.. _audit-events:

.. index:: single: audit events

Audit events table
==================

This table contains all events raised by :func:`sys.audit` or
:c:func:`PySys_Audit` calls throughout the CPython runtime and the
standard library.  These calls were added in 3.8 or later (see :pep:`578`).

See :func:`sys.addaudithook` and :c:func:`PySys_AddAuditHook` for
information on handling these events.

.. impl-detail::

   This table is generated from the CPython documentation, and may not
   represent events raised by other implementations. See your runtime
   specific documentation for actual events raised.

.. audit-event-table::

The following events are raised internally and do not correspond to any
public API of CPython:

+--------------------------+-------------------------------------------+
| Audit event              | Arguments                                 |
+==========================+===========================================+
| _winapi.CreateFile       | ``file_name``, ``desired_access``,        |
|                          | ``share_mode``, ``creation_disposition``, |
|                          | ``flags_and_attributes``                  |
+--------------------------+-------------------------------------------+
| _winapi.CreateJunction   | ``src_path``, ``dst_path``                |
+--------------------------+-------------------------------------------+
| _winapi.CreateNamedPipe  | ``name``, ``open_mode``, ``pipe_mode``    |
+--------------------------+-------------------------------------------+
| _winapi.CreatePipe       |                                           |
+--------------------------+-------------------------------------------+
| _winapi.CreateProcess    | ``application_name``, ``command_line``,   |
|                          | ``current_directory``                     |
+--------------------------+-------------------------------------------+
| _winapi.OpenProcess      | ``process_id``, ``desired_access``        |
+--------------------------+-------------------------------------------+
| _winapi.TerminateProcess | ``handle``, ``exit_code``                 |
+--------------------------+-------------------------------------------+
| ctypes.PyObj_FromPtr     | ``obj``                                   |
+--------------------------+-------------------------------------------+


================================================
File: /Doc/library/base64.rst
================================================
:mod:`!base64` --- Base16, Base32, Base64, Base85 Data Encodings
================================================================

.. module:: base64
   :synopsis: RFC 4648: Base16, Base32, Base64 Data Encodings;
              Base85 and Ascii85

**Source code:** :source:`Lib/base64.py`

.. index::
   pair: base64; encoding
   single: MIME; base64 encoding

--------------

This module provides functions for encoding binary data to printable
ASCII characters and decoding such encodings back to binary data.
It provides encoding and decoding functions for the encodings specified in
:rfc:`4648`, which defines the Base16, Base32, and Base64 algorithms,
and for the de-facto standard Ascii85 and Base85 encodings.

The :rfc:`4648` encodings are suitable for encoding binary data so that it can be
safely sent by email, used as parts of URLs, or included as part of an HTTP
POST request.  The encoding algorithm is not the same as the
:program:`uuencode` program.

There are two interfaces provided by this module.  The modern interface
supports encoding :term:`bytes-like objects <bytes-like object>` to ASCII
:class:`bytes`, and decoding :term:`bytes-like objects <bytes-like object>` or
strings containing ASCII to :class:`bytes`.  Both base-64 alphabets
defined in :rfc:`4648` (normal, and URL- and filesystem-safe) are supported.

The legacy interface does not support decoding from strings, but it does
provide functions for encoding and decoding to and from :term:`file objects
<file object>`.  It only supports the Base64 standard alphabet, and it adds
newlines every 76 characters as per :rfc:`2045`.  Note that if you are looking
for :rfc:`2045` support you probably want to be looking at the :mod:`email`
package instead.


.. versionchanged:: 3.3
   ASCII-only Unicode strings are now accepted by the decoding functions of
   the modern interface.

.. versionchanged:: 3.4
   Any :term:`bytes-like objects <bytes-like object>` are now accepted by all
   encoding and decoding functions in this module.  Ascii85/Base85 support added.

The modern interface provides:

.. function:: b64encode(s, altchars=None)

   Encode the :term:`bytes-like object` *s* using Base64 and return the encoded
   :class:`bytes`.

   Optional *altchars* must be a :term:`bytes-like object` of length 2 which
   specifies an alternative alphabet for the ``+`` and ``/`` characters.
   This allows an application to e.g. generate URL or filesystem safe Base64
   strings.  The default is ``None``, for which the standard Base64 alphabet is used.

   May assert or raise a :exc:`ValueError` if the length of *altchars* is not 2.  Raises a
   :exc:`TypeError` if *altchars* is not a :term:`bytes-like object`.


.. function:: b64decode(s, altchars=None, validate=False)

   Decode the Base64 encoded :term:`bytes-like object` or ASCII string
   *s* and return the decoded :class:`bytes`.

   Optional *altchars* must be a :term:`bytes-like object` or ASCII string
   of length 2 which specifies the alternative alphabet used instead of the
   ``+`` and ``/`` characters.

   A :exc:`binascii.Error` exception is raised
   if *s* is incorrectly padded.

   If *validate* is ``False`` (the default), characters that are neither
   in the normal base-64 alphabet nor the alternative alphabet are
   discarded prior to the padding check.  If *validate* is ``True``,
   these non-alphabet characters in the input result in a
   :exc:`binascii.Error`.

   For more information about the strict base64 check, see :func:`binascii.a2b_base64`

   May assert or raise a :exc:`ValueError` if the length of *altchars* is not 2.

.. function:: standard_b64encode(s)

   Encode :term:`bytes-like object` *s* using the standard Base64 alphabet
   and return the encoded :class:`bytes`.


.. function:: standard_b64decode(s)

   Decode :term:`bytes-like object` or ASCII string *s* using the standard
   Base64 alphabet and return the decoded :class:`bytes`.


.. function:: urlsafe_b64encode(s)

   Encode :term:`bytes-like object` *s* using the
   URL- and filesystem-safe alphabet, which
   substitutes ``-`` instead of ``+`` and ``_`` instead of ``/`` in the
   standard Base64 alphabet, and return the encoded :class:`bytes`.  The result
   can still contain ``=``.


.. function:: urlsafe_b64decode(s)

   Decode :term:`bytes-like object` or ASCII string *s*
   using the URL- and filesystem-safe
   alphabet, which substitutes ``-`` instead of ``+`` and ``_`` instead of
   ``/`` in the standard Base64 alphabet, and return the decoded
   :class:`bytes`.


.. function:: b32encode(s)

   Encode the :term:`bytes-like object` *s* using Base32 and return the
   encoded :class:`bytes`.


.. function:: b32decode(s, casefold=False, map01=None)

   Decode the Base32 encoded :term:`bytes-like object` or ASCII string *s* and
   return the decoded :class:`bytes`.

   Optional *casefold* is a flag specifying
   whether a lowercase alphabet is acceptable as input.  For security purposes,
   the default is ``False``.

   :rfc:`4648` allows for optional mapping of the digit 0 (zero) to the letter O
   (oh), and for optional mapping of the digit 1 (one) to either the letter I (eye)
   or letter L (el).  The optional argument *map01* when not ``None``, specifies
   which letter the digit 1 should be mapped to (when *map01* is not ``None``, the
   digit 0 is always mapped to the letter O).  For security purposes the default is
   ``None``, so that 0 and 1 are not allowed in the input.

   A :exc:`binascii.Error` is raised if *s* is
   incorrectly padded or if there are non-alphabet characters present in the
   input.


.. function:: b32hexencode(s)

   Similar to :func:`b32encode` but uses the Extended Hex Alphabet, as defined in
   :rfc:`4648`.

   .. versionadded:: 3.10


.. function:: b32hexdecode(s, casefold=False)

   Similar to :func:`b32decode` but uses the Extended Hex Alphabet, as defined in
   :rfc:`4648`.

   This version does not allow the digit 0 (zero) to the letter O (oh) and digit
   1 (one) to either the letter I (eye) or letter L (el) mappings, all these
   characters are included in the Extended Hex Alphabet and are not
   interchangeable.

   .. versionadded:: 3.10


.. function:: b16encode(s)

   Encode the :term:`bytes-like object` *s* using Base16 and return the
   encoded :class:`bytes`.


.. function:: b16decode(s, casefold=False)

   Decode the Base16 encoded :term:`bytes-like object` or ASCII string *s* and
   return the decoded :class:`bytes`.

   Optional *casefold* is a flag specifying whether a
   lowercase alphabet is acceptable as input.  For security purposes, the default
   is ``False``.

   A :exc:`binascii.Error` is raised if *s* is
   incorrectly padded or if there are non-alphabet characters present in the
   input.


.. function:: a85encode(b, *, foldspaces=False, wrapcol=0, pad=False, adobe=False)

   Encode the :term:`bytes-like object` *b* using Ascii85 and return the
   encoded :class:`bytes`.

   *foldspaces* is an optional flag that uses the special short sequence 'y'
   instead of 4 consecutive spaces (ASCII 0x20) as supported by 'btoa'. This
   feature is not supported by the "standard" Ascii85 encoding.

   *wrapcol* controls whether the output should have newline (``b'\n'``)
   characters added to it. If this is non-zero, each output line will be
   at most this many characters long, excluding the trailing newline.

   *pad* controls whether the input is padded to a multiple of 4
   before encoding. Note that the ``btoa`` implementation always pads.

   *adobe* controls whether the encoded byte sequence is framed with ``<~``
   and ``~>``, which is used by the Adobe implementation.

   .. versionadded:: 3.4


.. function:: a85decode(b, *, foldspaces=False, adobe=False, ignorechars=b' \t\n\r\v')

   Decode the Ascii85 encoded :term:`bytes-like object` or ASCII string *b* and
   return the decoded :class:`bytes`.

   *foldspaces* is a flag that specifies whether the 'y' short sequence
   should be accepted as shorthand for 4 consecutive spaces (ASCII 0x20).
   This feature is not supported by the "standard" Ascii85 encoding.

   *adobe* controls whether the input sequence is in Adobe Ascii85 format
   (i.e. is framed with <~ and ~>).

   *ignorechars* should be a :term:`bytes-like object` or ASCII string
   containing characters to ignore
   from the input. This should only contain whitespace characters, and by
   default contains all whitespace characters in ASCII.

   .. versionadded:: 3.4


.. function:: b85encode(b, pad=False)

   Encode the :term:`bytes-like object` *b* using base85 (as used in e.g.
   git-style binary diffs) and return the encoded :class:`bytes`.

   If *pad* is true, the input is padded with ``b'\0'`` so its length is a
   multiple of 4 bytes before encoding.

   .. versionadded:: 3.4


.. function:: b85decode(b)

   Decode the base85-encoded :term:`bytes-like object` or ASCII string *b* and
   return the decoded :class:`bytes`.  Padding is implicitly removed, if
   necessary.

   .. versionadded:: 3.4


.. function:: z85encode(s)

   Encode the :term:`bytes-like object` *s* using Z85 (as used in ZeroMQ)
   and return the encoded :class:`bytes`.  See `Z85  specification
   <https://rfc.zeromq.org/spec/32/>`_ for more information.

   .. versionadded:: 3.13


.. function:: z85decode(s)

   Decode the Z85-encoded :term:`bytes-like object` or ASCII string *s* and
   return the decoded :class:`bytes`.  See `Z85  specification
   <https://rfc.zeromq.org/spec/32/>`_ for more information.

   .. versionadded:: 3.13


The legacy interface:

.. function:: decode(input, output)

   Decode the contents of the binary *input* file and write the resulting binary
   data to the *output* file. *input* and *output* must be :term:`file objects
   <file object>`. *input* will be read until ``input.readline()`` returns an
   empty bytes object.


.. function:: decodebytes(s)

   Decode the :term:`bytes-like object` *s*, which must contain one or more
   lines of base64 encoded data, and return the decoded :class:`bytes`.

   .. versionadded:: 3.1


.. function:: encode(input, output)

   Encode the contents of the binary *input* file and write the resulting base64
   encoded data to the *output* file. *input* and *output* must be :term:`file
   objects <file object>`. *input* will be read until ``input.read()`` returns
   an empty bytes object. :func:`encode` inserts a newline character (``b'\n'``)
   after every 76 bytes of the output, as well as ensuring that the output
   always ends with a newline, as per :rfc:`2045` (MIME).


.. function:: encodebytes(s)

   Encode the :term:`bytes-like object` *s*, which can contain arbitrary binary
   data, and return :class:`bytes` containing the base64-encoded data, with newlines
   (``b'\n'``) inserted after every 76 bytes of output, and ensuring that
   there is a trailing newline, as per :rfc:`2045` (MIME).

   .. versionadded:: 3.1


An example usage of the module:

   >>> import base64
   >>> encoded = base64.b64encode(b'data to be encoded')
   >>> encoded
   b'ZGF0YSB0byBiZSBlbmNvZGVk'
   >>> data = base64.b64decode(encoded)
   >>> data
   b'data to be encoded'

.. _base64-security:

Security Considerations
-----------------------

A new security considerations section was added to :rfc:`4648` (section 12); it's
recommended to review the security section for any code deployed to production.

.. seealso::

   Module :mod:`binascii`
      Support module containing ASCII-to-binary and binary-to-ASCII conversions.

   :rfc:`1521` - MIME (Multipurpose Internet Mail Extensions) Part One: Mechanisms for Specifying and Describing the Format of Internet Message Bodies
      Section 5.2, "Base64 Content-Transfer-Encoding," provides the definition of the
      base64 encoding.



================================================
File: /Doc/library/bdb.rst
================================================
:mod:`!bdb` --- Debugger framework
==================================

.. module:: bdb
   :synopsis: Debugger framework.

**Source code:** :source:`Lib/bdb.py`

--------------

The :mod:`bdb` module handles basic debugger functions, like setting breakpoints
or managing execution via the debugger.

The following exception is defined:

.. exception:: BdbQuit

   Exception raised by the :class:`Bdb` class for quitting the debugger.


The :mod:`bdb` module also defines two classes:

.. class:: Breakpoint(self, file, line, temporary=False, cond=None, funcname=None)

   This class implements temporary breakpoints, ignore counts, disabling and
   (re-)enabling, and conditionals.

   Breakpoints are indexed by number through a list called :attr:`bpbynumber`
   and by ``(file, line)`` pairs through :attr:`bplist`.  The former points to
   a single instance of class :class:`Breakpoint`.  The latter points to a list
   of such instances since there may be more than one breakpoint per line.

   When creating a breakpoint, its associated :attr:`file name <file>` should
   be in canonical form.  If a :attr:`funcname` is defined, a breakpoint
   :attr:`hit <hits>` will be counted when the first line of that function is
   executed.  A :attr:`conditional <cond>` breakpoint always counts a
   :attr:`hit <hits>`.

   :class:`Breakpoint` instances have the following methods:

   .. method:: deleteMe()

      Delete the breakpoint from the list associated to a file/line.  If it is
      the last breakpoint in that position, it also deletes the entry for the
      file/line.


   .. method:: enable()

      Mark the breakpoint as enabled.


   .. method:: disable()

      Mark the breakpoint as disabled.


   .. method:: bpformat()

      Return a string with all the information about the breakpoint, nicely
      formatted:

      * Breakpoint number.
      * Temporary status (del or keep).
      * File/line position.
      * Break condition.
      * Number of times to ignore.
      * Number of times hit.

      .. versionadded:: 3.2

   .. method:: bpprint(out=None)

      Print the output of :meth:`bpformat` to the file *out*, or if it is
      ``None``, to standard output.

   :class:`Breakpoint` instances have the following attributes:

   .. attribute:: file

      File name of the :class:`Breakpoint`.

   .. attribute:: line

      Line number of the :class:`Breakpoint` within :attr:`file`.

   .. attribute:: temporary

      ``True`` if a :class:`Breakpoint` at (file, line) is temporary.

   .. attribute:: cond

      Condition for evaluating a :class:`Breakpoint` at (file, line).

   .. attribute:: funcname

      Function name that defines whether a :class:`Breakpoint` is hit upon
      entering the function.

   .. attribute:: enabled

      ``True`` if :class:`Breakpoint` is enabled.

   .. attribute:: bpbynumber

      Numeric index for a single instance of a :class:`Breakpoint`.

   .. attribute:: bplist

      Dictionary of :class:`Breakpoint` instances indexed by
      (:attr:`file`, :attr:`line`) tuples.

   .. attribute:: ignore

      Number of times to ignore a :class:`Breakpoint`.

   .. attribute:: hits

      Count of the number of times a :class:`Breakpoint` has been hit.

.. class:: Bdb(skip=None)

   The :class:`Bdb` class acts as a generic Python debugger base class.

   This class takes care of the details of the trace facility; a derived class
   should implement user interaction.  The standard debugger class
   (:class:`pdb.Pdb`) is an example.

   The *skip* argument, if given, must be an iterable of glob-style
   module name patterns.  The debugger will not step into frames that
   originate in a module that matches one of these patterns. Whether a
   frame is considered to originate in a certain module is determined
   by the ``__name__`` in the frame globals.

   .. versionchanged:: 3.1
      Added the *skip* parameter.

   The following methods of :class:`Bdb` normally don't need to be overridden.

   .. method:: canonic(filename)

      Return canonical form of *filename*.

      For real file names, the canonical form is an operating-system-dependent,
      :func:`case-normalized <os.path.normcase>` :func:`absolute path
      <os.path.abspath>`. A *filename* with angle brackets, such as ``"<stdin>"``
      generated in interactive mode, is returned unchanged.

   .. method:: reset()

      Set the :attr:`!botframe`, :attr:`!stopframe`, :attr:`!returnframe` and
      :attr:`quitting <Bdb.set_quit>` attributes with values ready to start debugging.

   .. method:: trace_dispatch(frame, event, arg)

      This function is installed as the trace function of debugged frames.  Its
      return value is the new trace function (in most cases, that is, itself).

      The default implementation decides how to dispatch a frame, depending on
      the type of event (passed as a string) that is about to be executed.
      *event* can be one of the following:

      * ``"line"``: A new line of code is going to be executed.
      * ``"call"``: A function is about to be called, or another code block
        entered.
      * ``"return"``: A function or other code block is about to return.
      * ``"exception"``: An exception has occurred.
      * ``"c_call"``: A C function is about to be called.
      * ``"c_return"``: A C function has returned.
      * ``"c_exception"``: A C function has raised an exception.

      For the Python events, specialized functions (see below) are called.  For
      the C events, no action is taken.

      The *arg* parameter depends on the previous event.

      See the documentation for :func:`sys.settrace` for more information on the
      trace function.  For more information on code and frame objects, refer to
      :ref:`types`.

   .. method:: dispatch_line(frame)

      If the debugger should stop on the current line, invoke the
      :meth:`user_line` method (which should be overridden in subclasses).
      Raise a :exc:`BdbQuit` exception if the :attr:`quitting  <Bdb.set_quit>` flag is set
      (which can be set from :meth:`user_line`).  Return a reference to the
      :meth:`trace_dispatch` method for further tracing in that scope.

   .. method:: dispatch_call(frame, arg)

      If the debugger should stop on this function call, invoke the
      :meth:`user_call` method (which should be overridden in subclasses).
      Raise a :exc:`BdbQuit` exception if the :attr:`quitting  <Bdb.set_quit>` flag is set
      (which can be set from :meth:`user_call`).  Return a reference to the
      :meth:`trace_dispatch` method for further tracing in that scope.

   .. method:: dispatch_return(frame, arg)

      If the debugger should stop on this function return, invoke the
      :meth:`user_return` method (which should be overridden in subclasses).
      Raise a :exc:`BdbQuit` exception if the :attr:`quitting  <Bdb.set_quit>` flag is set
      (which can be set from :meth:`user_return`).  Return a reference to the
      :meth:`trace_dispatch` method for further tracing in that scope.

   .. method:: dispatch_exception(frame, arg)

      If the debugger should stop at this exception, invokes the
      :meth:`user_exception` method (which should be overridden in subclasses).
      Raise a :exc:`BdbQuit` exception if the :attr:`quitting  <Bdb.set_quit>` flag is set
      (which can be set from :meth:`user_exception`).  Return a reference to the
      :meth:`trace_dispatch` method for further tracing in that scope.

   Normally derived classes don't override the following methods, but they may
   if they want to redefine the definition of stopping and breakpoints.

   .. method:: is_skipped_line(module_name)

      Return ``True`` if *module_name* matches any skip pattern.

   .. method:: stop_here(frame)

      Return ``True`` if *frame* is below the starting frame in the stack.

   .. method:: break_here(frame)

      Return ``True`` if there is an effective breakpoint for this line.

      Check whether a line or function breakpoint exists and is in effect.  Delete temporary
      breakpoints based on information from :func:`effective`.

   .. method:: break_anywhere(frame)

      Return ``True`` if any breakpoint exists for *frame*'s filename.

   Derived classes should override these methods to gain control over debugger
   operation.

   .. method:: user_call(frame, argument_list)

      Called from :meth:`dispatch_call` if a break might stop inside the
      called function.

      *argument_list* is not used anymore and will always be ``None``.
      The argument is kept for backwards compatibility.

   .. method:: user_line(frame)

      Called from :meth:`dispatch_line` when either :meth:`stop_here` or
      :meth:`break_here` returns ``True``.

   .. method:: user_return(frame, return_value)

      Called from :meth:`dispatch_return` when :meth:`stop_here` returns ``True``.

   .. method:: user_exception(frame, exc_info)

      Called from :meth:`dispatch_exception` when :meth:`stop_here`
      returns ``True``.

   .. method:: do_clear(arg)

      Handle how a breakpoint must be removed when it is a temporary one.

      This method must be implemented by derived classes.


   Derived classes and clients can call the following methods to affect the
   stepping state.

   .. method:: set_step()

      Stop after one line of code.

   .. method:: set_next(frame)

      Stop on the next line in or below the given frame.

   .. method:: set_return(frame)

      Stop when returning from the given frame.

   .. method:: set_until(frame, lineno=None)

      Stop when the line with the *lineno* greater than the current one is
      reached or when returning from current frame.

   .. method:: set_trace([frame])

      Start debugging from *frame*.  If *frame* is not specified, debugging
      starts from caller's frame.

      .. versionchanged:: 3.13
         :func:`set_trace` will enter the debugger immediately, rather than
         on the next line of code to be executed.

   .. method:: set_continue()

      Stop only at breakpoints or when finished.  If there are no breakpoints,
      set the system trace function to ``None``.

   .. method:: set_quit()

      .. index:: single: quitting (bdb.Bdb attribute)

      Set the :attr:`!quitting` attribute to ``True``.  This raises :exc:`BdbQuit` in
      the next call to one of the :meth:`!dispatch_\*` methods.


   Derived classes and clients can call the following methods to manipulate
   breakpoints.  These methods return a string containing an error message if
   something went wrong, or ``None`` if all is well.

   .. method:: set_break(filename, lineno, temporary=False, cond=None, funcname=None)

      Set a new breakpoint.  If the *lineno* line doesn't exist for the
      *filename* passed as argument, return an error message.  The *filename*
      should be in canonical form, as described in the :meth:`canonic` method.

   .. method:: clear_break(filename, lineno)

      Delete the breakpoints in *filename* and *lineno*.  If none were set,
      return an error message.

   .. method:: clear_bpbynumber(arg)

      Delete the breakpoint which has the index *arg* in the
      :attr:`Breakpoint.bpbynumber`.  If *arg* is not numeric or out of range,
      return an error message.

   .. method:: clear_all_file_breaks(filename)

      Delete all breakpoints in *filename*.  If none were set, return an error
      message.

   .. method:: clear_all_breaks()

      Delete all existing breakpoints.  If none were set, return an error
      message.

   .. method:: get_bpbynumber(arg)

      Return a breakpoint specified by the given number.  If *arg* is a string,
      it will be converted to a number.  If *arg* is a non-numeric string, if
      the given breakpoint never existed or has been deleted, a
      :exc:`ValueError` is raised.

      .. versionadded:: 3.2

   .. method:: get_break(filename, lineno)

      Return ``True`` if there is a breakpoint for *lineno* in *filename*.

   .. method:: get_breaks(filename, lineno)

      Return all breakpoints for *lineno* in *filename*, or an empty list if
      none are set.

   .. method:: get_file_breaks(filename)

      Return all breakpoints in *filename*, or an empty list if none are set.

   .. method:: get_all_breaks()

      Return all breakpoints that are set.


   Derived classes and clients can call the following methods to get a data
   structure representing a stack trace.

   .. method:: get_stack(f, t)

      Return a list of (frame, lineno) tuples in a stack trace, and a size.

      The most recently called frame is last in the list. The size is the number
      of frames below the frame where the debugger was invoked.

   .. method:: format_stack_entry(frame_lineno, lprefix=': ')

      Return a string with information about a stack entry, which is a
      ``(frame, lineno)`` tuple.  The return string contains:

      * The canonical filename which contains the frame.
      * The function name or ``"<lambda>"``.
      * The input arguments.
      * The return value.
      * The line of code (if it exists).


   The following two methods can be called by clients to use a debugger to debug
   a :term:`statement`, given as a string.

   .. method:: run(cmd, globals=None, locals=None)

      Debug a statement executed via the :func:`exec` function.  *globals*
      defaults to :attr:`!__main__.__dict__`, *locals* defaults to *globals*.

   .. method:: runeval(expr, globals=None, locals=None)

      Debug an expression executed via the :func:`eval` function.  *globals* and
      *locals* have the same meaning as in :meth:`run`.

   .. method:: runctx(cmd, globals, locals)

      For backwards compatibility.  Calls the :meth:`run` method.

   .. method:: runcall(func, /, *args, **kwds)

      Debug a single function call, and return its result.


Finally, the module defines the following functions:

.. function:: checkfuncname(b, frame)

   Return ``True`` if we should break here, depending on the way the
   :class:`Breakpoint` *b* was set.

   If it was set via line number, it checks if
   :attr:`b.line <bdb.Breakpoint.line>` is the same as the one in *frame*.
   If the breakpoint was set via
   :attr:`function name <bdb.Breakpoint.funcname>`, we have to check we are in
   the right *frame* (the right function) and if we are on its first executable
   line.

.. function:: effective(file, line, frame)

   Return ``(active breakpoint, delete temporary flag)`` or ``(None, None)`` as the
   breakpoint to act upon.

   The *active breakpoint* is the first entry in
   :attr:`bplist <bdb.Breakpoint.bplist>` for the
   (:attr:`file <bdb.Breakpoint.file>`, :attr:`line <bdb.Breakpoint.line>`)
   (which must exist) that is :attr:`enabled <bdb.Breakpoint.enabled>`, for
   which :func:`checkfuncname` is true, and that has neither a false
   :attr:`condition <bdb.Breakpoint.cond>` nor positive
   :attr:`ignore <bdb.Breakpoint.ignore>` count.  The *flag*, meaning that a
   temporary breakpoint should be deleted, is ``False`` only when the
   :attr:`cond <bdb.Breakpoint.cond>` cannot be evaluated (in which case,
   :attr:`ignore <bdb.Breakpoint.ignore>` count is ignored).

   If no such entry exists, then ``(None, None)`` is returned.


.. function:: set_trace()

   Start debugging with a :class:`Bdb` instance from caller's frame.


================================================
File: /Doc/library/binary.rst
================================================
.. _binaryservices:

********************
Binary Data Services
********************

The modules described in this chapter provide some basic services operations
for manipulation of binary data. Other operations on binary data, specifically
in relation to file formats and network protocols, are described in the
relevant sections.

Some libraries described under :ref:`textservices` also work with either
ASCII-compatible binary formats (for example, :mod:`re`) or all binary data
(for example, :mod:`difflib`).

In addition, see the documentation for Python's built-in binary data types in
:ref:`binaryseq`.

.. toctree::

   struct.rst
   codecs.rst



================================================
File: /Doc/library/binascii.rst
================================================
:mod:`!binascii` --- Convert between binary and ASCII
=====================================================

.. module:: binascii
   :synopsis: Tools for converting between binary and various ASCII-encoded binary
              representations.

.. index::
   pair: module; base64

--------------

The :mod:`binascii` module contains a number of methods to convert between
binary and various ASCII-encoded binary representations. Normally, you will not
use these functions directly but use wrapper modules like
:mod:`base64` instead. The :mod:`binascii` module contains
low-level functions written in C for greater speed that are used by the
higher-level modules.

.. note::

   ``a2b_*`` functions accept Unicode strings containing only ASCII characters.
   Other functions only accept :term:`bytes-like objects <bytes-like object>` (such as
   :class:`bytes`, :class:`bytearray` and other objects that support the buffer
   protocol).

   .. versionchanged:: 3.3
      ASCII-only unicode strings are now accepted by the ``a2b_*`` functions.


The :mod:`binascii` module defines the following functions:


.. function:: a2b_uu(string)

   Convert a single line of uuencoded data back to binary and return the binary
   data. Lines normally contain 45 (binary) bytes, except for the last line. Line
   data may be followed by whitespace.


.. function:: b2a_uu(data, *, backtick=False)

   Convert binary data to a line of ASCII characters, the return value is the
   converted line, including a newline char. The length of *data* should be at most
   45. If *backtick* is true, zeros are represented by ``'`'`` instead of spaces.

   .. versionchanged:: 3.7
      Added the *backtick* parameter.


.. function:: a2b_base64(string, /, *, strict_mode=False)

   Convert a block of base64 data back to binary and return the binary data. More
   than one line may be passed at a time.

   If *strict_mode* is true, only valid base64 data will be converted. Invalid base64
   data will raise :exc:`binascii.Error`.

   Valid base64:

   * Conforms to :rfc:`3548`.
   * Contains only characters from the base64 alphabet.
   * Contains no excess data after padding (including excess padding, newlines, etc.).
   * Does not start with a padding.

   .. versionchanged:: 3.11
      Added the *strict_mode* parameter.


.. function:: b2a_base64(data, *, newline=True)

   Convert binary data to a line of ASCII characters in base64 coding. The return
   value is the converted line, including a newline char if *newline* is
   true.  The output of this function conforms to :rfc:`3548`.

   .. versionchanged:: 3.6
      Added the *newline* parameter.


.. function:: a2b_qp(data, header=False)

   Convert a block of quoted-printable data back to binary and return the binary
   data. More than one line may be passed at a time. If the optional argument
   *header* is present and true, underscores will be decoded as spaces.


.. function:: b2a_qp(data, quotetabs=False, istext=True, header=False)

   Convert binary data to a line(s) of ASCII characters in quoted-printable
   encoding.  The return value is the converted line(s). If the optional argument
   *quotetabs* is present and true, all tabs and spaces will be encoded.   If the
   optional argument *istext* is present and true, newlines are not encoded but
   trailing whitespace will be encoded. If the optional argument *header* is
   present and true, spaces will be encoded as underscores per :rfc:`1522`. If the
   optional argument *header* is present and false, newline characters will be
   encoded as well; otherwise linefeed conversion might corrupt the binary data
   stream.


.. function:: crc_hqx(data, value)

   Compute a 16-bit CRC value of *data*, starting with *value* as the
   initial CRC, and return the result.  This uses the CRC-CCITT polynomial
   *x*:sup:`16` + *x*:sup:`12` + *x*:sup:`5` + 1, often represented as
   0x1021.  This CRC is used in the binhex4 format.


.. function:: crc32(data[, value])

   Compute CRC-32, the unsigned 32-bit checksum of *data*, starting with an
   initial CRC of *value*.  The default initial CRC is zero.  The algorithm
   is consistent with the ZIP file checksum.  Since the algorithm is designed for
   use as a checksum algorithm, it is not suitable for use as a general hash
   algorithm.  Use as follows::

      print(binascii.crc32(b"hello world"))
      # Or, in two pieces:
      crc = binascii.crc32(b"hello")
      crc = binascii.crc32(b" world", crc)
      print('crc32 = {:#010x}'.format(crc))

   .. versionchanged:: 3.0
      The result is always unsigned.

.. function:: b2a_hex(data[, sep[, bytes_per_sep=1]])
              hexlify(data[, sep[, bytes_per_sep=1]])

   Return the hexadecimal representation of the binary *data*.  Every byte of
   *data* is converted into the corresponding 2-digit hex representation.  The
   returned bytes object is therefore twice as long as the length of *data*.

   Similar functionality (but returning a text string) is also conveniently
   accessible using the :meth:`bytes.hex` method.

   If *sep* is specified, it must be a single character str or bytes object.
   It will be inserted in the output after every *bytes_per_sep* input bytes.
   Separator placement is counted from the right end of the output by default,
   if you wish to count from the left, supply a negative *bytes_per_sep* value.

      >>> import binascii
      >>> binascii.b2a_hex(b'\xb9\x01\xef')
      b'b901ef'
      >>> binascii.hexlify(b'\xb9\x01\xef', '-')
      b'b9-01-ef'
      >>> binascii.b2a_hex(b'\xb9\x01\xef', b'_', 2)
      b'b9_01ef'
      >>> binascii.b2a_hex(b'\xb9\x01\xef', b' ', -2)
      b'b901 ef'

   .. versionchanged:: 3.8
      The *sep* and *bytes_per_sep* parameters were added.

.. function:: a2b_hex(hexstr)
              unhexlify(hexstr)

   Return the binary data represented by the hexadecimal string *hexstr*.  This
   function is the inverse of :func:`b2a_hex`. *hexstr* must contain an even number
   of hexadecimal digits (which can be upper or lower case), otherwise an
   :exc:`Error` exception is raised.

   Similar functionality (accepting only text string arguments, but more
   liberal towards whitespace) is also accessible using the
   :meth:`bytes.fromhex` class method.

.. exception:: Error

   Exception raised on errors. These are usually programming errors.


.. exception:: Incomplete

   Exception raised on incomplete data. These are usually not programming errors,
   but may be handled by reading a little more data and trying again.


.. seealso::

   Module :mod:`base64`
      Support for RFC compliant base64-style encoding in base 16, 32, 64,
      and 85.

   Module :mod:`quopri`
      Support for quoted-printable encoding used in MIME email messages.


================================================
File: /Doc/library/bisect.rst
================================================
:mod:`!bisect` --- Array bisection algorithm
============================================

.. module:: bisect
   :synopsis: Array bisection algorithms for binary searching.
.. sectionauthor:: Fred L. Drake, Jr. <fdrake@acm.org>
.. sectionauthor:: Raymond Hettinger <python at rcn.com>
.. example based on the PyModules FAQ entry by Aaron Watters <arw@pythonpros.com>

**Source code:** :source:`Lib/bisect.py`

--------------

This module provides support for maintaining a list in sorted order without
having to sort the list after each insertion.  For long lists of items with
expensive comparison operations, this can be an improvement over
linear searches or frequent resorting.

The module is called :mod:`bisect` because it uses a basic bisection
algorithm to do its work.  Unlike other bisection tools that search for a
specific value, the functions in this module are designed to locate an
insertion point. Accordingly, the functions never call an :meth:`~object.__eq__`
method to determine whether a value has been found.  Instead, the
functions only call the :meth:`~object.__lt__` method and will return an insertion
point between values in an array.

.. _bisect functions:

The following functions are provided:


.. function:: bisect_left(a, x, lo=0, hi=len(a), *, key=None)

   Locate the insertion point for *x* in *a* to maintain sorted order.
   The parameters *lo* and *hi* may be used to specify a subset of the list
   which should be considered; by default the entire list is used.  If *x* is
   already present in *a*, the insertion point will be before (to the left of)
   any existing entries.  The return value is suitable for use as the first
   parameter to ``list.insert()`` assuming that *a* is already sorted.

   The returned insertion point *ip* partitions the array *a* into two
   slices such that ``all(elem < x for elem in a[lo : ip])`` is true for the
   left slice and ``all(elem >= x for elem in a[ip : hi])`` is true for the
   right slice.

   *key* specifies a :term:`key function` of one argument that is used to
   extract a comparison key from each element in the array.  To support
   searching complex records, the key function is not applied to the *x* value.

   If *key* is ``None``, the elements are compared directly and
   no key function is called.

   .. versionchanged:: 3.10
      Added the *key* parameter.


.. function:: bisect_right(a, x, lo=0, hi=len(a), *, key=None)
              bisect(a, x, lo=0, hi=len(a), *, key=None)

   Similar to :py:func:`~bisect.bisect_left`, but returns an insertion point which comes
   after (to the right of) any existing entries of *x* in *a*.

   The returned insertion point *ip* partitions the array *a* into two slices
   such that ``all(elem <= x for elem in a[lo : ip])`` is true for the left slice and
   ``all(elem > x for elem in a[ip : hi])`` is true for the right slice.

   .. versionchanged:: 3.10
      Added the *key* parameter.


.. function:: insort_left(a, x, lo=0, hi=len(a), *, key=None)

   Insert *x* in *a* in sorted order.

   This function first runs :py:func:`~bisect.bisect_left` to locate an insertion point.
   Next, it runs the :meth:`!insert` method on *a* to insert *x* at the
   appropriate position to maintain sort order.

   To support inserting records in a table, the *key* function (if any) is
   applied to *x* for the search step but not for the insertion step.

   Keep in mind that the *O*\ (log *n*) search is dominated by the slow *O*\ (*n*)
   insertion step.

   .. versionchanged:: 3.10
      Added the *key* parameter.


.. function:: insort_right(a, x, lo=0, hi=len(a), *, key=None)
              insort(a, x, lo=0, hi=len(a), *, key=None)

   Similar to :py:func:`~bisect.insort_left`, but inserting *x* in *a* after any existing
   entries of *x*.

   This function first runs :py:func:`~bisect.bisect_right` to locate an insertion point.
   Next, it runs the :meth:`!insert` method on *a* to insert *x* at the
   appropriate position to maintain sort order.

   To support inserting records in a table, the *key* function (if any) is
   applied to *x* for the search step but not for the insertion step.

   Keep in mind that the *O*\ (log *n*) search is dominated by the slow *O*\ (*n*)
   insertion step.

   .. versionchanged:: 3.10
      Added the *key* parameter.


Performance Notes
-----------------

When writing time sensitive code using *bisect()* and *insort()*, keep these
thoughts in mind:

* Bisection is effective for searching ranges of values.
  For locating specific values, dictionaries are more performant.

* The *insort()* functions are *O*\ (*n*) because the logarithmic search step
  is dominated by the linear time insertion step.

* The search functions are stateless and discard key function results after
  they are used.  Consequently, if the search functions are used in a loop,
  the key function may be called again and again on the same array elements.
  If the key function isn't fast, consider wrapping it with
  :py:func:`functools.cache` to avoid duplicate computations.  Alternatively,
  consider searching an array of precomputed keys to locate the insertion
  point (as shown in the examples section below).

.. seealso::

   * `Sorted Collections
     <https://grantjenks.com/docs/sortedcollections/>`_ is a high performance
     module that uses *bisect* to managed sorted collections of data.

   * The `SortedCollection recipe
     <https://code.activestate.com/recipes/577197-sortedcollection/>`_ uses
     bisect to build a full-featured collection class with straight-forward search
     methods and support for a key-function.  The keys are precomputed to save
     unnecessary calls to the key function during searches.


Searching Sorted Lists
----------------------

The above `bisect functions`_ are useful for finding insertion points but
can be tricky or awkward to use for common searching tasks. The following five
functions show how to transform them into the standard lookups for sorted
lists::

    def index(a, x):
        'Locate the leftmost value exactly equal to x'
        i = bisect_left(a, x)
        if i != len(a) and a[i] == x:
            return i
        raise ValueError

    def find_lt(a, x):
        'Find rightmost value less than x'
        i = bisect_left(a, x)
        if i:
            return a[i-1]
        raise ValueError

    def find_le(a, x):
        'Find rightmost value less than or equal to x'
        i = bisect_right(a, x)
        if i:
            return a[i-1]
        raise ValueError

    def find_gt(a, x):
        'Find leftmost value greater than x'
        i = bisect_right(a, x)
        if i != len(a):
            return a[i]
        raise ValueError

    def find_ge(a, x):
        'Find leftmost item greater than or equal to x'
        i = bisect_left(a, x)
        if i != len(a):
            return a[i]
        raise ValueError


Examples
--------

.. _bisect-example:

The :py:func:`~bisect.bisect` function can be useful for numeric table lookups. This
example uses :py:func:`~bisect.bisect` to look up a letter grade for an exam score (say)
based on a set of ordered numeric breakpoints: 90 and up is an 'A', 80 to 89 is
a 'B', and so on::

   >>> def grade(score, breakpoints=[60, 70, 80, 90], grades='FDCBA'):
   ...     i = bisect(breakpoints, score)
   ...     return grades[i]
   ...
   >>> [grade(score) for score in [33, 99, 77, 70, 89, 90, 100]]
   ['F', 'A', 'C', 'C', 'B', 'A', 'A']

The :py:func:`~bisect.bisect` and :py:func:`~bisect.insort` functions also work with
lists of tuples.  The *key* argument can serve to extract the field used for ordering
records in a table::

    >>> from collections import namedtuple
    >>> from operator import attrgetter
    >>> from bisect import bisect, insort
    >>> from pprint import pprint

    >>> Movie = namedtuple('Movie', ('name', 'released', 'director'))

    >>> movies = [
    ...     Movie('Jaws', 1975, 'Spielberg'),
    ...     Movie('Titanic', 1997, 'Cameron'),
    ...     Movie('The Birds', 1963, 'Hitchcock'),
    ...     Movie('Aliens', 1986, 'Cameron')
    ... ]

    >>> # Find the first movie released after 1960
    >>> by_year = attrgetter('released')
    >>> movies.sort(key=by_year)
    >>> movies[bisect(movies, 1960, key=by_year)]
    Movie(name='The Birds', released=1963, director='Hitchcock')

    >>> # Insert a movie while maintaining sort order
    >>> romance = Movie('Love Story', 1970, 'Hiller')
    >>> insort(movies, romance, key=by_year)
    >>> pprint(movies)
    [Movie(name='The Birds', released=1963, director='Hitchcock'),
     Movie(name='Love Story', released=1970, director='Hiller'),
     Movie(name='Jaws', released=1975, director='Spielberg'),
     Movie(name='Aliens', released=1986, director='Cameron'),
     Movie(name='Titanic', released=1997, director='Cameron')]

If the key function is expensive, it is possible to avoid repeated function
calls by searching a list of precomputed keys to find the index of a record::

    >>> data = [('red', 5), ('blue', 1), ('yellow', 8), ('black', 0)]
    >>> data.sort(key=lambda r: r[1])       # Or use operator.itemgetter(1).
    >>> keys = [r[1] for r in data]         # Precompute a list of keys.
    >>> data[bisect_left(keys, 0)]
    ('black', 0)
    >>> data[bisect_left(keys, 1)]
    ('blue', 1)
    >>> data[bisect_left(keys, 5)]
    ('red', 5)
    >>> data[bisect_left(keys, 8)]
    ('yellow', 8)


================================================
File: /Doc/library/builtins.rst
================================================
:mod:`!builtins` --- Built-in objects
=====================================

.. module:: builtins
   :synopsis: The module that provides the built-in namespace.

--------------

This module provides direct access to all 'built-in' identifiers of Python; for
example, ``builtins.open`` is the full name for the built-in function :func:`open`.

This module is not normally accessed explicitly by most applications, but can be
useful in modules that provide objects with the same name as a built-in value,
but in which the built-in of that name is also needed.  For example, in a module
that wants to implement an :func:`open` function that wraps the built-in
:func:`open`, this module can be used directly::

   import builtins

   def open(path):
       f = builtins.open(path, 'r')
       return UpperCaser(f)

   class UpperCaser:
       '''Wrapper around a file that converts output to uppercase.'''

       def __init__(self, f):
           self._f = f

       def read(self, count=-1):
           return self._f.read(count).upper()

       # ...

As an implementation detail, most modules have the name ``__builtins__`` made
available as part of their globals.  The value of ``__builtins__`` is normally
either this module or the value of this module's :attr:`~object.__dict__` attribute.
Since this is an implementation detail, it may not be used by alternate
implementations of Python.

.. seealso::

   * :ref:`built-in-consts`
   * :ref:`bltin-exceptions`
   * :ref:`built-in-funcs`
   * :ref:`bltin-types`


================================================
File: /Doc/library/bz2.rst
================================================
:mod:`!bz2` --- Support for :program:`bzip2` compression
========================================================

.. module:: bz2
   :synopsis: Interfaces for bzip2 compression and decompression.

.. moduleauthor:: Gustavo Niemeyer <niemeyer@conectiva.com>
.. moduleauthor:: Nadeem Vawda <nadeem.vawda@gmail.com>
.. sectionauthor:: Gustavo Niemeyer <niemeyer@conectiva.com>
.. sectionauthor:: Nadeem Vawda <nadeem.vawda@gmail.com>

**Source code:** :source:`Lib/bz2.py`

--------------

This module provides a comprehensive interface for compressing and
decompressing data using the bzip2 compression algorithm.

The :mod:`bz2` module contains:

* The :func:`.open` function and :class:`BZ2File` class for reading and
  writing compressed files.
* The :class:`BZ2Compressor` and :class:`BZ2Decompressor` classes for
  incremental (de)compression.
* The :func:`compress` and :func:`decompress` functions for one-shot
  (de)compression.


(De)compression of files
------------------------

.. function:: open(filename, mode='rb', compresslevel=9, encoding=None, errors=None, newline=None)

   Open a bzip2-compressed file in binary or text mode, returning a :term:`file
   object`.

   As with the constructor for :class:`BZ2File`, the *filename* argument can be
   an actual filename (a :class:`str` or :class:`bytes` object), or an existing
   file object to read from or write to.

   The *mode* argument can be any of ``'r'``, ``'rb'``, ``'w'``, ``'wb'``,
   ``'x'``, ``'xb'``, ``'a'`` or ``'ab'`` for binary mode, or ``'rt'``,
   ``'wt'``, ``'xt'``, or ``'at'`` for text mode. The default is ``'rb'``.

   The *compresslevel* argument is an integer from 1 to 9, as for the
   :class:`BZ2File` constructor.

   For binary mode, this function is equivalent to the :class:`BZ2File`
   constructor: ``BZ2File(filename, mode, compresslevel=compresslevel)``. In
   this case, the *encoding*, *errors* and *newline* arguments must not be
   provided.

   For text mode, a :class:`BZ2File` object is created, and wrapped in an
   :class:`io.TextIOWrapper` instance with the specified encoding, error
   handling behavior, and line ending(s).

   .. versionadded:: 3.3

   .. versionchanged:: 3.4
      The ``'x'`` (exclusive creation) mode was added.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


.. class:: BZ2File(filename, mode='r', *, compresslevel=9)

   Open a bzip2-compressed file in binary mode.

   If *filename* is a :class:`str` or :class:`bytes` object, open the named file
   directly. Otherwise, *filename* should be a :term:`file object`, which will
   be used to read or write the compressed data.

   The *mode* argument can be either ``'r'`` for reading (default), ``'w'`` for
   overwriting, ``'x'`` for exclusive creation, or ``'a'`` for appending. These
   can equivalently be given as ``'rb'``, ``'wb'``, ``'xb'`` and ``'ab'``
   respectively.

   If *filename* is a file object (rather than an actual file name), a mode of
   ``'w'`` does not truncate the file, and is instead equivalent to ``'a'``.

   If *mode* is ``'w'`` or ``'a'``, *compresslevel* can be an integer between
   ``1`` and ``9`` specifying the level of compression: ``1`` produces the
   least compression, and ``9`` (default) produces the most compression.

   If *mode* is ``'r'``, the input file may be the concatenation of multiple
   compressed streams.

   :class:`BZ2File` provides all of the members specified by the
   :class:`io.BufferedIOBase`, except for :meth:`~io.BufferedIOBase.detach`
   and :meth:`~io.IOBase.truncate`.
   Iteration and the :keyword:`with` statement are supported.

   :class:`BZ2File` also provides the following methods and attributes:

   .. method:: peek([n])

      Return buffered data without advancing the file position. At least one
      byte of data will be returned (unless at EOF). The exact number of bytes
      returned is unspecified.

      .. note:: While calling :meth:`peek` does not change the file position of
         the :class:`BZ2File`, it may change the position of the underlying file
         object (e.g. if the :class:`BZ2File` was constructed by passing a file
         object for *filename*).

      .. versionadded:: 3.3

   .. method:: fileno()

      Return the file descriptor for the underlying file.

      .. versionadded:: 3.3

   .. method:: readable()

      Return whether the file was opened for reading.

      .. versionadded:: 3.3

   .. method:: seekable()

      Return whether the file supports seeking.

      .. versionadded:: 3.3

   .. method:: writable()

      Return whether the file was opened for writing.

      .. versionadded:: 3.3

   .. method:: read1(size=-1)

      Read up to *size* uncompressed bytes, while trying to avoid
      making multiple reads from the underlying stream. Reads up to a
      buffer's worth of data if size is negative.

      Returns ``b''`` if the file is at EOF.

      .. versionadded:: 3.3

   .. method:: readinto(b)

      Read bytes into *b*.

      Returns the number of bytes read (0 for EOF).

      .. versionadded:: 3.3

   .. attribute:: mode

      ``'rb'`` for reading and ``'wb'`` for writing.

      .. versionadded:: 3.13

   .. attribute:: name

      The bzip2 file name.  Equivalent to the :attr:`~io.FileIO.name`
      attribute of the underlying :term:`file object`.

      .. versionadded:: 3.13


   .. versionchanged:: 3.1
      Support for the :keyword:`with` statement was added.

   .. versionchanged:: 3.3
      Support was added for *filename* being a :term:`file object` instead of an
      actual filename.

      The ``'a'`` (append) mode was added, along with support for reading
      multi-stream files.

   .. versionchanged:: 3.4
      The ``'x'`` (exclusive creation) mode was added.

   .. versionchanged:: 3.5
      The :meth:`~io.BufferedIOBase.read` method now accepts an argument of
      ``None``.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.

   .. versionchanged:: 3.9
      The *buffering* parameter has been removed. It was ignored and deprecated
      since Python 3.0. Pass an open file object to control how the file is
      opened.

      The *compresslevel* parameter became keyword-only.

   .. versionchanged:: 3.10
      This class is thread unsafe in the face of multiple simultaneous
      readers or writers, just like its equivalent classes in :mod:`gzip` and
      :mod:`lzma` have always been.


Incremental (de)compression
---------------------------

.. class:: BZ2Compressor(compresslevel=9)

   Create a new compressor object. This object may be used to compress data
   incrementally. For one-shot compression, use the :func:`compress` function
   instead.

   *compresslevel*, if given, must be an integer between ``1`` and ``9``. The
   default is ``9``.

   .. method:: compress(data)

      Provide data to the compressor object. Returns a chunk of compressed data
      if possible, or an empty byte string otherwise.

      When you have finished providing data to the compressor, call the
      :meth:`flush` method to finish the compression process.


   .. method:: flush()

      Finish the compression process. Returns the compressed data left in
      internal buffers.

      The compressor object may not be used after this method has been called.


.. class:: BZ2Decompressor()

   Create a new decompressor object. This object may be used to decompress data
   incrementally. For one-shot compression, use the :func:`decompress` function
   instead.

   .. note::
      This class does not transparently handle inputs containing multiple
      compressed streams, unlike :func:`decompress` and :class:`BZ2File`. If
      you need to decompress a multi-stream input with :class:`BZ2Decompressor`,
      you must use a new decompressor for each stream.

   .. method:: decompress(data, max_length=-1)

      Decompress *data* (a :term:`bytes-like object`), returning
      uncompressed data as bytes. Some of *data* may be buffered
      internally, for use in later calls to :meth:`decompress`. The
      returned data should be concatenated with the output of any
      previous calls to :meth:`decompress`.

      If *max_length* is nonnegative, returns at most *max_length*
      bytes of decompressed data. If this limit is reached and further
      output can be produced, the :attr:`~.needs_input` attribute will
      be set to ``False``. In this case, the next call to
      :meth:`~.decompress` may provide *data* as ``b''`` to obtain
      more of the output.

      If all of the input data was decompressed and returned (either
      because this was less than *max_length* bytes, or because
      *max_length* was negative), the :attr:`~.needs_input` attribute
      will be set to ``True``.

      Attempting to decompress data after the end of stream is reached
      raises an :exc:`EOFError`.  Any data found after the end of the
      stream is ignored and saved in the :attr:`~.unused_data` attribute.

      .. versionchanged:: 3.5
         Added the *max_length* parameter.

   .. attribute:: eof

      ``True`` if the end-of-stream marker has been reached.

      .. versionadded:: 3.3


   .. attribute:: unused_data

      Data found after the end of the compressed stream.

      If this attribute is accessed before the end of the stream has been
      reached, its value will be ``b''``.

   .. attribute:: needs_input

      ``False`` if the :meth:`.decompress` method can provide more
      decompressed data before requiring new uncompressed input.

      .. versionadded:: 3.5


One-shot (de)compression
------------------------

.. function:: compress(data, compresslevel=9)

   Compress *data*, a :term:`bytes-like object <bytes-like object>`.

   *compresslevel*, if given, must be an integer between ``1`` and ``9``. The
   default is ``9``.

   For incremental compression, use a :class:`BZ2Compressor` instead.


.. function:: decompress(data)

   Decompress *data*, a :term:`bytes-like object <bytes-like object>`.

   If *data* is the concatenation of multiple compressed streams, decompress
   all of the streams.

   For incremental decompression, use a :class:`BZ2Decompressor` instead.

   .. versionchanged:: 3.3
      Support for multi-stream inputs was added.

.. _bz2-usage-examples:

Examples of usage
-----------------

Below are some examples of typical usage of the :mod:`bz2` module.

Using :func:`compress` and :func:`decompress` to demonstrate round-trip compression:

    >>> import bz2
    >>> data = b"""\
    ... Donec rhoncus quis sapien sit amet molestie. Fusce scelerisque vel augue
    ... nec ullamcorper. Nam rutrum pretium placerat. Aliquam vel tristique lorem,
    ... sit amet cursus ante. In interdum laoreet mi, sit amet ultrices purus
    ... pulvinar a. Nam gravida euismod magna, non varius justo tincidunt feugiat.
    ... Aliquam pharetra lacus non risus vehicula rutrum. Maecenas aliquam leo
    ... felis. Pellentesque semper nunc sit amet nibh ullamcorper, ac elementum
    ... dolor luctus. Curabitur lacinia mi ornare consectetur vestibulum."""
    >>> c = bz2.compress(data)
    >>> len(data) / len(c)  # Data compression ratio
    1.513595166163142
    >>> d = bz2.decompress(c)
    >>> data == d  # Check equality to original object after round-trip
    True

Using :class:`BZ2Compressor` for incremental compression:

    >>> import bz2
    >>> def gen_data(chunks=10, chunksize=1000):
    ...     """Yield incremental blocks of chunksize bytes."""
    ...     for _ in range(chunks):
    ...         yield b"z" * chunksize
    ...
    >>> comp = bz2.BZ2Compressor()
    >>> out = b""
    >>> for chunk in gen_data():
    ...     # Provide data to the compressor object
    ...     out = out + comp.compress(chunk)
    ...
    >>> # Finish the compression process.  Call this once you have
    >>> # finished providing data to the compressor.
    >>> out = out + comp.flush()

The example above uses a very "nonrandom" stream of data
(a stream of ``b"z"`` chunks).  Random data tends to compress poorly,
while ordered, repetitive data usually yields a high compression ratio.

Writing and reading a bzip2-compressed file in binary mode:

    >>> import bz2
    >>> data = b"""\
    ... Donec rhoncus quis sapien sit amet molestie. Fusce scelerisque vel augue
    ... nec ullamcorper. Nam rutrum pretium placerat. Aliquam vel tristique lorem,
    ... sit amet cursus ante. In interdum laoreet mi, sit amet ultrices purus
    ... pulvinar a. Nam gravida euismod magna, non varius justo tincidunt feugiat.
    ... Aliquam pharetra lacus non risus vehicula rutrum. Maecenas aliquam leo
    ... felis. Pellentesque semper nunc sit amet nibh ullamcorper, ac elementum
    ... dolor luctus. Curabitur lacinia mi ornare consectetur vestibulum."""
    >>> with bz2.open("myfile.bz2", "wb") as f:
    ...     # Write compressed data to file
    ...     unused = f.write(data)
    ...
    >>> with bz2.open("myfile.bz2", "rb") as f:
    ...     # Decompress data from file
    ...     content = f.read()
    ...
    >>> content == data  # Check equality to original object after round-trip
    True

.. testcleanup::

   import os
   os.remove("myfile.bz2")


================================================
File: /Doc/library/calendar.rst
================================================
:mod:`!calendar` --- General calendar-related functions
=======================================================

.. module:: calendar
   :synopsis: Functions for working with calendars, including some emulation
              of the Unix cal program.

.. sectionauthor:: Drew Csillag <drew_csillag@geocities.com>

**Source code:** :source:`Lib/calendar.py`

--------------

This module allows you to output calendars like the Unix :program:`cal` program,
and provides additional useful functions related to the calendar. By default,
these calendars have Monday as the first day of the week, and Sunday as the last
(the European convention). Use :func:`setfirstweekday` to set the first day of
the week to Sunday (6) or to any other weekday.  Parameters that specify dates
are given as integers. For related
functionality, see also the :mod:`datetime` and :mod:`time` modules.

The functions and classes defined in this module
use an idealized calendar, the current Gregorian calendar extended indefinitely
in both directions.  This matches the definition of the "proleptic Gregorian"
calendar in Dershowitz and Reingold's book "Calendrical Calculations", where
it's the base calendar for all computations.  Zero and negative years are
interpreted as prescribed by the ISO 8601 standard.  Year 0 is 1 BC, year -1 is
2 BC, and so on.


.. class:: Calendar(firstweekday=0)

   Creates a :class:`Calendar` object. *firstweekday* is an integer specifying the
   first day of the week. :const:`MONDAY` is ``0`` (the default), :const:`SUNDAY` is ``6``.

   A :class:`Calendar` object provides several methods that can be used for
   preparing the calendar data for formatting. This class doesn't do any formatting
   itself. This is the job of subclasses.


   :class:`Calendar` instances have the following methods and attributes:

   .. attribute:: firstweekday

      The first weekday as an integer (0--6).

      This property can also be set and read using
      :meth:`~Calendar.setfirstweekday` and
      :meth:`~Calendar.getfirstweekday` respectively.

   .. method:: getfirstweekday()

      Return an :class:`int` for the current first weekday (0--6).

      Identical to reading the :attr:`~Calendar.firstweekday` property.

   .. method:: setfirstweekday(firstweekday)

      Set the first weekday to *firstweekday*, passed as an :class:`int` (0--6)

      Identical to setting the :attr:`~Calendar.firstweekday` property.

   .. method:: iterweekdays()

      Return an iterator for the week day numbers that will be used for one
      week.  The first value from the iterator will be the same as the value of
      the :attr:`~Calendar.firstweekday` property.


   .. method:: itermonthdates(year, month)

      Return an iterator for the month *month* (1--12) in the year *year*. This
      iterator will return all days (as :class:`datetime.date` objects) for the
      month and all days before the start of the month or after the end of the
      month that are required to get a complete week.


   .. method:: itermonthdays(year, month)

      Return an iterator for the month *month* in the year *year* similar to
      :meth:`itermonthdates`, but not restricted by the :class:`datetime.date`
      range. Days returned will simply be day of the month numbers.  For the
      days outside of the specified month, the day number is ``0``.


   .. method:: itermonthdays2(year, month)

      Return an iterator for the month *month* in the year *year* similar to
      :meth:`itermonthdates`, but not restricted by the :class:`datetime.date`
      range. Days returned will be tuples consisting of a day of the month
      number and a week day number.


   .. method:: itermonthdays3(year, month)

      Return an iterator for the month *month* in the year *year* similar to
      :meth:`itermonthdates`, but not restricted by the :class:`datetime.date`
      range. Days returned will be tuples consisting of a year, a month and a day
      of the month numbers.

      .. versionadded:: 3.7


   .. method:: itermonthdays4(year, month)

      Return an iterator for the month *month* in the year *year* similar to
      :meth:`itermonthdates`, but not restricted by the :class:`datetime.date`
      range. Days returned will be tuples consisting of a year, a month, a day
      of the month, and a day of the week numbers.

      .. versionadded:: 3.7


   .. method:: monthdatescalendar(year, month)

      Return a list of the weeks in the month *month* of the *year* as full
      weeks.  Weeks are lists of seven :class:`datetime.date` objects.


   .. method:: monthdays2calendar(year, month)

      Return a list of the weeks in the month *month* of the *year* as full
      weeks.  Weeks are lists of seven tuples of day numbers and weekday
      numbers.


   .. method:: monthdayscalendar(year, month)

      Return a list of the weeks in the month *month* of the *year* as full
      weeks.  Weeks are lists of seven day numbers.


   .. method:: yeardatescalendar(year, width=3)

      Return the data for the specified year ready for formatting. The return
      value is a list of month rows. Each month row contains up to *width*
      months (defaulting to 3). Each month contains between 4 and 6 weeks and
      each week contains 1--7 days. Days are :class:`datetime.date` objects.


   .. method:: yeardays2calendar(year, width=3)

      Return the data for the specified year ready for formatting (similar to
      :meth:`yeardatescalendar`). Entries in the week lists are tuples of day
      numbers and weekday numbers. Day numbers outside this month are zero.


   .. method:: yeardayscalendar(year, width=3)

      Return the data for the specified year ready for formatting (similar to
      :meth:`yeardatescalendar`). Entries in the week lists are day numbers. Day
      numbers outside this month are zero.


.. class:: TextCalendar(firstweekday=0)

   This class can be used to generate plain text calendars.

   :class:`TextCalendar` instances have the following methods:


   .. method:: formatday(theday, weekday, width)

      Return a string representing a single day formatted with the given *width*.
      If *theday* is ``0``, return a string of spaces of
      the specified width, representing an empty day. The *weekday* parameter
      is unused.

   .. method:: formatweek(theweek, w=0, highlight_day=None)

      Return a single week in a string with no newline. If *w* is provided, it
      specifies the width of the date columns, which are centered. Depends
      on the first weekday as specified in the constructor or set by the
      :meth:`setfirstweekday` method.

      .. versionchanged:: next
         If *highlight_day* is given, this date is highlighted in color.
         This can be :ref:`controlled using environment variables
         <using-on-controlling-color>`.


   .. method:: formatweekday(weekday, width)

      Return a string representing the name of a single weekday formatted to
      the specified *width*. The *weekday* parameter is an integer representing
      the day of the week, where ``0`` is Monday and ``6`` is Sunday.


   .. method:: formatweekheader(width)

      Return a string containing the header row of weekday names, formatted
      with the given *width* for each column. The names depend on the locale
      settings and are padded to the specified width.


   .. method:: formatmonth(theyear, themonth, w=0, l=0, highlight_day=None)

      Return a month's calendar in a multi-line string. If *w* is provided, it
      specifies the width of the date columns, which are centered. If *l* is
      given, it specifies the number of lines that each week will use. Depends
      on the first weekday as specified in the constructor or set by the
      :meth:`setfirstweekday` method.

      .. versionchanged:: next
         If *highlight_day* is given, this date is highlighted in color.
         This can be :ref:`controlled using environment variables
         <using-on-controlling-color>`.


   .. method:: formatmonthname(theyear, themonth, width=0, withyear=True)

      Return a string representing the month's name centered within the
      specified *width*. If *withyear* is ``True``, include the year in the
      output. The *theyear* and *themonth* parameters specify the year
      and month for the name to be formatted respectively.


   .. method:: prmonth(theyear, themonth, w=0, l=0)

      Print a month's calendar as returned by :meth:`formatmonth`.


   .. method:: formatyear(theyear, w=2, l=1, c=6, m=3, highlight_day=None)

      Return a *m*-column calendar for an entire year as a multi-line string.
      Optional parameters *w*, *l*, and *c* are for date column width, lines per
      week, and number of spaces between month columns, respectively. Depends on
      the first weekday as specified in the constructor or set by the
      :meth:`setfirstweekday` method.  The earliest year for which a calendar
      can be generated is platform-dependent.

      .. versionchanged:: next
         If *highlight_day* is given, this date is highlighted in color.
         This can be :ref:`controlled using environment variables
         <using-on-controlling-color>`.


   .. method:: pryear(theyear, w=2, l=1, c=6, m=3)

      Print the calendar for an entire year as returned by :meth:`formatyear`.


.. class:: HTMLCalendar(firstweekday=0)

   This class can be used to generate HTML calendars.


   :class:`!HTMLCalendar` instances have the following methods:

   .. method:: formatmonth(theyear, themonth, withyear=True)

      Return a month's calendar as an HTML table. If *withyear* is true the year
      will be included in the header, otherwise just the month name will be
      used.


   .. method:: formatyear(theyear, width=3)

      Return a year's calendar as an HTML table. *width* (defaulting to 3)
      specifies the number of months per row.


   .. method:: formatyearpage(theyear, width=3, css='calendar.css', encoding=None)

      Return a year's calendar as a complete HTML page. *width* (defaulting to
      3) specifies the number of months per row. *css* is the name for the
      cascading style sheet to be used. :const:`None` can be passed if no style
      sheet should be used. *encoding* specifies the encoding to be used for the
      output (defaulting to the system default encoding).


   .. method:: formatmonthname(theyear, themonth, withyear=True)

      Return a month name as an HTML table row. If *withyear* is true the year
      will be included in the row, otherwise just the month name will be
      used.


   :class:`!HTMLCalendar` has the following attributes you can override to
   customize the CSS classes used by the calendar:

   .. attribute:: cssclasses

      A list of CSS classes used for each weekday. The default class list is::

         cssclasses = ["mon", "tue", "wed", "thu", "fri", "sat", "sun"]

      more styles can be added for each day::

         cssclasses = ["mon text-bold", "tue", "wed", "thu", "fri", "sat", "sun red"]

      Note that the length of this list must be seven items.


   .. attribute:: cssclass_noday

      The CSS class for a weekday occurring in the previous or coming month.

      .. versionadded:: 3.7


   .. attribute:: cssclasses_weekday_head

      A list of CSS classes used for weekday names in the header row.
      The default is the same as :attr:`cssclasses`.

      .. versionadded:: 3.7


   .. attribute:: cssclass_month_head

      The month's head CSS class (used by :meth:`formatmonthname`).
      The default value is ``"month"``.

      .. versionadded:: 3.7


   .. attribute:: cssclass_month

      The CSS class for the whole month's table (used by :meth:`formatmonth`).
      The default value is ``"month"``.

      .. versionadded:: 3.7


   .. attribute:: cssclass_year

      The CSS class for the whole year's table of tables (used by
      :meth:`formatyear`). The default value is ``"year"``.

      .. versionadded:: 3.7


   .. attribute:: cssclass_year_head

      The CSS class for the table head for the whole year (used by
      :meth:`formatyear`). The default value is ``"year"``.

      .. versionadded:: 3.7


   Note that although the naming for the above described class attributes is
   singular (e.g. ``cssclass_month`` ``cssclass_noday``), one can replace the
   single CSS class with a space separated list of CSS classes, for example::

         "text-bold text-red"

   Here is an example how :class:`!HTMLCalendar` can be customized::

       class CustomHTMLCal(calendar.HTMLCalendar):
           cssclasses = [style + " text-nowrap" for style in
                         calendar.HTMLCalendar.cssclasses]
           cssclass_month_head = "text-center month-head"
           cssclass_month = "text-center month"
           cssclass_year = "text-italic lead"


.. class:: LocaleTextCalendar(firstweekday=0, locale=None)

   This subclass of :class:`TextCalendar` can be passed a locale name in the
   constructor and will return month and weekday names in the specified locale.


.. class:: LocaleHTMLCalendar(firstweekday=0, locale=None)

   This subclass of :class:`HTMLCalendar` can be passed a locale name in the
   constructor and will return month and weekday names in the specified
   locale.

.. note::

   The constructor, :meth:`!formatweekday` and :meth:`!formatmonthname` methods
   of these two classes temporarily change the ``LC_TIME`` locale to the given
   *locale*. Because the current locale is a process-wide setting, they are
   not thread-safe.


For simple text calendars this module provides the following functions.

.. function:: setfirstweekday(weekday)

   Sets the weekday (``0`` is Monday, ``6`` is Sunday) to start each week. The
   values :const:`MONDAY`, :const:`TUESDAY`, :const:`WEDNESDAY`, :const:`THURSDAY`,
   :const:`FRIDAY`, :const:`SATURDAY`, and :const:`SUNDAY` are provided for
   convenience. For example, to set the first weekday to Sunday::

      import calendar
      calendar.setfirstweekday(calendar.SUNDAY)


.. function:: firstweekday()

   Returns the current setting for the weekday to start each week.


.. function:: isleap(year)

   Returns :const:`True` if *year* is a leap year, otherwise :const:`False`.


.. function:: leapdays(y1, y2)

   Returns the number of leap years in the range from *y1* to *y2* (exclusive),
   where *y1* and *y2* are years.

   This function works for ranges spanning a century change.


.. function:: weekday(year, month, day)

   Returns the day of the week (``0`` is Monday) for *year* (``1970``--...),
   *month* (``1``--``12``), *day* (``1``--``31``).


.. function:: weekheader(n)

   Return a header containing abbreviated weekday names. *n* specifies the width in
   characters for one weekday.


.. function:: monthrange(year, month)

   Returns weekday of first day of the month and number of days in month,  for the
   specified *year* and *month*.


.. function:: monthcalendar(year, month)

   Returns a matrix representing a month's calendar.  Each row represents a week;
   days outside of the month are represented by zeros. Each week begins with Monday
   unless set by :func:`setfirstweekday`.


.. function:: prmonth(theyear, themonth, w=0, l=0)

   Prints a month's calendar as returned by :func:`month`.


.. function:: month(theyear, themonth, w=0, l=0)

   Returns a month's calendar in a multi-line string using the :meth:`~TextCalendar.formatmonth`
   of the :class:`TextCalendar` class.


.. function:: prcal(year, w=0, l=0, c=6, m=3)

   Prints the calendar for an entire year as returned by  :func:`calendar`.


.. function:: calendar(year, w=2, l=1, c=6, m=3)

   Returns a 3-column calendar for an entire year as a multi-line string using
   the :meth:`~TextCalendar.formatyear` of the :class:`TextCalendar` class.


.. function:: timegm(tuple)

   An unrelated but handy function that takes a time tuple such as returned by
   the :func:`~time.gmtime` function in the :mod:`time` module, and returns the
   corresponding Unix timestamp value, assuming an epoch of 1970, and the POSIX
   encoding.  In fact, :func:`time.gmtime` and :func:`timegm` are each others'
   inverse.


The :mod:`calendar` module exports the following data attributes:

.. data:: day_name

   A sequence that represents the days of the week in the current locale,
   where Monday is day number 0.

       >>> import calendar
       >>> list(calendar.day_name)
       ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']


.. data:: day_abbr

   A sequence that represents the abbreviated days of the week in the current locale,
   where Mon is day number 0.

       >>> import calendar
       >>> list(calendar.day_abbr)
       ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']

.. data:: MONDAY
          TUESDAY
          WEDNESDAY
          THURSDAY
          FRIDAY
          SATURDAY
          SUNDAY

   Aliases for the days of the week,
   where ``MONDAY`` is ``0`` and ``SUNDAY`` is ``6``.

   .. versionadded:: 3.12


.. class:: Day

   Enumeration defining days of the week as integer constants.
   The members of this enumeration are exported to the module scope as
   :data:`MONDAY` through :data:`SUNDAY`.

   .. versionadded:: 3.12


.. data:: month_name

   A sequence that represents the months of the year in the current locale.  This
   follows normal convention of January being month number 1, so it has a length of
   13 and ``month_name[0]`` is the empty string.

       >>> import calendar
       >>> list(calendar.month_name)
       ['', 'January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']


.. data:: month_abbr

   A sequence that represents the abbreviated months of the year in the current
   locale.  This follows normal convention of January being month number 1, so it
   has a length of 13 and  ``month_abbr[0]`` is the empty string.

       >>> import calendar
       >>> list(calendar.month_abbr)
       ['', 'Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']

.. data:: JANUARY
          FEBRUARY
          MARCH
          APRIL
          MAY
          JUNE
          JULY
          AUGUST
          SEPTEMBER
          OCTOBER
          NOVEMBER
          DECEMBER

   Aliases for the months of the year,
   where ``JANUARY`` is ``1`` and ``DECEMBER`` is ``12``.

   .. versionadded:: 3.12


.. class:: Month

   Enumeration defining months of the year as integer constants.
   The members of this enumeration are exported to the module scope as
   :data:`JANUARY` through :data:`DECEMBER`.

   .. versionadded:: 3.12


The :mod:`calendar` module defines the following exceptions:

.. exception:: IllegalMonthError(month)

   A subclass of :exc:`ValueError`,
   raised when the given month number is outside of the range 1-12 (inclusive).

   .. attribute:: month

      The invalid month number.


.. exception:: IllegalWeekdayError(weekday)

   A subclass of :exc:`ValueError`,
   raised when the given weekday number is outside of the range 0-6 (inclusive).

   .. attribute:: weekday

      The invalid weekday number.


.. seealso::

   Module :mod:`datetime`
      Object-oriented interface to dates and times with similar functionality to the
      :mod:`time` module.

   Module :mod:`time`
      Low-level time related functions.


.. _calendar-cli:

Command-line usage
------------------

.. versionadded:: 2.5

The :mod:`calendar` module can be executed as a script from the command line
to interactively print a calendar.

.. code-block:: shell

   python -m calendar [-h] [-L LOCALE] [-e ENCODING] [-t {text,html}]
                      [-w WIDTH] [-l LINES] [-s SPACING] [-m MONTHS] [-c CSS]
                      [-f FIRST_WEEKDAY] [year] [month]


For example, to print a calendar for the year 2000:

.. code-block:: console

   $ python -m calendar 2000
                                     2000

         January                   February                   March
   Mo Tu We Th Fr Sa Su      Mo Tu We Th Fr Sa Su      Mo Tu We Th Fr Sa Su
                   1  2          1  2  3  4  5  6             1  2  3  4  5
    3  4  5  6  7  8  9       7  8  9 10 11 12 13       6  7  8  9 10 11 12
   10 11 12 13 14 15 16      14 15 16 17 18 19 20      13 14 15 16 17 18 19
   17 18 19 20 21 22 23      21 22 23 24 25 26 27      20 21 22 23 24 25 26
   24 25 26 27 28 29 30      28 29                     27 28 29 30 31
   31

          April                      May                       June
   Mo Tu We Th Fr Sa Su      Mo Tu We Th Fr Sa Su      Mo Tu We Th Fr Sa Su
                   1  2       1  2  3  4  5  6  7                1  2  3  4
    3  4  5  6  7  8  9       8  9 10 11 12 13 14       5  6  7  8  9 10 11
   10 11 12 13 14 15 16      15 16 17 18 19 20 21      12 13 14 15 16 17 18
   17 18 19 20 21 22 23      22 23 24 25 26 27 28      19 20 21 22 23 24 25
   24 25 26 27 28 29 30      29 30 31                  26 27 28 29 30

           July                     August                  September
   Mo Tu We Th Fr Sa Su      Mo Tu We Th Fr Sa Su      Mo Tu We Th Fr Sa Su
                   1  2          1  2  3  4  5  6                   1  2  3
    3  4  5  6  7  8  9       7  8  9 10 11 12 13       4  5  6  7  8  9 10
   10 11 12 13 14 15 16      14 15 16 17 18 19 20      11 12 13 14 15 16 17
   17 18 19 20 21 22 23      21 22 23 24 25 26 27      18 19 20 21 22 23 24
   24 25 26 27 28 29 30      28 29 30 31               25 26 27 28 29 30
   31

         October                   November                  December
   Mo Tu We Th Fr Sa Su      Mo Tu We Th Fr Sa Su      Mo Tu We Th Fr Sa Su
                      1             1  2  3  4  5                   1  2  3
    2  3  4  5  6  7  8       6  7  8  9 10 11 12       4  5  6  7  8  9 10
    9 10 11 12 13 14 15      13 14 15 16 17 18 19      11 12 13 14 15 16 17
   16 17 18 19 20 21 22      20 21 22 23 24 25 26      18 19 20 21 22 23 24
   23 24 25 26 27 28 29      27 28 29 30               25 26 27 28 29 30 31
   30 31


The following options are accepted:

.. program:: calendar


.. option:: --help, -h

   Show the help message and exit.


.. option:: --locale LOCALE, -L LOCALE

   The locale to use for month and weekday names.
   Defaults to English.


.. option:: --encoding ENCODING, -e ENCODING

   The encoding to use for output.
   :option:`--encoding` is required if :option:`--locale` is set.


.. option:: --type {text,html}, -t {text,html}

   Print the calendar to the terminal as text,
   or as an HTML document.


.. option:: --first-weekday FIRST_WEEKDAY, -f FIRST_WEEKDAY

   The weekday to start each week.
   Must be a number between 0 (Monday) and 6 (Sunday).
   Defaults to 0.

   .. versionadded:: 3.13

.. option:: year

   The year to print the calendar for.
   Defaults to the current year.


.. option:: month

   The month of the specified :option:`year` to print the calendar for.
   Must be a number between 1 and 12,
   and may only be used in text mode.
   Defaults to printing a calendar for the full year.


*Text-mode options:*

.. option:: --width WIDTH, -w WIDTH

   The width of the date column in terminal columns.
   The date is printed centred in the column.
   Any value lower than 2 is ignored.
   Defaults to 2.


.. option:: --lines LINES, -l LINES

   The number of lines for each week in terminal rows.
   The date is printed top-aligned.
   Any value lower than 1 is ignored.
   Defaults to 1.


.. option:: --spacing SPACING, -s SPACING

   The space between months in columns.
   Any value lower than 2 is ignored.
   Defaults to 6.


.. option:: --months MONTHS, -m MONTHS

   The number of months printed per row.
   Defaults to 3.

.. versionchanged:: next
   By default, today's date is highlighted in color and can be
   :ref:`controlled using environment variables <using-on-controlling-color>`.

*HTML-mode options:*

.. option:: --css CSS, -c CSS

   The path of a CSS stylesheet to use for the calendar.
   This must either be relative to the generated HTML,
   or an absolute HTTP or ``file:///`` URL.


================================================
File: /Doc/library/cgi.rst
================================================
:mod:`!cgi` --- Common Gateway Interface support
================================================

.. module:: cgi
   :synopsis: Removed in 3.13.
   :deprecated:

.. deprecated-removed:: 3.11 3.13

This module is no longer part of the Python standard library.
It was :ref:`removed in Python 3.13 <whatsnew313-pep594>` after
being deprecated in Python 3.11.  The removal was decided in :pep:`594`.

A fork of the module on PyPI can be used instead: :pypi:`legacy-cgi`.
This is a copy of the cgi module, no longer maintained or supported by the core
Python team.

The last version of Python that provided the :mod:`!cgi` module was
`Python 3.12 <https://docs.python.org/3.12/library/cgi.html>`_.


================================================
File: /Doc/library/cgitb.rst
================================================
:mod:`!cgitb` --- Traceback manager for CGI scripts
===================================================

.. module:: cgitb
   :synopsis: Removed in 3.13.
   :deprecated:

.. deprecated-removed:: 3.11 3.13

This module is no longer part of the Python standard library.
It was :ref:`removed in Python 3.13 <whatsnew313-pep594>` after
being deprecated in Python 3.11.  The removal was decided in :pep:`594`.

A fork of the module on PyPI can now be used instead: :pypi:`legacy-cgi`.
This is a copy of the cgi module, no longer maintained or supported by the core
Python team.

The last version of Python that provided the :mod:`!cgitb` module was
`Python 3.12 <https://docs.python.org/3.12/library/cgitb.html>`_.


================================================
File: /Doc/library/chunk.rst
================================================
:mod:`!chunk` --- Read IFF chunked data
=======================================

.. module:: chunk
   :synopsis: Removed in 3.13.
   :deprecated:

.. deprecated-removed:: 3.11 3.13

This module is no longer part of the Python standard library.
It was :ref:`removed in Python 3.13 <whatsnew313-pep594>` after
being deprecated in Python 3.11.  The removal was decided in :pep:`594`.

The last version of Python that provided the :mod:`!chunk` module was
`Python 3.12 <https://docs.python.org/3.12/library/chunk.html>`_.


================================================
File: /Doc/library/cmath.rst
================================================
:mod:`!cmath` --- Mathematical functions for complex numbers
============================================================

.. module:: cmath
   :synopsis: Mathematical functions for complex numbers.

--------------

This module provides access to mathematical functions for complex numbers.  The
functions in this module accept integers, floating-point numbers or complex
numbers as arguments. They will also accept any Python object that has either a
:meth:`~object.__complex__` or a :meth:`~object.__float__` method: these methods are used to
convert the object to a complex or floating-point number, respectively, and
the function is then applied to the result of the conversion.

.. note::

   For functions involving branch cuts, we have the problem of deciding how to
   define those functions on the cut itself. Following Kahan's "Branch cuts for
   complex elementary functions" paper, as well as Annex G of C99 and later C
   standards, we use the sign of zero to distinguish one side of the branch cut
   from the other: for a branch cut along (a portion of) the real axis we look
   at the sign of the imaginary part, while for a branch cut along the
   imaginary axis we look at the sign of the real part.

   For example, the :func:`cmath.sqrt` function has a branch cut along the
   negative real axis. An argument of ``-2-0j`` is treated as
   though it lies *below* the branch cut, and so gives a result on the negative
   imaginary axis::

      >>> cmath.sqrt(-2-0j)
      -1.4142135623730951j

   But an argument of ``-2+0j`` is treated as though it lies above
   the branch cut::

      >>> cmath.sqrt(-2+0j)
      1.4142135623730951j


Conversions to and from polar coordinates
-----------------------------------------

A Python complex number ``z`` is stored internally using *rectangular*
or *Cartesian* coordinates.  It is completely determined by its *real
part* ``z.real`` and its *imaginary part* ``z.imag``.

*Polar coordinates* give an alternative way to represent a complex
number.  In polar coordinates, a complex number *z* is defined by the
modulus *r* and the phase angle *phi*. The modulus *r* is the distance
from *z* to the origin, while the phase *phi* is the counterclockwise
angle, measured in radians, from the positive x-axis to the line
segment that joins the origin to *z*.

The following functions can be used to convert from the native
rectangular coordinates to polar coordinates and back.

.. function:: phase(x)

   Return the phase of *x* (also known as the *argument* of *x*), as a float.
   ``phase(x)`` is equivalent to ``math.atan2(x.imag, x.real)``.  The result
   lies in the range [-\ **, **], and the branch cut for this operation lies
   along the negative real axis.  The sign of the result is the same as the
   sign of ``x.imag``, even when ``x.imag`` is zero::

      >>> phase(-1+0j)
      3.141592653589793
      >>> phase(-1-0j)
      -3.141592653589793


.. note::

   The modulus (absolute value) of a complex number *x* can be
   computed using the built-in :func:`abs` function.  There is no
   separate :mod:`cmath` module function for this operation.


.. function:: polar(x)

   Return the representation of *x* in polar coordinates.  Returns a
   pair ``(r, phi)`` where *r* is the modulus of *x* and phi is the
   phase of *x*.  ``polar(x)`` is equivalent to ``(abs(x),
   phase(x))``.


.. function:: rect(r, phi)

   Return the complex number *x* with polar coordinates *r* and *phi*.
   Equivalent to ``complex(r * math.cos(phi), r * math.sin(phi))``.


Power and logarithmic functions
-------------------------------

.. function:: exp(x)

   Return *e* raised to the power *x*, where *e* is the base of natural
   logarithms.


.. function:: log(x[, base])

   Returns the logarithm of *x* to the given *base*. If the *base* is not
   specified, returns the natural logarithm of *x*. There is one branch cut,
   from 0 along the negative real axis to -.


.. function:: log10(x)

   Return the base-10 logarithm of *x*. This has the same branch cut as
   :func:`log`.


.. function:: sqrt(x)

   Return the square root of *x*. This has the same branch cut as :func:`log`.


Trigonometric functions
-----------------------

.. function:: acos(x)

   Return the arc cosine of *x*. There are two branch cuts: One extends right
   from 1 along the real axis to . The other extends left from -1 along the
   real axis to -.


.. function:: asin(x)

   Return the arc sine of *x*. This has the same branch cuts as :func:`acos`.


.. function:: atan(x)

   Return the arc tangent of *x*. There are two branch cuts: One extends from
   ``1j`` along the imaginary axis to ``j``. The other extends from ``-1j``
   along the imaginary axis to ``-j``.


.. function:: cos(x)

   Return the cosine of *x*.


.. function:: sin(x)

   Return the sine of *x*.


.. function:: tan(x)

   Return the tangent of *x*.


Hyperbolic functions
--------------------

.. function:: acosh(x)

   Return the inverse hyperbolic cosine of *x*. There is one branch cut,
   extending left from 1 along the real axis to -.


.. function:: asinh(x)

   Return the inverse hyperbolic sine of *x*. There are two branch cuts:
   One extends from ``1j`` along the imaginary axis to ``j``.  The other
   extends from ``-1j`` along the imaginary axis to ``-j``.


.. function:: atanh(x)

   Return the inverse hyperbolic tangent of *x*. There are two branch cuts: One
   extends from ``1`` along the real axis to ````. The other extends from
   ``-1`` along the real axis to ``-``.


.. function:: cosh(x)

   Return the hyperbolic cosine of *x*.


.. function:: sinh(x)

   Return the hyperbolic sine of *x*.


.. function:: tanh(x)

   Return the hyperbolic tangent of *x*.


Classification functions
------------------------

.. function:: isfinite(x)

   Return ``True`` if both the real and imaginary parts of *x* are finite, and
   ``False`` otherwise.

   .. versionadded:: 3.2


.. function:: isinf(x)

   Return ``True`` if either the real or the imaginary part of *x* is an
   infinity, and ``False`` otherwise.


.. function:: isnan(x)

   Return ``True`` if either the real or the imaginary part of *x* is a NaN,
   and ``False`` otherwise.


.. function:: isclose(a, b, *, rel_tol=1e-09, abs_tol=0.0)

   Return ``True`` if the values *a* and *b* are close to each other and
   ``False`` otherwise.

   Whether or not two values are considered close is determined according to
   given absolute and relative tolerances.  If no errors occur, the result will
   be: ``abs(a-b) <= max(rel_tol * max(abs(a), abs(b)), abs_tol)``.

   *rel_tol* is the relative tolerance -- it is the maximum allowed difference
   between *a* and *b*, relative to the larger absolute value of *a* or *b*.
   For example, to set a tolerance of 5%, pass ``rel_tol=0.05``.  The default
   tolerance is ``1e-09``, which assures that the two values are the same
   within about 9 decimal digits.  *rel_tol* must be nonnegative and less
   than ``1.0``.

   *abs_tol* is the absolute tolerance; it defaults to ``0.0`` and it must be
   nonnegative.  When comparing ``x`` to ``0.0``, ``isclose(x, 0)`` is computed
   as ``abs(x) <= rel_tol  * abs(x)``, which is ``False`` for any ``x`` and
   rel_tol less than ``1.0``.  So add an appropriate positive abs_tol argument
   to the call.

   The IEEE 754 special values of ``NaN``, ``inf``, and ``-inf`` will be
   handled according to IEEE rules.  Specifically, ``NaN`` is not considered
   close to any other value, including ``NaN``.  ``inf`` and ``-inf`` are only
   considered close to themselves.

   .. versionadded:: 3.5

   .. seealso::

      :pep:`485` -- A function for testing approximate equality


Constants
---------

.. data:: pi

   The mathematical constant **, as a float.


.. data:: e

   The mathematical constant *e*, as a float.


.. data:: tau

   The mathematical constant **, as a float.

   .. versionadded:: 3.6


.. data:: inf

   Floating-point positive infinity. Equivalent to ``float('inf')``.

   .. versionadded:: 3.6


.. data:: infj

   Complex number with zero real part and positive infinity imaginary
   part. Equivalent to ``complex(0.0, float('inf'))``.

   .. versionadded:: 3.6


.. data:: nan

   A floating-point "not a number" (NaN) value.  Equivalent to
   ``float('nan')``.

   .. versionadded:: 3.6


.. data:: nanj

   Complex number with zero real part and NaN imaginary part. Equivalent to
   ``complex(0.0, float('nan'))``.

   .. versionadded:: 3.6


.. index:: pair: module; math

Note that the selection of functions is similar, but not identical, to that in
module :mod:`math`.  The reason for having two modules is that some users aren't
interested in complex numbers, and perhaps don't even know what they are.  They
would rather have ``math.sqrt(-1)`` raise an exception than return a complex
number. Also note that the functions defined in :mod:`cmath` always return a
complex number, even if the answer can be expressed as a real number (in which
case the complex number has an imaginary part of zero).

A note on branch cuts: They are curves along which the given function fails to
be continuous.  They are a necessary feature of many complex functions.  It is
assumed that if you need to compute with complex functions, you will understand
about branch cuts.  Consult almost any (not too elementary) book on complex
variables for enlightenment.  For information of the proper choice of branch
cuts for numerical purposes, a good reference should be the following:


.. seealso::

   Kahan, W:  Branch cuts for complex elementary functions; or, Much ado about
   nothing's sign bit.  In Iserles, A., and Powell, M. (eds.), The state of the art
   in numerical analysis. Clarendon Press (1987) pp165--211.


================================================
File: /Doc/library/cmd.rst
================================================
:mod:`!cmd` --- Support for line-oriented command interpreters
==============================================================

.. module:: cmd
   :synopsis: Build line-oriented command interpreters.

.. sectionauthor:: Eric S. Raymond <esr@snark.thyrsus.com>

**Source code:** :source:`Lib/cmd.py`

--------------

The :class:`Cmd` class provides a simple framework for writing line-oriented
command interpreters.  These are often useful for test harnesses, administrative
tools, and prototypes that will later be wrapped in a more sophisticated
interface.

.. class:: Cmd(completekey='tab', stdin=None, stdout=None)

   A :class:`Cmd` instance or subclass instance is a line-oriented interpreter
   framework.  There is no good reason to instantiate :class:`Cmd` itself; rather,
   it's useful as a superclass of an interpreter class you define yourself in order
   to inherit :class:`Cmd`'s methods and encapsulate action methods.

   The optional argument *completekey* is the :mod:`readline` name of a completion
   key; it defaults to :kbd:`Tab`. If *completekey* is not :const:`None` and
   :mod:`readline` is available, command completion is done automatically.

   The default, ``'tab'``, is treated specially, so that it refers to the
   :kbd:`Tab` key on every :data:`readline.backend`.
   Specifically, if :data:`readline.backend` is ``editline``,
   ``Cmd`` will use ``'^I'`` instead of ``'tab'``.
   Note that other values are not treated this way, and might only work
   with a specific backend.

   The optional arguments *stdin* and *stdout* specify the  input and output file
   objects that the Cmd instance or subclass  instance will use for input and
   output. If not specified, they will default to :data:`sys.stdin` and
   :data:`sys.stdout`.

   If you want a given *stdin* to be used, make sure to set the instance's
   :attr:`use_rawinput` attribute to ``False``, otherwise *stdin* will be
   ignored.

   .. versionchanged:: 3.13
      ``completekey='tab'`` is replaced by ``'^I'`` for ``editline``.


.. _cmd-objects:

Cmd Objects
-----------

A :class:`Cmd` instance has the following methods:


.. method:: Cmd.cmdloop(intro=None)

   Repeatedly issue a prompt, accept input, parse an initial prefix off the
   received input, and dispatch to action methods, passing them the remainder of
   the line as argument.

   The optional argument is a banner or intro string to be issued before the first
   prompt (this overrides the :attr:`intro` class attribute).

   If the :mod:`readline` module is loaded, input will automatically inherit
   :program:`bash`\ -like history-list editing (e.g. :kbd:`Control-P` scrolls back
   to the last command, :kbd:`Control-N` forward to the next one, :kbd:`Control-F`
   moves the cursor to the right non-destructively, :kbd:`Control-B` moves the
   cursor to the left non-destructively, etc.).

   An end-of-file on input is passed back as the string ``'EOF'``.

   .. index::
      single: ? (question mark); in a command interpreter
      single: ! (exclamation); in a command interpreter

   An interpreter instance will recognize a command name ``foo`` if and only if it
   has a method :meth:`!do_foo`.  As a special case, a line beginning with the
   character ``'?'`` is dispatched to the method :meth:`do_help`.  As another
   special case, a line beginning with the character ``'!'`` is dispatched to the
   method :meth:`!do_shell` (if such a method is defined).

   This method will return when the :meth:`postcmd` method returns a true value.
   The *stop* argument to :meth:`postcmd` is the return value from the command's
   corresponding :meth:`!do_\*` method.

   If completion is enabled, completing commands will be done automatically, and
   completing of commands args is done by calling :meth:`!complete_foo` with
   arguments *text*, *line*, *begidx*, and *endidx*.  *text* is the string prefix
   we are attempting to match: all returned matches must begin with it. *line* is
   the current input line with leading whitespace removed, *begidx* and *endidx*
   are the beginning and ending indexes of the prefix text, which could be used to
   provide different completion depending upon which position the argument is in.


.. method:: Cmd.do_help(arg)

   All subclasses of :class:`Cmd` inherit a predefined :meth:`!do_help`.  This
   method, called with an argument ``'bar'``, invokes the corresponding method
   :meth:`!help_bar`, and if that is not present, prints the docstring of
   :meth:`!do_bar`, if available.  With no argument, :meth:`!do_help` lists all
   available help topics (that is, all commands with corresponding
   :meth:`!help_\*` methods or commands that have docstrings), and also lists any
   undocumented commands.


.. method:: Cmd.onecmd(str)

   Interpret the argument as though it had been typed in response to the prompt.
   This may be overridden, but should not normally need to be; see the
   :meth:`precmd` and :meth:`postcmd` methods for useful execution hooks.  The
   return value is a flag indicating whether interpretation of commands by the
   interpreter should stop.  If there is a :meth:`!do_\*` method for the command
   *str*, the return value of that method is returned, otherwise the return value
   from the :meth:`default` method is returned.


.. method:: Cmd.emptyline()

   Method called when an empty line is entered in response to the prompt. If this
   method is not overridden, it repeats the last nonempty command entered.


.. method:: Cmd.default(line)

   Method called on an input line when the command prefix is not recognized. If
   this method is not overridden, it prints an error message and returns.


.. method:: Cmd.completedefault(text, line, begidx, endidx)

   Method called to complete an input line when no command-specific
   :meth:`!complete_\*` method is available.  By default, it returns an empty list.


.. method:: Cmd.columnize(list, displaywidth=80)

   Method called to display a list of strings as a compact set of columns.
   Each column is only as wide as necessary.
   Columns are separated by two spaces for readability.


.. method:: Cmd.precmd(line)

   Hook method executed just before the command line *line* is interpreted, but
   after the input prompt is generated and issued.  This method is a stub in
   :class:`Cmd`; it exists to be overridden by subclasses.  The return value is
   used as the command which will be executed by the :meth:`onecmd` method; the
   :meth:`precmd` implementation may re-write the command or simply return *line*
   unchanged.


.. method:: Cmd.postcmd(stop, line)

   Hook method executed just after a command dispatch is finished.  This method is
   a stub in :class:`Cmd`; it exists to be overridden by subclasses.  *line* is the
   command line which was executed, and *stop* is a flag which indicates whether
   execution will be terminated after the call to :meth:`postcmd`; this will be the
   return value of the :meth:`onecmd` method.  The return value of this method will
   be used as the new value for the internal flag which corresponds to *stop*;
   returning false will cause interpretation to continue.


.. method:: Cmd.preloop()

   Hook method executed once when :meth:`cmdloop` is called.  This method is a stub
   in :class:`Cmd`; it exists to be overridden by subclasses.


.. method:: Cmd.postloop()

   Hook method executed once when :meth:`cmdloop` is about to return. This method
   is a stub in :class:`Cmd`; it exists to be overridden by subclasses.


Instances of :class:`Cmd` subclasses have some public instance variables:

.. attribute:: Cmd.prompt

   The prompt issued to solicit input.


.. attribute:: Cmd.identchars

   The string of characters accepted for the command prefix.


.. attribute:: Cmd.lastcmd

   The last nonempty command prefix seen.


.. attribute:: Cmd.cmdqueue

   A list of queued input lines.  The cmdqueue list is checked in
   :meth:`cmdloop` when new input is needed; if it is nonempty, its elements
   will be processed in order, as if entered at the prompt.


.. attribute:: Cmd.intro

   A string to issue as an intro or banner.  May be overridden by giving the
   :meth:`cmdloop` method an argument.


.. attribute:: Cmd.doc_header

   The header to issue if the help output has a section for documented commands.


.. attribute:: Cmd.misc_header

   The header to issue if the help output has a section for miscellaneous  help
   topics (that is, there are :meth:`!help_\*` methods without corresponding
   :meth:`!do_\*` methods).


.. attribute:: Cmd.undoc_header

   The header to issue if the help output has a section for undocumented  commands
   (that is, there are :meth:`!do_\*` methods without corresponding :meth:`!help_\*`
   methods).


.. attribute:: Cmd.ruler

   The character used to draw separator lines under the help-message headers.  If
   empty, no ruler line is drawn.  It defaults to ``'='``.


.. attribute:: Cmd.use_rawinput

   A flag, defaulting to true.  If true, :meth:`cmdloop` uses :func:`input` to
   display a prompt and read the next command; if false, :data:`sys.stdout.write() <sys.stdout>`
   and :data:`sys.stdin.readline() <sys.stdin>` are used. (This means that by importing
   :mod:`readline`, on systems that support it, the interpreter will automatically
   support :program:`Emacs`\ -like line editing  and command-history keystrokes.)


.. _cmd-example:

Cmd Example
-----------

.. sectionauthor:: Raymond Hettinger <python at rcn dot com>

The :mod:`cmd` module is mainly useful for building custom shells that let a
user work with a program interactively.

This section presents a simple example of how to build a shell around a few of
the commands in the :mod:`turtle` module.

Basic turtle commands such as :meth:`~turtle.forward` are added to a
:class:`Cmd` subclass with method named :meth:`!do_forward`.  The argument is
converted to a number and dispatched to the turtle module.  The docstring is
used in the help utility provided by the shell.

The example also includes a basic record and playback facility implemented with
the :meth:`~Cmd.precmd` method which is responsible for converting the input to
lowercase and writing the commands to a file.  The :meth:`!do_playback` method
reads the file and adds the recorded commands to the :attr:`~Cmd.cmdqueue` for
immediate playback::

    import cmd, sys
    from turtle import *

    class TurtleShell(cmd.Cmd):
        intro = 'Welcome to the turtle shell.   Type help or ? to list commands.\n'
        prompt = '(turtle) '
        file = None

        # ----- basic turtle commands -----
        def do_forward(self, arg):
            'Move the turtle forward by the specified distance:  FORWARD 10'
            forward(*parse(arg))
        def do_right(self, arg):
            'Turn turtle right by given number of degrees:  RIGHT 20'
            right(*parse(arg))
        def do_left(self, arg):
            'Turn turtle left by given number of degrees:  LEFT 90'
            left(*parse(arg))
        def do_goto(self, arg):
            'Move turtle to an absolute position with changing orientation.  GOTO 100 200'
            goto(*parse(arg))
        def do_home(self, arg):
            'Return turtle to the home position:  HOME'
            home()
        def do_circle(self, arg):
            'Draw circle with given radius an options extent and steps:  CIRCLE 50'
            circle(*parse(arg))
        def do_position(self, arg):
            'Print the current turtle position:  POSITION'
            print('Current position is %d %d\n' % position())
        def do_heading(self, arg):
            'Print the current turtle heading in degrees:  HEADING'
            print('Current heading is %d\n' % (heading(),))
        def do_color(self, arg):
            'Set the color:  COLOR BLUE'
            color(arg.lower())
        def do_undo(self, arg):
            'Undo (repeatedly) the last turtle action(s):  UNDO'
        def do_reset(self, arg):
            'Clear the screen and return turtle to center:  RESET'
            reset()
        def do_bye(self, arg):
            'Stop recording, close the turtle window, and exit:  BYE'
            print('Thank you for using Turtle')
            self.close()
            bye()
            return True

        # ----- record and playback -----
        def do_record(self, arg):
            'Save future commands to filename:  RECORD rose.cmd'
            self.file = open(arg, 'w')
        def do_playback(self, arg):
            'Playback commands from a file:  PLAYBACK rose.cmd'
            self.close()
            with open(arg) as f:
                self.cmdqueue.extend(f.read().splitlines())
        def precmd(self, line):
            line = line.lower()
            if self.file and 'playback' not in line:
                print(line, file=self.file)
            return line
        def close(self):
            if self.file:
                self.file.close()
                self.file = None

    def parse(arg):
        'Convert a series of zero or more numbers to an argument tuple'
        return tuple(map(int, arg.split()))

    if __name__ == '__main__':
        TurtleShell().cmdloop()


Here is a sample session with the turtle shell showing the help functions, using
blank lines to repeat commands, and the simple record and playback facility:

.. code-block:: none

    Welcome to the turtle shell.   Type help or ? to list commands.

    (turtle) ?

    Documented commands (type help <topic>):
    ========================================
    bye     color    goto     home  playback  record  right
    circle  forward  heading  left  position  reset   undo

    (turtle) help forward
    Move the turtle forward by the specified distance:  FORWARD 10
    (turtle) record spiral.cmd
    (turtle) position
    Current position is 0 0

    (turtle) heading
    Current heading is 0

    (turtle) reset
    (turtle) circle 20
    (turtle) right 30
    (turtle) circle 40
    (turtle) right 30
    (turtle) circle 60
    (turtle) right 30
    (turtle) circle 80
    (turtle) right 30
    (turtle) circle 100
    (turtle) right 30
    (turtle) circle 120
    (turtle) right 30
    (turtle) circle 120
    (turtle) heading
    Current heading is 180

    (turtle) forward 100
    (turtle)
    (turtle) right 90
    (turtle) forward 100
    (turtle)
    (turtle) right 90
    (turtle) forward 400
    (turtle) right 90
    (turtle) forward 500
    (turtle) right 90
    (turtle) forward 400
    (turtle) right 90
    (turtle) forward 300
    (turtle) playback spiral.cmd
    Current position is 0 0

    Current heading is 0

    Current heading is 180

    (turtle) bye
    Thank you for using Turtle


================================================
File: /Doc/library/cmdline.rst
================================================
++++++++++++++++++++++++++++++++++++
Modules command-line interface (CLI)
++++++++++++++++++++++++++++++++++++

The following modules have a command-line interface.

* :ref:`ast <ast-cli>`
* :ref:`asyncio <asyncio-cli>`
* :mod:`base64`
* :ref:`calendar <calendar-cli>`
* :mod:`code`
* :ref:`compileall <compileall-cli>`
* :mod:`cProfile`: see :ref:`profile <profile-cli>`
* :ref:`difflib <difflib-interface>`
* :ref:`dis <dis-cli>`
* :mod:`doctest`
* :mod:`!encodings.rot_13`
* :mod:`ensurepip`
* :mod:`filecmp`
* :mod:`fileinput`
* :mod:`ftplib`
* :ref:`gzip <gzip-cli>`
* :ref:`http.server <http-server-cli>`
* :mod:`!idlelib`
* :ref:`inspect <inspect-module-cli>`
* :ref:`json <json-commandline>`
* :mod:`mimetypes`
* :mod:`pdb`
* :mod:`pickle`
* :ref:`pickletools <pickletools-cli>`
* :mod:`platform`
* :mod:`poplib`
* :ref:`profile <profile-cli>`
* :mod:`pstats`
* :ref:`py_compile <py_compile-cli>`
* :mod:`pyclbr`
* :mod:`pydoc`
* :mod:`quopri`
* :ref:`random <random-cli>`
* :mod:`runpy`
* :ref:`site <site-commandline>`
* :ref:`sqlite3 <sqlite3-cli>`
* :ref:`symtable <symtable-cli>`
* :ref:`sysconfig <sysconfig-cli>`
* :mod:`tabnanny`
* :ref:`tarfile <tarfile-commandline>`
* :mod:`!this`
* :ref:`timeit <timeit-command-line-interface>`
* :ref:`tokenize <tokenize-cli>`
* :ref:`trace <trace-cli>`
* :mod:`turtledemo`
* :ref:`unittest <unittest-command-line-interface>`
* :ref:`uuid <uuid-cli>`
* :mod:`venv`
* :mod:`webbrowser`
* :ref:`zipapp <zipapp-command-line-interface>`
* :ref:`zipfile <zipfile-commandline>`

See also the :ref:`Python command-line interface <using-on-general>`.


================================================
File: /Doc/library/cmdlinelibs.rst
================================================
.. _cmdlinelibs:

********************************
Command Line Interface Libraries
********************************

The modules described in this chapter assist with implementing
command line and terminal interfaces for applications.

Here's an overview:

.. toctree::
   :maxdepth: 1

   argparse.rst
   optparse.rst
   getpass.rst
   fileinput.rst
   curses.rst
   curses.ascii.rst
   curses.panel.rst


================================================
File: /Doc/library/code.rst
================================================
:mod:`!code` --- Interpreter base classes
=========================================

.. module:: code
   :synopsis: Facilities to implement read-eval-print loops.

**Source code:** :source:`Lib/code.py`

--------------

The ``code`` module provides facilities to implement read-eval-print loops in
Python.  Two classes and convenience functions are included which can be used to
build applications which provide an interactive interpreter prompt.


.. class:: InteractiveInterpreter(locals=None)

   This class deals with parsing and interpreter state (the user's namespace); it
   does not deal with input buffering or prompting or input file naming (the
   filename is always passed in explicitly). The optional *locals* argument
   specifies a mapping to use as the namespace in which code will be executed;
   it defaults to a newly created dictionary with key ``'__name__'`` set to
   ``'__console__'`` and key ``'__doc__'`` set to ``None``.


.. class:: InteractiveConsole(locals=None, filename="<console>", local_exit=False)

   Closely emulate the behavior of the interactive Python interpreter. This class
   builds on :class:`InteractiveInterpreter` and adds prompting using the familiar
   ``sys.ps1`` and ``sys.ps2``, and input buffering. If *local_exit* is true,
   ``exit()`` and ``quit()`` in the console will not raise :exc:`SystemExit`, but
   instead return to the calling code.

   .. versionchanged:: 3.13
      Added *local_exit* parameter.

.. function:: interact(banner=None, readfunc=None, local=None, exitmsg=None, local_exit=False)

   Convenience function to run a read-eval-print loop.  This creates a new
   instance of :class:`InteractiveConsole` and sets *readfunc* to be used as
   the :meth:`InteractiveConsole.raw_input` method, if provided.  If *local* is
   provided, it is passed to the :class:`InteractiveConsole` constructor for
   use as the default namespace for the interpreter loop.  If *local_exit* is provided,
   it is passed to the :class:`InteractiveConsole` constructor.  The :meth:`~InteractiveConsole.interact`
   method of the instance is then run with *banner* and *exitmsg* passed as the
   banner and exit message to use, if provided.  The console object is discarded
   after use.

   .. versionchanged:: 3.6
      Added *exitmsg* parameter.

   .. versionchanged:: 3.13
      Added *local_exit* parameter.

.. function:: compile_command(source, filename="<input>", symbol="single")

   This function is useful for programs that want to emulate Python's interpreter
   main loop (a.k.a. the read-eval-print loop).  The tricky part is to determine
   when the user has entered an incomplete command that can be completed by
   entering more text (as opposed to a complete command or a syntax error).  This
   function *almost* always makes the same decision as the real interpreter main
   loop.

   *source* is the source string; *filename* is the optional filename from which
   source was read, defaulting to ``'<input>'``; and *symbol* is the optional
   grammar start symbol, which should be ``'single'`` (the default), ``'eval'``
   or ``'exec'``.

   Returns a code object (the same as ``compile(source, filename, symbol)``) if the
   command is complete and valid; ``None`` if the command is incomplete; raises
   :exc:`SyntaxError` if the command is complete and contains a syntax error, or
   raises :exc:`OverflowError` or :exc:`ValueError` if the command contains an
   invalid literal.


.. _interpreter-objects:

Interactive Interpreter Objects
-------------------------------


.. method:: InteractiveInterpreter.runsource(source, filename="<input>", symbol="single")

   Compile and run some source in the interpreter. Arguments are the same as for
   :func:`compile_command`; the default for *filename* is ``'<input>'``, and for
   *symbol* is ``'single'``.  One of several things can happen:

   * The input is incorrect; :func:`compile_command` raised an exception
     (:exc:`SyntaxError` or :exc:`OverflowError`).  A syntax traceback will be
     printed by calling the :meth:`showsyntaxerror` method.  :meth:`runsource`
     returns ``False``.

   * The input is incomplete, and more input is required; :func:`compile_command`
     returned ``None``. :meth:`runsource` returns ``True``.

   * The input is complete; :func:`compile_command` returned a code object.  The
     code is executed by calling the :meth:`runcode` (which also handles run-time
     exceptions, except for :exc:`SystemExit`). :meth:`runsource` returns ``False``.

   The return value can be used to decide whether to use ``sys.ps1`` or ``sys.ps2``
   to prompt the next line.


.. method:: InteractiveInterpreter.runcode(code)

   Execute a code object. When an exception occurs, :meth:`showtraceback` is called
   to display a traceback.  All exceptions are caught except :exc:`SystemExit`,
   which is allowed to propagate.

   A note about :exc:`KeyboardInterrupt`: this exception may occur elsewhere in
   this code, and may not always be caught.  The caller should be prepared to deal
   with it.


.. method:: InteractiveInterpreter.showsyntaxerror(filename=None)

   Display the syntax error that just occurred.  This does not display a stack
   trace because there isn't one for syntax errors. If *filename* is given, it is
   stuffed into the exception instead of the default filename provided by Python's
   parser, because it always uses ``'<string>'`` when reading from a string. The
   output is written by the :meth:`write` method.


.. method:: InteractiveInterpreter.showtraceback()

   Display the exception that just occurred.  We remove the first stack item
   because it is within the interpreter object implementation. The output is
   written by the :meth:`write` method.

   .. versionchanged:: 3.5 The full chained traceback is displayed instead
      of just the primary traceback.


.. method:: InteractiveInterpreter.write(data)

   Write a string to the standard error stream (``sys.stderr``). Derived classes
   should override this to provide the appropriate output handling as needed.


.. _console-objects:

Interactive Console Objects
---------------------------

The :class:`InteractiveConsole` class is a subclass of
:class:`InteractiveInterpreter`, and so offers all the methods of the
interpreter objects as well as the following additions.


.. method:: InteractiveConsole.interact(banner=None, exitmsg=None)

   Closely emulate the interactive Python console. The optional *banner* argument
   specify the banner to print before the first interaction; by default it prints a
   banner similar to the one printed by the standard Python interpreter, followed
   by the class name of the console object in parentheses (so as not to confuse
   this with the real interpreter -- since it's so close!).

   The optional *exitmsg* argument specifies an exit message printed when exiting.
   Pass the empty string to suppress the exit message. If *exitmsg* is not given or
   ``None``, a default message is printed.

   .. versionchanged:: 3.4
      To suppress printing any banner, pass an empty string.

   .. versionchanged:: 3.6
      Print an exit message when exiting.


.. method:: InteractiveConsole.push(line)

   Push a line of source text to the interpreter. The line should not have a
   trailing newline; it may have internal newlines.  The line is appended to a
   buffer and the interpreter's :meth:`~InteractiveInterpreter.runsource` method is called with the
   concatenated contents of the buffer as source.  If this indicates that the
   command was executed or invalid, the buffer is reset; otherwise, the command is
   incomplete, and the buffer is left as it was after the line was appended.  The
   return value is ``True`` if more input is required, ``False`` if the line was
   dealt with in some way (this is the same as :meth:`!runsource`).


.. method:: InteractiveConsole.resetbuffer()

   Remove any unhandled source text from the input buffer.


.. method:: InteractiveConsole.raw_input(prompt="")

   Write a prompt and read a line.  The returned line does not include the trailing
   newline.  When the user enters the EOF key sequence, :exc:`EOFError` is raised.
   The base implementation reads from ``sys.stdin``; a subclass may replace this
   with a different implementation.


================================================
File: /Doc/library/codeop.rst
================================================
:mod:`!codeop` --- Compile Python code
======================================

.. module:: codeop
   :synopsis: Compile (possibly incomplete) Python code.

.. sectionauthor:: Moshe Zadka <moshez@zadka.site.co.il>
.. sectionauthor:: Michael Hudson <mwh@python.net>

**Source code:** :source:`Lib/codeop.py`

--------------

The :mod:`codeop` module provides utilities upon which the Python
read-eval-print loop can be emulated, as is done in the :mod:`code` module.  As
a result, you probably don't want to use the module directly; if you want to
include such a loop in your program you probably want to use the :mod:`code`
module instead.

There are two parts to this job:

#. Being able to tell if a line of input completes a Python statement: in
   short, telling whether to print '``>>>``' or '``...``' next.

#. Remembering which future statements the user has entered, so subsequent
   input can be compiled with these in effect.

The :mod:`codeop` module provides a way of doing each of these things, and a way
of doing them both.

To do just the former:

.. function:: compile_command(source, filename="<input>", symbol="single")

   Tries to compile *source*, which should be a string of Python code and return a
   code object if *source* is valid Python code.  In that case, the filename
   attribute of the code object will be *filename*, which defaults to
   ``'<input>'``.  Returns ``None`` if *source* is *not* valid Python code, but is a
   prefix of valid Python code.

   If there is a problem with *source*, an exception will be raised.
   :exc:`SyntaxError` is raised if there is invalid Python syntax, and
   :exc:`OverflowError` or :exc:`ValueError` if there is an invalid literal.

   The *symbol* argument determines whether *source* is compiled as a statement
   (``'single'``, the default), as a sequence of :term:`statement` (``'exec'``) or
   as an :term:`expression` (``'eval'``).  Any other value will
   cause :exc:`ValueError` to be raised.

   .. note::

      It is possible (but not likely) that the parser stops parsing with a
      successful outcome before reaching the end of the source; in this case,
      trailing symbols may be ignored instead of causing an error.  For example,
      a backslash followed by two newlines may be followed by arbitrary garbage.
      This will be fixed once the API for the parser is better.


.. class:: Compile()

   Instances of this class have :meth:`~object.__call__` methods identical in signature to
   the built-in function :func:`compile`, but with the difference that if the
   instance compiles program text containing a :mod:`__future__` statement, the
   instance 'remembers' and compiles all subsequent program texts with the
   statement in force.


.. class:: CommandCompiler()

   Instances of this class have :meth:`~object.__call__` methods identical in signature to
   :func:`compile_command`; the difference is that if the instance compiles program
   text containing a :mod:`__future__` statement, the instance 'remembers' and
   compiles all subsequent program texts with the statement in force.


================================================
File: /Doc/library/collections.abc.rst
================================================
:mod:`!collections.abc` --- Abstract Base Classes for Containers
================================================================

.. module:: collections.abc
   :synopsis: Abstract base classes for containers

.. moduleauthor:: Raymond Hettinger <python at rcn.com>
.. sectionauthor:: Raymond Hettinger <python at rcn.com>

.. versionadded:: 3.3
   Formerly, this module was part of the :mod:`collections` module.

**Source code:** :source:`Lib/_collections_abc.py`

.. testsetup:: *

   from collections.abc import *
   import itertools
   __name__ = '<doctest>'

--------------

This module provides :term:`abstract base classes <abstract base class>` that
can be used to test whether a class provides a particular interface; for
example, whether it is :term:`hashable` or whether it is a :term:`mapping`.

An :func:`issubclass` or :func:`isinstance` test for an interface works in one
of three ways.

1) A newly written class can inherit directly from one of the
abstract base classes.  The class must supply the required abstract
methods.  The remaining mixin methods come from inheritance and can be
overridden if desired.  Other methods may be added as needed:

.. testcode::

    class C(Sequence):                      # Direct inheritance
        def __init__(self): ...             # Extra method not required by the ABC
        def __getitem__(self, index):  ...  # Required abstract method
        def __len__(self):  ...             # Required abstract method
        def count(self, value): ...         # Optionally override a mixin method

.. doctest::

   >>> issubclass(C, Sequence)
   True
   >>> isinstance(C(), Sequence)
   True

2) Existing classes and built-in classes can be registered as "virtual
subclasses" of the ABCs.  Those classes should define the full API
including all of the abstract methods and all of the mixin methods.
This lets users rely on :func:`issubclass` or :func:`isinstance` tests
to determine whether the full interface is supported.  The exception to
this rule is for methods that are automatically inferred from the rest
of the API:

.. testcode::

    class D:                                 # No inheritance
        def __init__(self): ...              # Extra method not required by the ABC
        def __getitem__(self, index):  ...   # Abstract method
        def __len__(self):  ...              # Abstract method
        def count(self, value): ...          # Mixin method
        def index(self, value): ...          # Mixin method

    Sequence.register(D)                     # Register instead of inherit

.. doctest::

   >>> issubclass(D, Sequence)
   True
   >>> isinstance(D(), Sequence)
   True

In this example, class :class:`!D` does not need to define
``__contains__``, ``__iter__``, and ``__reversed__`` because the
:ref:`in-operator <comparisons>`, the :term:`iteration <iterable>`
logic, and the :func:`reversed` function automatically fall back to
using ``__getitem__`` and ``__len__``.

3) Some simple interfaces are directly recognizable by the presence of
the required methods (unless those methods have been set to
:const:`None`):

.. testcode::

    class E:
        def __iter__(self): ...
        def __next__(self): ...

.. doctest::

   >>> issubclass(E, Iterable)
   True
   >>> isinstance(E(), Iterable)
   True

Complex interfaces do not support this last technique because an
interface is more than just the presence of method names.  Interfaces
specify semantics and relationships between methods that cannot be
inferred solely from the presence of specific method names.  For
example, knowing that a class supplies ``__getitem__``, ``__len__``, and
``__iter__`` is insufficient for distinguishing a :class:`Sequence` from
a :class:`Mapping`.

.. versionadded:: 3.9
   These abstract classes now support ``[]``. See :ref:`types-genericalias`
   and :pep:`585`.

.. _collections-abstract-base-classes:

Collections Abstract Base Classes
---------------------------------

The collections module offers the following :term:`ABCs <abstract base class>`:

.. tabularcolumns:: |l|L|L|L|

============================== ====================== ======================= ====================================================
ABC                            Inherits from          Abstract Methods        Mixin Methods
============================== ====================== ======================= ====================================================
:class:`Container` [1]_                               ``__contains__``
:class:`Hashable` [1]_                                ``__hash__``
:class:`Iterable` [1]_ [2]_                           ``__iter__``
:class:`Iterator` [1]_         :class:`Iterable`      ``__next__``            ``__iter__``
:class:`Reversible` [1]_       :class:`Iterable`      ``__reversed__``
:class:`Generator`  [1]_       :class:`Iterator`      ``send``, ``throw``     ``close``, ``__iter__``, ``__next__``
:class:`Sized`  [1]_                                  ``__len__``
:class:`Callable`  [1]_                               ``__call__``
:class:`Collection`  [1]_      :class:`Sized`,        ``__contains__``,
                               :class:`Iterable`,     ``__iter__``,
                               :class:`Container`     ``__len__``

:class:`Sequence`              :class:`Reversible`,   ``__getitem__``,        ``__contains__``, ``__iter__``, ``__reversed__``,
                               :class:`Collection`    ``__len__``             ``index``, and ``count``

:class:`MutableSequence`       :class:`Sequence`      ``__getitem__``,        Inherited :class:`Sequence` methods and
                                                      ``__setitem__``,        ``append``, ``clear``, ``reverse``, ``extend``,
                                                      ``__delitem__``,        ``pop``, ``remove``, and ``__iadd__``
                                                      ``__len__``,
                                                      ``insert``

:class:`Set`                   :class:`Collection`    ``__contains__``,       ``__le__``, ``__lt__``, ``__eq__``, ``__ne__``,
                                                      ``__iter__``,           ``__gt__``, ``__ge__``, ``__and__``, ``__or__``,
                                                      ``__len__``             ``__sub__``, ``__rsub__``, ``__xor__``, ``__rxor__``
                                                                              and ``isdisjoint``

:class:`MutableSet`            :class:`Set`           ``__contains__``,       Inherited :class:`Set` methods and
                                                      ``__iter__``,           ``clear``, ``pop``, ``remove``, ``__ior__``,
                                                      ``__len__``,            ``__iand__``, ``__ixor__``, and ``__isub__``
                                                      ``add``,
                                                      ``discard``

:class:`Mapping`               :class:`Collection`    ``__getitem__``,        ``__contains__``, ``keys``, ``items``, ``values``,
                                                      ``__iter__``,           ``get``, ``__eq__``, and ``__ne__``
                                                      ``__len__``

:class:`MutableMapping`        :class:`Mapping`       ``__getitem__``,        Inherited :class:`Mapping` methods and
                                                      ``__setitem__``,        ``pop``, ``popitem``, ``clear``, ``update``,
                                                      ``__delitem__``,        and ``setdefault``
                                                      ``__iter__``,
                                                      ``__len__``


:class:`MappingView`           :class:`Sized`                                 ``__init__``, ``__len__`` and ``__repr__``
:class:`ItemsView`             :class:`MappingView`,                          ``__contains__``,
                               :class:`Set`                                   ``__iter__``
:class:`KeysView`              :class:`MappingView`,                          ``__contains__``,
                               :class:`Set`                                   ``__iter__``
:class:`ValuesView`            :class:`MappingView`,                          ``__contains__``, ``__iter__``
                               :class:`Collection`
:class:`Awaitable` [1]_                               ``__await__``
:class:`Coroutine` [1]_        :class:`Awaitable`     ``send``, ``throw``     ``close``
:class:`AsyncIterable` [1]_                           ``__aiter__``
:class:`AsyncIterator` [1]_    :class:`AsyncIterable` ``__anext__``           ``__aiter__``
:class:`AsyncGenerator` [1]_   :class:`AsyncIterator` ``asend``, ``athrow``   ``aclose``, ``__aiter__``, ``__anext__``
:class:`Buffer` [1]_                                  ``__buffer__``
============================== ====================== ======================= ====================================================


.. rubric:: Footnotes

.. [1] These ABCs override :meth:`~abc.ABCMeta.__subclasshook__` to support
   testing an interface by verifying the required methods are present
   and have not been set to :const:`None`.  This only works for simple
   interfaces.  More complex interfaces require registration or direct
   subclassing.

.. [2] Checking ``isinstance(obj, Iterable)`` detects classes that are
   registered as :class:`Iterable` or that have an :meth:`~container.__iter__`
   method, but it does not detect classes that iterate with the
   :meth:`~object.__getitem__` method.  The only reliable way to determine
   whether an object is :term:`iterable` is to call ``iter(obj)``.


Collections Abstract Base Classes -- Detailed Descriptions
----------------------------------------------------------


.. class:: Container

   ABC for classes that provide the :meth:`~object.__contains__` method.

.. class:: Hashable

   ABC for classes that provide the :meth:`~object.__hash__` method.

.. class:: Sized

   ABC for classes that provide the :meth:`~object.__len__` method.

.. class:: Callable

   ABC for classes that provide the :meth:`~object.__call__` method.

   See :ref:`annotating-callables` for details on how to use
   :class:`!Callable` in type annotations.

.. class:: Iterable

   ABC for classes that provide the :meth:`~container.__iter__` method.

   Checking ``isinstance(obj, Iterable)`` detects classes that are registered
   as :class:`Iterable` or that have an :meth:`~container.__iter__` method,
   but it does
   not detect classes that iterate with the :meth:`~object.__getitem__` method.
   The only reliable way to determine whether an object is :term:`iterable`
   is to call ``iter(obj)``.

.. class:: Collection

   ABC for sized iterable container classes.

   .. versionadded:: 3.6

.. class:: Iterator

   ABC for classes that provide the :meth:`~iterator.__iter__` and
   :meth:`~iterator.__next__` methods.  See also the definition of
   :term:`iterator`.

.. class:: Reversible

   ABC for iterable classes that also provide the :meth:`~object.__reversed__`
   method.

   .. versionadded:: 3.6

.. class:: Generator

   ABC for :term:`generator` classes that implement the protocol defined in
   :pep:`342` that extends :term:`iterators <iterator>` with the
   :meth:`~generator.send`,
   :meth:`~generator.throw` and :meth:`~generator.close` methods.

   See :ref:`annotating-generators-and-coroutines`
   for details on using :class:`!Generator` in type annotations.

   .. versionadded:: 3.5

.. class:: Sequence
           MutableSequence

   ABCs for read-only and mutable :term:`sequences <sequence>`.

   Implementation note: Some of the mixin methods, such as
   :meth:`~container.__iter__`, :meth:`~object.__reversed__` and :meth:`index`, make
   repeated calls to the underlying :meth:`~object.__getitem__` method.
   Consequently, if :meth:`~object.__getitem__` is implemented with constant
   access speed, the mixin methods will have linear performance;
   however, if the underlying method is linear (as it would be with a
   linked list), the mixins will have quadratic performance and will
   likely need to be overridden.

   .. versionchanged:: 3.5
      The index() method added support for *stop* and *start*
      arguments.

.. class:: Set
           MutableSet

   ABCs for read-only and mutable :ref:`sets <types-set>`.

.. class:: Mapping
           MutableMapping

   ABCs for read-only and mutable :term:`mappings <mapping>`.

.. class:: MappingView
           ItemsView
           KeysView
           ValuesView

   ABCs for mapping, items, keys, and values :term:`views <dictionary view>`.

.. class:: Awaitable

   ABC for :term:`awaitable` objects, which can be used in :keyword:`await`
   expressions.  Custom implementations must provide the
   :meth:`~object.__await__` method.

   :term:`Coroutine <coroutine>` objects and instances of the
   :class:`~collections.abc.Coroutine` ABC are all instances of this ABC.

   .. note::
      In CPython, generator-based coroutines (:term:`generators <generator>`
      decorated with :func:`@types.coroutine <types.coroutine>`) are
      *awaitables*, even though they do not have an :meth:`~object.__await__` method.
      Using ``isinstance(gencoro, Awaitable)`` for them will return ``False``.
      Use :func:`inspect.isawaitable` to detect them.

   .. versionadded:: 3.5

.. class:: Coroutine

   ABC for :term:`coroutine` compatible classes.  These implement the
   following methods, defined in :ref:`coroutine-objects`:
   :meth:`~coroutine.send`, :meth:`~coroutine.throw`, and
   :meth:`~coroutine.close`.  Custom implementations must also implement
   :meth:`~object.__await__`.  All :class:`Coroutine` instances are also
   instances of :class:`Awaitable`.

   .. note::
      In CPython, generator-based coroutines (:term:`generators <generator>`
      decorated with :func:`@types.coroutine <types.coroutine>`) are
      *awaitables*, even though they do not have an :meth:`~object.__await__` method.
      Using ``isinstance(gencoro, Coroutine)`` for them will return ``False``.
      Use :func:`inspect.isawaitable` to detect them.

   See :ref:`annotating-generators-and-coroutines`
   for details on using :class:`!Coroutine` in type annotations.
   The variance and order of type parameters correspond to those of
   :class:`Generator`.

   .. versionadded:: 3.5

.. class:: AsyncIterable

   ABC for classes that provide an ``__aiter__`` method.  See also the
   definition of :term:`asynchronous iterable`.

   .. versionadded:: 3.5

.. class:: AsyncIterator

   ABC for classes that provide ``__aiter__`` and ``__anext__``
   methods.  See also the definition of :term:`asynchronous iterator`.

   .. versionadded:: 3.5

.. class:: AsyncGenerator

   ABC for :term:`asynchronous generator` classes that implement the protocol
   defined in :pep:`525` and :pep:`492`.

   See :ref:`annotating-generators-and-coroutines`
   for details on using :class:`!AsyncGenerator` in type annotations.

   .. versionadded:: 3.6

.. class:: Buffer

   ABC for classes that provide the :meth:`~object.__buffer__` method,
   implementing the :ref:`buffer protocol <bufferobjects>`. See :pep:`688`.

   .. versionadded:: 3.12

Examples and Recipes
--------------------

ABCs allow us to ask classes or instances if they provide
particular functionality, for example::

    size = None
    if isinstance(myvar, collections.abc.Sized):
        size = len(myvar)

Several of the ABCs are also useful as mixins that make it easier to develop
classes supporting container APIs.  For example, to write a class supporting
the full :class:`Set` API, it is only necessary to supply the three underlying
abstract methods: :meth:`~object.__contains__`, :meth:`~container.__iter__`, and
:meth:`~object.__len__`. The ABC supplies the remaining methods such as
:meth:`!__and__` and :meth:`~frozenset.isdisjoint`::

    class ListBasedSet(collections.abc.Set):
        ''' Alternate set implementation favoring space over speed
            and not requiring the set elements to be hashable. '''
        def __init__(self, iterable):
            self.elements = lst = []
            for value in iterable:
                if value not in lst:
                    lst.append(value)

        def __iter__(self):
            return iter(self.elements)

        def __contains__(self, value):
            return value in self.elements

        def __len__(self):
            return len(self.elements)

    s1 = ListBasedSet('abcdef')
    s2 = ListBasedSet('defghi')
    overlap = s1 & s2            # The __and__() method is supported automatically

Notes on using :class:`Set` and :class:`MutableSet` as a mixin:

(1)
   Since some set operations create new sets, the default mixin methods need
   a way to create new instances from an :term:`iterable`. The class constructor is
   assumed to have a signature in the form ``ClassName(iterable)``.
   That assumption is factored-out to an internal :class:`classmethod` called
   :meth:`!_from_iterable` which calls ``cls(iterable)`` to produce a new set.
   If the :class:`Set` mixin is being used in a class with a different
   constructor signature, you will need to override :meth:`!_from_iterable`
   with a classmethod or regular method that can construct new instances from
   an iterable argument.

(2)
   To override the comparisons (presumably for speed, as the
   semantics are fixed), redefine :meth:`~object.__le__` and
   :meth:`~object.__ge__`,
   then the other operations will automatically follow suit.

(3)
   The :class:`Set` mixin provides a :meth:`!_hash` method to compute a hash value
   for the set; however, :meth:`~object.__hash__` is not defined because not all sets
   are :term:`hashable` or immutable.  To add set hashability using mixins,
   inherit from both :meth:`Set` and :meth:`Hashable`, then define
   ``__hash__ = Set._hash``.

.. seealso::

   * `OrderedSet recipe <https://code.activestate.com/recipes/576694/>`_ for an
     example built on :class:`MutableSet`.

   * For more about ABCs, see the :mod:`abc` module and :pep:`3119`.


================================================
File: /Doc/library/colorsys.rst
================================================
:mod:`!colorsys` --- Conversions between color systems
======================================================

.. module:: colorsys
   :synopsis: Conversion functions between RGB and other color systems.

.. sectionauthor:: David Ascher <da@python.net>

**Source code:** :source:`Lib/colorsys.py`

--------------

The :mod:`colorsys` module defines bidirectional conversions of color values
between colors expressed in the RGB (Red Green Blue) color space used in
computer monitors and three other coordinate systems: YIQ, HLS (Hue Lightness
Saturation) and HSV (Hue Saturation Value).  Coordinates in all of these color
spaces are floating-point values.  In the YIQ space, the Y coordinate is between
0 and 1, but the I and Q coordinates can be positive or negative.  In all other
spaces, the coordinates are all between 0 and 1.

.. seealso::

   More information about color spaces can be found at
   https://poynton.ca/ColorFAQ.html and
   https://www.cambridgeincolour.com/tutorials/color-spaces.htm.

The :mod:`colorsys` module defines the following functions:


.. function:: rgb_to_yiq(r, g, b)

   Convert the color from RGB coordinates to YIQ coordinates.


.. function:: yiq_to_rgb(y, i, q)

   Convert the color from YIQ coordinates to RGB coordinates.


.. function:: rgb_to_hls(r, g, b)

   Convert the color from RGB coordinates to HLS coordinates.


.. function:: hls_to_rgb(h, l, s)

   Convert the color from HLS coordinates to RGB coordinates.


.. function:: rgb_to_hsv(r, g, b)

   Convert the color from RGB coordinates to HSV coordinates.


.. function:: hsv_to_rgb(h, s, v)

   Convert the color from HSV coordinates to RGB coordinates.

Example::

   >>> import colorsys
   >>> colorsys.rgb_to_hsv(0.2, 0.4, 0.4)
   (0.5, 0.5, 0.4)
   >>> colorsys.hsv_to_rgb(0.5, 0.5, 0.4)
   (0.2, 0.4, 0.4)


================================================
File: /Doc/library/compileall.rst
================================================
:mod:`!compileall` --- Byte-compile Python libraries
====================================================

.. module:: compileall
   :synopsis: Tools for byte-compiling all Python source files in a directory tree.

**Source code:** :source:`Lib/compileall.py`

--------------

This module provides some utility functions to support installing Python
libraries.  These functions compile Python source files in a directory tree.
This module can be used to create the cached byte-code files at library
installation time, which makes them available for use even by users who don't
have write permission to the library directories.

.. include:: ../includes/wasm-notavail.rst

.. _compileall-cli:

Command-line use
----------------

This module can work as a script (using :program:`python -m compileall`) to
compile Python sources.

.. program:: compileall

.. option:: directory ...
            file ...

   Positional arguments are files to compile or directories that contain
   source files, traversed recursively.  If no argument is given, behave as if
   the command line was :samp:`-l {<directories from sys.path>}`.

.. option:: -l

   Do not recurse into subdirectories, only compile source code files directly
   contained in the named or implied directories.

.. option:: -f

   Force rebuild even if timestamps are up-to-date.

.. option:: -q

   Do not print the list of files compiled. If passed once, error messages will
   still be printed. If passed twice (``-qq``), all output is suppressed.

.. option:: -d destdir

   Directory prepended to the path to each file being compiled.  This will
   appear in compilation time tracebacks, and is also compiled in to the
   byte-code file, where it will be used in tracebacks and other messages in
   cases where the source file does not exist at the time the byte-code file is
   executed.

.. option:: -s strip_prefix
.. option:: -p prepend_prefix

   Remove (``-s``) or append (``-p``) the given prefix of paths
   recorded in the ``.pyc`` files.
   Cannot be combined with ``-d``.

.. option:: -x regex

   regex is used to search the full path to each file considered for
   compilation, and if the regex produces a match, the file is skipped.

.. option:: -i list

   Read the file ``list`` and add each line that it contains to the list of
   files and directories to compile.  If ``list`` is ``-``, read lines from
   ``stdin``.

.. option:: -b

   Write the byte-code files to their legacy locations and names, which may
   overwrite byte-code files created by another version of Python.  The default
   is to write files to their :pep:`3147` locations and names, which allows
   byte-code files from multiple versions of Python to coexist.

.. option:: -r

   Control the maximum recursion level for subdirectories.
   If this is given, then ``-l`` option will not be taken into account.
   :program:`python -m compileall <directory> -r 0` is equivalent to
   :program:`python -m compileall <directory> -l`.

.. option:: -j N

   Use *N* workers to compile the files within the given directory.
   If ``0`` is used, then the result of :func:`os.process_cpu_count`
   will be used.

.. option:: --invalidation-mode [timestamp|checked-hash|unchecked-hash]

   Control how the generated byte-code files are invalidated at runtime.
   The ``timestamp`` value, means that ``.pyc`` files with the source timestamp
   and size embedded will be generated. The ``checked-hash`` and
   ``unchecked-hash`` values cause hash-based pycs to be generated. Hash-based
   pycs embed a hash of the source file contents rather than a timestamp. See
   :ref:`pyc-invalidation` for more information on how Python validates
   bytecode cache files at runtime.
   The default is ``timestamp`` if the :envvar:`SOURCE_DATE_EPOCH` environment
   variable is not set, and ``checked-hash`` if the ``SOURCE_DATE_EPOCH``
   environment variable is set.

.. option:: -o level

   Compile with the given optimization level. May be used multiple times
   to compile for multiple levels at a time (for example,
   ``compileall -o 1 -o 2``).

.. option:: -e dir

   Ignore symlinks pointing outside the given directory.

.. option:: --hardlink-dupes

   If two ``.pyc`` files with different optimization level have
   the same content, use hard links to consolidate duplicate files.

.. versionchanged:: 3.2
   Added the ``-i``, ``-b`` and ``-h`` options.

.. versionchanged:: 3.5
   Added the  ``-j``, ``-r``, and ``-qq`` options.  ``-q`` option
   was changed to a multilevel value.  ``-b`` will always produce a
   byte-code file ending in ``.pyc``, never ``.pyo``.

.. versionchanged:: 3.7
   Added the ``--invalidation-mode`` option.

.. versionchanged:: 3.9
   Added the ``-s``, ``-p``, ``-e`` and ``--hardlink-dupes`` options.
   Raised the default recursion limit from 10 to
   :py:func:`sys.getrecursionlimit()`.
   Added the possibility to specify the ``-o`` option multiple times.


There is no command-line option to control the optimization level used by the
:func:`compile` function, because the Python interpreter itself already
provides the option: :program:`python -O -m compileall`.

Similarly, the :func:`compile` function respects the :data:`sys.pycache_prefix`
setting. The generated bytecode cache will only be useful if :func:`compile` is
run with the same :data:`sys.pycache_prefix` (if any) that will be used at
runtime.

Public functions
----------------

.. function:: compile_dir(dir, maxlevels=sys.getrecursionlimit(), ddir=None, force=False, rx=None, quiet=0, legacy=False, optimize=-1, workers=1, invalidation_mode=None, *, stripdir=None, prependdir=None, limit_sl_dest=None, hardlink_dupes=False)

   Recursively descend the directory tree named by *dir*, compiling all :file:`.py`
   files along the way. Return a true value if all the files compiled successfully,
   and a false value otherwise.

   The *maxlevels* parameter is used to limit the depth of the recursion; it
   defaults to ``sys.getrecursionlimit()``.

   If *ddir* is given, it is prepended to the path to each file being compiled
   for use in compilation time tracebacks, and is also compiled in to the
   byte-code file, where it will be used in tracebacks and other messages in
   cases where the source file does not exist at the time the byte-code file is
   executed.

   If *force* is true, modules are re-compiled even if the timestamps are up to
   date.

   If *rx* is given, its ``search`` method is called on the complete path to each
   file considered for compilation, and if it returns a true value, the file
   is skipped. This can be used to exclude files matching a regular expression,
   given as a :ref:`re.Pattern <re-objects>` object.

   If *quiet* is ``False`` or ``0`` (the default), the filenames and other
   information are printed to standard out. Set to ``1``, only errors are
   printed. Set to ``2``, all output is suppressed.

   If *legacy* is true, byte-code files are written to their legacy locations
   and names, which may overwrite byte-code files created by another version of
   Python.  The default is to write files to their :pep:`3147` locations and
   names, which allows byte-code files from multiple versions of Python to
   coexist.

   *optimize* specifies the optimization level for the compiler.  It is passed to
   the built-in :func:`compile` function. Accepts also a sequence of optimization
   levels which lead to multiple compilations of one :file:`.py` file in one call.

   The argument *workers* specifies how many workers are used to
   compile files in parallel. The default is to not use multiple workers.
   If the platform can't use multiple workers and *workers* argument is given,
   then sequential compilation will be used as a fallback.  If *workers*
   is 0, the number of cores in the system is used.  If *workers* is
   lower than ``0``, a :exc:`ValueError` will be raised.

   *invalidation_mode* should be a member of the
   :class:`py_compile.PycInvalidationMode` enum and controls how the generated
   pycs are invalidated at runtime.

   The *stripdir*, *prependdir* and *limit_sl_dest* arguments correspond to
   the ``-s``, ``-p`` and ``-e`` options described above.
   They may be specified as ``str`` or :py:class:`os.PathLike`.

   If *hardlink_dupes* is true and two ``.pyc`` files with different optimization
   level have the same content, use hard links to consolidate duplicate files.

   .. versionchanged:: 3.2
      Added the *legacy* and *optimize* parameter.

   .. versionchanged:: 3.5
      Added the *workers* parameter.

   .. versionchanged:: 3.5
      *quiet* parameter was changed to a multilevel value.

   .. versionchanged:: 3.5
      The *legacy* parameter only writes out ``.pyc`` files, not ``.pyo`` files
      no matter what the value of *optimize* is.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.

   .. versionchanged:: 3.7
      The *invalidation_mode* parameter was added.

   .. versionchanged:: 3.7.2
      The *invalidation_mode* parameter's default value is updated to ``None``.

   .. versionchanged:: 3.8
      Setting *workers* to 0 now chooses the optimal number of cores.

   .. versionchanged:: 3.9
      Added *stripdir*, *prependdir*, *limit_sl_dest* and *hardlink_dupes* arguments.
      Default value of *maxlevels* was changed from ``10`` to ``sys.getrecursionlimit()``

.. function:: compile_file(fullname, ddir=None, force=False, rx=None, quiet=0, legacy=False, optimize=-1, invalidation_mode=None, *, stripdir=None, prependdir=None, limit_sl_dest=None, hardlink_dupes=False)

   Compile the file with path *fullname*. Return a true value if the file
   compiled successfully, and a false value otherwise.

   If *ddir* is given, it is prepended to the path to the file being compiled
   for use in compilation time tracebacks, and is also compiled in to the
   byte-code file, where it will be used in tracebacks and other messages in
   cases where the source file does not exist at the time the byte-code file is
   executed.

   If *rx* is given, its ``search`` method is passed the full path name to the
   file being compiled, and if it returns a true value, the file is not
   compiled and ``True`` is returned. This can be used to exclude files matching
   a regular expression, given as a :ref:`re.Pattern <re-objects>` object.

   If *quiet* is ``False`` or ``0`` (the default), the filenames and other
   information are printed to standard out. Set to ``1``, only errors are
   printed. Set to ``2``, all output is suppressed.

   If *legacy* is true, byte-code files are written to their legacy locations
   and names, which may overwrite byte-code files created by another version of
   Python.  The default is to write files to their :pep:`3147` locations and
   names, which allows byte-code files from multiple versions of Python to
   coexist.

   *optimize* specifies the optimization level for the compiler.  It is passed to
   the built-in :func:`compile` function. Accepts also a sequence of optimization
   levels which lead to multiple compilations of one :file:`.py` file in one call.

   *invalidation_mode* should be a member of the
   :class:`py_compile.PycInvalidationMode` enum and controls how the generated
   pycs are invalidated at runtime.

   The *stripdir*, *prependdir* and *limit_sl_dest* arguments correspond to
   the ``-s``, ``-p`` and ``-e`` options described above.
   They may be specified as ``str`` or :py:class:`os.PathLike`.

   If *hardlink_dupes* is true and two ``.pyc`` files with different optimization
   level have the same content, use hard links to consolidate duplicate files.

   .. versionadded:: 3.2

   .. versionchanged:: 3.5
      *quiet* parameter was changed to a multilevel value.

   .. versionchanged:: 3.5
      The *legacy* parameter only writes out ``.pyc`` files, not ``.pyo`` files
      no matter what the value of *optimize* is.

   .. versionchanged:: 3.7
      The *invalidation_mode* parameter was added.

   .. versionchanged:: 3.7.2
      The *invalidation_mode* parameter's default value is updated to ``None``.

   .. versionchanged:: 3.9
      Added *stripdir*, *prependdir*, *limit_sl_dest* and *hardlink_dupes* arguments.

.. function:: compile_path(skip_curdir=True, maxlevels=0, force=False, quiet=0, legacy=False, optimize=-1, invalidation_mode=None)

   Byte-compile all the :file:`.py` files found along ``sys.path``. Return a
   true value if all the files compiled successfully, and a false value otherwise.

   If *skip_curdir* is true (the default), the current directory is not included
   in the search.  All other parameters are passed to the :func:`compile_dir`
   function.  Note that unlike the other compile functions, ``maxlevels``
   defaults to ``0``.

   .. versionchanged:: 3.2
      Added the *legacy* and *optimize* parameter.

   .. versionchanged:: 3.5
      *quiet* parameter was changed to a multilevel value.

   .. versionchanged:: 3.5
      The *legacy* parameter only writes out ``.pyc`` files, not ``.pyo`` files
      no matter what the value of *optimize* is.

   .. versionchanged:: 3.7
      The *invalidation_mode* parameter was added.

   .. versionchanged:: 3.7.2
      The *invalidation_mode* parameter's default value is updated to ``None``.

To force a recompile of all the :file:`.py` files in the :file:`Lib/`
subdirectory and all its subdirectories::

   import compileall

   compileall.compile_dir('Lib/', force=True)

   # Perform same compilation, excluding files in .svn directories.
   import re
   compileall.compile_dir('Lib/', rx=re.compile(r'[/\\][.]svn'), force=True)

   # pathlib.Path objects can also be used.
   import pathlib
   compileall.compile_dir(pathlib.Path('Lib/'), force=True)

.. seealso::

   Module :mod:`py_compile`
      Byte-compile a single source file.


================================================
File: /Doc/library/concurrency.rst
================================================
.. _concurrency:

********************
Concurrent Execution
********************

The modules described in this chapter provide support for concurrent
execution of code. The appropriate choice of tool will depend on the
task to be executed (CPU bound vs IO bound) and preferred style of
development (event driven cooperative multitasking vs preemptive
multitasking). Here's an overview:


.. toctree::

   threading.rst
   multiprocessing.rst
   multiprocessing.shared_memory.rst
   concurrent.rst
   concurrent.futures.rst
   subprocess.rst
   sched.rst
   queue.rst
   contextvars.rst


The following are support modules for some of the above services:

.. toctree::

   _thread.rst


================================================
File: /Doc/library/concurrent.futures.rst
================================================
:mod:`!concurrent.futures` --- Launching parallel tasks
=======================================================

.. module:: concurrent.futures
   :synopsis: Execute computations concurrently using threads or processes.

.. versionadded:: 3.2

**Source code:** :source:`Lib/concurrent/futures/thread.py`
and :source:`Lib/concurrent/futures/process.py`

--------------

The :mod:`concurrent.futures` module provides a high-level interface for
asynchronously executing callables.

The asynchronous execution can be performed with threads, using
:class:`ThreadPoolExecutor` or :class:`InterpreterPoolExecutor`,
or separate processes, using :class:`ProcessPoolExecutor`.
Each implements the same interface, which is defined
by the abstract :class:`Executor` class.

.. include:: ../includes/wasm-notavail.rst

Executor Objects
----------------

.. class:: Executor

   An abstract class that provides methods to execute calls asynchronously.  It
   should not be used directly, but through its concrete subclasses.

   .. method:: submit(fn, /, *args, **kwargs)

      Schedules the callable, *fn*, to be executed as ``fn(*args, **kwargs)``
      and returns a :class:`Future` object representing the execution of the
      callable. ::

         with ThreadPoolExecutor(max_workers=1) as executor:
             future = executor.submit(pow, 323, 1235)
             print(future.result())

   .. method:: map(fn, *iterables, timeout=None, chunksize=1)

      Similar to :func:`map(fn, *iterables) <map>` except:

      * the *iterables* are collected immediately rather than lazily;

      * *fn* is executed asynchronously and several calls to
        *fn* may be made concurrently.

      The returned iterator raises a :exc:`TimeoutError`
      if :meth:`~iterator.__next__` is called and the result isn't available
      after *timeout* seconds from the original call to :meth:`Executor.map`.
      *timeout* can be an int or a float.  If *timeout* is not specified or
      ``None``, there is no limit to the wait time.

      If a *fn* call raises an exception, then that exception will be
      raised when its value is retrieved from the iterator.

      When using :class:`ProcessPoolExecutor`, this method chops *iterables*
      into a number of chunks which it submits to the pool as separate
      tasks.  The (approximate) size of these chunks can be specified by
      setting *chunksize* to a positive integer.  For very long iterables,
      using a large value for *chunksize* can significantly improve
      performance compared to the default size of 1.  With
      :class:`ThreadPoolExecutor` and :class:`InterpreterPoolExecutor`,
      *chunksize* has no effect.

      .. versionchanged:: 3.5
         Added the *chunksize* argument.

   .. method:: shutdown(wait=True, *, cancel_futures=False)

      Signal the executor that it should free any resources that it is using
      when the currently pending futures are done executing.  Calls to
      :meth:`Executor.submit` and :meth:`Executor.map` made after shutdown will
      raise :exc:`RuntimeError`.

      If *wait* is ``True`` then this method will not return until all the
      pending futures are done executing and the resources associated with the
      executor have been freed.  If *wait* is ``False`` then this method will
      return immediately and the resources associated with the executor will be
      freed when all pending futures are done executing.  Regardless of the
      value of *wait*, the entire Python program will not exit until all
      pending futures are done executing.

      If *cancel_futures* is ``True``, this method will cancel all pending
      futures that the executor has not started running. Any futures that
      are completed or running won't be cancelled, regardless of the value
      of *cancel_futures*.

      If both *cancel_futures* and *wait* are ``True``, all futures that the
      executor has started running will be completed prior to this method
      returning. The remaining futures are cancelled.

      You can avoid having to call this method explicitly if you use the
      :keyword:`with` statement, which will shutdown the :class:`Executor`
      (waiting as if :meth:`Executor.shutdown` were called with *wait* set to
      ``True``)::

         import shutil
         with ThreadPoolExecutor(max_workers=4) as e:
             e.submit(shutil.copy, 'src1.txt', 'dest1.txt')
             e.submit(shutil.copy, 'src2.txt', 'dest2.txt')
             e.submit(shutil.copy, 'src3.txt', 'dest3.txt')
             e.submit(shutil.copy, 'src4.txt', 'dest4.txt')

      .. versionchanged:: 3.9
         Added *cancel_futures*.


ThreadPoolExecutor
------------------

:class:`ThreadPoolExecutor` is an :class:`Executor` subclass that uses a pool of
threads to execute calls asynchronously.

Deadlocks can occur when the callable associated with a :class:`Future` waits on
the results of another :class:`Future`.  For example::

   import time
   def wait_on_b():
       time.sleep(5)
       print(b.result())  # b will never complete because it is waiting on a.
       return 5

   def wait_on_a():
       time.sleep(5)
       print(a.result())  # a will never complete because it is waiting on b.
       return 6


   executor = ThreadPoolExecutor(max_workers=2)
   a = executor.submit(wait_on_b)
   b = executor.submit(wait_on_a)

And::

   def wait_on_future():
       f = executor.submit(pow, 5, 2)
       # This will never complete because there is only one worker thread and
       # it is executing this function.
       print(f.result())

   executor = ThreadPoolExecutor(max_workers=1)
   executor.submit(wait_on_future)


.. class:: ThreadPoolExecutor(max_workers=None, thread_name_prefix='', initializer=None, initargs=())

   An :class:`Executor` subclass that uses a pool of at most *max_workers*
   threads to execute calls asynchronously.

   All threads enqueued to ``ThreadPoolExecutor`` will be joined before the
   interpreter can exit. Note that the exit handler which does this is
   executed *before* any exit handlers added using ``atexit``. This means
   exceptions in the main thread must be caught and handled in order to
   signal threads to exit gracefully. For this reason, it is recommended
   that ``ThreadPoolExecutor`` not be used for long-running tasks.

   *initializer* is an optional callable that is called at the start of
   each worker thread; *initargs* is a tuple of arguments passed to the
   initializer.  Should *initializer* raise an exception, all currently
   pending jobs will raise a :exc:`~concurrent.futures.thread.BrokenThreadPool`,
   as well as any attempt to submit more jobs to the pool.

   .. versionchanged:: 3.5
      If *max_workers* is ``None`` or
      not given, it will default to the number of processors on the machine,
      multiplied by ``5``, assuming that :class:`ThreadPoolExecutor` is often
      used to overlap I/O instead of CPU work and the number of workers
      should be higher than the number of workers
      for :class:`ProcessPoolExecutor`.

   .. versionchanged:: 3.6
      Added the *thread_name_prefix* parameter to allow users to
      control the :class:`threading.Thread` names for worker threads created by
      the pool for easier debugging.

   .. versionchanged:: 3.7
      Added the *initializer* and *initargs* arguments.

   .. versionchanged:: 3.8
      Default value of *max_workers* is changed to ``min(32, os.cpu_count() + 4)``.
      This default value preserves at least 5 workers for I/O bound tasks.
      It utilizes at most 32 CPU cores for CPU bound tasks which release the GIL.
      And it avoids using very large resources implicitly on many-core machines.

      ThreadPoolExecutor now reuses idle worker threads before starting
      *max_workers* worker threads too.

   .. versionchanged:: 3.13
      Default value of *max_workers* is changed to
      ``min(32, (os.process_cpu_count() or 1) + 4)``.


.. _threadpoolexecutor-example:

ThreadPoolExecutor Example
~~~~~~~~~~~~~~~~~~~~~~~~~~
::

   import concurrent.futures
   import urllib.request

   URLS = ['http://www.foxnews.com/',
           'http://www.cnn.com/',
           'http://europe.wsj.com/',
           'http://www.bbc.co.uk/',
           'http://nonexistent-subdomain.python.org/']

   # Retrieve a single page and report the URL and contents
   def load_url(url, timeout):
       with urllib.request.urlopen(url, timeout=timeout) as conn:
           return conn.read()

   # We can use a with statement to ensure threads are cleaned up promptly
   with concurrent.futures.ThreadPoolExecutor(max_workers=5) as executor:
       # Start the load operations and mark each future with its URL
       future_to_url = {executor.submit(load_url, url, 60): url for url in URLS}
       for future in concurrent.futures.as_completed(future_to_url):
           url = future_to_url[future]
           try:
               data = future.result()
           except Exception as exc:
               print('%r generated an exception: %s' % (url, exc))
           else:
               print('%r page is %d bytes' % (url, len(data)))


InterpreterPoolExecutor
-----------------------

The :class:`InterpreterPoolExecutor` class uses a pool of interpreters
to execute calls asynchronously.  It is a :class:`ThreadPoolExecutor`
subclass, which means each worker is running in its own thread.
The difference here is that each worker has its own interpreter,
and runs each task using that interpreter.

The biggest benefit to using interpreters instead of only threads
is true multi-core parallelism.  Each interpreter has its own
:term:`Global Interpreter Lock <global interpreter lock>`, so code
running in one interpreter can run on one CPU core, while code in
another interpreter runs unblocked on a different core.

The tradeoff is that writing concurrent code for use with multiple
interpreters can take extra effort.  However, this is because it
forces you to be deliberate about how and when interpreters interact,
and to be explicit about what data is shared between interpreters.
This results in several benefits that help balance the extra effort,
including true multi-core parallelism,  For example, code written
this way can make it easier to reason about concurrency.  Another
major benefit is that you don't have to deal with several of the
big pain points of using threads, like race conditions.

Each worker's interpreter is isolated from all the other interpreters.
"Isolated" means each interpreter has its own runtime state and
operates completely independently.  For example, if you redirect
:data:`sys.stdout` in one interpreter, it will not be automatically
redirected any other interpreter.  If you import a module in one
interpreter, it is not automatically imported in any other.  You
would need to import the module separately in interpreter where
you need it.  In fact, each module imported in an interpreter is
a completely separate object from the same module in a different
interpreter, including :mod:`sys`, :mod:`builtins`,
and even ``__main__``.

Isolation means a mutable object, or other data, cannot be used
by more than one interpreter at the same time.  That effectively means
interpreters cannot actually share such objects or data.  Instead,
each interpreter must have its own copy, and you will have to
synchronize any changes between the copies manually.  Immutable
objects and data, like the builtin singletons, strings, and tuples
of immutable objects, don't have these limitations.

Communicating and synchronizing between interpreters is most effectively
done using dedicated tools, like those proposed in :pep:`734`.  One less
efficient alternative is to serialize with :mod:`pickle` and then send
the bytes over a shared :mod:`socket <socket>` or
:func:`pipe <os.pipe>`.

.. class:: InterpreterPoolExecutor(max_workers=None, thread_name_prefix='', initializer=None, initargs=(), shared=None)

   A :class:`ThreadPoolExecutor` subclass that executes calls asynchronously
   using a pool of at most *max_workers* threads.  Each thread runs
   tasks in its own interpreter.  The worker interpreters are isolated
   from each other, which means each has its own runtime state and that
   they can't share any mutable objects or other data.  Each interpreter
   has its own :term:`Global Interpreter Lock <global interpreter lock>`,
   which means code run with this executor has true multi-core parallelism.

   The optional *initializer* and *initargs* arguments have the same
   meaning as for :class:`!ThreadPoolExecutor`: the initializer is run
   when each worker is created, though in this case it is run.in
   the worker's interpreter.  The executor serializes the *initializer*
   and *initargs* using :mod:`pickle` when sending them to the worker's
   interpreter.

   .. note::
      Functions defined in the ``__main__`` module cannot be pickled
      and thus cannot be used.

   .. note::
      The executor may replace uncaught exceptions from *initializer*
      with :class:`~concurrent.futures.interpreter.ExecutionFailed`.

   The optional *shared* argument is a :class:`dict` of objects that all
   interpreters in the pool share.  The *shared* items are added to each
   interpreter's ``__main__`` module.  Not all objects are shareable.
   Shareable objects include the builtin singletons, :class:`str`
   and :class:`bytes`, and :class:`memoryview`.  See :pep:`734`
   for more info.

   Other caveats from parent :class:`ThreadPoolExecutor` apply here.

:meth:`~Executor.submit` and :meth:`~Executor.map` work like normal,
except the worker serializes the callable and arguments using
:mod:`pickle` when sending them to its interpreter.  The worker
likewise serializes the return value when sending it back.

.. note::
   Functions defined in the ``__main__`` module cannot be pickled
   and thus cannot be used.

When a worker's current task raises an uncaught exception, the worker
always tries to preserve the exception as-is.  If that is successful
then it also sets the ``__cause__`` to a corresponding
:class:`~concurrent.futures.interpreter.ExecutionFailed`
instance, which contains a summary of the original exception.
In the uncommon case that the worker is not able to preserve the
original as-is then it directly preserves the corresponding
:class:`~concurrent.futures.interpreter.ExecutionFailed`
instance instead.


ProcessPoolExecutor
-------------------

The :class:`ProcessPoolExecutor` class is an :class:`Executor` subclass that
uses a pool of processes to execute calls asynchronously.
:class:`ProcessPoolExecutor` uses the :mod:`multiprocessing` module, which
allows it to side-step the :term:`Global Interpreter Lock
<global interpreter lock>` but also means that
only picklable objects can be executed and returned.

The ``__main__`` module must be importable by worker subprocesses. This means
that :class:`ProcessPoolExecutor` will not work in the interactive interpreter.

Calling :class:`Executor` or :class:`Future` methods from a callable submitted
to a :class:`ProcessPoolExecutor` will result in deadlock.

.. class:: ProcessPoolExecutor(max_workers=None, mp_context=None, initializer=None, initargs=(), max_tasks_per_child=None)

   An :class:`Executor` subclass that executes calls asynchronously using a pool
   of at most *max_workers* processes.  If *max_workers* is ``None`` or not
   given, it will default to :func:`os.process_cpu_count`.
   If *max_workers* is less than or equal to ``0``, then a :exc:`ValueError`
   will be raised.
   On Windows, *max_workers* must be less than or equal to ``61``. If it is not
   then :exc:`ValueError` will be raised. If *max_workers* is ``None``, then
   the default chosen will be at most ``61``, even if more processors are
   available.
   *mp_context* can be a :mod:`multiprocessing` context or ``None``. It will be
   used to launch the workers. If *mp_context* is ``None`` or not given, the
   default :mod:`multiprocessing` context is used.
   See :ref:`multiprocessing-start-methods`.

   *initializer* is an optional callable that is called at the start of
   each worker process; *initargs* is a tuple of arguments passed to the
   initializer.  Should *initializer* raise an exception, all currently
   pending jobs will raise a :exc:`~concurrent.futures.process.BrokenProcessPool`,
   as well as any attempt to submit more jobs to the pool.

   *max_tasks_per_child* is an optional argument that specifies the maximum
   number of tasks a single process can execute before it will exit and be
   replaced with a fresh worker process. By default *max_tasks_per_child* is
   ``None`` which means worker processes will live as long as the pool. When
   a max is specified, the "spawn" multiprocessing start method will be used by
   default in absence of a *mp_context* parameter. This feature is incompatible
   with the "fork" start method.

   .. versionchanged:: 3.3
      When one of the worker processes terminates abruptly, a
      :exc:`~concurrent.futures.process.BrokenProcessPool` error is now raised.
      Previously, behaviour
      was undefined but operations on the executor or its futures would often
      freeze or deadlock.

   .. versionchanged:: 3.7
      The *mp_context* argument was added to allow users to control the
      start_method for worker processes created by the pool.

      Added the *initializer* and *initargs* arguments.

   .. versionchanged:: 3.11
      The *max_tasks_per_child* argument was added to allow users to
      control the lifetime of workers in the pool.

   .. versionchanged:: 3.12
      On POSIX systems, if your application has multiple threads and the
      :mod:`multiprocessing` context uses the ``"fork"`` start method:
      The :func:`os.fork` function called internally to spawn workers may raise a
      :exc:`DeprecationWarning`. Pass a *mp_context* configured to use a
      different start method. See the :func:`os.fork` documentation for
      further explanation.

   .. versionchanged:: 3.13
      *max_workers* uses :func:`os.process_cpu_count` by default, instead of
      :func:`os.cpu_count`.

   .. versionchanged:: 3.14
      The default process start method (see
      :ref:`multiprocessing-start-methods`) changed away from *fork*. If you
      require the *fork* start method for :class:`ProcessPoolExecutor` you must
      explicitly pass ``mp_context=multiprocessing.get_context("fork")``.

.. _processpoolexecutor-example:

ProcessPoolExecutor Example
~~~~~~~~~~~~~~~~~~~~~~~~~~~
::

   import concurrent.futures
   import math

   PRIMES = [
       112272535095293,
       112582705942171,
       112272535095293,
       115280095190773,
       115797848077099,
       1099726899285419]

   def is_prime(n):
       if n < 2:
           return False
       if n == 2:
           return True
       if n % 2 == 0:
           return False

       sqrt_n = int(math.floor(math.sqrt(n)))
       for i in range(3, sqrt_n + 1, 2):
           if n % i == 0:
               return False
       return True

   def main():
       with concurrent.futures.ProcessPoolExecutor() as executor:
           for number, prime in zip(PRIMES, executor.map(is_prime, PRIMES)):
               print('%d is prime: %s' % (number, prime))

   if __name__ == '__main__':
       main()


Future Objects
--------------

The :class:`Future` class encapsulates the asynchronous execution of a callable.
:class:`Future` instances are created by :meth:`Executor.submit`.

.. class:: Future

   Encapsulates the asynchronous execution of a callable.  :class:`Future`
   instances are created by :meth:`Executor.submit` and should not be created
   directly except for testing.

   .. method:: cancel()

      Attempt to cancel the call.  If the call is currently being executed or
      finished running and cannot be cancelled then the method will return
      ``False``, otherwise the call will be cancelled and the method will
      return ``True``.

   .. method:: cancelled()

      Return ``True`` if the call was successfully cancelled.

   .. method:: running()

      Return ``True`` if the call is currently being executed and cannot be
      cancelled.

   .. method:: done()

      Return ``True`` if the call was successfully cancelled or finished
      running.

   .. method:: result(timeout=None)

      Return the value returned by the call. If the call hasn't yet completed
      then this method will wait up to *timeout* seconds.  If the call hasn't
      completed in *timeout* seconds, then a
      :exc:`TimeoutError` will be raised. *timeout* can be
      an int or float.  If *timeout* is not specified or ``None``, there is no
      limit to the wait time.

      If the future is cancelled before completing then :exc:`.CancelledError`
      will be raised.

      If the call raised an exception, this method will raise the same exception.

   .. method:: exception(timeout=None)

      Return the exception raised by the call.  If the call hasn't yet
      completed then this method will wait up to *timeout* seconds.  If the
      call hasn't completed in *timeout* seconds, then a
      :exc:`TimeoutError` will be raised.  *timeout* can be
      an int or float.  If *timeout* is not specified or ``None``, there is no
      limit to the wait time.

      If the future is cancelled before completing then :exc:`.CancelledError`
      will be raised.

      If the call completed without raising, ``None`` is returned.

   .. method:: add_done_callback(fn)

      Attaches the callable *fn* to the future.  *fn* will be called, with the
      future as its only argument, when the future is cancelled or finishes
      running.

      Added callables are called in the order that they were added and are
      always called in a thread belonging to the process that added them.  If
      the callable raises an :exc:`Exception` subclass, it will be logged and
      ignored.  If the callable raises a :exc:`BaseException` subclass, the
      behavior is undefined.

      If the future has already completed or been cancelled, *fn* will be
      called immediately.

   The following :class:`Future` methods are meant for use in unit tests and
   :class:`Executor` implementations.

   .. method:: set_running_or_notify_cancel()

      This method should only be called by :class:`Executor` implementations
      before executing the work associated with the :class:`Future` and by unit
      tests.

      If the method returns ``False`` then the :class:`Future` was cancelled,
      i.e. :meth:`Future.cancel` was called and returned ``True``.  Any threads
      waiting on the :class:`Future` completing (i.e. through
      :func:`as_completed` or :func:`wait`) will be woken up.

      If the method returns ``True`` then the :class:`Future` was not cancelled
      and has been put in the running state, i.e. calls to
      :meth:`Future.running` will return ``True``.

      This method can only be called once and cannot be called after
      :meth:`Future.set_result` or :meth:`Future.set_exception` have been
      called.

   .. method:: set_result(result)

      Sets the result of the work associated with the :class:`Future` to
      *result*.

      This method should only be used by :class:`Executor` implementations and
      unit tests.

      .. versionchanged:: 3.8
         This method raises
         :exc:`concurrent.futures.InvalidStateError` if the :class:`Future` is
         already done.

   .. method:: set_exception(exception)

      Sets the result of the work associated with the :class:`Future` to the
      :class:`Exception` *exception*.

      This method should only be used by :class:`Executor` implementations and
      unit tests.

      .. versionchanged:: 3.8
         This method raises
         :exc:`concurrent.futures.InvalidStateError` if the :class:`Future` is
         already done.

Module Functions
----------------

.. function:: wait(fs, timeout=None, return_when=ALL_COMPLETED)

   Wait for the :class:`Future` instances (possibly created by different
   :class:`Executor` instances) given by *fs* to complete. Duplicate futures
   given to *fs* are removed and will be returned only once. Returns a named
   2-tuple of sets.  The first set, named ``done``, contains the futures that
   completed (finished or cancelled futures) before the wait completed.  The
   second set, named ``not_done``, contains the futures that did not complete
   (pending or running futures).

   *timeout* can be used to control the maximum number of seconds to wait before
   returning.  *timeout* can be an int or float.  If *timeout* is not specified
   or ``None``, there is no limit to the wait time.

   *return_when* indicates when this function should return.  It must be one of
   the following constants:

   .. list-table::
      :header-rows: 1

      * - Constant
        - Description

      * - .. data:: FIRST_COMPLETED
        - The function will return when any future finishes or is cancelled.

      * - .. data:: FIRST_EXCEPTION
        - The function will return when any future finishes by raising an
          exception. If no future raises an exception
          then it is equivalent to :const:`ALL_COMPLETED`.

      * - .. data:: ALL_COMPLETED
        - The function will return when all futures finish or are cancelled.

.. function:: as_completed(fs, timeout=None)

   Returns an iterator over the :class:`Future` instances (possibly created by
   different :class:`Executor` instances) given by *fs* that yields futures as
   they complete (finished or cancelled futures). Any futures given by *fs* that
   are duplicated will be returned once. Any futures that completed before
   :func:`as_completed` is called will be yielded first.  The returned iterator
   raises a :exc:`TimeoutError` if :meth:`~iterator.__next__`
   is called and the result isn't available after *timeout* seconds from the
   original call to :func:`as_completed`.  *timeout* can be an int or float. If
   *timeout* is not specified or ``None``, there is no limit to the wait time.


.. seealso::

   :pep:`3148` -- futures - execute computations asynchronously
      The proposal which described this feature for inclusion in the Python
      standard library.


Exception classes
-----------------

.. currentmodule:: concurrent.futures

.. exception:: CancelledError

   Raised when a future is cancelled.

.. exception:: TimeoutError

   A deprecated alias of :exc:`TimeoutError`,
   raised when a future operation exceeds the given timeout.

   .. versionchanged:: 3.11

      This class was made an alias of :exc:`TimeoutError`.


.. exception:: BrokenExecutor

   Derived from :exc:`RuntimeError`, this exception class is raised
   when an executor is broken for some reason, and cannot be used
   to submit or execute new tasks.

   .. versionadded:: 3.7

.. exception:: InvalidStateError

   Raised when an operation is performed on a future that is not allowed
   in the current state.

   .. versionadded:: 3.8

.. currentmodule:: concurrent.futures.thread

.. exception:: BrokenThreadPool

   Derived from :exc:`~concurrent.futures.BrokenExecutor`, this exception
   class is raised when one of the workers
   of a :class:`~concurrent.futures.ThreadPoolExecutor`
   has failed initializing.

   .. versionadded:: 3.7

.. currentmodule:: concurrent.futures.interpreter

.. exception:: BrokenInterpreterPool

   Derived from :exc:`~concurrent.futures.thread.BrokenThreadPool`,
   this exception class is raised when one of the workers
   of a :class:`~concurrent.futures.InterpreterPoolExecutor`
   has failed initializing.

   .. versionadded:: 3.14

.. exception:: ExecutionFailed

   Raised from :class:`~concurrent.futures.InterpreterPoolExecutor` when
   the given initializer fails or from
   :meth:`~concurrent.futures.Executor.submit` when there's an uncaught
   exception from the submitted task.

   .. versionadded:: 3.14

.. currentmodule:: concurrent.futures.process

.. exception:: BrokenProcessPool

   Derived from :exc:`~concurrent.futures.BrokenExecutor` (formerly
   :exc:`RuntimeError`), this exception class is raised when one of the
   workers of a :class:`~concurrent.futures.ProcessPoolExecutor`
   has terminated in a non-clean
   fashion (for example, if it was killed from the outside).

   .. versionadded:: 3.3


================================================
File: /Doc/library/concurrent.rst
================================================
The :mod:`!concurrent` package
==============================

Currently, there is only one module in this package:

* :mod:`concurrent.futures` -- Launching parallel tasks


================================================
File: /Doc/library/constants.rst
================================================
.. _built-in-consts:

Built-in Constants
==================

A small number of constants live in the built-in namespace.  They are:

.. data:: False

   The false value of the :class:`bool` type. Assignments to ``False``
   are illegal and raise a :exc:`SyntaxError`.


.. data:: True

   The true value of the :class:`bool` type. Assignments to ``True``
   are illegal and raise a :exc:`SyntaxError`.


.. data:: None

   An object frequently used to represent the absence of a value, as when
   default arguments are not passed to a function. Assignments to ``None``
   are illegal and raise a :exc:`SyntaxError`.
   ``None`` is the sole instance of the :data:`~types.NoneType` type.


.. data:: NotImplemented

   A special value which should be returned by the binary special methods
   (e.g. :meth:`~object.__eq__`, :meth:`~object.__lt__`, :meth:`~object.__add__`, :meth:`~object.__rsub__`,
   etc.) to indicate that the operation is not implemented with respect to
   the other type; may be returned by the in-place binary special methods
   (e.g. :meth:`~object.__imul__`, :meth:`~object.__iand__`, etc.) for the same purpose.
   It should not be evaluated in a boolean context.
   :data:`!NotImplemented` is the sole instance of the :data:`types.NotImplementedType` type.

   .. note::

      When a binary (or in-place) method returns :data:`!NotImplemented` the
      interpreter will try the reflected operation on the other type (or some
      other fallback, depending on the operator).  If all attempts return
      :data:`!NotImplemented`, the interpreter will raise an appropriate exception.
      Incorrectly returning :data:`!NotImplemented` will result in a misleading
      error message or the :data:`!NotImplemented` value being returned to Python code.

      See :ref:`implementing-the-arithmetic-operations` for examples.

   .. note::

      ``NotImplementedError`` and :data:`!NotImplemented` are not interchangeable,
      even though they have similar names and purposes.
      See :exc:`NotImplementedError` for details on when to use it.

   .. versionchanged:: 3.9
      Evaluating :data:`!NotImplemented` in a boolean context was deprecated.

   .. versionchanged:: 3.14
      Evaluating :data:`!NotImplemented` in a boolean context now raises a :exc:`TypeError`.
      It previously evaluated to :const:`True` and emitted a :exc:`DeprecationWarning`
      since Python 3.9.


.. index:: single: ...; ellipsis literal
.. data:: Ellipsis

   The same as the ellipsis literal "``...``". Special value used mostly in conjunction
   with extended slicing syntax for user-defined container data types.
   ``Ellipsis`` is the sole instance of the :data:`types.EllipsisType` type.


.. data:: __debug__

   This constant is true if Python was not started with an :option:`-O` option.
   See also the :keyword:`assert` statement.


.. note::

   The names :data:`None`, :data:`False`, :data:`True` and :data:`__debug__`
   cannot be reassigned (assignments to them, even as an attribute name, raise
   :exc:`SyntaxError`), so they can be considered "true" constants.


.. _site-consts:

Constants added by the :mod:`site` module
-----------------------------------------

The :mod:`site` module (which is imported automatically during startup, except
if the :option:`-S` command-line option is given) adds several constants to the
built-in namespace.  They are useful for the interactive interpreter shell and
should not be used in programs.

.. data:: quit(code=None)
          exit(code=None)

   Objects that when printed, print a message like "Use quit() or Ctrl-D
   (i.e. EOF) to exit", and when called, raise :exc:`SystemExit` with the
   specified exit code.

.. data:: help
   :noindex:

   Object that when printed, prints the message "Type help() for interactive
   help, or help(object) for help about object.", and when called,
   acts as described :func:`elsewhere <help>`.

.. data:: copyright
          credits

   Objects that when printed or called, print the text of copyright or
   credits, respectively.

.. data:: license

   Object that when printed, prints the message "Type license() to see the
   full license text", and when called, displays the full license text in a
   pager-like fashion (one screen at a time).


================================================
File: /Doc/library/contextlib.rst
================================================
:mod:`!contextlib` --- Utilities for :keyword:`!with`\ -statement contexts
==========================================================================

.. module:: contextlib
   :synopsis: Utilities for with-statement contexts.

**Source code:** :source:`Lib/contextlib.py`

--------------

This module provides utilities for common tasks involving the :keyword:`with`
statement. For more information see also :ref:`typecontextmanager` and
:ref:`context-managers`.


Utilities
---------

Functions and classes provided:

.. class:: AbstractContextManager

   An :term:`abstract base class` for classes that implement
   :meth:`object.__enter__` and :meth:`object.__exit__`. A default
   implementation for :meth:`object.__enter__` is provided which returns
   ``self`` while :meth:`object.__exit__` is an abstract method which by default
   returns ``None``. See also the definition of :ref:`typecontextmanager`.

   .. versionadded:: 3.6


.. class:: AbstractAsyncContextManager

   An :term:`abstract base class` for classes that implement
   :meth:`object.__aenter__` and :meth:`object.__aexit__`. A default
   implementation for :meth:`object.__aenter__` is provided which returns
   ``self`` while :meth:`object.__aexit__` is an abstract method which by default
   returns ``None``. See also the definition of
   :ref:`async-context-managers`.

   .. versionadded:: 3.7


.. decorator:: contextmanager

   This function is a :term:`decorator` that can be used to define a factory
   function for :keyword:`with` statement context managers, without needing to
   create a class or separate :meth:`~object.__enter__` and :meth:`~object.__exit__` methods.

   While many objects natively support use in with statements, sometimes a
   resource needs to be managed that isn't a context manager in its own right,
   and doesn't implement a ``close()`` method for use with ``contextlib.closing``

   An abstract example would be the following to ensure correct resource
   management::

      from contextlib import contextmanager

      @contextmanager
      def managed_resource(*args, **kwds):
          # Code to acquire resource, e.g.:
          resource = acquire_resource(*args, **kwds)
          try:
              yield resource
          finally:
              # Code to release resource, e.g.:
              release_resource(resource)

   The function can then be used like this::

      >>> with managed_resource(timeout=3600) as resource:
      ...     # Resource is released at the end of this block,
      ...     # even if code in the block raises an exception

   The function being decorated must return a :term:`generator`-iterator when
   called. This iterator must yield exactly one value, which will be bound to
   the targets in the :keyword:`with` statement's :keyword:`!as` clause, if any.

   At the point where the generator yields, the block nested in the :keyword:`with`
   statement is executed.  The generator is then resumed after the block is exited.
   If an unhandled exception occurs in the block, it is reraised inside the
   generator at the point where the yield occurred.  Thus, you can use a
   :keyword:`try`...\ :keyword:`except`...\ :keyword:`finally` statement to trap
   the error (if any), or ensure that some cleanup takes place. If an exception is
   trapped merely in order to log it or to perform some action (rather than to
   suppress it entirely), the generator must reraise that exception. Otherwise the
   generator context manager will indicate to the :keyword:`!with` statement that
   the exception has been handled, and execution will resume with the statement
   immediately following the :keyword:`!with` statement.

   :func:`contextmanager` uses :class:`ContextDecorator` so the context managers
   it creates can be used as decorators as well as in :keyword:`with` statements.
   When used as a decorator, a new generator instance is implicitly created on
   each function call (this allows the otherwise "one-shot" context managers
   created by :func:`contextmanager` to meet the requirement that context
   managers support multiple invocations in order to be used as decorators).

   .. versionchanged:: 3.2
      Use of :class:`ContextDecorator`.


.. decorator:: asynccontextmanager

   Similar to :func:`~contextlib.contextmanager`, but creates an
   :ref:`asynchronous context manager <async-context-managers>`.

   This function is a :term:`decorator` that can be used to define a factory
   function for :keyword:`async with` statement asynchronous context managers,
   without needing to create a class or separate :meth:`~object.__aenter__` and
   :meth:`~object.__aexit__` methods. It must be applied to an :term:`asynchronous
   generator` function.

   A simple example::

      from contextlib import asynccontextmanager

      @asynccontextmanager
      async def get_connection():
          conn = await acquire_db_connection()
          try:
              yield conn
          finally:
              await release_db_connection(conn)

      async def get_all_users():
          async with get_connection() as conn:
              return conn.query('SELECT ...')

   .. versionadded:: 3.7

   Context managers defined with :func:`asynccontextmanager` can be used
   either as decorators or with :keyword:`async with` statements::

     import time
     from contextlib import asynccontextmanager

     @asynccontextmanager
     async def timeit():
         now = time.monotonic()
         try:
             yield
         finally:
             print(f'it took {time.monotonic() - now}s to run')

     @timeit()
     async def main():
         # ... async code ...

   When used as a decorator, a new generator instance is implicitly created on
   each function call. This allows the otherwise "one-shot" context managers
   created by :func:`asynccontextmanager` to meet the requirement that context
   managers support multiple invocations in order to be used as decorators.

   .. versionchanged:: 3.10
      Async context managers created with :func:`asynccontextmanager` can
      be used as decorators.


.. function:: closing(thing)

   Return a context manager that closes *thing* upon completion of the block.  This
   is basically equivalent to::

      from contextlib import contextmanager

      @contextmanager
      def closing(thing):
          try:
              yield thing
          finally:
              thing.close()

   And lets you write code like this::

      from contextlib import closing
      from urllib.request import urlopen

      with closing(urlopen('https://www.python.org')) as page:
          for line in page:
              print(line)

   without needing to explicitly close ``page``.  Even if an error occurs,
   ``page.close()`` will be called when the :keyword:`with` block is exited.

   .. note::

      Most types managing resources support the :term:`context manager` protocol,
      which closes *thing* on leaving the :keyword:`with` statement.
      As such, :func:`!closing` is most useful for third party types that don't
      support context managers.
      This example is purely for illustration purposes,
      as :func:`~urllib.request.urlopen` would normally be used in a context manager.

.. function:: aclosing(thing)

   Return an async context manager that calls the ``aclose()`` method of *thing*
   upon completion of the block.  This is basically equivalent to::

      from contextlib import asynccontextmanager

      @asynccontextmanager
      async def aclosing(thing):
          try:
              yield thing
          finally:
              await thing.aclose()

   Significantly, ``aclosing()`` supports deterministic cleanup of async
   generators when they happen to exit early by :keyword:`break` or an
   exception.  For example::

      from contextlib import aclosing

      async with aclosing(my_generator()) as values:
          async for value in values:
              if value == 42:
                  break

   This pattern ensures that the generator's async exit code is executed in
   the same context as its iterations (so that exceptions and context
   variables work as expected, and the exit code isn't run after the
   lifetime of some task it depends on).

   .. versionadded:: 3.10


.. _simplifying-support-for-single-optional-context-managers:

.. function:: nullcontext(enter_result=None)

   Return a context manager that returns *enter_result* from ``__enter__``, but
   otherwise does nothing. It is intended to be used as a stand-in for an
   optional context manager, for example::

      def myfunction(arg, ignore_exceptions=False):
          if ignore_exceptions:
              # Use suppress to ignore all exceptions.
              cm = contextlib.suppress(Exception)
          else:
              # Do not ignore any exceptions, cm has no effect.
              cm = contextlib.nullcontext()
          with cm:
              # Do something

   An example using *enter_result*::

      def process_file(file_or_path):
          if isinstance(file_or_path, str):
              # If string, open file
              cm = open(file_or_path)
          else:
              # Caller is responsible for closing file
              cm = nullcontext(file_or_path)

          with cm as file:
              # Perform processing on the file

   It can also be used as a stand-in for
   :ref:`asynchronous context managers <async-context-managers>`::

       async def send_http(session=None):
           if not session:
               # If no http session, create it with aiohttp
               cm = aiohttp.ClientSession()
           else:
               # Caller is responsible for closing the session
               cm = nullcontext(session)

           async with cm as session:
               # Send http requests with session

   .. versionadded:: 3.7

   .. versionchanged:: 3.10
      :term:`asynchronous context manager` support was added.



.. function:: suppress(*exceptions)

   Return a context manager that suppresses any of the specified exceptions
   if they occur in the body of a :keyword:`!with` statement and then
   resumes execution with the first statement following the end of the
   :keyword:`!with` statement.

   As with any other mechanism that completely suppresses exceptions, this
   context manager should be used only to cover very specific errors where
   silently continuing with program execution is known to be the right
   thing to do.

   For example::

       from contextlib import suppress

       with suppress(FileNotFoundError):
           os.remove('somefile.tmp')

       with suppress(FileNotFoundError):
           os.remove('someotherfile.tmp')

   This code is equivalent to::

       try:
           os.remove('somefile.tmp')
       except FileNotFoundError:
           pass

       try:
           os.remove('someotherfile.tmp')
       except FileNotFoundError:
           pass

   This context manager is :ref:`reentrant <reentrant-cms>`.

   If the code within the :keyword:`!with` block raises a
   :exc:`BaseExceptionGroup`, suppressed exceptions are removed from the
   group.  Any exceptions of the group which are not suppressed are re-raised in
   a new group which is created using the original group's :meth:`~BaseExceptionGroup.derive`
   method.

   .. versionadded:: 3.4

   .. versionchanged:: 3.12
      ``suppress`` now supports suppressing exceptions raised as
      part of a :exc:`BaseExceptionGroup`.

.. function:: redirect_stdout(new_target)

   Context manager for temporarily redirecting :data:`sys.stdout` to
   another file or file-like object.

   This tool adds flexibility to existing functions or classes whose output
   is hardwired to stdout.

   For example, the output of :func:`help` normally is sent to *sys.stdout*.
   You can capture that output in a string by redirecting the output to an
   :class:`io.StringIO` object. The replacement stream is returned from the
   ``__enter__`` method and so is available as the target of the
   :keyword:`with` statement::

        with redirect_stdout(io.StringIO()) as f:
            help(pow)
        s = f.getvalue()

   To send the output of :func:`help` to a file on disk, redirect the output
   to a regular file::

        with open('help.txt', 'w') as f:
            with redirect_stdout(f):
                help(pow)

   To send the output of :func:`help` to *sys.stderr*::

        with redirect_stdout(sys.stderr):
            help(pow)

   Note that the global side effect on :data:`sys.stdout` means that this
   context manager is not suitable for use in library code and most threaded
   applications. It also has no effect on the output of subprocesses.
   However, it is still a useful approach for many utility scripts.

   This context manager is :ref:`reentrant <reentrant-cms>`.

   .. versionadded:: 3.4


.. function:: redirect_stderr(new_target)

   Similar to :func:`~contextlib.redirect_stdout` but redirecting
   :data:`sys.stderr` to another file or file-like object.

   This context manager is :ref:`reentrant <reentrant-cms>`.

   .. versionadded:: 3.5


.. function:: chdir(path)

   Non parallel-safe context manager to change the current working directory.
   As this changes a global state, the working directory, it is not suitable
   for use in most threaded or async contexts. It is also not suitable for most
   non-linear code execution, like generators, where the program execution is
   temporarily relinquished -- unless explicitly desired, you should not yield
   when this context manager is active.

   This is a simple wrapper around :func:`~os.chdir`, it changes the current
   working directory upon entering and restores the old one on exit.

   This context manager is :ref:`reentrant <reentrant-cms>`.

   .. versionadded:: 3.11


.. class:: ContextDecorator()

   A base class that enables a context manager to also be used as a decorator.

   Context managers inheriting from ``ContextDecorator`` have to implement
   ``__enter__`` and ``__exit__`` as normal. ``__exit__`` retains its optional
   exception handling even when used as a decorator.

   ``ContextDecorator`` is used by :func:`contextmanager`, so you get this
   functionality automatically.

   Example of ``ContextDecorator``::

      from contextlib import ContextDecorator

      class mycontext(ContextDecorator):
          def __enter__(self):
              print('Starting')
              return self

          def __exit__(self, *exc):
              print('Finishing')
              return False

   The class can then be used like this::

      >>> @mycontext()
      ... def function():
      ...     print('The bit in the middle')
      ...
      >>> function()
      Starting
      The bit in the middle
      Finishing

      >>> with mycontext():
      ...     print('The bit in the middle')
      ...
      Starting
      The bit in the middle
      Finishing

   This change is just syntactic sugar for any construct of the following form::

      def f():
          with cm():
              # Do stuff

   ``ContextDecorator`` lets you instead write::

      @cm()
      def f():
          # Do stuff

   It makes it clear that the ``cm`` applies to the whole function, rather than
   just a piece of it (and saving an indentation level is nice, too).

   Existing context managers that already have a base class can be extended by
   using ``ContextDecorator`` as a mixin class::

      from contextlib import ContextDecorator

      class mycontext(ContextBaseClass, ContextDecorator):
          def __enter__(self):
              return self

          def __exit__(self, *exc):
              return False

   .. note::
      As the decorated function must be able to be called multiple times, the
      underlying context manager must support use in multiple :keyword:`with`
      statements. If this is not the case, then the original construct with the
      explicit :keyword:`!with` statement inside the function should be used.

   .. versionadded:: 3.2


.. class:: AsyncContextDecorator

   Similar to :class:`ContextDecorator` but only for asynchronous functions.

   Example of ``AsyncContextDecorator``::

      from asyncio import run
      from contextlib import AsyncContextDecorator

      class mycontext(AsyncContextDecorator):
          async def __aenter__(self):
              print('Starting')
              return self

          async def __aexit__(self, *exc):
              print('Finishing')
              return False

   The class can then be used like this::

      >>> @mycontext()
      ... async def function():
      ...     print('The bit in the middle')
      ...
      >>> run(function())
      Starting
      The bit in the middle
      Finishing

      >>> async def function():
      ...    async with mycontext():
      ...         print('The bit in the middle')
      ...
      >>> run(function())
      Starting
      The bit in the middle
      Finishing

   .. versionadded:: 3.10


.. class:: ExitStack()

   A context manager that is designed to make it easy to programmatically
   combine other context managers and cleanup functions, especially those
   that are optional or otherwise driven by input data.

   For example, a set of files may easily be handled in a single with
   statement as follows::

      with ExitStack() as stack:
          files = [stack.enter_context(open(fname)) for fname in filenames]
          # All opened files will automatically be closed at the end of
          # the with statement, even if attempts to open files later
          # in the list raise an exception

   The :meth:`~object.__enter__` method returns the :class:`ExitStack` instance, and
   performs no additional operations.

   Each instance maintains a stack of registered callbacks that are called in
   reverse order when the instance is closed (either explicitly or implicitly
   at the end of a :keyword:`with` statement). Note that callbacks are *not*
   invoked implicitly when the context stack instance is garbage collected.

   This stack model is used so that context managers that acquire their
   resources in their ``__init__`` method (such as file objects) can be
   handled correctly.

   Since registered callbacks are invoked in the reverse order of
   registration, this ends up behaving as if multiple nested :keyword:`with`
   statements had been used with the registered set of callbacks. This even
   extends to exception handling - if an inner callback suppresses or replaces
   an exception, then outer callbacks will be passed arguments based on that
   updated state.

   This is a relatively low level API that takes care of the details of
   correctly unwinding the stack of exit callbacks. It provides a suitable
   foundation for higher level context managers that manipulate the exit
   stack in application specific ways.

   .. versionadded:: 3.3

   .. method:: enter_context(cm)

      Enters a new context manager and adds its :meth:`~object.__exit__` method to
      the callback stack. The return value is the result of the context
      manager's own :meth:`~object.__enter__` method.

      These context managers may suppress exceptions just as they normally
      would if used directly as part of a :keyword:`with` statement.

      .. versionchanged:: 3.11
         Raises :exc:`TypeError` instead of :exc:`AttributeError` if *cm*
         is not a context manager.

   .. method:: push(exit)

      Adds a context manager's :meth:`~object.__exit__` method to the callback stack.

      As ``__enter__`` is *not* invoked, this method can be used to cover
      part of an :meth:`~object.__enter__` implementation with a context manager's own
      :meth:`~object.__exit__` method.

      If passed an object that is not a context manager, this method assumes
      it is a callback with the same signature as a context manager's
      :meth:`~object.__exit__` method and adds it directly to the callback stack.

      By returning true values, these callbacks can suppress exceptions the
      same way context manager :meth:`~object.__exit__` methods can.

      The passed in object is returned from the function, allowing this
      method to be used as a function decorator.

   .. method:: callback(callback, /, *args, **kwds)

      Accepts an arbitrary callback function and arguments and adds it to
      the callback stack.

      Unlike the other methods, callbacks added this way cannot suppress
      exceptions (as they are never passed the exception details).

      The passed in callback is returned from the function, allowing this
      method to be used as a function decorator.

   .. method:: pop_all()

      Transfers the callback stack to a fresh :class:`ExitStack` instance
      and returns it. No callbacks are invoked by this operation - instead,
      they will now be invoked when the new stack is closed (either
      explicitly or implicitly at the end of a :keyword:`with` statement).

      For example, a group of files can be opened as an "all or nothing"
      operation as follows::

         with ExitStack() as stack:
             files = [stack.enter_context(open(fname)) for fname in filenames]
             # Hold onto the close method, but don't call it yet.
             close_files = stack.pop_all().close
             # If opening any file fails, all previously opened files will be
             # closed automatically. If all files are opened successfully,
             # they will remain open even after the with statement ends.
             # close_files() can then be invoked explicitly to close them all.

   .. method:: close()

      Immediately unwinds the callback stack, invoking callbacks in the
      reverse order of registration. For any context managers and exit
      callbacks registered, the arguments passed in will indicate that no
      exception occurred.

.. class:: AsyncExitStack()

   An :ref:`asynchronous context manager <async-context-managers>`, similar
   to :class:`ExitStack`, that supports combining both synchronous and
   asynchronous context managers, as well as having coroutines for
   cleanup logic.

   The :meth:`~ExitStack.close` method is not implemented; :meth:`aclose` must be used
   instead.

   .. coroutinemethod:: enter_async_context(cm)

      Similar to :meth:`ExitStack.enter_context` but expects an asynchronous context
      manager.

      .. versionchanged:: 3.11
         Raises :exc:`TypeError` instead of :exc:`AttributeError` if *cm*
         is not an asynchronous context manager.

   .. method:: push_async_exit(exit)

      Similar to :meth:`ExitStack.push` but expects either an asynchronous context manager
      or a coroutine function.

   .. method:: push_async_callback(callback, /, *args, **kwds)

      Similar to :meth:`ExitStack.callback` but expects a coroutine function.

   .. coroutinemethod:: aclose()

      Similar to :meth:`ExitStack.close` but properly handles awaitables.

   Continuing the example for :func:`asynccontextmanager`::

      async with AsyncExitStack() as stack:
          connections = [await stack.enter_async_context(get_connection())
              for i in range(5)]
          # All opened connections will automatically be released at the end of
          # the async with statement, even if attempts to open a connection
          # later in the list raise an exception.

   .. versionadded:: 3.7

Examples and Recipes
--------------------

This section describes some examples and recipes for making effective use of
the tools provided by :mod:`contextlib`.


Supporting a variable number of context managers
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The primary use case for :class:`ExitStack` is the one given in the class
documentation: supporting a variable number of context managers and other
cleanup operations in a single :keyword:`with` statement. The variability
may come from the number of context managers needed being driven by user
input (such as opening a user specified collection of files), or from
some of the context managers being optional::

    with ExitStack() as stack:
        for resource in resources:
            stack.enter_context(resource)
        if need_special_resource():
            special = acquire_special_resource()
            stack.callback(release_special_resource, special)
        # Perform operations that use the acquired resources

As shown, :class:`ExitStack` also makes it quite easy to use :keyword:`with`
statements to manage arbitrary resources that don't natively support the
context management protocol.


Catching exceptions from ``__enter__`` methods
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

It is occasionally desirable to catch exceptions from an ``__enter__``
method implementation, *without* inadvertently catching exceptions from
the :keyword:`with` statement body or the context manager's ``__exit__``
method. By using :class:`ExitStack` the steps in the context management
protocol can be separated slightly in order to allow this::

   stack = ExitStack()
   try:
       x = stack.enter_context(cm)
   except Exception:
       # handle __enter__ exception
   else:
       with stack:
           # Handle normal case

Actually needing to do this is likely to indicate that the underlying API
should be providing a direct resource management interface for use with
:keyword:`try`/:keyword:`except`/:keyword:`finally` statements, but not
all APIs are well designed in that regard. When a context manager is the
only resource management API provided, then :class:`ExitStack` can make it
easier to handle various situations that can't be handled directly in a
:keyword:`with` statement.


Cleaning up in an ``__enter__`` implementation
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

As noted in the documentation of :meth:`ExitStack.push`, this
method can be useful in cleaning up an already allocated resource if later
steps in the :meth:`~object.__enter__` implementation fail.

Here's an example of doing this for a context manager that accepts resource
acquisition and release functions, along with an optional validation function,
and maps them to the context management protocol::

   from contextlib import contextmanager, AbstractContextManager, ExitStack

   class ResourceManager(AbstractContextManager):

       def __init__(self, acquire_resource, release_resource, check_resource_ok=None):
           self.acquire_resource = acquire_resource
           self.release_resource = release_resource
           if check_resource_ok is None:
               def check_resource_ok(resource):
                   return True
           self.check_resource_ok = check_resource_ok

       @contextmanager
       def _cleanup_on_error(self):
           with ExitStack() as stack:
               stack.push(self)
               yield
               # The validation check passed and didn't raise an exception
               # Accordingly, we want to keep the resource, and pass it
               # back to our caller
               stack.pop_all()

       def __enter__(self):
           resource = self.acquire_resource()
           with self._cleanup_on_error():
               if not self.check_resource_ok(resource):
                   msg = "Failed validation for {!r}"
                   raise RuntimeError(msg.format(resource))
           return resource

       def __exit__(self, *exc_details):
           # We don't need to duplicate any of our resource release logic
           self.release_resource()


Replacing any use of ``try-finally`` and flag variables
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

A pattern you will sometimes see is a ``try-finally`` statement with a flag
variable to indicate whether or not the body of the ``finally`` clause should
be executed. In its simplest form (that can't already be handled just by
using an ``except`` clause instead), it looks something like this::

   cleanup_needed = True
   try:
       result = perform_operation()
       if result:
           cleanup_needed = False
   finally:
       if cleanup_needed:
           cleanup_resources()

As with any ``try`` statement based code, this can cause problems for
development and review, because the setup code and the cleanup code can end
up being separated by arbitrarily long sections of code.

:class:`ExitStack` makes it possible to instead register a callback for
execution at the end of a ``with`` statement, and then later decide to skip
executing that callback::

   from contextlib import ExitStack

   with ExitStack() as stack:
       stack.callback(cleanup_resources)
       result = perform_operation()
       if result:
           stack.pop_all()

This allows the intended cleanup behaviour to be made explicit up front,
rather than requiring a separate flag variable.

If a particular application uses this pattern a lot, it can be simplified
even further by means of a small helper class::

   from contextlib import ExitStack

   class Callback(ExitStack):
       def __init__(self, callback, /, *args, **kwds):
           super().__init__()
           self.callback(callback, *args, **kwds)

       def cancel(self):
           self.pop_all()

   with Callback(cleanup_resources) as cb:
       result = perform_operation()
       if result:
           cb.cancel()

If the resource cleanup isn't already neatly bundled into a standalone
function, then it is still possible to use the decorator form of
:meth:`ExitStack.callback` to declare the resource cleanup in
advance::

   from contextlib import ExitStack

   with ExitStack() as stack:
       @stack.callback
       def cleanup_resources():
           ...
       result = perform_operation()
       if result:
           stack.pop_all()

Due to the way the decorator protocol works, a callback function
declared this way cannot take any parameters. Instead, any resources to
be released must be accessed as closure variables.


Using a context manager as a function decorator
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

:class:`ContextDecorator` makes it possible to use a context manager in
both an ordinary ``with`` statement and also as a function decorator.

For example, it is sometimes useful to wrap functions or groups of statements
with a logger that can track the time of entry and time of exit.  Rather than
writing both a function decorator and a context manager for the task,
inheriting from :class:`ContextDecorator` provides both capabilities in a
single definition::

    from contextlib import ContextDecorator
    import logging

    logging.basicConfig(level=logging.INFO)

    class track_entry_and_exit(ContextDecorator):
        def __init__(self, name):
            self.name = name

        def __enter__(self):
            logging.info('Entering: %s', self.name)

        def __exit__(self, exc_type, exc, exc_tb):
            logging.info('Exiting: %s', self.name)

Instances of this class can be used as both a context manager::

    with track_entry_and_exit('widget loader'):
        print('Some time consuming activity goes here')
        load_widget()

And also as a function decorator::

    @track_entry_and_exit('widget loader')
    def activity():
        print('Some time consuming activity goes here')
        load_widget()

Note that there is one additional limitation when using context managers
as function decorators: there's no way to access the return value of
:meth:`~object.__enter__`. If that value is needed, then it is still necessary to use
an explicit ``with`` statement.

.. seealso::

   :pep:`343` - The "with" statement
      The specification, background, and examples for the Python :keyword:`with`
      statement.

.. _single-use-reusable-and-reentrant-cms:

Single use, reusable and reentrant context managers
---------------------------------------------------

Most context managers are written in a way that means they can only be
used effectively in a :keyword:`with` statement once. These single use
context managers must be created afresh each time they're used -
attempting to use them a second time will trigger an exception or
otherwise not work correctly.

This common limitation means that it is generally advisable to create
context managers directly in the header of the :keyword:`with` statement
where they are used (as shown in all of the usage examples above).

Files are an example of effectively single use context managers, since
the first :keyword:`with` statement will close the file, preventing any
further IO operations using that file object.

Context managers created using :func:`contextmanager` are also single use
context managers, and will complain about the underlying generator failing
to yield if an attempt is made to use them a second time::

    >>> from contextlib import contextmanager
    >>> @contextmanager
    ... def singleuse():
    ...     print("Before")
    ...     yield
    ...     print("After")
    ...
    >>> cm = singleuse()
    >>> with cm:
    ...     pass
    ...
    Before
    After
    >>> with cm:
    ...     pass
    ...
    Traceback (most recent call last):
        ...
    RuntimeError: generator didn't yield


.. _reentrant-cms:

Reentrant context managers
^^^^^^^^^^^^^^^^^^^^^^^^^^

More sophisticated context managers may be "reentrant". These context
managers can not only be used in multiple :keyword:`with` statements,
but may also be used *inside* a :keyword:`!with` statement that is already
using the same context manager.

:class:`threading.RLock` is an example of a reentrant context manager, as are
:func:`suppress`, :func:`redirect_stdout`, and :func:`chdir`. Here's a very
simple example of reentrant use::

    >>> from contextlib import redirect_stdout
    >>> from io import StringIO
    >>> stream = StringIO()
    >>> write_to_stream = redirect_stdout(stream)
    >>> with write_to_stream:
    ...     print("This is written to the stream rather than stdout")
    ...     with write_to_stream:
    ...         print("This is also written to the stream")
    ...
    >>> print("This is written directly to stdout")
    This is written directly to stdout
    >>> print(stream.getvalue())
    This is written to the stream rather than stdout
    This is also written to the stream

Real world examples of reentrancy are more likely to involve multiple
functions calling each other and hence be far more complicated than this
example.

Note also that being reentrant is *not* the same thing as being thread safe.
:func:`redirect_stdout`, for example, is definitely not thread safe, as it
makes a global modification to the system state by binding :data:`sys.stdout`
to a different stream.


.. _reusable-cms:

Reusable context managers
^^^^^^^^^^^^^^^^^^^^^^^^^

Distinct from both single use and reentrant context managers are "reusable"
context managers (or, to be completely explicit, "reusable, but not
reentrant" context managers, since reentrant context managers are also
reusable). These context managers support being used multiple times, but
will fail (or otherwise not work correctly) if the specific context manager
instance has already been used in a containing with statement.

:class:`threading.Lock` is an example of a reusable, but not reentrant,
context manager (for a reentrant lock, it is necessary to use
:class:`threading.RLock` instead).

Another example of a reusable, but not reentrant, context manager is
:class:`ExitStack`, as it invokes *all* currently registered callbacks
when leaving any with statement, regardless of where those callbacks
were added::

    >>> from contextlib import ExitStack
    >>> stack = ExitStack()
    >>> with stack:
    ...     stack.callback(print, "Callback: from first context")
    ...     print("Leaving first context")
    ...
    Leaving first context
    Callback: from first context
    >>> with stack:
    ...     stack.callback(print, "Callback: from second context")
    ...     print("Leaving second context")
    ...
    Leaving second context
    Callback: from second context
    >>> with stack:
    ...     stack.callback(print, "Callback: from outer context")
    ...     with stack:
    ...         stack.callback(print, "Callback: from inner context")
    ...         print("Leaving inner context")
    ...     print("Leaving outer context")
    ...
    Leaving inner context
    Callback: from inner context
    Callback: from outer context
    Leaving outer context

As the output from the example shows, reusing a single stack object across
multiple with statements works correctly, but attempting to nest them
will cause the stack to be cleared at the end of the innermost with
statement, which is unlikely to be desirable behaviour.

Using separate :class:`ExitStack` instances instead of reusing a single
instance avoids that problem::

    >>> from contextlib import ExitStack
    >>> with ExitStack() as outer_stack:
    ...     outer_stack.callback(print, "Callback: from outer context")
    ...     with ExitStack() as inner_stack:
    ...         inner_stack.callback(print, "Callback: from inner context")
    ...         print("Leaving inner context")
    ...     print("Leaving outer context")
    ...
    Leaving inner context
    Callback: from inner context
    Leaving outer context
    Callback: from outer context


================================================
File: /Doc/library/contextvars.rst
================================================
:mod:`!contextvars` --- Context Variables
=========================================

.. module:: contextvars
   :synopsis: Context Variables

.. sectionauthor:: Yury Selivanov <yury@magic.io>

--------------

This module provides APIs to manage, store, and access context-local
state.  The :class:`~contextvars.ContextVar` class is used to declare
and work with *Context Variables*.  The :func:`~contextvars.copy_context`
function and the :class:`~contextvars.Context` class should be used to
manage the current context in asynchronous frameworks.

Context managers that have state should use Context Variables
instead of :func:`threading.local` to prevent their state from
bleeding to other code unexpectedly, when used in concurrent code.

See also :pep:`567` for additional details.

.. versionadded:: 3.7


Context Variables
-----------------

.. class:: ContextVar(name, [*, default])

   This class is used to declare a new Context Variable, e.g.::

       var: ContextVar[int] = ContextVar('var', default=42)

   The required *name* parameter is used for introspection and debug
   purposes.

   The optional keyword-only *default* parameter is returned by
   :meth:`ContextVar.get` when no value for the variable is found
   in the current context.

   **Important:** Context Variables should be created at the top module
   level and never in closures.  :class:`Context` objects hold strong
   references to context variables which prevents context variables
   from being properly garbage collected.

   .. attribute:: ContextVar.name

      The name of the variable.  This is a read-only property.

      .. versionadded:: 3.7.1

   .. method:: get([default])

      Return a value for the context variable for the current context.

      If there is no value for the variable in the current context,
      the method will:

      * return the value of the *default* argument of the method,
        if provided; or

      * return the default value for the context variable,
        if it was created with one; or

      * raise a :exc:`LookupError`.

   .. method:: set(value)

      Call to set a new value for the context variable in the current
      context.

      The required *value* argument is the new value for the context
      variable.

      Returns a :class:`~contextvars.Token` object that can be used
      to restore the variable to its previous value via the
      :meth:`ContextVar.reset` method.

   .. method:: reset(token)

      Reset the context variable to the value it had before the
      :meth:`ContextVar.set` that created the *token* was used.

      For example::

          var = ContextVar('var')

          token = var.set('new value')
          # code that uses 'var'; var.get() returns 'new value'.
          var.reset(token)

          # After the reset call the var has no value again, so
          # var.get() would raise a LookupError.


.. class:: Token

   *Token* objects are returned by the :meth:`ContextVar.set` method.
   They can be passed to the :meth:`ContextVar.reset` method to revert
   the value of the variable to what it was before the corresponding
   *set*.

   .. attribute:: Token.var

      A read-only property.  Points to the :class:`ContextVar` object
      that created the token.

   .. attribute:: Token.old_value

      A read-only property.  Set to the value the variable had before
      the :meth:`ContextVar.set` method call that created the token.
      It points to :attr:`Token.MISSING` if the variable was not set
      before the call.

   .. attribute:: Token.MISSING

      A marker object used by :attr:`Token.old_value`.


Manual Context Management
-------------------------

.. function:: copy_context()

   Returns a copy of the current :class:`~contextvars.Context` object.

   The following snippet gets a copy of the current context and prints
   all variables and their values that are set in it::

      ctx: Context = copy_context()
      print(list(ctx.items()))

   The function has an *O*\ (1) complexity, i.e. works equally fast for
   contexts with a few context variables and for contexts that have
   a lot of them.


.. class:: Context()

   A mapping of :class:`ContextVars <ContextVar>` to their values.

   ``Context()`` creates an empty context with no values in it.
   To get a copy of the current context use the
   :func:`~contextvars.copy_context` function.

   Each thread has its own effective stack of :class:`!Context` objects.  The
   :term:`current context` is the :class:`!Context` object at the top of the
   current thread's stack.  All :class:`!Context` objects in the stacks are
   considered to be *entered*.

   *Entering* a context, which can be done by calling its :meth:`~Context.run`
   method, makes the context the current context by pushing it onto the top of
   the current thread's context stack.

   *Exiting* from the current context, which can be done by returning from the
   callback passed to the :meth:`~Context.run` method, restores the current
   context to what it was before the context was entered by popping the context
   off the top of the context stack.

   Since each thread has its own context stack, :class:`ContextVar` objects
   behave in a similar fashion to :func:`threading.local` when values are
   assigned in different threads.

   Attempting to enter an already entered context, including contexts entered in
   other threads, raises a :exc:`RuntimeError`.

   After exiting a context, it can later be re-entered (from any thread).

   Any changes to :class:`ContextVar` values via the :meth:`ContextVar.set`
   method are recorded in the current context.  The :meth:`ContextVar.get`
   method returns the value associated with the current context.  Exiting a
   context effectively reverts any changes made to context variables while the
   context was entered (if needed, the values can be restored by re-entering the
   context).

   Context implements the :class:`collections.abc.Mapping` interface.

   .. method:: run(callable, *args, **kwargs)

      Enters the Context, executes ``callable(*args, **kwargs)``, then exits the
      Context.  Returns *callable*'s return value, or propagates an exception if
      one occurred.

      Example:

      .. testcode::

         import contextvars

         var = contextvars.ContextVar('var')
         var.set('spam')
         print(var.get())  # 'spam'

         ctx = contextvars.copy_context()

         def main():
             # 'var' was set to 'spam' before
             # calling 'copy_context()' and 'ctx.run(main)', so:
             print(var.get())  # 'spam'
             print(ctx[var])  # 'spam'

             var.set('ham')

             # Now, after setting 'var' to 'ham':
             print(var.get())  # 'ham'
             print(ctx[var])  # 'ham'

         # Any changes that the 'main' function makes to 'var'
         # will be contained in 'ctx'.
         ctx.run(main)

         # The 'main()' function was run in the 'ctx' context,
         # so changes to 'var' are contained in it:
         print(ctx[var])  # 'ham'

         # However, outside of 'ctx', 'var' is still set to 'spam':
         print(var.get())  # 'spam'

      .. testoutput::
         :hide:

         spam
         spam
         spam
         ham
         ham
         ham
         spam

   .. method:: copy()

      Return a shallow copy of the context object.

   .. describe:: var in context

      Return ``True`` if the *context* has a value for *var* set;
      return ``False`` otherwise.

   .. describe:: context[var]

      Return the value of the *var* :class:`ContextVar` variable.
      If the variable is not set in the context object, a
      :exc:`KeyError` is raised.

   .. method:: get(var, [default])

      Return the value for *var* if *var* has the value in the context
      object.  Return *default* otherwise.  If *default* is not given,
      return ``None``.

   .. describe:: iter(context)

      Return an iterator over the variables stored in the context
      object.

   .. describe:: len(proxy)

      Return the number of variables set in the context object.

   .. method:: keys()

      Return a list of all variables in the context object.

   .. method:: values()

      Return a list of all variables' values in the context object.


   .. method:: items()

      Return a list of 2-tuples containing all variables and their
      values in the context object.


asyncio support
---------------

Context variables are natively supported in :mod:`asyncio` and are
ready to be used without any extra configuration.  For example, here
is a simple echo server, that uses a context variable to make the
address of a remote client available in the Task that handles that
client::

    import asyncio
    import contextvars

    client_addr_var = contextvars.ContextVar('client_addr')

    def render_goodbye():
        # The address of the currently handled client can be accessed
        # without passing it explicitly to this function.

        client_addr = client_addr_var.get()
        return f'Good bye, client @ {client_addr}\r\n'.encode()

    async def handle_request(reader, writer):
        addr = writer.transport.get_extra_info('socket').getpeername()
        client_addr_var.set(addr)

        # In any code that we call is now possible to get
        # client's address by calling 'client_addr_var.get()'.

        while True:
            line = await reader.readline()
            print(line)
            if not line.strip():
                break

        writer.write(b'HTTP/1.1 200 OK\r\n')  # status line
        writer.write(b'\r\n')  # headers
        writer.write(render_goodbye())  # body
        writer.close()

    async def main():
        srv = await asyncio.start_server(
            handle_request, '127.0.0.1', 8081)

        async with srv:
            await srv.serve_forever()

    asyncio.run(main())

    # To test it you can use telnet or curl:
    #     telnet 127.0.0.1 8081
    #     curl 127.0.0.1:8081


================================================
File: /Doc/library/copy.rst
================================================
:mod:`!copy` --- Shallow and deep copy operations
=================================================

.. module:: copy
   :synopsis: Shallow and deep copy operations.

**Source code:** :source:`Lib/copy.py`

--------------

Assignment statements in Python do not copy objects, they create bindings
between a target and an object. For collections that are mutable or contain
mutable items, a copy is sometimes needed so one can change one copy without
changing the other. This module provides generic shallow and deep copy
operations (explained below).


Interface summary:

.. function:: copy(obj)

   Return a shallow copy of *obj*.


.. function:: deepcopy(obj[, memo])

   Return a deep copy of *obj*.


.. function:: replace(obj, /, **changes)

   Creates a new object of the same type as *obj*, replacing fields with values
   from *changes*.

   .. versionadded:: 3.13


.. exception:: Error

   Raised for module specific errors.

.. _shallow_vs_deep_copy:

The difference between shallow and deep copying is only relevant for compound
objects (objects that contain other objects, like lists or class instances):

* A *shallow copy* constructs a new compound object and then (to the extent
  possible) inserts *references* into it to the objects found in the original.

* A *deep copy* constructs a new compound object and then, recursively, inserts
  *copies* into it of the objects found in the original.

Two problems often exist with deep copy operations that don't exist with shallow
copy operations:

* Recursive objects (compound objects that, directly or indirectly, contain a
  reference to themselves) may cause a recursive loop.

* Because deep copy copies everything it may copy too much, such as data
  which is intended to be shared between copies.

The :func:`deepcopy` function avoids these problems by:

* keeping a ``memo`` dictionary of objects already copied during the current
  copying pass; and

* letting user-defined classes override the copying operation or the set of
  components copied.

This module does not copy types like module, method, stack trace, stack frame,
file, socket, window, or any similar types.  It does "copy" functions and
classes (shallow and deeply), by returning the original object unchanged; this
is compatible with the way these are treated by the :mod:`pickle` module.

Shallow copies of dictionaries can be made using :meth:`dict.copy`, and
of lists by assigning a slice of the entire list, for example,
``copied_list = original_list[:]``.

.. index:: pair: module; pickle

Classes can use the same interfaces to control copying that they use to control
pickling.  See the description of module :mod:`pickle` for information on these
methods.  In fact, the :mod:`copy` module uses the registered
pickle functions from the :mod:`copyreg` module.

.. index::
   single: __copy__() (copy protocol)
   single: __deepcopy__() (copy protocol)

.. currentmodule:: None

In order for a class to define its own copy implementation, it can define
special methods :meth:`~object.__copy__` and :meth:`~object.__deepcopy__`.

.. method:: object.__copy__(self)
   :noindexentry:

   Called to implement the shallow copy operation;
   no additional arguments are passed.

.. method:: object.__deepcopy__(self, memo)
   :noindexentry:

   Called to implement the deep copy operation; it is passed one
   argument, the *memo* dictionary.  If the ``__deepcopy__`` implementation needs
   to make a deep copy of a component, it should call the :func:`~copy.deepcopy` function
   with the component as first argument and the *memo* dictionary as second argument.
   The *memo* dictionary should be treated as an opaque object.


.. index::
   single: __replace__() (replace protocol)

Function :func:`!copy.replace` is more limited
than :func:`~copy.copy` and :func:`~copy.deepcopy`,
and only supports named tuples created by :func:`~collections.namedtuple`,
:mod:`dataclasses`, and other classes which define method :meth:`~object.__replace__`.

.. method:: object.__replace__(self, /, **changes)
   :noindexentry:

   This method should create a new object of the same type,
   replacing fields with values from *changes*.


.. seealso::

   Module :mod:`pickle`
      Discussion of the special methods used to support object state retrieval and
      restoration.



================================================
File: /Doc/library/copyreg.rst
================================================
:mod:`!copyreg` --- Register :mod:`!pickle` support functions
=============================================================

.. module:: copyreg
   :synopsis: Register pickle support functions.

**Source code:** :source:`Lib/copyreg.py`

.. index::
   pair: module; pickle
   pair: module; copy

--------------

The :mod:`copyreg` module offers a way to define functions used while pickling
specific objects.  The :mod:`pickle` and :mod:`copy` modules use those functions
when pickling/copying those objects.  The module provides configuration
information about object constructors which are not classes.
Such constructors may be factory functions or class instances.


.. function:: constructor(object)

   Declares *object* to be a valid constructor.  If *object* is not callable (and
   hence not valid as a constructor), raises :exc:`TypeError`.


.. function:: pickle(type, function, constructor_ob=None)

   Declares that *function* should be used as a "reduction" function for objects
   of type *type*.  *function* must return either a string or a tuple
   containing between two and six elements. See the :attr:`~pickle.Pickler.dispatch_table`
   for more details on the interface of *function*.

   The *constructor_ob* parameter is a legacy feature and is now ignored, but if
   passed it must be a callable.

   Note that the :attr:`~pickle.Pickler.dispatch_table` attribute of a pickler
   object or subclass of :class:`pickle.Pickler` can also be used for
   declaring reduction functions.

Example
-------

The example below would like to show how to register a pickle function and how
it will be used:

   >>> import copyreg, copy, pickle
   >>> class C:
   ...     def __init__(self, a):
   ...         self.a = a
   ...
   >>> def pickle_c(c):
   ...     print("pickling a C instance...")
   ...     return C, (c.a,)
   ...
   >>> copyreg.pickle(C, pickle_c)
   >>> c = C(1)
   >>> d = copy.copy(c)  # doctest: +SKIP
   pickling a C instance...
   >>> p = pickle.dumps(c)  # doctest: +SKIP
   pickling a C instance...


================================================
File: /Doc/library/crypt.rst
================================================
:mod:`!crypt` --- Function to check Unix passwords
==================================================

.. module:: crypt
   :synopsis: Removed in 3.13.
   :deprecated:

.. deprecated-removed:: 3.11 3.13

This module is no longer part of the Python standard library.
It was :ref:`removed in Python 3.13 <whatsnew313-pep594>` after
being deprecated in Python 3.11.  The removal was decided in :pep:`594`.

Applications can use the :mod:`hashlib` module from the standard library.
Other possible replacements are third-party libraries from PyPI:
:pypi:`legacycrypt`, :pypi:`bcrypt`, :pypi:`argon2-cffi`, or :pypi:`passlib`.
These are not supported or maintained by the Python core team.

The last version of Python that provided the :mod:`!crypt` module was
