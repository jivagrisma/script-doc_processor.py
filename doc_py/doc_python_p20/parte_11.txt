        return s

You can also use the :meth:`!locate` method to get the absolute
path to the file::

    >>> util.locate()  # doctest: +SKIP
    PosixPath('/home/gustav/example/lib/site-packages/wheel/util.py')

In the case where the metadata file listing files
(``RECORD`` or ``SOURCES.txt``) is missing, :func:`!files` will
return :const:`None`. The caller may wish to wrap calls to
:func:`!files` in `always_iterable
<https://more-itertools.readthedocs.io/en/stable/api.html#more_itertools.always_iterable>`_
or otherwise guard against this condition if the target
distribution is not known to have the metadata present.

.. _requirements:

Distribution requirements
-------------------------

.. function:: requires(distribution_name)

   Return the declared dependency specifiers for the named
   distribution package.

   Raises :exc:`PackageNotFoundError` if the named distribution
   package is not installed in the current Python environment.

To get the full set of requirements for a `Distribution Package <https://packaging.python.org/en/latest/glossary/#term-Distribution-Package>`_,
use the :func:`!requires`
function::

    >>> requires('wheel')  # doctest: +SKIP
    ["pytest (>=3.0.0) ; extra == 'test'", "pytest-cov ; extra == 'test'"]


.. _package-distributions:
.. _import-distribution-package-mapping:

Mapping import to distribution packages
---------------------------------------

.. function:: packages_distributions()

   Return a mapping from the top level module and import package
   names found via :attr:`sys.meta_path` to the names of the distribution
   packages (if any) that provide the corresponding files.

   To allow for namespace packages (which may have members provided by
   multiple distribution packages), each top level import name maps to a
   list of distribution names rather than mapping directly to a single name.

A convenience method to resolve the `Distribution Package <https://packaging.python.org/en/latest/glossary/#term-Distribution-Package>`_
name (or names, in the case of a namespace package)
that provide each importable top-level
Python module or `Import Package <https://packaging.python.org/en/latest/glossary/#term-Import-Package>`_::

    >>> packages_distributions()
    {'importlib_metadata': ['importlib-metadata'], 'yaml': ['PyYAML'], 'jaraco': ['jaraco.classes', 'jaraco.functools'], ...}

Some editable installs, `do not supply top-level names
<https://github.com/pypa/packaging-problems/issues/609>`_, and thus this
function is not reliable with such installs.

.. versionadded:: 3.10

.. _distributions:

Distributions
=============

.. function:: distribution(distribution_name)

   Return a :class:`Distribution` instance describing the named
   distribution package.

   Raises :exc:`PackageNotFoundError` if the named distribution
   package is not installed in the current Python environment.

.. class:: Distribution

   Details of an installed distribution package.

   Note: different :class:`!Distribution` instances do not currently compare
   equal, even if they relate to the same installed distribution and
   accordingly have the same attributes.

While the module level API described above is the most common and convenient usage,
you can get all of that information from the :class:`!Distribution` class.
:class:`!Distribution` is an abstract object that represents the metadata for
a Python `Distribution Package <https://packaging.python.org/en/latest/glossary/#term-Distribution-Package>`_.
You can get the concreate :class:`!Distribution` subclass instance for an installed
distribution package by calling the :func:`distribution` function::

    >>> from importlib.metadata import distribution  # doctest: +SKIP
    >>> dist = distribution('wheel')  # doctest: +SKIP
    >>> type(dist)  # doctest: +SKIP
    <class 'importlib.metadata.PathDistribution'>

Thus, an alternative way to get the version number is through the
:class:`!Distribution` instance::

    >>> dist.version  # doctest: +SKIP
    '0.32.3'

There are all kinds of additional metadata available on :class:`!Distribution`
instances::

    >>> dist.metadata['Requires-Python']  # doctest: +SKIP
    '>=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*'
    >>> dist.metadata['License']  # doctest: +SKIP
    'MIT'

For editable packages, an ``origin`` property may present :pep:`610`
metadata::

    >>> dist.origin.url
    'file:///path/to/wheel-0.32.3.editable-py3-none-any.whl'

The full set of available metadata is not described here.
See the PyPA `Core metadata specification <https://packaging.python.org/en/latest/specifications/core-metadata/#core-metadata>`_ for additional details.

.. versionadded:: 3.13
   The ``.origin`` property was added.

Distribution Discovery
======================

By default, this package provides built-in support for discovery of metadata
for file system and zip file `Distribution Package <https://packaging.python.org/en/latest/glossary/#term-Distribution-Package>`_\s.
This metadata finder search defaults to ``sys.path``, but varies slightly in how it interprets those values from how other import machinery does. In particular:

- ``importlib.metadata`` does not honor :class:`bytes` objects on ``sys.path``.
- ``importlib.metadata`` will incidentally honor :py:class:`pathlib.Path` objects on ``sys.path`` even though such values will be ignored for imports.


Implementing Custom Providers
=============================

``importlib.metadata`` address two API surfaces, one for *consumers*
and another for *providers*. Most users are consumers, consuming
metadata provided by the packages. There are other use-cases, however,
where users wish to expose metadata through some other mechanism,
such as alongside a custom importer. Such a use case calls for a
*custom provider*.

Because `Distribution Package <https://packaging.python.org/en/latest/glossary/#term-Distribution-Package>`_ metadata
is not available through :data:`sys.path` searches, or
package loaders directly,
the metadata for a distribution is found through import
system :ref:`finders <finders-and-loaders>`. To find a distribution package's metadata,
``importlib.metadata`` queries the list of :term:`meta path finders <meta path finder>` on
:data:`sys.meta_path`.

The implementation has hooks integrated into the ``PathFinder``,
serving metadata for distribution packages found on the file system.

The abstract class :py:class:`importlib.abc.MetaPathFinder` defines the
interface expected of finders by Python's import system.
``importlib.metadata`` extends this protocol by looking for an optional
``find_distributions`` callable on the finders from
:data:`sys.meta_path` and presents this extended interface as the
``DistributionFinder`` abstract base class, which defines this abstract
method::

    @abc.abstractmethod
    def find_distributions(context=DistributionFinder.Context()) -> Iterable[Distribution]:
        """Return an iterable of all Distribution instances capable of
        loading the metadata for packages for the indicated ``context``.
        """

The ``DistributionFinder.Context`` object provides ``.path`` and ``.name``
properties indicating the path to search and name to match and may
supply other relevant context sought by the consumer.

In practice, to support finding distribution package
metadata in locations other than the file system, subclass
``Distribution`` and implement the abstract methods. Then from
a custom finder, return instances of this derived ``Distribution`` in the
``find_distributions()`` method.

Example
-------

Imagine a custom finder that loads Python modules from a database::

    class DatabaseImporter(importlib.abc.MetaPathFinder):
        def __init__(self, db):
            self.db = db

        def find_spec(self, fullname, target=None) -> ModuleSpec:
            return self.db.spec_from_name(fullname)

    sys.meta_path.append(DatabaseImporter(connect_db(...)))

That importer now presumably provides importable modules from a
database, but it provides no metadata or entry points. For this
custom importer to provide metadata, it would also need to implement
``DistributionFinder``::

    from importlib.metadata import DistributionFinder

    class DatabaseImporter(DistributionFinder):
        ...

        def find_distributions(self, context=DistributionFinder.Context()):
            query = dict(name=context.name) if context.name else {}
            for dist_record in self.db.query_distributions(query):
                yield DatabaseDistribution(dist_record)

In this way, ``query_distributions`` would return records for
each distribution served by the database matching the query. For
example, if ``requests-1.0`` is in the database, ``find_distributions``
would yield a ``DatabaseDistribution`` for ``Context(name='requests')``
or ``Context(name=None)``.

For the sake of simplicity, this example ignores ``context.path``\. The
``path`` attribute defaults to ``sys.path`` and is the set of import paths to
be considered in the search. A ``DatabaseImporter`` could potentially function
without any concern for a search path. Assuming the importer does no
partitioning, the "path" would be irrelevant. In order to illustrate the
purpose of ``path``, the example would need to illustrate a more complex
``DatabaseImporter`` whose behavior varied depending on
``sys.path``/``PYTHONPATH``. In that case, the ``find_distributions`` should
honor the ``context.path`` and only yield ``Distribution``\ s pertinent to that
path.

``DatabaseDistribution``, then, would look something like::

    class DatabaseDistribution(importlib.metadata.Distribution):
        def __init__(self, record):
            self.record = record

        def read_text(self, filename):
            """
            Read a file like "METADATA" for the current distribution.
            """
            if filename == "METADATA":
                return f"""Name: {self.record.name}
    Version: {self.record.version}
    """
            if filename == "entry_points.txt":
                return "\n".join(
                  f"""[{ep.group}]\n{ep.name}={ep.value}"""
                  for ep in self.record.entry_points)

        def locate_file(self, path):
            raise RuntimeError("This distribution has no file system")

This basic implementation should provide metadata and entry points for
packages served by the ``DatabaseImporter``, assuming that the
``record`` supplies suitable ``.name``, ``.version``, and
``.entry_points`` attributes.

The ``DatabaseDistribution`` may also provide other metadata files, like
``RECORD`` (required for ``Distribution.files``) or override the
implementation of ``Distribution.files``. See the source for more inspiration.


.. _`entry point API`: https://setuptools.readthedocs.io/en/latest/pkg_resources.html#entry-points
.. _`metadata API`: https://setuptools.readthedocs.io/en/latest/pkg_resources.html#metadata-api


================================================
File: /Doc/library/importlib.resources.abc.rst
================================================
:mod:`!importlib.resources.abc` -- Abstract base classes for resources
----------------------------------------------------------------------

.. module:: importlib.resources.abc
    :synopsis: Abstract base classes for resources

**Source code:** :source:`Lib/importlib/resources/abc.py`

--------------

.. versionadded:: 3.11

.. class:: ResourceReader

    *Superseded by TraversableResources*

    An :term:`abstract base class` to provide the ability to read
    *resources*.

    From the perspective of this ABC, a *resource* is a binary
    artifact that is shipped within a package. Typically this is
    something like a data file that lives next to the ``__init__.py``
    file of the package. The purpose of this class is to help abstract
    out the accessing of such data files so that it does not matter if
    the package and its data file(s) are stored e.g. in a zip file
    versus on the file system.

    For any of methods of this class, a *resource* argument is
    expected to be a :term:`path-like object` which represents
    conceptually just a file name. This means that no subdirectory
    paths should be included in the *resource* argument. This is
    because the location of the package the reader is for, acts as the
    "directory". Hence the metaphor for directories and file
    names is packages and resources, respectively. This is also why
    instances of this class are expected to directly correlate to
    a specific package (instead of potentially representing multiple
    packages or a module).

    Loaders that wish to support resource reading are expected to
    provide a method called ``get_resource_reader(fullname)`` which
    returns an object implementing this ABC's interface. If the module
    specified by fullname is not a package, this method should return
    :const:`None`. An object compatible with this ABC should only be
    returned when the specified module is a package.

    .. deprecated:: 3.12
       Use :class:`importlib.resources.abc.TraversableResources` instead.

    .. abstractmethod:: open_resource(resource)

        Returns an opened, :term:`file-like object` for binary reading
        of the *resource*.

        If the resource cannot be found, :exc:`FileNotFoundError` is
        raised.

    .. abstractmethod:: resource_path(resource)

        Returns the file system path to the *resource*.

        If the resource does not concretely exist on the file system,
        raise :exc:`FileNotFoundError`.

    .. abstractmethod:: is_resource(name)

        Returns ``True`` if the named *name* is considered a resource.
        :exc:`FileNotFoundError` is raised if *name* does not exist.

    .. abstractmethod:: contents()

        Returns an :term:`iterable` of strings over the contents of
        the package. Do note that it is not required that all names
        returned by the iterator be actual resources, e.g. it is
        acceptable to return names for which :meth:`is_resource` would
        be false.

        Allowing non-resource names to be returned is to allow for
        situations where how a package and its resources are stored
        are known a priori and the non-resource names would be useful.
        For instance, returning subdirectory names is allowed so that
        when it is known that the package and resources are stored on
        the file system then those subdirectory names can be used
        directly.

        The abstract method returns an iterable of no items.


.. class:: Traversable

    An object with a subset of :class:`pathlib.Path` methods suitable for
    traversing directories and opening files.

    For a representation of the object on the file-system, use
    :meth:`importlib.resources.as_file`.

    .. attribute:: name

       Abstract. The base name of this object without any parent references.

    .. abstractmethod:: iterdir()

       Yield Traversable objects in self.

    .. abstractmethod:: is_dir()

       Return ``True`` if self is a directory.

    .. abstractmethod:: is_file()

       Return ``True`` if self is a file.

    .. abstractmethod:: joinpath(*pathsegments)

       Traverse directories according to *pathsegments* and return
       the result as :class:`!Traversable`.

       Each *pathsegments* argument may contain multiple names separated by
       forward slashes (``/``, ``posixpath.sep`` ).
       For example, the following are equivalent::

           files.joinpath('subdir', 'subsuddir', 'file.txt')
           files.joinpath('subdir/subsuddir/file.txt')

       Note that some :class:`!Traversable` implementations
       might not be updated to the latest version of the protocol.
       For compatibility with such implementations, provide a single argument
       without path separators to each call to ``joinpath``. For example::

           files.joinpath('subdir').joinpath('subsubdir').joinpath('file.txt')

       .. versionchanged:: 3.11

          ``joinpath`` accepts multiple *pathsegments*, and these segments
          may contain forward slashes as path separators.
          Previously, only a single *child* argument was accepted.

    .. abstractmethod:: __truediv__(child)

       Return Traversable child in self.
       Equivalent to ``joinpath(child)``.

    .. abstractmethod:: open(mode='r', *args, **kwargs)

       *mode* may be 'r' or 'rb' to open as text or binary. Return a handle
       suitable for reading (same as :attr:`pathlib.Path.open`).

       When opening as text, accepts encoding parameters such as those
       accepted by :class:`io.TextIOWrapper`.

    .. method:: read_bytes()

       Read contents of self as bytes.

    .. method:: read_text(encoding=None)

       Read contents of self as text.


.. class:: TraversableResources

    An abstract base class for resource readers capable of serving
    the :meth:`importlib.resources.files` interface. Subclasses
    :class:`ResourceReader` and provides
    concrete implementations of the :class:`!ResourceReader`'s
    abstract methods. Therefore, any loader supplying
    :class:`!TraversableResources` also supplies :class:`!ResourceReader`.

    Loaders that wish to support resource reading are expected to
    implement this interface.

    .. abstractmethod:: files()

       Returns a :class:`importlib.resources.abc.Traversable` object for the loaded
       package.


================================================
File: /Doc/library/importlib.resources.rst
================================================
:mod:`!importlib.resources` -- Package resource reading, opening and access
---------------------------------------------------------------------------

.. module:: importlib.resources
    :synopsis: Package resource reading, opening, and access

**Source code:** :source:`Lib/importlib/resources/__init__.py`

--------------

.. versionadded:: 3.7

This module leverages Python's import system to provide access to *resources*
within *packages*.

"Resources" are file-like resources associated with a module or package in
Python. The resources may be contained directly in a package, within a
subdirectory contained in that package, or adjacent to modules outside a
package. Resources may be text or binary. As a result, Python module sources
(.py) of a package and compilation artifacts (pycache) are technically
de-facto resources of that package. In practice, however, resources are
primarily those non-Python artifacts exposed specifically by the package
author.

Resources can be opened or read in either binary or text mode.

Resources are roughly akin to files inside directories, though it's important
to keep in mind that this is just a metaphor.  Resources and packages **do
not** have to exist as physical files and directories on the file system:
for example, a package and its resources can be imported from a zip file using
:py:mod:`zipimport`.

.. note::

   This module provides functionality similar to `pkg_resources
   <https://setuptools.readthedocs.io/en/latest/pkg_resources.html>`_ `Basic
   Resource Access
   <https://setuptools.readthedocs.io/en/latest/pkg_resources.html#basic-resource-access>`_
   without the performance overhead of that package.  This makes reading
   resources included in packages easier, with more stable and consistent
   semantics.

   The standalone backport of this module provides more information
   on `using importlib.resources
   <https://importlib-resources.readthedocs.io/en/latest/using.html>`_ and
   `migrating from pkg_resources to importlib.resources
   <https://importlib-resources.readthedocs.io/en/latest/migration.html>`_.

:class:`Loaders <importlib.abc.Loader>` that wish to support resource reading should implement a
``get_resource_reader(fullname)`` method as specified by
:class:`importlib.resources.abc.ResourceReader`.

.. class:: Anchor

    Represents an anchor for resources, either a :class:`module object
    <types.ModuleType>` or a module name as a string. Defined as
    ``Union[str, ModuleType]``.

.. function:: files(anchor: Optional[Anchor] = None)

    Returns a :class:`~importlib.resources.abc.Traversable` object
    representing the resource container (think directory) and its resources
    (think files). A Traversable may contain other containers (think
    subdirectories).

    *anchor* is an optional :class:`Anchor`. If the anchor is a
    package, resources are resolved from that package. If a module,
    resources are resolved adjacent to that module (in the same package
    or the package root). If the anchor is omitted, the caller's module
    is used.

    .. versionadded:: 3.9

    .. versionchanged:: 3.12
       *package* parameter was renamed to *anchor*. *anchor* can now
       be a non-package module and if omitted will default to the caller's
       module. *package* is still accepted for compatibility but will raise
       a :exc:`DeprecationWarning`. Consider passing the anchor positionally or
       using ``importlib_resources >= 5.10`` for a compatible interface
       on older Pythons.

.. function:: as_file(traversable)

    Given a :class:`~importlib.resources.abc.Traversable` object representing
    a file or directory, typically from :func:`importlib.resources.files`,
    return a context manager for use in a :keyword:`with` statement.
    The context manager provides a :class:`pathlib.Path` object.

    Exiting the context manager cleans up any temporary file or directory
    created when the resource was extracted from e.g. a zip file.

    Use ``as_file`` when the Traversable methods
    (``read_text``, etc) are insufficient and an actual file or directory on
    the file system is required.

    .. versionadded:: 3.9

    .. versionchanged:: 3.12
       Added support for *traversable* representing a directory.


.. _importlib_resources_functional:

Functional API
^^^^^^^^^^^^^^

A set of simplified, backwards-compatible helpers is available.
These allow common operations in a single function call.

For all the following functions:

- *anchor* is an :class:`~importlib.resources.Anchor`,
  as in :func:`~importlib.resources.files`.
  Unlike in ``files``, it may not be omitted.

- *path_names* are components of a resource's path name, relative to
  the anchor.
  For example, to get the text of resource named ``info.txt``, use::

      importlib.resources.read_text(my_module, "info.txt")

  Like :meth:`Traversable.joinpath <importlib.resources.abc.Traversable>`,
  The individual components should use forward slashes (``/``)
  as path separators.
  For example, the following are equivalent::

      importlib.resources.read_binary(my_module, "pics/painting.png")
      importlib.resources.read_binary(my_module, "pics", "painting.png")

  For backward compatibility reasons, functions that read text require
  an explicit *encoding* argument if multiple *path_names* are given.
  For example, to get the text of ``info/chapter1.txt``, use::

      importlib.resources.read_text(my_module, "info", "chapter1.txt",
                                    encoding='utf-8')

.. function:: open_binary(anchor, *path_names)

    Open the named resource for binary reading.

    See :ref:`the introduction <importlib_resources_functional>` for
    details on *anchor* and *path_names*.

    This function returns a :class:`~typing.BinaryIO` object,
    that is, a binary stream open for reading.

    This function is roughly equivalent to::

        files(anchor).joinpath(*path_names).open('rb')

    .. versionchanged:: 3.13
        Multiple *path_names* are accepted.


.. function:: open_text(anchor, *path_names, encoding='utf-8', errors='strict')

    Open the named resource for text reading.
    By default, the contents are read as strict UTF-8.

    See :ref:`the introduction <importlib_resources_functional>` for
    details on *anchor* and *path_names*.
    *encoding* and *errors* have the same meaning as in built-in :func:`open`.

    For backward compatibility reasons, the *encoding* argument must be given
    explicitly if there are multiple *path_names*.
    This limitation is scheduled to be removed in Python 3.15.

    This function returns a :class:`~typing.TextIO` object,
    that is, a text stream open for reading.

    This function is roughly equivalent to::

          files(anchor).joinpath(*path_names).open('r', encoding=encoding)

    .. versionchanged:: 3.13
        Multiple *path_names* are accepted.
        *encoding* and *errors* must be given as keyword arguments.


.. function:: read_binary(anchor, *path_names)

    Read and return the contents of the named resource as :class:`bytes`.

    See :ref:`the introduction <importlib_resources_functional>` for
    details on *anchor* and *path_names*.

    This function is roughly equivalent to::

          files(anchor).joinpath(*path_names).read_bytes()

    .. versionchanged:: 3.13
        Multiple *path_names* are accepted.


.. function:: read_text(anchor, *path_names, encoding='utf-8', errors='strict')

    Read and return the contents of the named resource as :class:`str`.
    By default, the contents are read as strict UTF-8.

    See :ref:`the introduction <importlib_resources_functional>` for
    details on *anchor* and *path_names*.
    *encoding* and *errors* have the same meaning as in built-in :func:`open`.

    For backward compatibility reasons, the *encoding* argument must be given
    explicitly if there are multiple *path_names*.
    This limitation is scheduled to be removed in Python 3.15.

    This function is roughly equivalent to::

          files(anchor).joinpath(*path_names).read_text(encoding=encoding)

    .. versionchanged:: 3.13
        Multiple *path_names* are accepted.
        *encoding* and *errors* must be given as keyword arguments.


.. function:: path(anchor, *path_names)

    Provides the path to the *resource* as an actual file system path.  This
    function returns a context manager for use in a :keyword:`with` statement.
    The context manager provides a :class:`pathlib.Path` object.

    Exiting the context manager cleans up any temporary files created, e.g.
    when the resource needs to be extracted from a zip file.

    For example, the :meth:`~pathlib.Path.stat` method requires
    an actual file system path; it can be used like this::

        with importlib.resources.path(anchor, "resource.txt") as fspath:
            result = fspath.stat()

    See :ref:`the introduction <importlib_resources_functional>` for
    details on *anchor* and *path_names*.

    This function is roughly equivalent to::

          as_file(files(anchor).joinpath(*path_names))

    .. versionchanged:: 3.13
        Multiple *path_names* are accepted.
        *encoding* and *errors* must be given as keyword arguments.


.. function:: is_resource(anchor, *path_names)

    Return ``True`` if the named resource exists, otherwise ``False``.
    This function does not consider directories to be resources.

    See :ref:`the introduction <importlib_resources_functional>` for
    details on *anchor* and *path_names*.

    This function is roughly equivalent to::

          files(anchor).joinpath(*path_names).is_file()

    .. versionchanged:: 3.13
        Multiple *path_names* are accepted.


.. function:: contents(anchor, *path_names)

    Return an iterable over the named items within the package or path.
    The iterable returns names of resources (e.g. files) and non-resources
    (e.g. directories) as :class:`str`.
    The iterable does not recurse into subdirectories.

    See :ref:`the introduction <importlib_resources_functional>` for
    details on *anchor* and *path_names*.

    This function is roughly equivalent to::

        for resource in files(anchor).joinpath(*path_names).iterdir():
            yield resource.name

    .. deprecated:: 3.11
        Prefer ``iterdir()`` as above, which offers more control over the
        results and richer functionality.


================================================
File: /Doc/library/index.rst
================================================
.. _library-index:

###############################
  The Python Standard Library
###############################

While :ref:`reference-index` describes the exact syntax and
semantics of the Python language, this library reference manual
describes the standard library that is distributed with Python. It also
describes some of the optional components that are commonly included
in Python distributions.

Python's standard library is very extensive, offering a wide range of
facilities as indicated by the long table of contents listed below. The
library contains built-in modules (written in C) that provide access to
system functionality such as file I/O that would otherwise be
inaccessible to Python programmers, as well as modules written in Python
that provide standardized solutions for many problems that occur in
everyday programming. Some of these modules are explicitly designed to
encourage and enhance the portability of Python programs by abstracting
away platform-specifics into platform-neutral APIs.

The Python installers for the Windows platform usually include
the entire standard library and often also include many additional
components. For Unix-like operating systems Python is normally provided
as a collection of packages, so it may be necessary to use the packaging
tools provided with the operating system to obtain some or all of the
optional components.

In addition to the standard library, there is an active collection of
hundreds of thousands of components (from individual programs and modules to
packages and entire application development frameworks), available from
the `Python Package Index <https://pypi.org>`_.

.. We don't use :numbered: option for the TOC below as it enforces
   numbered sections for the entire stdlib docs.  If desired,
   :numbered: can be enabled on a per-module basis.
.. toctree::
   :maxdepth: 2

   intro.rst
   functions.rst
   constants.rst
   stdtypes.rst
   exceptions.rst

   text.rst
   binary.rst
   datatypes.rst
   numeric.rst
   functional.rst
   filesys.rst
   persistence.rst
   archiving.rst
   fileformats.rst
   crypto.rst
   allos.rst
   cmdlinelibs.rst
   concurrency.rst
   ipc.rst
   netdata.rst
   markup.rst
   internet.rst
   mm.rst
   i18n.rst
   frameworks.rst
   tk.rst
   development.rst
   debug.rst
   distribution.rst
   python.rst
   custominterp.rst
   modules.rst
   language.rst
   windows.rst
   unix.rst
   cmdline.rst
   superseded.rst
   removed.rst
   security_warnings.rst


================================================
File: /Doc/library/internet.rst
================================================
.. _internet:

******************************
Internet Protocols and Support
******************************

.. index::
   single: WWW
   single: Internet
   single: World Wide Web

.. index:: pair: module; socket

The modules described in this chapter implement internet protocols and  support
for related technology.  They are all implemented in Python. Most of these
modules require the presence of the system-dependent module :mod:`socket`, which
is currently supported on most popular platforms.  Here is an overview:


.. toctree::

   webbrowser.rst
   wsgiref.rst
   urllib.rst
   urllib.request.rst
   urllib.parse.rst
   urllib.error.rst
   urllib.robotparser.rst
   http.rst
   http.client.rst
   ftplib.rst
   poplib.rst
   imaplib.rst
   smtplib.rst
   uuid.rst
   socketserver.rst
   http.server.rst
   http.cookies.rst
   http.cookiejar.rst
   xmlrpc.rst
   xmlrpc.client.rst
   xmlrpc.server.rst
   ipaddress.rst


================================================
File: /Doc/library/intro.rst
================================================
.. _library-intro:

************
Introduction
************

The "Python library" contains several different kinds of components.

It contains data types that would normally be considered part of the "core" of a
language, such as numbers and lists.  For these types, the Python language core
defines the form of literals and places some constraints on their semantics, but
does not fully define the semantics.  (On the other hand, the language core does
define syntactic properties like the spelling and priorities of operators.)

The library also contains built-in functions and exceptions --- objects that can
be used by all Python code without the need of an :keyword:`import` statement.
Some of these are defined by the core language, but many are not essential for
the core semantics and are only described here.

The bulk of the library, however, consists of a collection of modules. There are
many ways to dissect this collection.  Some modules are written in C and built
in to the Python interpreter; others are written in Python and imported in
source form.  Some modules provide interfaces that are highly specific to
Python, like printing a stack trace; some provide interfaces that are specific
to particular operating systems, such as access to specific hardware; others
provide interfaces that are specific to a particular application domain, like
the World Wide Web. Some modules are available in all versions and ports of
Python; others are only available when the underlying system supports or
requires them; yet others are available only when a particular configuration
option was chosen at the time when Python was compiled and installed.

This manual is organized "from the inside out:" it first describes the built-in
functions, data types and exceptions, and finally the modules, grouped in
chapters of related modules.

This means that if you start reading this manual from the start, and skip to the
next chapter when you get bored, you will get a reasonable overview of the
available modules and application areas that are supported by the Python
library.  Of course, you don't *have* to read it like a novel --- you can also
browse the table of contents (in front of the manual), or look for a specific
function, module or term in the index (in the back).  And finally, if you enjoy
learning about random subjects, you choose a random page number (see module
:mod:`random`) and read a section or two.  Regardless of the order in which you
read the sections of this manual, it helps to start with chapter
:ref:`built-in-funcs`, as the remainder of the manual assumes familiarity with
this material.

Let the show begin!


.. _availability:

Notes on availability
=====================

* An "Availability: Unix" note means that this function is commonly found on
  Unix systems.  It does not make any claims about its existence on a specific
  operating system.

* If not separately noted, all functions that claim "Availability: Unix" are
  supported on macOS, iOS and Android, all of which build on a Unix core.

* If an availability note contains both a minimum Kernel version and a minimum
  libc version, then both conditions must hold. For example a feature with note
  *Availability: Linux >= 3.17 with glibc >= 2.27* requires both Linux 3.17 or
  newer and glibc 2.27 or newer.

.. _wasm-availability:

WebAssembly platforms
---------------------

The `WebAssembly`_ platforms ``wasm32-emscripten`` (`Emscripten`_) and
``wasm32-wasi`` (`WASI`_) provide a subset of POSIX APIs. WebAssembly runtimes
and browsers are sandboxed and have limited access to the host and external
resources. Any Python standard library module that uses processes, threading,
networking, signals, or other forms of inter-process communication (IPC), is
either not available or may not work as on other Unix-like systems. File I/O,
file system, and Unix permission-related functions are restricted, too.
Emscripten does not permit blocking I/O. Other blocking operations like
:func:`~time.sleep` block the browser event loop.

The properties and behavior of Python on WebAssembly platforms depend on the
`Emscripten`_-SDK or `WASI`_-SDK version, WASM runtimes (browser, NodeJS,
`wasmtime`_), and Python build time flags. WebAssembly, Emscripten, and WASI
are evolving standards; some features like networking may be
supported in the future.

For Python in the browser, users should consider `Pyodide`_ or `PyScript`_.
PyScript is built on top of Pyodide, which itself is built on top of
CPython and Emscripten. Pyodide provides access to browsers' JavaScript and
DOM APIs as well as limited networking capabilities with JavaScript's
``XMLHttpRequest`` and ``Fetch`` APIs.

* Process-related APIs are not available or always fail with an error. That
  includes APIs that spawn new processes (:func:`~os.fork`,
  :func:`~os.execve`), wait for processes (:func:`~os.waitpid`), send signals
  (:func:`~os.kill`), or otherwise interact with processes. The
  :mod:`subprocess` is importable but does not work.

* The :mod:`socket` module is available, but is limited and behaves
  differently from other platforms. On Emscripten, sockets are always
  non-blocking and require additional JavaScript code and helpers on the
  server to proxy TCP through WebSockets; see `Emscripten Networking`_
  for more information. WASI snapshot preview 1 only permits sockets from an
  existing file descriptor.

* Some functions are stubs that either don't do anything and always return
  hardcoded values.

* Functions related to file descriptors, file permissions, file ownership, and
  links are limited and don't support some operations. For example, WASI does
  not permit symlinks with absolute file names.

.. _WebAssembly: https://webassembly.org/
.. _Emscripten: https://emscripten.org/
.. _Emscripten Networking: https://emscripten.org/docs/porting/networking.html
.. _WASI: https://wasi.dev/
.. _wasmtime: https://wasmtime.dev/
.. _Pyodide: https://pyodide.org/
.. _PyScript: https://pyscript.net/

.. _mobile-availability:
.. _iOS-availability:

Mobile platforms
----------------

Android and iOS are, in most respects, POSIX operating systems. File I/O, socket handling,
and threading all behave as they would on any POSIX operating system. However,
there are several major differences:

* Mobile platforms can only use Python in "embedded" mode. There is no Python
  REPL, and no ability to use separate executables such as :program:`python` or
  :program:`pip`. To add Python code to your mobile app, you must use
  the :ref:`Python embedding API <embedding>`. For more details, see
  :ref:`using-android` and :ref:`using-ios`.

* Subprocesses:

  * On Android, creating subprocesses is possible but `officially unsupported
    <https://issuetracker.google.com/issues/128554619#comment4>`__.
    In particular, Android does not support any part of the System V IPC API,
    so :mod:`multiprocessing` is not available.

  * An iOS app cannot use any form of subprocessing, multiprocessing, or
    inter-process communication. If an iOS app attempts to create a subprocess,
    the process creating the subprocess will either lock up, or crash. An iOS app
    has no visibility of other applications that are running, nor any ability to
    communicate with other running applications, outside of the iOS-specific APIs
    that exist for this purpose.

* Mobile apps have limited access to modify system resources (such as the system
  clock). These resources will often be *readable*, but attempts to modify
  those resources will usually fail.

* Console input and output:

  * On Android, the native ``stdout`` and ``stderr`` are not connected to
    anything, so Python installs its own streams which redirect messages to the
    system log. These can be seen under the tags ``python.stdout`` and
    ``python.stderr`` respectively.

  * iOS apps have a limited concept of console output. ``stdout`` and
    ``stderr`` *exist*, and content written to ``stdout`` and ``stderr`` will be
    visible in logs when running in Xcode, but this content *won't* be recorded
    in the system log. If a user who has installed your app provides their app
    logs as a diagnostic aid, they will not include any detail written to
    ``stdout`` or ``stderr``.

  * Mobile apps have no usable ``stdin`` at all. While apps can display an on-screen
    keyboard, this is a software feature, not something that is attached to
    ``stdin``.

    As a result, Python modules that involve console manipulation (such as
    :mod:`curses` and :mod:`readline`) are not available on mobile platforms.


================================================
File: /Doc/library/io.rst
================================================
:mod:`!io` --- Core tools for working with streams
==================================================

.. module:: io
   :synopsis: Core tools for working with streams.

.. moduleauthor:: Guido van Rossum <guido@python.org>
.. moduleauthor:: Mike Verdone <mike.verdone@gmail.com>
.. moduleauthor:: Mark Russell <mark.russell@zen.co.uk>
.. moduleauthor:: Antoine Pitrou <solipsis@pitrou.net>
.. moduleauthor:: Amaury Forgeot d'Arc <amauryfa@gmail.com>
.. moduleauthor:: Benjamin Peterson <benjamin@python.org>
.. sectionauthor:: Benjamin Peterson <benjamin@python.org>

**Source code:** :source:`Lib/io.py`

--------------

.. _io-overview:

Overview
--------

.. index::
   single: file object; io module

The :mod:`io` module provides Python's main facilities for dealing with various
types of I/O.  There are three main types of I/O: *text I/O*, *binary I/O*
and *raw I/O*.  These are generic categories, and various backing stores can
be used for each of them.  A concrete object belonging to any of these
categories is called a :term:`file object`.  Other common terms are *stream*
and *file-like object*.

Independent of its category, each concrete stream object will also have
various capabilities: it can be read-only, write-only, or read-write. It can
also allow arbitrary random access (seeking forwards or backwards to any
location), or only sequential access (for example in the case of a socket or
pipe).

All streams are careful about the type of data you give to them.  For example
giving a :class:`str` object to the :meth:`!write` method of a binary stream
will raise a :exc:`TypeError`.  So will giving a :class:`bytes` object to the
:meth:`!write` method of a text stream.

.. versionchanged:: 3.3
   Operations that used to raise :exc:`IOError` now raise :exc:`OSError`, since
   :exc:`IOError` is now an alias of :exc:`OSError`.


Text I/O
^^^^^^^^

Text I/O expects and produces :class:`str` objects.  This means that whenever
the backing store is natively made of bytes (such as in the case of a file),
encoding and decoding of data is made transparently as well as optional
translation of platform-specific newline characters.

The easiest way to create a text stream is with :meth:`open`, optionally
specifying an encoding::

   f = open("myfile.txt", "r", encoding="utf-8")

In-memory text streams are also available as :class:`StringIO` objects::

   f = io.StringIO("some initial text data")

.. note::

   When working with a non-blocking stream, be aware that read operations on text I/O objects
   might raise a :exc:`BlockingIOError` if the stream cannot perform the operation
   immediately.

The text stream API is described in detail in the documentation of
:class:`TextIOBase`.


Binary I/O
^^^^^^^^^^

Binary I/O (also called *buffered I/O*) expects
:term:`bytes-like objects <bytes-like object>` and produces :class:`bytes`
objects.  No encoding, decoding, or newline translation is performed.  This
category of streams can be used for all kinds of non-text data, and also when
manual control over the handling of text data is desired.

The easiest way to create a binary stream is with :meth:`open` with ``'b'`` in
the mode string::

   f = open("myfile.jpg", "rb")

In-memory binary streams are also available as :class:`BytesIO` objects::

   f = io.BytesIO(b"some initial binary data: \x00\x01")

The binary stream API is described in detail in the docs of
:class:`BufferedIOBase`.

Other library modules may provide additional ways to create text or binary
streams.  See :meth:`socket.socket.makefile` for example.


Raw I/O
^^^^^^^

Raw I/O (also called *unbuffered I/O*) is generally used as a low-level
building-block for binary and text streams; it is rarely useful to directly
manipulate a raw stream from user code.  Nevertheless, you can create a raw
stream by opening a file in binary mode with buffering disabled::

   f = open("myfile.jpg", "rb", buffering=0)

The raw stream API is described in detail in the docs of :class:`RawIOBase`.


.. _io-text-encoding:

Text Encoding
-------------

The default encoding of :class:`TextIOWrapper` and :func:`open` is
locale-specific (:func:`locale.getencoding`).

However, many developers forget to specify the encoding when opening text files
encoded in UTF-8 (e.g. JSON, TOML, Markdown, etc...) since most Unix
platforms use UTF-8 locale by default. This causes bugs because the locale
encoding is not UTF-8 for most Windows users. For example::

   # May not work on Windows when non-ASCII characters in the file.
   with open("README.md") as f:
       long_description = f.read()

Accordingly, it is highly recommended that you specify the encoding
explicitly when opening text files. If you want to use UTF-8, pass
``encoding="utf-8"``. To use the current locale encoding,
``encoding="locale"`` is supported since Python 3.10.

.. seealso::

   :ref:`utf8-mode`
      Python UTF-8 Mode can be used to change the default encoding to
      UTF-8 from locale-specific encoding.

   :pep:`686`
      Python 3.15 will make :ref:`utf8-mode` default.

.. _io-encoding-warning:

Opt-in EncodingWarning
^^^^^^^^^^^^^^^^^^^^^^

.. versionadded:: 3.10
   See :pep:`597` for more details.

To find where the default locale encoding is used, you can enable
the :option:`-X warn_default_encoding <-X>` command line option or set the
:envvar:`PYTHONWARNDEFAULTENCODING` environment variable, which will
emit an :exc:`EncodingWarning` when the default encoding is used.

If you are providing an API that uses :func:`open` or
:class:`TextIOWrapper` and passes ``encoding=None`` as a parameter, you
can use :func:`text_encoding` so that callers of the API will emit an
:exc:`EncodingWarning` if they don't pass an ``encoding``. However,
please consider using UTF-8 by default (i.e. ``encoding="utf-8"``) for
new APIs.


High-level Module Interface
---------------------------

.. data:: DEFAULT_BUFFER_SIZE

   An int containing the default buffer size used by the module's buffered I/O
   classes.  :func:`open` uses the file's blksize (as obtained by
   :func:`os.stat`) if possible.


.. function:: open(file, mode='r', buffering=-1, encoding=None, errors=None, newline=None, closefd=True, opener=None)

   This is an alias for the builtin :func:`open` function.

   .. audit-event:: open path,mode,flags io.open

      This function raises an :ref:`auditing event <auditing>` ``open`` with
      arguments *path*, *mode* and *flags*. The *mode* and *flags*
      arguments may have been modified or inferred from the original call.


.. function:: open_code(path)

   Opens the provided file with mode ``'rb'``. This function should be used
   when the intent is to treat the contents as executable code.

   *path* should be a :class:`str` and an absolute path.

   The behavior of this function may be overridden by an earlier call to the
   :c:func:`PyFile_SetOpenCodeHook`. However, assuming that *path* is a
   :class:`str` and an absolute path, ``open_code(path)`` should always behave
   the same as ``open(path, 'rb')``. Overriding the behavior is intended for
   additional validation or preprocessing of the file.

   .. versionadded:: 3.8


.. function:: text_encoding(encoding, stacklevel=2, /)

   This is a helper function for callables that use :func:`open` or
   :class:`TextIOWrapper` and have an ``encoding=None`` parameter.

   This function returns *encoding* if it is not ``None``.
   Otherwise, it returns ``"locale"`` or ``"utf-8"`` depending on
   :ref:`UTF-8 Mode <utf8-mode>`.

   This function emits an :class:`EncodingWarning` if
   :data:`sys.flags.warn_default_encoding <sys.flags>` is true and *encoding*
   is ``None``. *stacklevel* specifies where the warning is emitted.
   For example::

      def read_text(path, encoding=None):
          encoding = io.text_encoding(encoding)  # stacklevel=2
          with open(path, encoding) as f:
              return f.read()

   In this example, an :class:`EncodingWarning` is emitted for the caller of
   ``read_text()``.

   See :ref:`io-text-encoding` for more information.

   .. versionadded:: 3.10

   .. versionchanged:: 3.11
      :func:`text_encoding` returns "utf-8" when UTF-8 mode is enabled and
      *encoding* is ``None``.


.. exception:: BlockingIOError

   This is a compatibility alias for the builtin :exc:`BlockingIOError`
   exception.


.. exception:: UnsupportedOperation

   An exception inheriting :exc:`OSError` and :exc:`ValueError` that is raised
   when an unsupported operation is called on a stream.


.. seealso::

   :mod:`sys`
       contains the standard IO streams: :data:`sys.stdin`, :data:`sys.stdout`,
       and :data:`sys.stderr`.


Class hierarchy
---------------

The implementation of I/O streams is organized as a hierarchy of classes.  First
:term:`abstract base classes <abstract base class>` (ABCs), which are used to
specify the various categories of streams, then concrete classes providing the
standard stream implementations.

.. note::

   The abstract base classes also provide default implementations of some
   methods in order to help implementation of concrete stream classes.  For
   example, :class:`BufferedIOBase` provides unoptimized implementations of
   :meth:`!readinto` and :meth:`!readline`.

At the top of the I/O hierarchy is the abstract base class :class:`IOBase`.  It
defines the basic interface to a stream.  Note, however, that there is no
separation between reading and writing to streams; implementations are allowed
to raise :exc:`UnsupportedOperation` if they do not support a given operation.

The :class:`RawIOBase` ABC extends :class:`IOBase`.  It deals with the reading
and writing of bytes to a stream.  :class:`FileIO` subclasses :class:`RawIOBase`
to provide an interface to files in the machine's file system.

The :class:`BufferedIOBase` ABC extends :class:`IOBase`.  It deals with
buffering on a raw binary stream (:class:`RawIOBase`).  Its subclasses,
:class:`BufferedWriter`, :class:`BufferedReader`, and :class:`BufferedRWPair`
buffer raw binary streams that are writable, readable, and both readable and writable,
respectively. :class:`BufferedRandom` provides a buffered interface to seekable streams.
Another :class:`BufferedIOBase` subclass, :class:`BytesIO`, is a stream of
in-memory bytes.

The :class:`TextIOBase` ABC extends :class:`IOBase`.  It deals with
streams whose bytes represent text, and handles encoding and decoding to and
from strings.  :class:`TextIOWrapper`, which extends :class:`TextIOBase`, is a buffered text
interface to a buffered raw stream (:class:`BufferedIOBase`).  Finally,
:class:`StringIO` is an in-memory stream for text.

Argument names are not part of the specification, and only the arguments of
:func:`open` are intended to be used as keyword arguments.

The following table summarizes the ABCs provided by the :mod:`io` module:

.. tabularcolumns:: |l|l|L|L|

=========================  ==================  ========================  ==================================================
ABC                        Inherits            Stub Methods              Mixin Methods and Properties
=========================  ==================  ========================  ==================================================
:class:`IOBase`                                ``fileno``, ``seek``,     ``close``, ``closed``, ``__enter__``,
                                               and ``truncate``          ``__exit__``, ``flush``, ``isatty``, ``__iter__``,
                                                                         ``__next__``, ``readable``, ``readline``,
                                                                         ``readlines``, ``seekable``, ``tell``,
                                                                         ``writable``, and ``writelines``
:class:`RawIOBase`         :class:`IOBase`     ``readinto`` and          Inherited :class:`IOBase` methods, ``read``,
                                               ``write``                 and ``readall``
:class:`BufferedIOBase`    :class:`IOBase`     ``detach``, ``read``,     Inherited :class:`IOBase` methods, ``readinto``,
                                               ``read1``, and ``write``  and ``readinto1``
:class:`TextIOBase`        :class:`IOBase`     ``detach``, ``read``,     Inherited :class:`IOBase` methods, ``encoding``,
                                               ``readline``, and         ``errors``, and ``newlines``
                                               ``write``
=========================  ==================  ========================  ==================================================


I/O Base Classes
^^^^^^^^^^^^^^^^

.. class:: IOBase

   The abstract base class for all I/O classes.

   This class provides empty abstract implementations for many methods
   that derived classes can override selectively; the default
   implementations represent a file that cannot be read, written or
   seeked.

   Even though :class:`IOBase` does not declare :meth:`!read`
   or :meth:`!write` because their signatures will vary, implementations and
   clients should consider those methods part of the interface.  Also,
   implementations may raise a :exc:`ValueError` (or :exc:`UnsupportedOperation`)
   when operations they do not support are called.

   The basic type used for binary data read from or written to a file is
   :class:`bytes`.  Other :term:`bytes-like objects <bytes-like object>` are
   accepted as method arguments too.  Text I/O classes work with :class:`str` data.

   Note that calling any method (even inquiries) on a closed stream is
   undefined.  Implementations may raise :exc:`ValueError` in this case.

   :class:`IOBase` (and its subclasses) supports the iterator protocol, meaning
   that an :class:`IOBase` object can be iterated over yielding the lines in a
   stream.  Lines are defined slightly differently depending on whether the
   stream is a binary stream (yielding bytes), or a text stream (yielding
   character strings).  See :meth:`~IOBase.readline` below.

   :class:`IOBase` is also a context manager and therefore supports the
   :keyword:`with` statement.  In this example, *file* is closed after the
   :keyword:`!with` statement's suite is finished---even if an exception occurs::

      with open('spam.txt', 'w') as file:
          file.write('Spam and eggs!')

   :class:`IOBase` provides these data attributes and methods:

   .. method:: close()

      Flush and close this stream. This method has no effect if the file is
      already closed. Once the file is closed, any operation on the file
      (e.g. reading or writing) will raise a :exc:`ValueError`.

      As a convenience, it is allowed to call this method more than once;
      only the first call, however, will have an effect.

   .. attribute:: closed

      ``True`` if the stream is closed.

   .. method:: fileno()

      Return the underlying file descriptor (an integer) of the stream if it
      exists.  An :exc:`OSError` is raised if the IO object does not use a file
      descriptor.

   .. method:: flush()

      Flush the write buffers of the stream if applicable.  This does nothing
      for read-only and non-blocking streams.

   .. method:: isatty()

      Return ``True`` if the stream is interactive (i.e., connected to
      a terminal/tty device).

   .. method:: readable()

      Return ``True`` if the stream can be read from.
      If ``False``, :meth:`!read` will raise :exc:`OSError`.

   .. method:: readline(size=-1, /)

      Read and return one line from the stream.  If *size* is specified, at
      most *size* bytes will be read.

      The line terminator is always ``b'\n'`` for binary files; for text files,
      the *newline* argument to :func:`open` can be used to select the line
      terminator(s) recognized.

   .. method:: readlines(hint=-1, /)

      Read and return a list of lines from the stream.  *hint* can be specified
      to control the number of lines read: no more lines will be read if the
      total size (in bytes/characters) of all lines so far exceeds *hint*.

      *hint* values of ``0`` or less, as well as ``None``, are treated as no
      hint.

      Note that it's already possible to iterate on file objects using ``for
      line in file: ...`` without calling :meth:`!file.readlines`.

   .. method:: seek(offset, whence=os.SEEK_SET, /)

      Change the stream position to the given byte *offset*,
      interpreted relative to the position indicated by *whence*,
      and return the new absolute position.
      Values for *whence* are:

      * :data:`os.SEEK_SET` or ``0`` -- start of the stream (the default);
        *offset* should be zero or positive
      * :data:`os.SEEK_CUR` or ``1`` -- current stream position;
        *offset* may be negative
      * :data:`os.SEEK_END` or ``2`` -- end of the stream;
        *offset* is usually negative

      .. versionadded:: 3.1
         The :data:`!SEEK_*` constants.

      .. versionadded:: 3.3
         Some operating systems could support additional values, like
         :const:`os.SEEK_HOLE` or :const:`os.SEEK_DATA`. The valid values
         for a file could depend on it being open in text or binary mode.

   .. method:: seekable()

      Return ``True`` if the stream supports random access.  If ``False``,
      :meth:`seek`, :meth:`tell` and :meth:`truncate` will raise :exc:`OSError`.

   .. method:: tell()

      Return the current stream position.

   .. method:: truncate(size=None, /)

      Resize the stream to the given *size* in bytes (or the current position
      if *size* is not specified).  The current stream position isn't changed.
      This resizing can extend or reduce the current file size.  In case of
      extension, the contents of the new file area depend on the platform
      (on most systems, additional bytes are zero-filled).  The new file size
      is returned.

      .. versionchanged:: 3.5
         Windows will now zero-fill files when extending.

   .. method:: writable()

      Return ``True`` if the stream supports writing.  If ``False``,
      :meth:`!write` and :meth:`truncate` will raise :exc:`OSError`.

   .. method:: writelines(lines, /)

      Write a list of lines to the stream.  Line separators are not added, so it
      is usual for each of the lines provided to have a line separator at the
      end.

   .. method:: __del__()

      Prepare for object destruction. :class:`IOBase` provides a default
      implementation of this method that calls the instance's
      :meth:`~IOBase.close` method.


.. class:: RawIOBase

   Base class for raw binary streams.  It inherits from :class:`IOBase`.

   Raw binary streams typically provide low-level access to an underlying OS
   device or API, and do not try to encapsulate it in high-level primitives
   (this functionality is done at a higher-level in buffered binary streams and text streams, described later
   in this page).

   :class:`RawIOBase` provides these methods in addition to those from
   :class:`IOBase`:

   .. method:: read(size=-1, /)

      Read up to *size* bytes from the object and return them.  As a convenience,
      if *size* is unspecified or -1, all bytes until EOF are returned.
      Otherwise, only one system call is ever made.  Fewer than *size* bytes may
      be returned if the operating system call returns fewer than *size* bytes.

      If 0 bytes are returned, and *size* was not 0, this indicates end of file.
      If the object is in non-blocking mode and no bytes are available,
      ``None`` is returned.

      The default implementation defers to :meth:`readall` and
      :meth:`readinto`.

   .. method:: readall()

      Read and return all the bytes from the stream until EOF, using multiple
      calls to the stream if necessary.

   .. method:: readinto(b, /)

      Read bytes into a pre-allocated, writable
      :term:`bytes-like object` *b*, and return the
      number of bytes read.  For example, *b* might be a :class:`bytearray`.
      If the object is in non-blocking mode and no bytes
      are available, ``None`` is returned.

   .. method:: write(b, /)

      Write the given :term:`bytes-like object`, *b*, to the
      underlying raw stream, and return the number of
      bytes written.  This can be less than the length of *b* in
      bytes, depending on specifics of the underlying raw
      stream, and especially if it is in non-blocking mode.  ``None`` is
      returned if the raw stream is set not to block and no single byte could
      be readily written to it.  The caller may release or mutate *b* after
      this method returns, so the implementation should only access *b*
      during the method call.


.. class:: BufferedIOBase

   Base class for binary streams that support some kind of buffering.
   It inherits from :class:`IOBase`.

   The main difference with :class:`RawIOBase` is that methods :meth:`read`,
   :meth:`readinto` and :meth:`write` will try (respectively) to read as much
   input as requested or to consume all given output, at the expense of
   making perhaps more than one system call.

   In addition, those methods can raise :exc:`BlockingIOError` if the
   underlying raw stream is in non-blocking mode and cannot take or give
   enough data; unlike their :class:`RawIOBase` counterparts, they will
   never return ``None``.

   Besides, the :meth:`read` method does not have a default
   implementation that defers to :meth:`readinto`.

   A typical :class:`BufferedIOBase` implementation should not inherit from a
   :class:`RawIOBase` implementation, but wrap one, like
   :class:`BufferedWriter` and :class:`BufferedReader` do.

   :class:`BufferedIOBase` provides or overrides these data attributes and
   methods in addition to those from :class:`IOBase`:

   .. attribute:: raw

      The underlying raw stream (a :class:`RawIOBase` instance) that
      :class:`BufferedIOBase` deals with.  This is not part of the
      :class:`BufferedIOBase` API and may not exist on some implementations.

   .. method:: detach()

      Separate the underlying raw stream from the buffer and return it.

      After the raw stream has been detached, the buffer is in an unusable
      state.

      Some buffers, like :class:`BytesIO`, do not have the concept of a single
      raw stream to return from this method.  They raise
      :exc:`UnsupportedOperation`.

      .. versionadded:: 3.1

   .. method:: read(size=-1, /)

      Read and return up to *size* bytes.  If the argument is omitted, ``None``,
      or negative, data is read and returned until EOF is reached.  An empty
      :class:`bytes` object is returned if the stream is already at EOF.

      If the argument is positive, and the underlying raw stream is not
      interactive, multiple raw reads may be issued to satisfy the byte count
      (unless EOF is reached first).  But for interactive raw streams, at most
      one raw read will be issued, and a short result does not imply that EOF is
      imminent.

      A :exc:`BlockingIOError` is raised if the underlying raw stream is in
      non blocking-mode, and has no data available at the moment.

   .. method:: read1(size=-1, /)

      Read and return up to *size* bytes, with at most one call to the
      underlying raw stream's :meth:`~RawIOBase.read` (or
      :meth:`~RawIOBase.readinto`) method.  This can be useful if you are
      implementing your own buffering on top of a :class:`BufferedIOBase`
      object.

      If *size* is ``-1`` (the default), an arbitrary number of bytes are
      returned (more than zero unless EOF is reached).

   .. method:: readinto(b, /)

      Read bytes into a pre-allocated, writable
      :term:`bytes-like object` *b* and return the number of bytes read.
      For example, *b* might be a :class:`bytearray`.

      Like :meth:`read`, multiple reads may be issued to the underlying raw
      stream, unless the latter is interactive.

      A :exc:`BlockingIOError` is raised if the underlying raw stream is in non
      blocking-mode, and has no data available at the moment.

   .. method:: readinto1(b, /)

      Read bytes into a pre-allocated, writable
      :term:`bytes-like object` *b*, using at most one call to
      the underlying raw stream's :meth:`~RawIOBase.read` (or
      :meth:`~RawIOBase.readinto`) method. Return the number of bytes read.

      A :exc:`BlockingIOError` is raised if the underlying raw stream is in non
      blocking-mode, and has no data available at the moment.

      .. versionadded:: 3.5

   .. method:: write(b, /)

      Write the given :term:`bytes-like object`, *b*, and return the number
      of bytes written (always equal to the length of *b* in bytes, since if
      the write fails an :exc:`OSError` will be raised).  Depending on the
      actual implementation, these bytes may be readily written to the
      underlying stream, or held in a buffer for performance and latency
      reasons.

      When in non-blocking mode, a :exc:`BlockingIOError` is raised if the
      data needed to be written to the raw stream but it couldn't accept
      all the data without blocking.

      The caller may release or mutate *b* after this method returns,
      so the implementation should only access *b* during the method call.


Raw File I/O
^^^^^^^^^^^^

.. class:: FileIO(name, mode='r', closefd=True, opener=None)

   A raw binary stream representing an OS-level file containing bytes data.  It
   inherits from :class:`RawIOBase`.

   The *name* can be one of two things:

   * a character string or :class:`bytes` object representing the path to the
     file which will be opened. In this case closefd must be ``True`` (the default)
     otherwise an error will be raised.
   * an integer representing the number of an existing OS-level file descriptor
     to which the resulting :class:`FileIO` object will give access. When the
     FileIO object is closed this fd will be closed as well, unless *closefd*
     is set to ``False``.

   The *mode* can be ``'r'``, ``'w'``, ``'x'`` or ``'a'`` for reading
   (default), writing, exclusive creation or appending. The file will be
   created if it doesn't exist when opened for writing or appending; it will be
   truncated when opened for writing. :exc:`FileExistsError` will be raised if
   it already exists when opened for creating. Opening a file for creating
   implies writing, so this mode behaves in a similar way to ``'w'``. Add a
   ``'+'`` to the mode to allow simultaneous reading and writing.

   The :meth:`~RawIOBase.read` (when called with a positive argument),
   :meth:`~RawIOBase.readinto` and :meth:`~RawIOBase.write` methods on this
   class will only make one system call.

   A custom opener can be used by passing a callable as *opener*. The underlying
   file descriptor for the file object is then obtained by calling *opener* with
   (*name*, *flags*). *opener* must return an open file descriptor (passing
   :mod:`os.open` as *opener* results in functionality similar to passing
   ``None``).

   The newly created file is :ref:`non-inheritable <fd_inheritance>`.

   See the :func:`open` built-in function for examples on using the *opener*
   parameter.

   .. versionchanged:: 3.3
      The *opener* parameter was added.
      The ``'x'`` mode was added.

   .. versionchanged:: 3.4
      The file is now non-inheritable.

   :class:`FileIO` provides these data attributes in addition to those from
   :class:`RawIOBase` and :class:`IOBase`:

   .. attribute:: mode

      The mode as given in the constructor.

   .. attribute:: name

      The file name.  This is the file descriptor of the file when no name is
      given in the constructor.


Buffered Streams
^^^^^^^^^^^^^^^^

Buffered I/O streams provide a higher-level interface to an I/O device
than raw I/O does.

.. class:: BytesIO(initial_bytes=b'')

   A binary stream using an in-memory bytes buffer.  It inherits from
   :class:`BufferedIOBase`.  The buffer is discarded when the
   :meth:`~IOBase.close` method is called.

   The optional argument *initial_bytes* is a :term:`bytes-like object` that
   contains initial data.

   :class:`BytesIO` provides or overrides these methods in addition to those
   from :class:`BufferedIOBase` and :class:`IOBase`:

   .. method:: getbuffer()

      Return a readable and writable view over the contents of the buffer
      without copying them.  Also, mutating the view will transparently
      update the contents of the buffer::

         >>> b = io.BytesIO(b"abcdef")
         >>> view = b.getbuffer()
         >>> view[2:4] = b"56"
         >>> b.getvalue()
         b'ab56ef'

      .. note::
         As long as the view exists, the :class:`BytesIO` object cannot be
         resized or closed.

      .. versionadded:: 3.2

   .. method:: getvalue()

      Return :class:`bytes` containing the entire contents of the buffer.


   .. method:: read1(size=-1, /)

      In :class:`BytesIO`, this is the same as :meth:`~BufferedIOBase.read`.

      .. versionchanged:: 3.7
         The *size* argument is now optional.

   .. method:: readinto1(b, /)

      In :class:`BytesIO`, this is the same as :meth:`~BufferedIOBase.readinto`.

      .. versionadded:: 3.5

.. class:: BufferedReader(raw, buffer_size=DEFAULT_BUFFER_SIZE)

   A buffered binary stream providing higher-level access to a readable, non
   seekable :class:`RawIOBase` raw binary stream.  It inherits from
   :class:`BufferedIOBase`.

   When reading data from this object, a larger amount of data may be
   requested from the underlying raw stream, and kept in an internal buffer.
   The buffered data can then be returned directly on subsequent reads.

   The constructor creates a :class:`BufferedReader` for the given readable
   *raw* stream and *buffer_size*.  If *buffer_size* is omitted,
   :data:`DEFAULT_BUFFER_SIZE` is used.

   :class:`BufferedReader` provides or overrides these methods in addition to
   those from :class:`BufferedIOBase` and :class:`IOBase`:

   .. method:: peek(size=0, /)

      Return bytes from the stream without advancing the position.  At most one
      single read on the raw stream is done to satisfy the call. The number of
      bytes returned may be less or more than requested.

   .. method:: read(size=-1, /)

      Read and return *size* bytes, or if *size* is not given or negative, until
      EOF or if the read call would block in non-blocking mode.

      .. note::

         When the underlying raw stream is non-blocking, a :exc:`BlockingIOError`
         may be raised if a read operation cannot be completed immediately.

   .. method:: read1(size=-1, /)

      Read and return up to *size* bytes with only one call on the raw stream.
      If at least one byte is buffered, only buffered bytes are returned.
      Otherwise, one raw stream read call is made.

      .. versionchanged:: 3.7
         The *size* argument is now optional.

      .. note::

         When the underlying raw stream is non-blocking, a :exc:`BlockingIOError`
         may be raised if a read operation cannot be completed immediately.

.. class:: BufferedWriter(raw, buffer_size=DEFAULT_BUFFER_SIZE)

   A buffered binary stream providing higher-level access to a writeable, non
   seekable :class:`RawIOBase` raw binary stream.  It inherits from
   :class:`BufferedIOBase`.

   When writing to this object, data is normally placed into an internal
   buffer.  The buffer will be written out to the underlying :class:`RawIOBase`
   object under various conditions, including:

   * when the buffer gets too small for all pending data;
   * when :meth:`flush` is called;
   * when a :meth:`~IOBase.seek` is requested (for :class:`BufferedRandom` objects);
   * when the :class:`BufferedWriter` object is closed or destroyed.

   The constructor creates a :class:`BufferedWriter` for the given writeable
   *raw* stream.  If the *buffer_size* is not given, it defaults to
   :data:`DEFAULT_BUFFER_SIZE`.

   :class:`BufferedWriter` provides or overrides these methods in addition to
   those from :class:`BufferedIOBase` and :class:`IOBase`:

   .. method:: flush()

      Force bytes held in the buffer into the raw stream.  A
      :exc:`BlockingIOError` should be raised if the raw stream blocks.

   .. method:: write(b, /)

      Write the :term:`bytes-like object`, *b*, and return the
      number of bytes written.  When in non-blocking mode, a
      :exc:`BlockingIOError` is raised if the buffer needs to be written out but
      the raw stream blocks.


.. class:: BufferedRandom(raw, buffer_size=DEFAULT_BUFFER_SIZE)

   A buffered binary stream providing higher-level access to a seekable
   :class:`RawIOBase` raw binary stream.  It inherits from :class:`BufferedReader`
   and :class:`BufferedWriter`.

   The constructor creates a reader and writer for a seekable raw stream, given
   in the first argument.  If the *buffer_size* is omitted it defaults to
   :data:`DEFAULT_BUFFER_SIZE`.

   :class:`BufferedRandom` is capable of anything :class:`BufferedReader` or
   :class:`BufferedWriter` can do.  In addition, :meth:`~IOBase.seek` and
   :meth:`~IOBase.tell` are guaranteed to be implemented.


.. class:: BufferedRWPair(reader, writer, buffer_size=DEFAULT_BUFFER_SIZE, /)

   A buffered binary stream providing higher-level access to two non seekable
   :class:`RawIOBase` raw binary streams---one readable, the other writeable.
   It inherits from :class:`BufferedIOBase`.

   *reader* and *writer* are :class:`RawIOBase` objects that are readable and
   writeable respectively.  If the *buffer_size* is omitted it defaults to
   :data:`DEFAULT_BUFFER_SIZE`.

   :class:`BufferedRWPair` implements all of :class:`BufferedIOBase`\'s methods
   except for :meth:`~BufferedIOBase.detach`, which raises
   :exc:`UnsupportedOperation`.

   .. warning::

      :class:`BufferedRWPair` does not attempt to synchronize accesses to
      its underlying raw streams.  You should not pass it the same object
      as reader and writer; use :class:`BufferedRandom` instead.


Text I/O
^^^^^^^^

.. class:: TextIOBase

   Base class for text streams.  This class provides a character and line based
   interface to stream I/O.  It inherits from :class:`IOBase`.

   :class:`TextIOBase` provides or overrides these data attributes and
   methods in addition to those from :class:`IOBase`:

   .. attribute:: encoding

      The name of the encoding used to decode the stream's bytes into
      strings, and to encode strings into bytes.

   .. attribute:: errors

      The error setting of the decoder or encoder.

   .. attribute:: newlines

      A string, a tuple of strings, or ``None``, indicating the newlines
      translated so far.  Depending on the implementation and the initial
      constructor flags, this may not be available.

   .. attribute:: buffer

      The underlying binary buffer (a :class:`BufferedIOBase` instance) that
      :class:`TextIOBase` deals with.  This is not part of the
      :class:`TextIOBase` API and may not exist in some implementations.

   .. method:: detach()

      Separate the underlying binary buffer from the :class:`TextIOBase` and
      return it.

      After the underlying buffer has been detached, the :class:`TextIOBase` is
      in an unusable state.

      Some :class:`TextIOBase` implementations, like :class:`StringIO`, may not
      have the concept of an underlying buffer and calling this method will
      raise :exc:`UnsupportedOperation`.

      .. versionadded:: 3.1

   .. method:: read(size=-1, /)

      Read and return at most *size* characters from the stream as a single
      :class:`str`.  If *size* is negative or ``None``, reads until EOF.

   .. method:: readline(size=-1, /)

      Read until newline or EOF and return a single :class:`str`.  If the stream is
      already at EOF, an empty string is returned.

      If *size* is specified, at most *size* characters will be read.

   .. method:: seek(offset, whence=SEEK_SET, /)

      Change the stream position to the given *offset*.  Behaviour depends on
      the *whence* parameter.  The default value for *whence* is
      :data:`!SEEK_SET`.

      * :data:`!SEEK_SET` or ``0``: seek from the start of the stream
        (the default); *offset* must either be a number returned by
        :meth:`TextIOBase.tell`, or zero.  Any other *offset* value
        produces undefined behaviour.
      * :data:`!SEEK_CUR` or ``1``: "seek" to the current position;
        *offset* must be zero, which is a no-operation (all other values
        are unsupported).
      * :data:`!SEEK_END` or ``2``: seek to the end of the stream;
        *offset* must be zero (all other values are unsupported).

      Return the new absolute position as an opaque number.

      .. versionadded:: 3.1
         The :data:`!SEEK_*` constants.

   .. method:: tell()

      Return the current stream position as an opaque number.  The number
      does not usually represent a number of bytes in the underlying
      binary storage.

   .. method:: write(s, /)

      Write the string *s* to the stream and return the number of characters
      written.


.. class:: TextIOWrapper(buffer, encoding=None, errors=None, newline=None, \
                         line_buffering=False, write_through=False)

   A buffered text stream providing higher-level access to a
   :class:`BufferedIOBase` buffered binary stream.  It inherits from
   :class:`TextIOBase`.

   *encoding* gives the name of the encoding that the stream will be decoded or
   encoded with.  It defaults to :func:`locale.getencoding`.
   ``encoding="locale"`` can be used to specify the current locale's encoding
   explicitly. See :ref:`io-text-encoding` for more information.

   *errors* is an optional string that specifies how encoding and decoding
   errors are to be handled.  Pass ``'strict'`` to raise a :exc:`ValueError`
   exception if there is an encoding error (the default of ``None`` has the same
   effect), or pass ``'ignore'`` to ignore errors.  (Note that ignoring encoding
   errors can lead to data loss.)  ``'replace'`` causes a replacement marker
   (such as ``'?'``) to be inserted where there is malformed data.
   ``'backslashreplace'`` causes malformed data to be replaced by a
   backslashed escape sequence.  When writing, ``'xmlcharrefreplace'``
   (replace with the appropriate XML character reference)  or ``'namereplace'``
   (replace with ``\N{...}`` escape sequences) can be used.  Any other error
   handling name that has been registered with
   :func:`codecs.register_error` is also valid.

   .. index::
      single: universal newlines; io.TextIOWrapper class

   *newline* controls how line endings are handled.  It can be ``None``,
   ``''``, ``'\n'``, ``'\r'``, and ``'\r\n'``.  It works as follows:

   * When reading input from the stream, if *newline* is ``None``,
     :term:`universal newlines` mode is enabled.  Lines in the input can end in
     ``'\n'``, ``'\r'``, or ``'\r\n'``, and these are translated into ``'\n'``
     before being returned to the caller.  If *newline* is ``''``, universal
     newlines mode is enabled, but line endings are returned to the caller
     untranslated.  If *newline* has any of the other legal values, input lines
     are only terminated by the given string, and the line ending is returned to
     the caller untranslated.

   * When writing output to the stream, if *newline* is ``None``, any ``'\n'``
     characters written are translated to the system default line separator,
     :data:`os.linesep`.  If *newline* is ``''`` or ``'\n'``, no translation
     takes place.  If *newline* is any of the other legal values, any ``'\n'``
     characters written are translated to the given string.

   If *line_buffering* is ``True``, :meth:`~IOBase.flush` is implied when a call to
   write contains a newline character or a carriage return.

   If *write_through* is ``True``, calls to :meth:`~BufferedIOBase.write` are guaranteed
   not to be buffered: any data written on the :class:`TextIOWrapper`
   object is immediately handled to its underlying binary *buffer*.

   .. versionchanged:: 3.3
      The *write_through* argument has been added.

   .. versionchanged:: 3.3
      The default *encoding* is now ``locale.getpreferredencoding(False)``
      instead of ``locale.getpreferredencoding()``. Don't change temporary the
      locale encoding using :func:`locale.setlocale`, use the current locale
      encoding instead of the user preferred encoding.

   .. versionchanged:: 3.10
      The *encoding* argument now supports the ``"locale"`` dummy encoding name.

   .. note::

      When the underlying raw stream is non-blocking, a :exc:`BlockingIOError`
      may be raised if a read operation cannot be completed immediately.

   :class:`TextIOWrapper` provides these data attributes and methods in
   addition to those from :class:`TextIOBase` and :class:`IOBase`:

   .. attribute:: line_buffering

      Whether line buffering is enabled.

   .. attribute:: write_through

      Whether writes are passed immediately to the underlying binary
      buffer.

      .. versionadded:: 3.7

   .. method:: reconfigure(*, encoding=None, errors=None, newline=None, \
                           line_buffering=None, write_through=None)

      Reconfigure this text stream using new settings for *encoding*,
      *errors*, *newline*, *line_buffering* and *write_through*.

      Parameters not specified keep current settings, except
      ``errors='strict'`` is used when *encoding* is specified but
      *errors* is not specified.

      It is not possible to change the encoding or newline if some data
      has already been read from the stream. On the other hand, changing
      encoding after write is possible.

      This method does an implicit stream flush before setting the
      new parameters.

      .. versionadded:: 3.7

      .. versionchanged:: 3.11
         The method supports ``encoding="locale"`` option.

   .. method:: seek(cookie, whence=os.SEEK_SET, /)

      Set the stream position.
      Return the new stream position as an :class:`int`.

      Four operations are supported,
      given by the following argument combinations:

      * ``seek(0, SEEK_SET)``: Rewind to the start of the stream.
      * ``seek(cookie, SEEK_SET)``: Restore a previous position;
        *cookie* **must be** a number returned by :meth:`tell`.
      * ``seek(0, SEEK_END)``: Fast-forward to the end of the stream.
      * ``seek(0, SEEK_CUR)``: Leave the current stream position unchanged.

      Any other argument combinations are invalid,
      and may raise exceptions.

      .. seealso::

         :data:`os.SEEK_SET`, :data:`os.SEEK_CUR`, and :data:`os.SEEK_END`.

   .. method:: tell()

      Return the stream position as an opaque number.
      The return value of :meth:`!tell` can be given as input to :meth:`seek`,
      to restore a previous stream position.


.. class:: StringIO(initial_value='', newline='\n')

   A text stream using an in-memory text buffer.  It inherits from
   :class:`TextIOBase`.

   The text buffer is discarded when the :meth:`~IOBase.close` method is
   called.

   The initial value of the buffer can be set by providing *initial_value*.
   If newline translation is enabled, newlines will be encoded as if by
   :meth:`~TextIOBase.write`.  The stream is positioned at the start of the
   buffer which emulates opening an existing file in a ``w+`` mode, making it
   ready for an immediate write from the beginning or for a write that
   would overwrite the initial value.  To emulate opening a file in an ``a+``
   mode ready for appending, use ``f.seek(0, io.SEEK_END)`` to reposition the
   stream at the end of the buffer.

   The *newline* argument works like that of :class:`TextIOWrapper`,
   except that when writing output to the stream, if *newline* is ``None``,
   newlines are written as ``\n`` on all platforms.

   :class:`StringIO` provides this method in addition to those from
   :class:`TextIOBase` and :class:`IOBase`:

   .. method:: getvalue()

      Return a :class:`str` containing the entire contents of the buffer.
      Newlines are decoded as if by :meth:`~TextIOBase.read`, although
      the stream position is not changed.

   Example usage::

      import io

      output = io.StringIO()
      output.write('First line.\n')
      print('Second line.', file=output)

      # Retrieve file contents -- this will be
      # 'First line.\nSecond line.\n'
      contents = output.getvalue()

      # Close object and discard memory buffer --
      # .getvalue() will now raise an exception.
      output.close()


.. index::
   single: universal newlines; io.IncrementalNewlineDecoder class

.. class:: IncrementalNewlineDecoder

   A helper codec that decodes newlines for :term:`universal newlines` mode.
   It inherits from :class:`codecs.IncrementalDecoder`.


Performance
-----------

This section discusses the performance of the provided concrete I/O
implementations.

Binary I/O
^^^^^^^^^^

By reading and writing only large chunks of data even when the user asks for a
single byte, buffered I/O hides any inefficiency in calling and executing the
operating system's unbuffered I/O routines.  The gain depends on the OS and the
kind of I/O which is performed.  For example, on some modern OSes such as Linux,
unbuffered disk I/O can be as fast as buffered I/O.  The bottom line, however,
is that buffered I/O offers predictable performance regardless of the platform
and the backing device.  Therefore, it is almost always preferable to use
buffered I/O rather than unbuffered I/O for binary data.

Text I/O
^^^^^^^^

Text I/O over a binary storage (such as a file) is significantly slower than
binary I/O over the same storage, because it requires conversions between
unicode and binary data using a character codec.  This can become noticeable
handling huge amounts of text data like large log files.  Also,
:meth:`~TextIOBase.tell` and :meth:`~TextIOBase.seek` are both quite slow
due to the reconstruction algorithm used.

:class:`StringIO`, however, is a native in-memory unicode container and will
exhibit similar speed to :class:`BytesIO`.

Multi-threading
^^^^^^^^^^^^^^^

:class:`FileIO` objects are thread-safe to the extent that the operating system
calls (such as :manpage:`read(2)` under Unix) they wrap are thread-safe too.

Binary buffered objects (instances of :class:`BufferedReader`,
:class:`BufferedWriter`, :class:`BufferedRandom` and :class:`BufferedRWPair`)
protect their internal structures using a lock; it is therefore safe to call
them from multiple threads at once.

:class:`TextIOWrapper` objects are not thread-safe.

Reentrancy
^^^^^^^^^^

Binary buffered objects (instances of :class:`BufferedReader`,
:class:`BufferedWriter`, :class:`BufferedRandom` and :class:`BufferedRWPair`)
are not reentrant.  While reentrant calls will not happen in normal situations,
they can arise from doing I/O in a :mod:`signal` handler.  If a thread tries to
re-enter a buffered object which it is already accessing, a :exc:`RuntimeError`
is raised.  Note this doesn't prohibit a different thread from entering the
buffered object.

The above implicitly extends to text files, since the :func:`open` function
will wrap a buffered object inside a :class:`TextIOWrapper`.  This includes
standard streams and therefore affects the built-in :func:`print` function as
well.


================================================
File: /Doc/library/ipaddress.rst
================================================
:mod:`!ipaddress` --- IPv4/IPv6 manipulation library
====================================================

.. module:: ipaddress
   :synopsis: IPv4/IPv6 manipulation library.

.. moduleauthor:: Peter Moody

**Source code:** :source:`Lib/ipaddress.py`

--------------

:mod:`ipaddress` provides the capabilities to create, manipulate and
operate on IPv4 and IPv6 addresses and networks.

The functions and classes in this module make it straightforward to handle
various tasks related to IP addresses, including checking whether or not two
hosts are on the same subnet, iterating over all hosts in a particular
subnet, checking whether or not a string represents a valid IP address or
network definition, and so on.

This is the full module API referencefor an overview and introduction, see
:ref:`ipaddress-howto`.

.. versionadded:: 3.3

.. testsetup::

   import ipaddress
   from ipaddress import (
       ip_network, IPv4Address, IPv4Interface, IPv4Network,
   )

Convenience factory functions
-----------------------------

The :mod:`ipaddress` module provides factory functions to conveniently create
IP addresses, networks and interfaces:

.. function:: ip_address(address)

   Return an :class:`IPv4Address` or :class:`IPv6Address` object depending on
   the IP address passed as argument.  Either IPv4 or IPv6 addresses may be
   supplied; integers less than ``2**32`` will be considered to be IPv4 by default.
   A :exc:`ValueError` is raised if *address* does not represent a valid IPv4
   or IPv6 address.

   >>> ipaddress.ip_address('192.168.0.1')
   IPv4Address('192.168.0.1')
   >>> ipaddress.ip_address('2001:db8::')
   IPv6Address('2001:db8::')


.. function:: ip_network(address, strict=True)

   Return an :class:`IPv4Network` or :class:`IPv6Network` object depending on
   the IP address passed as argument.  *address* is a string or integer
   representing the IP network.  Either IPv4 or IPv6 networks may be supplied;
   integers less than ``2**32`` will be considered to be IPv4 by default.  *strict*
   is passed to :class:`IPv4Network` or :class:`IPv6Network` constructor.  A
   :exc:`ValueError` is raised if *address* does not represent a valid IPv4 or
   IPv6 address, or if the network has host bits set.

   >>> ipaddress.ip_network('192.168.0.0/28')
   IPv4Network('192.168.0.0/28')


.. function:: ip_interface(address)

   Return an :class:`IPv4Interface` or :class:`IPv6Interface` object depending
   on the IP address passed as argument.  *address* is a string or integer
   representing the IP address.  Either IPv4 or IPv6 addresses may be supplied;
   integers less than ``2**32`` will be considered to be IPv4 by default.  A
   :exc:`ValueError` is raised if *address* does not represent a valid IPv4 or
   IPv6 address.

One downside of these convenience functions is that the need to handle both
IPv4 and IPv6 formats means that error messages provide minimal
information on the precise error, as the functions don't know whether the
IPv4 or IPv6 format was intended. More detailed error reporting can be
obtained by calling the appropriate version specific class constructors
directly.


IP Addresses
------------

Address objects
^^^^^^^^^^^^^^^

The :class:`IPv4Address` and :class:`IPv6Address` objects share a lot of common
attributes.  Some attributes that are only meaningful for IPv6 addresses are
also implemented by :class:`IPv4Address` objects, in order to make it easier to
write code that handles both IP versions correctly.  Address objects are
:term:`hashable`, so they can be used as keys in dictionaries.

.. class:: IPv4Address(address)

   Construct an IPv4 address.  An :exc:`AddressValueError` is raised if
   *address* is not a valid IPv4 address.

   The following constitutes a valid IPv4 address:

   1. A string in decimal-dot notation, consisting of four decimal integers in
      the inclusive range 0--255, separated by dots (e.g. ``192.168.0.1``). Each
      integer represents an octet (byte) in the address. Leading zeroes are
      not tolerated to prevent confusion with octal notation.
   2. An integer that fits into 32 bits.
   3. An integer packed into a :class:`bytes` object of length 4 (most
      significant octet first).

   >>> ipaddress.IPv4Address('192.168.0.1')
   IPv4Address('192.168.0.1')
   >>> ipaddress.IPv4Address(3232235521)
   IPv4Address('192.168.0.1')
   >>> ipaddress.IPv4Address(b'\xC0\xA8\x00\x01')
   IPv4Address('192.168.0.1')

   .. versionchanged:: 3.8

      Leading zeros are tolerated, even in ambiguous cases that look like
      octal notation.

   .. versionchanged:: 3.9.5

      Leading zeros are no longer tolerated and are treated as an error.
      IPv4 address strings are now parsed as strict as glibc
      :func:`~socket.inet_pton`.

   .. attribute:: version

      The appropriate version number: ``4`` for IPv4, ``6`` for IPv6.

      .. versionchanged:: 3.14

         Made available on the class.

   .. attribute:: max_prefixlen

      The total number of bits in the address representation for this
      version: ``32`` for IPv4, ``128`` for IPv6.

      The prefix defines the number of leading bits in an  address that
      are compared to determine whether or not an address is part of a
      network.

      .. versionchanged:: 3.14

         Made available on the class.

   .. attribute:: compressed
   .. attribute:: exploded

      The string representation in dotted decimal notation. Leading zeroes
      are never included in the representation.

      As IPv4 does not define a shorthand notation for addresses with octets
      set to zero, these two attributes are always the same as ``str(addr)``
      for IPv4 addresses. Exposing these attributes makes it easier to
      write display code that can handle both IPv4 and IPv6 addresses.

   .. attribute:: packed

      The binary representation of this address - a :class:`bytes` object of
      the appropriate length (most significant octet first). This is 4 bytes
      for IPv4 and 16 bytes for IPv6.

   .. attribute:: reverse_pointer

      The name of the reverse DNS PTR record for the IP address, e.g.::

          >>> ipaddress.ip_address("127.0.0.1").reverse_pointer
          '1.0.0.127.in-addr.arpa'
          >>> ipaddress.ip_address("2001:db8::1").reverse_pointer
          '1.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.0.8.b.d.0.1.0.0.2.ip6.arpa'

      This is the name that could be used for performing a PTR lookup, not the
      resolved hostname itself.

      .. versionadded:: 3.5

   .. attribute:: is_multicast

      ``True`` if the address is reserved for multicast use.  See
      :RFC:`3171` (for IPv4) or :RFC:`2373` (for IPv6).

   .. attribute:: is_private

      ``True`` if the address is defined as not globally reachable by
      iana-ipv4-special-registry_ (for IPv4) or iana-ipv6-special-registry_
      (for IPv6) with the following exceptions:

      * ``is_private`` is ``False`` for the shared address space (``100.64.0.0/10``)
      * For IPv4-mapped IPv6-addresses the ``is_private`` value is determined by the
        semantics of the underlying IPv4 addresses and the following condition holds
        (see :attr:`IPv6Address.ipv4_mapped`)::

            address.is_private == address.ipv4_mapped.is_private

      ``is_private`` has value opposite to :attr:`is_global`, except for the shared address space
      (``100.64.0.0/10`` range) where they are both ``False``.

      .. versionchanged:: 3.13

         Fixed some false positives and false negatives.

         * ``192.0.0.0/24`` is considered private with the exception of ``192.0.0.9/32`` and
           ``192.0.0.10/32`` (previously: only the ``192.0.0.0/29`` sub-range was considered private).
         * ``64:ff9b:1::/48`` is considered private.
         * ``2002::/16`` is considered private.
         * There are exceptions within ``2001::/23`` (otherwise considered private): ``2001:1::1/128``,
           ``2001:1::2/128``, ``2001:3::/32``, ``2001:4:112::/48``, ``2001:20::/28``, ``2001:30::/28``.
           The exceptions are not considered private.

   .. attribute:: is_global

      ``True`` if the address is defined as globally reachable by
      iana-ipv4-special-registry_ (for IPv4) or iana-ipv6-special-registry_
      (for IPv6) with the following exception:

      For IPv4-mapped IPv6-addresses the ``is_private`` value is determined by the
      semantics of the underlying IPv4 addresses and the following condition holds
      (see :attr:`IPv6Address.ipv4_mapped`)::

         address.is_global == address.ipv4_mapped.is_global

      ``is_global`` has value opposite to :attr:`is_private`, except for the shared address space
      (``100.64.0.0/10`` range) where they are both ``False``.

      .. versionadded:: 3.4

      .. versionchanged:: 3.13

         Fixed some false positives and false negatives, see :attr:`is_private` for details.

   .. attribute:: is_unspecified

      ``True`` if the address is unspecified.  See :RFC:`5735` (for IPv4)
      or :RFC:`2373` (for IPv6).

   .. attribute:: is_reserved

      ``True`` if the address is otherwise IETF reserved.

   .. attribute:: is_loopback

      ``True`` if this is a loopback address.  See :RFC:`3330` (for IPv4)
      or :RFC:`2373` (for IPv6).

   .. attribute:: is_link_local

      ``True`` if the address is reserved for link-local usage.  See
      :RFC:`3927`.

   .. attribute:: ipv6_mapped

      :class:`IPv4Address` object representing the IPv4-mapped IPv6 address. See :RFC:`4291`.

      .. versionadded:: 3.13


.. _iana-ipv4-special-registry: https://www.iana.org/assignments/iana-ipv4-special-registry/iana-ipv4-special-registry.xhtml
.. _iana-ipv6-special-registry: https://www.iana.org/assignments/iana-ipv6-special-registry/iana-ipv6-special-registry.xhtml

.. method:: IPv4Address.__format__(fmt)

   Returns a string representation of the IP address, controlled by
   an explicit format string.
   *fmt* can be one of the following: ``'s'``, the default option,
   equivalent to :func:`str`, ``'b'`` for a zero-padded binary string,
   ``'X'`` or ``'x'`` for an uppercase or lowercase hexadecimal
   representation, or ``'n'``, which is equivalent to ``'b'`` for IPv4
   addresses and ``'x'`` for IPv6. For binary and hexadecimal
   representations, the form specifier ``'#'`` and the grouping option
   ``'_'`` are available. ``__format__`` is used by ``format``, ``str.format``
   and f-strings.

      >>> format(ipaddress.IPv4Address('192.168.0.1'))
      '192.168.0.1'
      >>> '{:#b}'.format(ipaddress.IPv4Address('192.168.0.1'))
      '0b11000000101010000000000000000001'
      >>> f'{ipaddress.IPv6Address("2001:db8::1000"):s}'
      '2001:db8::1000'
      >>> format(ipaddress.IPv6Address('2001:db8::1000'), '_X')
      '2001_0DB8_0000_0000_0000_0000_0000_1000'
      >>> '{:#_n}'.format(ipaddress.IPv6Address('2001:db8::1000'))
      '0x2001_0db8_0000_0000_0000_0000_0000_1000'

   .. versionadded:: 3.9


.. class:: IPv6Address(address)

   Construct an IPv6 address.  An :exc:`AddressValueError` is raised if
   *address* is not a valid IPv6 address.

   The following constitutes a valid IPv6 address:

   1. A string consisting of eight groups of four hexadecimal digits, each
      group representing 16 bits.  The groups are separated by colons.
      This describes an *exploded* (longhand) notation.  The string can
      also be *compressed* (shorthand notation) by various means.  See
      :RFC:`4291` for details.  For example,
      ``"0000:0000:0000:0000:0000:0abc:0007:0def"`` can be compressed to
      ``"::abc:7:def"``.

      Optionally, the string may also have a scope zone ID, expressed
      with a suffix ``%scope_id``. If present, the scope ID must be non-empty,
      and may not contain ``%``.
      See :RFC:`4007` for details.
      For example, ``fe80::1234%1`` might identify address ``fe80::1234`` on the first link of the node.
   2. An integer that fits into 128 bits.
   3. An integer packed into a :class:`bytes` object of length 16, big-endian.


   >>> ipaddress.IPv6Address('2001:db8::1000')
   IPv6Address('2001:db8::1000')
   >>> ipaddress.IPv6Address('ff02::5678%1')
   IPv6Address('ff02::5678%1')

   .. attribute:: compressed

   The short form of the address representation, with leading zeroes in
   groups omitted and the longest sequence of groups consisting entirely of
   zeroes collapsed to a single empty group.

   This is also the value returned by ``str(addr)`` for IPv6 addresses.

   .. attribute:: exploded

   The long form of the address representation, with all leading zeroes and
   groups consisting entirely of zeroes included.


   For the following attributes and methods, see the corresponding
   documentation of the :class:`IPv4Address` class:

   .. attribute:: packed
   .. attribute:: reverse_pointer
   .. attribute:: version
   .. attribute:: max_prefixlen
   .. attribute:: is_multicast
   .. attribute:: is_private
   .. attribute:: is_global

      .. versionadded:: 3.4

   .. attribute:: is_unspecified
   .. attribute:: is_reserved
   .. attribute:: is_loopback
   .. attribute:: is_link_local

   .. attribute:: is_site_local

      ``True`` if the address is reserved for site-local usage.  Note that
      the site-local address space has been deprecated by :RFC:`3879`. Use
      :attr:`~IPv4Address.is_private` to test if this address is in the
      space of unique local addresses as defined by :RFC:`4193`.

   .. attribute:: ipv4_mapped

      For addresses that appear to be IPv4 mapped addresses (starting with
      ``::FFFF/96``), this property will report the embedded IPv4 address.
      For any other address, this property will be ``None``.

   .. attribute:: scope_id

      For scoped addresses as defined by :RFC:`4007`, this property identifies
      the particular zone of the address's scope that the address belongs to,
      as a string. When no scope zone is specified, this property will be ``None``.

   .. attribute:: sixtofour

      For addresses that appear to be 6to4 addresses  (starting with
      ``2002::/16``) as defined by :RFC:`3056`, this property will report
      the embedded IPv4 address.  For any other address, this property will
      be ``None``.

   .. attribute:: teredo

      For addresses that appear to be Teredo addresses (starting with
      ``2001::/32``) as defined by :RFC:`4380`, this property will report
      the embedded ``(server, client)`` IP address pair.  For any other
      address, this property will be ``None``.

.. method:: IPv6Address.__format__(fmt)

   Refer to the corresponding method documentation in
   :class:`IPv4Address`.

   .. versionadded:: 3.9

Conversion to Strings and Integers
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

To interoperate with networking interfaces such as the socket module,
addresses must be converted to strings or integers. This is handled using
the :func:`str` and :func:`int` builtin functions::

   >>> str(ipaddress.IPv4Address('192.168.0.1'))
   '192.168.0.1'
   >>> int(ipaddress.IPv4Address('192.168.0.1'))
   3232235521
   >>> str(ipaddress.IPv6Address('::1'))
   '::1'
   >>> int(ipaddress.IPv6Address('::1'))
   1

Note that IPv6 scoped addresses are converted to integers without scope zone ID.


Operators
^^^^^^^^^

Address objects support some operators.  Unless stated otherwise, operators can
only be applied between compatible objects (i.e. IPv4 with IPv4, IPv6 with
IPv6).


Comparison operators
""""""""""""""""""""

Address objects can be compared with the usual set of comparison operators.
Same IPv6 addresses with different scope zone IDs are not equal.
Some examples::

   >>> IPv4Address('127.0.0.2') > IPv4Address('127.0.0.1')
   True
   >>> IPv4Address('127.0.0.2') == IPv4Address('127.0.0.1')
   False
   >>> IPv4Address('127.0.0.2') != IPv4Address('127.0.0.1')
   True
   >>> IPv6Address('fe80::1234') == IPv6Address('fe80::1234%1')
   False
   >>> IPv6Address('fe80::1234%1') != IPv6Address('fe80::1234%2')
   True


Arithmetic operators
""""""""""""""""""""

Integers can be added to or subtracted from address objects.  Some examples::

   >>> IPv4Address('127.0.0.2') + 3
   IPv4Address('127.0.0.5')
   >>> IPv4Address('127.0.0.2') - 3
   IPv4Address('126.255.255.255')
   >>> IPv4Address('255.255.255.255') + 1
   Traceback (most recent call last):
     File "<stdin>", line 1, in <module>
   ipaddress.AddressValueError: 4294967296 (>= 2**32) is not permitted as an IPv4 address


IP Network definitions
----------------------

The :class:`IPv4Network` and :class:`IPv6Network` objects provide a mechanism
for defining and inspecting IP network definitions.  A network definition
consists of a *mask* and a *network address*, and as such defines a range of
IP addresses that equal the network address when masked (binary AND) with the
mask.  For example, a network definition with the mask ``255.255.255.0`` and
the network address ``192.168.1.0`` consists of IP addresses in the inclusive
range ``192.168.1.0`` to ``192.168.1.255``.


Prefix, net mask and host mask
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

There are several equivalent ways to specify IP network masks.  A *prefix*
``/<nbits>`` is a notation that denotes how many high-order bits are set in
the network mask.  A *net mask* is an IP address with some number of
high-order bits set.  Thus the prefix ``/24`` is equivalent to the net mask
``255.255.255.0`` in IPv4, or ``ffff:ff00::`` in IPv6.  In addition, a
*host mask* is the logical inverse of a *net mask*, and is sometimes used
(for example in Cisco access control lists) to denote a network mask.  The
host mask equivalent to ``/24`` in IPv4 is ``0.0.0.255``.


Network objects
^^^^^^^^^^^^^^^

All attributes implemented by address objects are implemented by network
objects as well.  In addition, network objects implement additional attributes.
All of these are common between :class:`IPv4Network` and :class:`IPv6Network`,
so to avoid duplication they are only documented for :class:`IPv4Network`.
Network objects are :term:`hashable`, so they can be used as keys in
dictionaries.

.. class:: IPv4Network(address, strict=True)

   Construct an IPv4 network definition.  *address* can be one of the following:

   1. A string consisting of an IP address and an optional mask, separated by
      a slash (``/``).  The IP address is the network address, and the mask
      can be either a single number, which means it's a *prefix*, or a string
      representation of an IPv4 address.  If it's the latter, the mask is
      interpreted as a *net mask* if it starts with a non-zero field, or as a
      *host mask* if it starts with a zero field, with the single exception of
      an all-zero mask which is treated as a *net mask*.  If no mask is provided,
      it's considered to be ``/32``.

      For example, the following *address* specifications are equivalent:
      ``192.168.1.0/24``, ``192.168.1.0/255.255.255.0`` and
      ``192.168.1.0/0.0.0.255``.

   2. An integer that fits into 32 bits.  This is equivalent to a
      single-address network, with the network address being *address* and
      the mask being ``/32``.

   3. An integer packed into a :class:`bytes` object of length 4, big-endian.
      The interpretation is similar to an integer *address*.

   4. A two-tuple of an address description and a netmask, where the address
      description is either a string, a 32-bits integer, a 4-bytes packed
      integer, or an existing :class:`IPv4Address` object; and the netmask is either
      an integer representing the prefix length (e.g. ``24``) or a string
      representing the prefix mask (e.g. ``255.255.255.0``).

   An :exc:`AddressValueError` is raised if *address* is not a valid IPv4
   address.  A :exc:`NetmaskValueError` is raised if the mask is not valid for
   an IPv4 address.

   If *strict* is ``True`` and host bits are set in the supplied address,
   then :exc:`ValueError` is raised.  Otherwise, the host bits are masked out
   to determine the appropriate network address.

   Unless stated otherwise, all network methods accepting other network/address
   objects will raise :exc:`TypeError` if the argument's IP version is
   incompatible to ``self``.

   .. versionchanged:: 3.5

      Added the two-tuple form for the *address* constructor parameter.

   .. attribute:: version
   .. attribute:: max_prefixlen

      Refer to the corresponding attribute documentation in
      :class:`IPv4Address`.

   .. attribute:: is_multicast
   .. attribute:: is_private
   .. attribute:: is_unspecified
   .. attribute:: is_reserved
   .. attribute:: is_loopback
   .. attribute:: is_link_local

      These attributes are true for the network as a whole if they are true
      for both the network address and the broadcast address.

   .. attribute:: network_address

      The network address for the network. The network address and the
      prefix length together uniquely define a network.

   .. attribute:: broadcast_address

      The broadcast address for the network. Packets sent to the broadcast
      address should be received by every host on the network.

   .. attribute:: hostmask

      The host mask, as an :class:`IPv4Address` object.

   .. attribute:: netmask

      The net mask, as an :class:`IPv4Address` object.

   .. attribute:: with_prefixlen
   .. attribute:: compressed
   .. attribute:: exploded

      A string representation of the network, with the mask in prefix
      notation.

      ``with_prefixlen`` and ``compressed`` are always the same as
      ``str(network)``.
      ``exploded`` uses the exploded form the network address.

   .. attribute:: with_netmask

      A string representation of the network, with the mask in net mask
      notation.

   .. attribute:: with_hostmask

      A string representation of the network, with the mask in host mask
      notation.

   .. attribute:: num_addresses

      The total number of addresses in the network.

   .. attribute:: prefixlen

      Length of the network prefix, in bits.

   .. method:: hosts()

      Returns an iterator over the usable hosts in the network.  The usable
      hosts are all the IP addresses that belong to the network, except the
      network address itself and the network broadcast address.  For networks
      with a mask length of 31, the network address and network broadcast
      address are also included in the result. Networks with a mask of 32
      will return a list containing the single host address.

         >>> list(ip_network('192.0.2.0/29').hosts())  #doctest: +NORMALIZE_WHITESPACE
         [IPv4Address('192.0.2.1'), IPv4Address('192.0.2.2'),
          IPv4Address('192.0.2.3'), IPv4Address('192.0.2.4'),
          IPv4Address('192.0.2.5'), IPv4Address('192.0.2.6')]
         >>> list(ip_network('192.0.2.0/31').hosts())
         [IPv4Address('192.0.2.0'), IPv4Address('192.0.2.1')]
         >>> list(ip_network('192.0.2.1/32').hosts())
         [IPv4Address('192.0.2.1')]

   .. method:: overlaps(other)

      ``True`` if this network is partly or wholly contained in *other* or
      *other* is wholly contained in this network.

   .. method:: address_exclude(network)

      Computes the network definitions resulting from removing the given
      *network* from this one.  Returns an iterator of network objects.
      Raises :exc:`ValueError` if *network* is not completely contained in
      this network.

         >>> n1 = ip_network('192.0.2.0/28')
         >>> n2 = ip_network('192.0.2.1/32')
         >>> list(n1.address_exclude(n2))  #doctest: +NORMALIZE_WHITESPACE
         [IPv4Network('192.0.2.8/29'), IPv4Network('192.0.2.4/30'),
          IPv4Network('192.0.2.2/31'), IPv4Network('192.0.2.0/32')]

   .. method:: subnets(prefixlen_diff=1, new_prefix=None)

      The subnets that join to make the current network definition, depending
      on the argument values.  *prefixlen_diff* is the amount our prefix
      length should be increased by.  *new_prefix* is the desired new
      prefix of the subnets; it must be larger than our prefix.  One and
      only one of *prefixlen_diff* and *new_prefix* must be set.  Returns an
      iterator of network objects.

         >>> list(ip_network('192.0.2.0/24').subnets())
         [IPv4Network('192.0.2.0/25'), IPv4Network('192.0.2.128/25')]
         >>> list(ip_network('192.0.2.0/24').subnets(prefixlen_diff=2))  #doctest: +NORMALIZE_WHITESPACE
         [IPv4Network('192.0.2.0/26'), IPv4Network('192.0.2.64/26'),
          IPv4Network('192.0.2.128/26'), IPv4Network('192.0.2.192/26')]
         >>> list(ip_network('192.0.2.0/24').subnets(new_prefix=26))  #doctest: +NORMALIZE_WHITESPACE
         [IPv4Network('192.0.2.0/26'), IPv4Network('192.0.2.64/26'),
          IPv4Network('192.0.2.128/26'), IPv4Network('192.0.2.192/26')]
         >>> list(ip_network('192.0.2.0/24').subnets(new_prefix=23))
         Traceback (most recent call last):
           File "<stdin>", line 1, in <module>
             raise ValueError('new prefix must be longer')
         ValueError: new prefix must be longer
         >>> list(ip_network('192.0.2.0/24').subnets(new_prefix=25))
         [IPv4Network('192.0.2.0/25'), IPv4Network('192.0.2.128/25')]

   .. method:: supernet(prefixlen_diff=1, new_prefix=None)

      The supernet containing this network definition, depending on the
      argument values.  *prefixlen_diff* is the amount our prefix length
      should be decreased by.  *new_prefix* is the desired new prefix of
      the supernet; it must be smaller than our prefix.  One and only one
      of *prefixlen_diff* and *new_prefix* must be set.  Returns a single
      network object.

         >>> ip_network('192.0.2.0/24').supernet()
         IPv4Network('192.0.2.0/23')
         >>> ip_network('192.0.2.0/24').supernet(prefixlen_diff=2)
         IPv4Network('192.0.0.0/22')
         >>> ip_network('192.0.2.0/24').supernet(new_prefix=20)
         IPv4Network('192.0.0.0/20')

   .. method:: subnet_of(other)

      Return ``True`` if this network is a subnet of *other*.

        >>> a = ip_network('192.168.1.0/24')
        >>> b = ip_network('192.168.1.128/30')
        >>> b.subnet_of(a)
        True

      .. versionadded:: 3.7

   .. method:: supernet_of(other)

      Return ``True`` if this network is a supernet of *other*.

        >>> a = ip_network('192.168.1.0/24')
        >>> b = ip_network('192.168.1.128/30')
        >>> a.supernet_of(b)
        True

      .. versionadded:: 3.7

   .. method:: compare_networks(other)

      Compare this network to *other*.  In this comparison only the network
      addresses are considered; host bits aren't.  Returns either ``-1``,
      ``0`` or ``1``.

         >>> ip_network('192.0.2.1/32').compare_networks(ip_network('192.0.2.2/32'))
         -1
         >>> ip_network('192.0.2.1/32').compare_networks(ip_network('192.0.2.0/32'))
         1
         >>> ip_network('192.0.2.1/32').compare_networks(ip_network('192.0.2.1/32'))
         0

      .. deprecated:: 3.7
         It uses the same ordering and comparison algorithm as "<", "==", and ">"


.. class:: IPv6Network(address, strict=True)

   Construct an IPv6 network definition.  *address* can be one of the following:

   1. A string consisting of an IP address and an optional prefix length,
      separated by a slash (``/``).  The IP address is the network address,
      and the prefix length must be a single number, the *prefix*.  If no
      prefix length is provided, it's considered to be ``/128``.

      Note that currently expanded netmasks are not supported.  That means
      ``2001:db00::0/24`` is a valid argument while ``2001:db00::0/ffff:ff00::``
      is not.

   2. An integer that fits into 128 bits.  This is equivalent to a
      single-address network, with the network address being *address* and
      the mask being ``/128``.

   3. An integer packed into a :class:`bytes` object of length 16, big-endian.
      The interpretation is similar to an integer *address*.

   4. A two-tuple of an address description and a netmask, where the address
      description is either a string, a 128-bits integer, a 16-bytes packed
      integer, or an existing :class:`IPv6Address` object; and the netmask is an
      integer representing the prefix length.

   An :exc:`AddressValueError` is raised if *address* is not a valid IPv6
   address.  A :exc:`NetmaskValueError` is raised if the mask is not valid for
   an IPv6 address.

   If *strict* is ``True`` and host bits are set in the supplied address,
   then :exc:`ValueError` is raised.  Otherwise, the host bits are masked out
   to determine the appropriate network address.

   .. versionchanged:: 3.5

      Added the two-tuple form for the *address* constructor parameter.

   .. attribute:: version
   .. attribute:: max_prefixlen
   .. attribute:: is_multicast
   .. attribute:: is_private
   .. attribute:: is_unspecified
   .. attribute:: is_reserved
   .. attribute:: is_loopback
   .. attribute:: is_link_local
   .. attribute:: network_address
   .. attribute:: broadcast_address
   .. attribute:: hostmask
   .. attribute:: netmask
   .. attribute:: with_prefixlen
   .. attribute:: compressed
   .. attribute:: exploded
   .. attribute:: with_netmask
   .. attribute:: with_hostmask
   .. attribute:: num_addresses
   .. attribute:: prefixlen
   .. method:: hosts()

      Returns an iterator over the usable hosts in the network.  The usable
      hosts are all the IP addresses that belong to the network, except the
      Subnet-Router anycast address.  For networks with a mask length of 127,
      the Subnet-Router anycast address is also included in the result.
      Networks with a mask of 128 will return a list containing the
      single host address.

   .. method:: overlaps(other)
   .. method:: address_exclude(network)
   .. method:: subnets(prefixlen_diff=1, new_prefix=None)
   .. method:: supernet(prefixlen_diff=1, new_prefix=None)
   .. method:: subnet_of(other)
   .. method:: supernet_of(other)
   .. method:: compare_networks(other)

      Refer to the corresponding attribute documentation in
      :class:`IPv4Network`.

   .. attribute:: is_site_local

      This attribute is true for the network as a whole if it is true
      for both the network address and the broadcast address.


Operators
^^^^^^^^^

Network objects support some operators.  Unless stated otherwise, operators can
only be applied between compatible objects (i.e. IPv4 with IPv4, IPv6 with
IPv6).


Logical operators
"""""""""""""""""

Network objects can be compared with the usual set of logical operators.
Network objects are ordered first by network address, then by net mask.


Iteration
"""""""""

Network objects can be iterated to list all the addresses belonging to the
network.  For iteration, *all* hosts are returned, including unusable hosts
(for usable hosts, use the :meth:`~IPv4Network.hosts` method).  An
example::

   >>> for addr in IPv4Network('192.0.2.0/28'):
   ...     addr
   ...
   IPv4Address('192.0.2.0')
   IPv4Address('192.0.2.1')
   IPv4Address('192.0.2.2')
   IPv4Address('192.0.2.3')
   IPv4Address('192.0.2.4')
   IPv4Address('192.0.2.5')
   IPv4Address('192.0.2.6')
   IPv4Address('192.0.2.7')
   IPv4Address('192.0.2.8')
   IPv4Address('192.0.2.9')
   IPv4Address('192.0.2.10')
   IPv4Address('192.0.2.11')
   IPv4Address('192.0.2.12')
   IPv4Address('192.0.2.13')
   IPv4Address('192.0.2.14')
   IPv4Address('192.0.2.15')


Networks as containers of addresses
"""""""""""""""""""""""""""""""""""

Network objects can act as containers of addresses.  Some examples::

   >>> IPv4Network('192.0.2.0/28')[0]
   IPv4Address('192.0.2.0')
   >>> IPv4Network('192.0.2.0/28')[15]
   IPv4Address('192.0.2.15')
   >>> IPv4Address('192.0.2.6') in IPv4Network('192.0.2.0/28')
   True
   >>> IPv4Address('192.0.3.6') in IPv4Network('192.0.2.0/28')
   False


Interface objects
-----------------

Interface objects are :term:`hashable`, so they can be used as keys in
dictionaries.

.. class:: IPv4Interface(address)

   Construct an IPv4 interface.  The meaning of *address* is as in the
   constructor of :class:`IPv4Network`, except that arbitrary host addresses
   are always accepted.

   :class:`IPv4Interface` is a subclass of :class:`IPv4Address`, so it inherits
   all the attributes from that class.  In addition, the following attributes
   are available:

   .. attribute:: ip

      The address (:class:`IPv4Address`) without network information.

         >>> interface = IPv4Interface('192.0.2.5/24')
         >>> interface.ip
         IPv4Address('192.0.2.5')

   .. attribute:: network

      The network (:class:`IPv4Network`) this interface belongs to.

         >>> interface = IPv4Interface('192.0.2.5/24')
         >>> interface.network
         IPv4Network('192.0.2.0/24')

   .. attribute:: with_prefixlen

      A string representation of the interface with the mask in prefix notation.

         >>> interface = IPv4Interface('192.0.2.5/24')
         >>> interface.with_prefixlen
         '192.0.2.5/24'

   .. attribute:: with_netmask

      A string representation of the interface with the network as a net mask.

         >>> interface = IPv4Interface('192.0.2.5/24')
         >>> interface.with_netmask
         '192.0.2.5/255.255.255.0'

   .. attribute:: with_hostmask

      A string representation of the interface with the network as a host mask.

         >>> interface = IPv4Interface('192.0.2.5/24')
         >>> interface.with_hostmask
         '192.0.2.5/0.0.0.255'


.. class:: IPv6Interface(address)

   Construct an IPv6 interface.  The meaning of *address* is as in the
   constructor of :class:`IPv6Network`, except that arbitrary host addresses
   are always accepted.

   :class:`IPv6Interface` is a subclass of :class:`IPv6Address`, so it inherits
   all the attributes from that class.  In addition, the following attributes
   are available:

   .. attribute:: ip
   .. attribute:: network
   .. attribute:: with_prefixlen
   .. attribute:: with_netmask
   .. attribute:: with_hostmask

      Refer to the corresponding attribute documentation in
      :class:`IPv4Interface`.


Operators
^^^^^^^^^

Interface objects support some operators.  Unless stated otherwise, operators
can only be applied between compatible objects (i.e. IPv4 with IPv4, IPv6 with
IPv6).


Logical operators
"""""""""""""""""

Interface objects can be compared with the usual set of logical operators.

For equality comparison (``==`` and ``!=``), both the IP address and network
must be the same for the objects to be equal.  An interface will not compare
equal to any address or network object.

For ordering (``<``, ``>``, etc) the rules are different.  Interface and
address objects with the same IP version can be compared, and the address
objects will always sort before the interface objects.  Two interface objects
are first compared by their networks and, if those are the same, then by their
IP addresses.


Other Module Level Functions
----------------------------

The module also provides the following module level functions:

.. function:: v4_int_to_packed(address)

   Represent an address as 4 packed bytes in network (big-endian) order.
   *address* is an integer representation of an IPv4 IP address.  A
   :exc:`ValueError` is raised if the integer is negative or too large to be an
   IPv4 IP address.

   >>> ipaddress.ip_address(3221225985)
   IPv4Address('192.0.2.1')
   >>> ipaddress.v4_int_to_packed(3221225985)
   b'\xc0\x00\x02\x01'


.. function:: v6_int_to_packed(address)

   Represent an address as 16 packed bytes in network (big-endian) order.
   *address* is an integer representation of an IPv6 IP address.  A
   :exc:`ValueError` is raised if the integer is negative or too large to be an
   IPv6 IP address.


.. function:: summarize_address_range(first, last)

   Return an iterator of the summarized network range given the first and last
   IP addresses.  *first* is the first :class:`IPv4Address` or
   :class:`IPv6Address` in the range and *last* is the last :class:`IPv4Address`
   or :class:`IPv6Address` in the range.  A :exc:`TypeError` is raised if
   *first* or *last* are not IP addresses or are not of the same version.  A
   :exc:`ValueError` is raised if *last* is not greater than *first* or if
   *first* address version is not 4 or 6.

   >>> [ipaddr for ipaddr in ipaddress.summarize_address_range(
   ...    ipaddress.IPv4Address('192.0.2.0'),
   ...    ipaddress.IPv4Address('192.0.2.130'))]
   [IPv4Network('192.0.2.0/25'), IPv4Network('192.0.2.128/31'), IPv4Network('192.0.2.130/32')]


.. function:: collapse_addresses(addresses)

   Return an iterator of the collapsed :class:`IPv4Network` or
   :class:`IPv6Network` objects.  *addresses* is an :term:`iterable` of
   :class:`IPv4Network` or :class:`IPv6Network` objects.  A :exc:`TypeError` is
   raised if *addresses* contains mixed version objects.

   >>> [ipaddr for ipaddr in
   ... ipaddress.collapse_addresses([ipaddress.IPv4Network('192.0.2.0/25'),
   ... ipaddress.IPv4Network('192.0.2.128/25')])]
   [IPv4Network('192.0.2.0/24')]


.. function:: get_mixed_type_key(obj)

   Return a key suitable for sorting between networks and addresses.  Address
   and Network objects are not sortable by default; they're fundamentally
   different, so the expression::

     IPv4Address('192.0.2.0') <= IPv4Network('192.0.2.0/24')

   doesn't make sense.  There are some times however, where you may wish to
   have :mod:`ipaddress` sort these anyway.  If you need to do this, you can use
   this function as the *key* argument to :func:`sorted`.

   *obj* is either a network or address object.


Custom Exceptions
-----------------

To support more specific error reporting from class constructors, the
module defines the following exceptions:

.. exception:: AddressValueError(ValueError)

   Any value error related to the address.


.. exception:: NetmaskValueError(ValueError)

   Any value error related to the net mask.


================================================
File: /Doc/library/ipc.rst
================================================
.. _ipc:

*****************************************
Networking and Interprocess Communication
*****************************************

The modules described in this chapter provide mechanisms for
networking and inter-processes communication.

Some modules only work for two processes that are on the same machine, e.g.
:mod:`signal` and :mod:`mmap`.  Other modules support networking protocols
that two or more processes can use to communicate across machines.

The list of modules described in this chapter is:


.. toctree::
   :maxdepth: 1

   asyncio.rst
   socket.rst
   ssl.rst
   select.rst
   selectors.rst
   signal.rst
   mmap.rst


================================================
File: /Doc/library/json.rst
================================================
:mod:`!json` --- JSON encoder and decoder
=========================================

.. module:: json
   :synopsis: Encode and decode the JSON format.

.. moduleauthor:: Bob Ippolito <bob@redivi.com>
.. sectionauthor:: Bob Ippolito <bob@redivi.com>

**Source code:** :source:`Lib/json/__init__.py`

--------------

`JSON (JavaScript Object Notation) <https://json.org>`_, specified by
:rfc:`7159` (which obsoletes :rfc:`4627`) and by
`ECMA-404 <https://ecma-international.org/publications-and-standards/standards/ecma-404/>`_,
is a lightweight data interchange format inspired by
`JavaScript <https://en.wikipedia.org/wiki/JavaScript>`_ object literal syntax
(although it is not a strict subset of JavaScript [#rfc-errata]_ ).

.. warning::
   Be cautious when parsing JSON data from untrusted sources. A malicious
   JSON string may cause the decoder to consume considerable CPU and memory
   resources. Limiting the size of data to be parsed is recommended.

:mod:`json` exposes an API familiar to users of the standard library
:mod:`marshal` and :mod:`pickle` modules.

Encoding basic Python object hierarchies::

    >>> import json
    >>> json.dumps(['foo', {'bar': ('baz', None, 1.0, 2)}])
    '["foo", {"bar": ["baz", null, 1.0, 2]}]'
    >>> print(json.dumps("\"foo\bar"))
    "\"foo\bar"
    >>> print(json.dumps('\u1234'))
    "\u1234"
    >>> print(json.dumps('\\'))
    "\\"
    >>> print(json.dumps({"c": 0, "b": 0, "a": 0}, sort_keys=True))
    {"a": 0, "b": 0, "c": 0}
    >>> from io import StringIO
    >>> io = StringIO()
    >>> json.dump(['streaming API'], io)
    >>> io.getvalue()
    '["streaming API"]'

Compact encoding::

    >>> import json
    >>> json.dumps([1, 2, 3, {'4': 5, '6': 7}], separators=(',', ':'))
    '[1,2,3,{"4":5,"6":7}]'

Pretty printing::

    >>> import json
    >>> print(json.dumps({'6': 7, '4': 5}, sort_keys=True, indent=4))
    {
        "4": 5,
        "6": 7
    }

Specializing JSON object encoding::

   >>> import json
   >>> def custom_json(obj):
   ...     if isinstance(obj, complex):
   ...         return {'__complex__': True, 'real': obj.real, 'imag': obj.imag}
   ...     raise TypeError(f'Cannot serialize object of {type(obj)}')
   ...
   >>> json.dumps(1 + 2j, default=custom_json)
   '{"__complex__": true, "real": 1.0, "imag": 2.0}'

Decoding JSON::

    >>> import json
    >>> json.loads('["foo", {"bar":["baz", null, 1.0, 2]}]')
    ['foo', {'bar': ['baz', None, 1.0, 2]}]
    >>> json.loads('"\\"foo\\bar"')
    '"foo\x08ar'
    >>> from io import StringIO
    >>> io = StringIO('["streaming API"]')
    >>> json.load(io)
    ['streaming API']

Specializing JSON object decoding::

    >>> import json
    >>> def as_complex(dct):
    ...     if '__complex__' in dct:
    ...         return complex(dct['real'], dct['imag'])
    ...     return dct
    ...
    >>> json.loads('{"__complex__": true, "real": 1, "imag": 2}',
    ...     object_hook=as_complex)
    (1+2j)
    >>> import decimal
    >>> json.loads('1.1', parse_float=decimal.Decimal)
    Decimal('1.1')

Extending :class:`JSONEncoder`::

    >>> import json
    >>> class ComplexEncoder(json.JSONEncoder):
    ...     def default(self, obj):
    ...         if isinstance(obj, complex):
    ...             return [obj.real, obj.imag]
    ...         # Let the base class default method raise the TypeError
    ...         return super().default(obj)
    ...
    >>> json.dumps(2 + 1j, cls=ComplexEncoder)
    '[2.0, 1.0]'
    >>> ComplexEncoder().encode(2 + 1j)
    '[2.0, 1.0]'
    >>> list(ComplexEncoder().iterencode(2 + 1j))
    ['[2.0', ', 1.0', ']']


Using :mod:`json` from the shell to validate and pretty-print:

.. code-block:: shell-session

    $ echo '{"json":"obj"}' | python -m json
    {
        "json": "obj"
    }
    $ echo '{1.2:3.4}' | python -m json
    Expecting property name enclosed in double quotes: line 1 column 2 (char 1)

See :ref:`json-commandline` for detailed documentation.

.. note::

   JSON is a subset of `YAML <https://yaml.org/>`_ 1.2.  The JSON produced by
   this module's default settings (in particular, the default *separators*
   value) is also a subset of YAML 1.0 and 1.1.  This module can thus also be
   used as a YAML serializer.

.. note::

   This module's encoders and decoders preserve input and output order by
   default.  Order is only lost if the underlying containers are unordered.


Basic Usage
-----------

.. function:: dump(obj, fp, *, skipkeys=False, ensure_ascii=True, \
                   check_circular=True, allow_nan=True, cls=None, \
                   indent=None, separators=None, default=None, \
                   sort_keys=False, **kw)

   Serialize *obj* as a JSON formatted stream to *fp* (a ``.write()``-supporting
   :term:`file-like object`) using this :ref:`Python-to-JSON conversion table
   <py-to-json-table>`.

   .. note::

      Unlike :mod:`pickle` and :mod:`marshal`, JSON is not a framed protocol,
      so trying to serialize multiple objects with repeated calls to
      :func:`dump` using the same *fp* will result in an invalid JSON file.

   :param object obj:
      The Python object to be serialized.

   :param fp:
      The file-like object *obj* will be serialized to.
      The :mod:`!json` module always produces :class:`str` objects,
      not :class:`bytes` objects,
      therefore ``fp.write()`` must support :class:`str` input.
   :type fp: :term:`file-like object`

   :param bool skipkeys:
      If ``True``, keys that are not of a basic type
      (:class:`str`, :class:`int`, :class:`float`, :class:`bool`, ``None``)
      will be skipped instead of raising a :exc:`TypeError`.
      Default ``False``.

   :param bool ensure_ascii:
      If ``True`` (the default), the output is guaranteed to
      have all incoming non-ASCII characters escaped.
      If ``False``, these characters will be outputted as-is.

   :param bool check_circular:
      If ``False``, the circular reference check for container types is skipped
      and a circular reference will result in a :exc:`RecursionError` (or worse).
      Default ``True``.

   :param bool allow_nan:
      If ``False``, serialization of out-of-range :class:`float` values
      (``nan``, ``inf``, ``-inf``) will result in a :exc:`ValueError`,
      in strict compliance with the JSON specification.
      If ``True`` (the default), their JavaScript equivalents
      (``NaN``, ``Infinity``, ``-Infinity``) are used.

   :param cls:
      If set, a custom JSON encoder with the
      :meth:`~JSONEncoder.default` method overridden,
      for serializing into custom datatypes.
      If ``None`` (the default), :class:`!JSONEncoder` is used.
   :type cls: a :class:`JSONEncoder` subclass

   :param indent:
      If a positive integer or string, JSON array elements and
      object members will be pretty-printed with that indent level.
      A positive integer indents that many spaces per level;
      a string (such as ``"\t"``) is used to indent each level.
      If zero, negative, or ``""`` (the empty string),
      only newlines are inserted.
      If ``None`` (the default), the most compact representation is used.
   :type indent: int | str | None

   :param separators:
      A two-tuple: ``(item_separator, key_separator)``.
      If ``None`` (the default), *separators* defaults to
      ``(', ', ': ')`` if *indent* is ``None``,
      and ``(',', ': ')`` otherwise.
      For the most compact JSON,
      specify ``(',', ':')`` to eliminate whitespace.
   :type separators: tuple | None

   :param default:
      A function that is called for objects that can't otherwise be serialized.
      It should return a JSON encodable version of the object
      or raise a :exc:`TypeError`.
      If ``None`` (the default), :exc:`!TypeError` is raised.
   :type default: :term:`callable` | None

   :param bool sort_keys:
      If ``True``, dictionaries will be outputted sorted by key.
      Default ``False``.

   .. versionchanged:: 3.2
      Allow strings for *indent* in addition to integers.

   .. versionchanged:: 3.4
      Use ``(',', ': ')`` as default if *indent* is not ``None``.

   .. versionchanged:: 3.6
      All optional parameters are now :ref:`keyword-only <keyword-only_parameter>`.


.. function:: dumps(obj, *, skipkeys=False, ensure_ascii=True, \
                    check_circular=True, allow_nan=True, cls=None, \
                    indent=None, separators=None, default=None, \
                    sort_keys=False, **kw)

   Serialize *obj* to a JSON formatted :class:`str` using this :ref:`conversion
   table <py-to-json-table>`.  The arguments have the same meaning as in
   :func:`dump`.

   .. note::

      Keys in key/value pairs of JSON are always of the type :class:`str`. When
      a dictionary is converted into JSON, all the keys of the dictionary are
      coerced to strings. As a result of this, if a dictionary is converted
      into JSON and then back into a dictionary, the dictionary may not equal
      the original one. That is, ``loads(dumps(x)) != x`` if x has non-string
      keys.

.. function:: load(fp, *, cls=None, object_hook=None, parse_float=None, \
                   parse_int=None, parse_constant=None, \
                   object_pairs_hook=None, **kw)

   Deserialize *fp* to a Python object
   using the :ref:`JSON-to-Python conversion table <json-to-py-table>`.

   :param fp:
      A ``.read()``-supporting :term:`text file` or :term:`binary file`
      containing the JSON document to be deserialized.
   :type fp: :term:`file-like object`

   :param cls:
      If set, a custom JSON decoder.
      Additional keyword arguments to :func:`!load`
      will be passed to the constructor of *cls*.
      If ``None`` (the default), :class:`!JSONDecoder` is used.
   :type cls: a :class:`JSONDecoder` subclass

   :param object_hook:
      If set, a function that is called with the result of
      any object literal decoded (a :class:`dict`).
      The return value of this function will be used
      instead of the :class:`dict`.
      This feature can be used to implement custom decoders,
      for example `JSON-RPC <https://www.jsonrpc.org>`_ class hinting.
      Default ``None``.
   :type object_hook: :term:`callable` | None

   :param object_pairs_hook:
      If set, a function that is called with the result of
      any object literal decoded with an ordered list of pairs.
      The return value of this function will be used
      instead of the :class:`dict`.
      This feature can be used to implement custom decoders.
      If *object_hook* is also set, *object_pairs_hook* takes priority.
      Default ``None``.
   :type object_pairs_hook: :term:`callable` | None

   :param parse_float:
      If set, a function that is called with
      the string of every JSON float to be decoded.
      If ``None`` (the default), it is equivalent to ``float(num_str)``.
      This can be used to parse JSON floats into custom datatypes,
      for example :class:`decimal.Decimal`.
   :type parse_float: :term:`callable` | None

   :param parse_int:
      If set, a function that is called with
      the string of every JSON int to be decoded.
      If ``None`` (the default), it is equivalent to ``int(num_str)``.
      This can be used to parse JSON integers into custom datatypes,
      for example :class:`float`.
   :type parse_int: :term:`callable` | None

   :param parse_constant:
      If set, a function that is called with one of the following strings:
      ``'-Infinity'``, ``'Infinity'``, or ``'NaN'``.
      This can be used to raise an exception
      if invalid JSON numbers are encountered.
      Default ``None``.
   :type parse_constant: :term:`callable` | None

   :raises JSONDecodeError:
      When the data being deserialized is not a valid JSON document.

   :raises UnicodeDecodeError:
      When the data being deserialized does not contain
      UTF-8, UTF-16 or UTF-32 encoded data.

   .. versionchanged:: 3.1

      * Added the optional *object_pairs_hook* parameter.
      * *parse_constant* doesn't get called on 'null', 'true', 'false' anymore.

   .. versionchanged:: 3.6

      * All optional parameters are now :ref:`keyword-only <keyword-only_parameter>`.
      * *fp* can now be a :term:`binary file`.
        The input encoding should be UTF-8, UTF-16 or UTF-32.

   .. versionchanged:: 3.11
      The default *parse_int* of :func:`int` now limits the maximum length of
      the integer string via the interpreter's :ref:`integer string
      conversion length limitation <int_max_str_digits>` to help avoid denial
      of service attacks.

.. function:: loads(s, *, cls=None, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, object_pairs_hook=None, **kw)

   Identical to :func:`load`, but instead of a file-like object,
   deserialize *s* (a :class:`str`, :class:`bytes` or :class:`bytearray`
   instance containing a JSON document) to a Python object using this
   :ref:`conversion table <json-to-py-table>`.

   .. versionchanged:: 3.6
      *s* can now be of type :class:`bytes` or :class:`bytearray`. The
      input encoding should be UTF-8, UTF-16 or UTF-32.

   .. versionchanged:: 3.9
      The keyword argument *encoding* has been removed.


Encoders and Decoders
---------------------

.. class:: JSONDecoder(*, object_hook=None, parse_float=None, parse_int=None, parse_constant=None, strict=True, object_pairs_hook=None)

   Simple JSON decoder.

   Performs the following translations in decoding by default:

   .. _json-to-py-table:

   +---------------+-------------------+
   | JSON          | Python            |
   +===============+===================+
   | object        | dict              |
   +---------------+-------------------+
   | array         | list              |
   +---------------+-------------------+
   | string        | str               |
   +---------------+-------------------+
   | number (int)  | int               |
   +---------------+-------------------+
   | number (real) | float             |
   +---------------+-------------------+
   | true          | True              |
   +---------------+-------------------+
   | false         | False             |
   +---------------+-------------------+
   | null          | None              |
   +---------------+-------------------+

   It also understands ``NaN``, ``Infinity``, and ``-Infinity`` as their
   corresponding ``float`` values, which is outside the JSON spec.

   *object_hook* is an optional function that will be called with the result of
   every JSON object decoded and its return value will be used in place of the
   given :class:`dict`.  This can be used to provide custom deserializations
   (e.g. to support `JSON-RPC <https://www.jsonrpc.org>`_ class hinting).

   *object_pairs_hook* is an optional function that will be called with the
   result of every JSON object decoded with an ordered list of pairs.  The
   return value of *object_pairs_hook* will be used instead of the
   :class:`dict`.  This feature can be used to implement custom decoders.  If
   *object_hook* is also defined, the *object_pairs_hook* takes priority.

   .. versionchanged:: 3.1
      Added support for *object_pairs_hook*.

   *parse_float* is an optional function that will be called with the string of
   every JSON float to be decoded.  By default, this is equivalent to
   ``float(num_str)``.  This can be used to use another datatype or parser for
   JSON floats (e.g. :class:`decimal.Decimal`).

   *parse_int* is an optional function that will be called with the string of
   every JSON int to be decoded.  By default, this is equivalent to
   ``int(num_str)``.  This can be used to use another datatype or parser for
   JSON integers (e.g. :class:`float`).

   *parse_constant* is an optional function that will be called with one of the
   following strings: ``'-Infinity'``, ``'Infinity'``, ``'NaN'``.  This can be
   used to raise an exception if invalid JSON numbers are encountered.

   If *strict* is false (``True`` is the default), then control characters
   will be allowed inside strings.  Control characters in this context are
   those with character codes in the 0--31 range, including ``'\t'`` (tab),
   ``'\n'``, ``'\r'`` and ``'\0'``.

   If the data being deserialized is not a valid JSON document, a
   :exc:`JSONDecodeError` will be raised.

   .. versionchanged:: 3.6
      All parameters are now :ref:`keyword-only <keyword-only_parameter>`.

   .. method:: decode(s)

      Return the Python representation of *s* (a :class:`str` instance
      containing a JSON document).

      :exc:`JSONDecodeError` will be raised if the given JSON document is not
      valid.

   .. method:: raw_decode(s)

      Decode a JSON document from *s* (a :class:`str` beginning with a
      JSON document) and return a 2-tuple of the Python representation
      and the index in *s* where the document ended.

      This can be used to decode a JSON document from a string that may have
      extraneous data at the end.


.. class:: JSONEncoder(*, skipkeys=False, ensure_ascii=True, check_circular=True, allow_nan=True, sort_keys=False, indent=None, separators=None, default=None)

   Extensible JSON encoder for Python data structures.

   Supports the following objects and types by default:

   .. _py-to-json-table:

   +----------------------------------------+---------------+
   | Python                                 | JSON          |
   +========================================+===============+
   | dict                                   | object        |
   +----------------------------------------+---------------+
   | list, tuple                            | array         |
   +----------------------------------------+---------------+
   | str                                    | string        |
   +----------------------------------------+---------------+
   | int, float, int- & float-derived Enums | number        |
   +----------------------------------------+---------------+
   | True                                   | true          |
   +----------------------------------------+---------------+
   | False                                  | false         |
   +----------------------------------------+---------------+
   | None                                   | null          |
   +----------------------------------------+---------------+

   .. versionchanged:: 3.4
      Added support for int- and float-derived Enum classes.

   To extend this to recognize other objects, subclass and implement a
   :meth:`~JSONEncoder.default` method with another method that returns a serializable object
   for ``o`` if possible, otherwise it should call the superclass implementation
   (to raise :exc:`TypeError`).

   If *skipkeys* is false (the default), a :exc:`TypeError` will be raised when
   trying to encode keys that are not :class:`str`, :class:`int`, :class:`float`
   or ``None``.  If *skipkeys* is true, such items are simply skipped.

   If *ensure_ascii* is true (the default), the output is guaranteed to
   have all incoming non-ASCII characters escaped.  If *ensure_ascii* is
   false, these characters will be output as-is.

   If *check_circular* is true (the default), then lists, dicts, and custom
   encoded objects will be checked for circular references during encoding to
   prevent an infinite recursion (which would cause a :exc:`RecursionError`).
   Otherwise, no such check takes place.

   If *allow_nan* is true (the default), then ``NaN``, ``Infinity``, and
   ``-Infinity`` will be encoded as such.  This behavior is not JSON
   specification compliant, but is consistent with most JavaScript based
   encoders and decoders.  Otherwise, it will be a :exc:`ValueError` to encode
   such floats.

   If *sort_keys* is true (default: ``False``), then the output of dictionaries
   will be sorted by key; this is useful for regression tests to ensure that
   JSON serializations can be compared on a day-to-day basis.

   If *indent* is a non-negative integer or string, then JSON array elements and
   object members will be pretty-printed with that indent level.  An indent level
   of 0, negative, or ``""`` will only insert newlines.  ``None`` (the default)
   selects the most compact representation. Using a positive integer indent
   indents that many spaces per level.  If *indent* is a string (such as ``"\t"``),
   that string is used to indent each level.

   .. versionchanged:: 3.2
      Allow strings for *indent* in addition to integers.

   If specified, *separators* should be an ``(item_separator, key_separator)``
   tuple.  The default is ``(', ', ': ')`` if *indent* is ``None`` and
   ``(',', ': ')`` otherwise.  To get the most compact JSON representation,
   you should specify ``(',', ':')`` to eliminate whitespace.

   .. versionchanged:: 3.4
      Use ``(',', ': ')`` as default if *indent* is not ``None``.

   If specified, *default* should be a function that gets called for objects that
   can't otherwise be serialized.  It should return a JSON encodable version of
   the object or raise a :exc:`TypeError`.  If not specified, :exc:`TypeError`
   is raised.

   .. versionchanged:: 3.6
      All parameters are now :ref:`keyword-only <keyword-only_parameter>`.


   .. method:: default(o)

      Implement this method in a subclass such that it returns a serializable
      object for *o*, or calls the base implementation (to raise a
      :exc:`TypeError`).

      For example, to support arbitrary iterators, you could implement
      :meth:`~JSONEncoder.default` like this::

         def default(self, o):
            try:
                iterable = iter(o)
            except TypeError:
                pass
            else:
                return list(iterable)
            # Let the base class default method raise the TypeError
            return super().default(o)


   .. method:: encode(o)

      Return a JSON string representation of a Python data structure, *o*.  For
      example::

        >>> json.JSONEncoder().encode({"foo": ["bar", "baz"]})
        '{"foo": ["bar", "baz"]}'


   .. method:: iterencode(o)

      Encode the given object, *o*, and yield each string representation as
      available.  For example::

            for chunk in json.JSONEncoder().iterencode(bigobject):
                mysocket.write(chunk)


Exceptions
----------

.. exception:: JSONDecodeError(msg, doc, pos)

   Subclass of :exc:`ValueError` with the following additional attributes:

   .. attribute:: msg

      The unformatted error message.

   .. attribute:: doc

      The JSON document being parsed.

   .. attribute:: pos

      The start index of *doc* where parsing failed.

   .. attribute:: lineno

      The line corresponding to *pos*.

   .. attribute:: colno

      The column corresponding to *pos*.

   .. versionadded:: 3.5


Standard Compliance and Interoperability
----------------------------------------

The JSON format is specified by :rfc:`7159` and by
`ECMA-404 <https://ecma-international.org/publications-and-standards/standards/ecma-404/>`_.
This section details this module's level of compliance with the RFC.
For simplicity, :class:`JSONEncoder` and :class:`JSONDecoder` subclasses, and
parameters other than those explicitly mentioned, are not considered.

This module does not comply with the RFC in a strict fashion, implementing some
extensions that are valid JavaScript but not valid JSON.  In particular:

- Infinite and NaN number values are accepted and output;
- Repeated names within an object are accepted, and only the value of the last
  name-value pair is used.

Since the RFC permits RFC-compliant parsers to accept input texts that are not
RFC-compliant, this module's deserializer is technically RFC-compliant under
default settings.

Character Encodings
^^^^^^^^^^^^^^^^^^^

The RFC requires that JSON be represented using either UTF-8, UTF-16, or
UTF-32, with UTF-8 being the recommended default for maximum interoperability.

As permitted, though not required, by the RFC, this module's serializer sets
*ensure_ascii=True* by default, thus escaping the output so that the resulting
strings only contain ASCII characters.

Other than the *ensure_ascii* parameter, this module is defined strictly in
terms of conversion between Python objects and
:class:`Unicode strings <str>`, and thus does not otherwise directly address
the issue of character encodings.

The RFC prohibits adding a byte order mark (BOM) to the start of a JSON text,
and this module's serializer does not add a BOM to its output.
The RFC permits, but does not require, JSON deserializers to ignore an initial
BOM in their input.  This module's deserializer raises a :exc:`ValueError`
when an initial BOM is present.

The RFC does not explicitly forbid JSON strings which contain byte sequences
that don't correspond to valid Unicode characters (e.g. unpaired UTF-16
surrogates), but it does note that they may cause interoperability problems.
By default, this module accepts and outputs (when present in the original
:class:`str`) code points for such sequences.


Infinite and NaN Number Values
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The RFC does not permit the representation of infinite or NaN number values.
Despite that, by default, this module accepts and outputs ``Infinity``,
``-Infinity``, and ``NaN`` as if they were valid JSON number literal values::

   >>> # Neither of these calls raises an exception, but the results are not valid JSON
   >>> json.dumps(float('-inf'))
   '-Infinity'
   >>> json.dumps(float('nan'))
   'NaN'
   >>> # Same when deserializing
   >>> json.loads('-Infinity')
   -inf
   >>> json.loads('NaN')
   nan

In the serializer, the *allow_nan* parameter can be used to alter this
behavior.  In the deserializer, the *parse_constant* parameter can be used to
alter this behavior.


Repeated Names Within an Object
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The RFC specifies that the names within a JSON object should be unique, but
does not mandate how repeated names in JSON objects should be handled.  By
default, this module does not raise an exception; instead, it ignores all but
the last name-value pair for a given name::

   >>> weird_json = '{"x": 1, "x": 2, "x": 3}'
   >>> json.loads(weird_json)
   {'x': 3}

The *object_pairs_hook* parameter can be used to alter this behavior.


Top-level Non-Object, Non-Array Values
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The old version of JSON specified by the obsolete :rfc:`4627` required that
the top-level value of a JSON text must be either a JSON object or array
(Python :class:`dict` or :class:`list`), and could not be a JSON null,
boolean, number, or string value.  :rfc:`7159` removed that restriction, and
this module does not and has never implemented that restriction in either its
serializer or its deserializer.

Regardless, for maximum interoperability, you may wish to voluntarily adhere
to the restriction yourself.


Implementation Limitations
^^^^^^^^^^^^^^^^^^^^^^^^^^

Some JSON deserializer implementations may set limits on:

* the size of accepted JSON texts
* the maximum level of nesting of JSON objects and arrays
* the range and precision of JSON numbers
* the content and maximum length of JSON strings

This module does not impose any such limits beyond those of the relevant
Python datatypes themselves or the Python interpreter itself.

When serializing to JSON, beware any such limitations in applications that may
consume your JSON.  In particular, it is common for JSON numbers to be
deserialized into IEEE 754 double precision numbers and thus subject to that
representation's range and precision limitations.  This is especially relevant
when serializing Python :class:`int` values of extremely large magnitude, or
when serializing instances of "exotic" numerical types such as
:class:`decimal.Decimal`.


.. _json-commandline:
.. program:: json

Command-line interface
----------------------

.. module:: json.tool
    :synopsis: A command-line interface to validate and pretty-print JSON.

**Source code:** :source:`Lib/json/tool.py`

--------------

The :mod:`json` module can be invoked as a script via ``python -m json``
to validate and pretty-print JSON objects. The :mod:`json.tool` submodule
implements this interface.

If the optional ``infile`` and ``outfile`` arguments are not
specified, :data:`sys.stdin` and :data:`sys.stdout` will be used respectively:

.. code-block:: shell-session

    $ echo '{"json": "obj"}' | python -m json
    {
        "json": "obj"
    }
    $ echo '{1.2:3.4}' | python -m json
    Expecting property name enclosed in double quotes: line 1 column 2 (char 1)

.. versionchanged:: 3.5
   The output is now in the same order as the input. Use the
   :option:`--sort-keys` option to sort the output of dictionaries
   alphabetically by key.

.. versionchanged:: 3.14
   The :mod:`json` module may now be directly executed as
   ``python -m json``. For backwards compatibility, invoking
   the CLI as ``python -m json.tool`` remains supported.


Command-line options
^^^^^^^^^^^^^^^^^^^^

.. option:: infile

   The JSON file to be validated or pretty-printed:

   .. code-block:: shell-session

      $ python -m json mp_films.json
      [
          {
              "title": "And Now for Something Completely Different",
              "year": 1971
          },
          {
              "title": "Monty Python and the Holy Grail",
              "year": 1975
          }
      ]

   If *infile* is not specified, read from :data:`sys.stdin`.

.. option:: outfile

   Write the output of the *infile* to the given *outfile*. Otherwise, write it
   to :data:`sys.stdout`.

.. option:: --sort-keys

   Sort the output of dictionaries alphabetically by key.

   .. versionadded:: 3.5

.. option:: --no-ensure-ascii

   Disable escaping of non-ascii characters, see :func:`json.dumps` for more information.

   .. versionadded:: 3.9

.. option:: --json-lines

   Parse every input line as separate JSON object.

   .. versionadded:: 3.8

.. option:: --indent, --tab, --no-indent, --compact

   Mutually exclusive options for whitespace control.

   .. versionadded:: 3.9

.. option:: -h, --help

   Show the help message.


.. rubric:: Footnotes

.. [#rfc-errata] As noted in `the errata for RFC 7159
   <https://www.rfc-editor.org/errata_search.php?rfc=7159>`_,
   JSON permits literal U+2028 (LINE SEPARATOR) and
   U+2029 (PARAGRAPH SEPARATOR) characters in strings, whereas JavaScript
   (as of ECMAScript Edition 5.1) does not.


================================================
File: /Doc/library/keyword.rst
================================================
:mod:`!keyword` --- Testing for Python keywords
===============================================

.. module:: keyword
   :synopsis: Test whether a string is a keyword in Python.

**Source code:** :source:`Lib/keyword.py`

--------------

This module allows a Python program to determine if a string is a
:ref:`keyword <keywords>` or :ref:`soft keyword <soft-keywords>`.


.. function:: iskeyword(s)

   Return ``True`` if *s* is a Python :ref:`keyword <keywords>`.


.. data:: kwlist

   Sequence containing all the :ref:`keywords <keywords>` defined for the
   interpreter.  If any keywords are defined to only be active when particular
   :mod:`__future__` statements are in effect, these will be included as well.


.. function:: issoftkeyword(s)

   Return ``True`` if *s* is a Python :ref:`soft keyword <soft-keywords>`.

   .. versionadded:: 3.9


.. data:: softkwlist

   Sequence containing all the :ref:`soft keywords <soft-keywords>` defined for the
   interpreter.  If any soft keywords are defined to only be active when particular
   :mod:`__future__` statements are in effect, these will be included as well.

   .. versionadded:: 3.9


================================================
File: /Doc/library/language.rst
================================================
.. _language:

************************
Python Language Services
************************

Python provides a number of modules to assist in working with the Python
language.  These modules support tokenizing, parsing, syntax analysis, bytecode
disassembly, and various other facilities.

These modules include:


.. toctree::

   ast.rst
   symtable.rst
   token.rst
   keyword.rst
   tokenize.rst
   tabnanny.rst
   pyclbr.rst
   py_compile.rst
   compileall.rst
   dis.rst
   pickletools.rst


================================================
File: /Doc/library/linecache.rst
================================================
:mod:`!linecache` --- Random access to text lines
=================================================

.. module:: linecache
   :synopsis: Provides random access to individual lines from text files.

.. sectionauthor:: Moshe Zadka <moshez@zadka.site.co.il>

**Source code:** :source:`Lib/linecache.py`

--------------

The :mod:`linecache` module allows one to get any line from a Python source file, while
attempting to optimize internally, using a cache, the common case where many
lines are read from a single file.  This is used by the :mod:`traceback` module
to retrieve source lines for inclusion in  the formatted traceback.

The :func:`tokenize.open` function is used to open files. This
function uses :func:`tokenize.detect_encoding` to get the encoding of the
file; in the absence of an encoding token, the file encoding defaults to UTF-8.

The :mod:`linecache` module defines the following functions:


.. function:: getline(filename, lineno, module_globals=None)

   Get line *lineno* from file named *filename*. This function will never raise an
   exception --- it will return ``''`` on errors (the terminating newline character
   will be included for lines that are found).

   .. index:: triple: module; search; path

   If a file named *filename* is not found, the function first checks
   for a :pep:`302` ``__loader__`` in *module_globals*.
   If there is such a loader and it defines a ``get_source`` method,
   then that determines the source lines
   (if ``get_source()`` returns ``None``, then ``''`` is returned).
   Finally, if *filename* is a relative filename,
   it is looked up relative to the entries in the module search path, ``sys.path``.


.. function:: clearcache()

   Clear the cache.  Use this function if you no longer need lines from files
   previously read using :func:`getline`.


.. function:: checkcache(filename=None)

   Check the cache for validity.  Use this function if files in the cache  may have
   changed on disk, and you require the updated version.  If *filename* is omitted,
   it will check all the entries in the cache.

.. function:: lazycache(filename, module_globals)

   Capture enough detail about a non-file-based module to permit getting its
   lines later via :func:`getline` even if *module_globals* is ``None`` in the later
   call. This avoids doing I/O until a line is actually needed, without having
   to carry the module globals around indefinitely.

   .. versionadded:: 3.5

Example::

   >>> import linecache
   >>> linecache.getline(linecache.__file__, 8)
   'import sys\n'


================================================
File: /Doc/library/locale.rst
================================================
:mod:`!locale` --- Internationalization services
================================================

.. module:: locale
   :synopsis: Internationalization services.

.. moduleauthor:: Martin von Lwis <martin@v.loewis.de>
.. sectionauthor:: Martin von Lwis <martin@v.loewis.de>

**Source code:** :source:`Lib/locale.py`

--------------

The :mod:`locale` module opens access to the POSIX locale database and
functionality. The POSIX locale mechanism allows programmers to deal with
certain cultural issues in an application, without requiring the programmer to
know all the specifics of each country where the software is executed.

.. index:: pair: module; _locale

The :mod:`locale` module is implemented on top of the :mod:`!_locale` module,
which in turn uses an ANSI C locale implementation if available.

The :mod:`locale` module defines the following exception and functions:


.. exception:: Error

   Exception raised when the locale passed to :func:`setlocale` is not
   recognized.


.. function:: setlocale(category, locale=None)

   If *locale* is given and not ``None``, :func:`setlocale` modifies the locale
   setting for the *category*. The available categories are listed in the data
   description below. *locale* may be a string, or an iterable of two strings
   (language code and encoding). If it's an iterable, it's converted to a locale
   name using the locale aliasing engine. An empty string specifies the user's
   default settings. If the modification of the locale fails, the exception
   :exc:`Error` is raised. If successful, the new locale setting is returned.

   If *locale* is omitted or ``None``, the current setting for *category* is
   returned.

   :func:`setlocale` is not thread-safe on most systems. Applications typically
   start with a call of ::

      import locale
      locale.setlocale(locale.LC_ALL, '')

   This sets the locale for all categories to the user's default setting (typically
   specified in the :envvar:`LANG` environment variable).  If the locale is not
   changed thereafter, using multithreading should not cause problems.


.. function:: localeconv()

   Returns the database of the local conventions as a dictionary. This dictionary
   has the following strings as keys:

   .. tabularcolumns:: |l|l|L|

   +----------------------+-------------------------------------+--------------------------------+
   | Category             | Key                                 | Meaning                        |
   +======================+=====================================+================================+
   | :const:`LC_NUMERIC`  | ``'decimal_point'``                 | Decimal point character.       |
   +----------------------+-------------------------------------+--------------------------------+
   |                      | ``'grouping'``                      | Sequence of numbers specifying |
   |                      |                                     | which relative positions the   |
   |                      |                                     | ``'thousands_sep'`` is         |
   |                      |                                     | expected.  If the sequence is  |
   |                      |                                     | terminated with                |
   |                      |                                     | :const:`CHAR_MAX`, no further  |
   |                      |                                     | grouping is performed. If the  |
   |                      |                                     | sequence terminates with a     |
   |                      |                                     | ``0``,  the last group size is |
   |                      |                                     | repeatedly used.               |
   +----------------------+-------------------------------------+--------------------------------+
   |                      | ``'thousands_sep'``                 | Character used between groups. |
   +----------------------+-------------------------------------+--------------------------------+
   | :const:`LC_MONETARY` | ``'int_curr_symbol'``               | International currency symbol. |
   +----------------------+-------------------------------------+--------------------------------+
   |                      | ``'currency_symbol'``               | Local currency symbol.         |
   +----------------------+-------------------------------------+--------------------------------+
   |                      | ``'p_cs_precedes/n_cs_precedes'``   | Whether the currency symbol    |
   |                      |                                     | precedes the value (for        |
   |                      |                                     | positive resp. negative        |
   |                      |                                     | values).                       |
   +----------------------+-------------------------------------+--------------------------------+
   |                      | ``'p_sep_by_space/n_sep_by_space'`` | Whether the currency symbol is |
   |                      |                                     | separated from the value  by a |
   |                      |                                     | space (for positive resp.      |
   |                      |                                     | negative values).              |
   +----------------------+-------------------------------------+--------------------------------+
   |                      | ``'mon_decimal_point'``             | Decimal point used for         |
   |                      |                                     | monetary values.               |
   +----------------------+-------------------------------------+--------------------------------+
   |                      | ``'frac_digits'``                   | Number of fractional digits    |
   |                      |                                     | used in local formatting of    |
   |                      |                                     | monetary values.               |
   +----------------------+-------------------------------------+--------------------------------+
   |                      | ``'int_frac_digits'``               | Number of fractional digits    |
   |                      |                                     | used in international          |
   |                      |                                     | formatting of monetary values. |
   +----------------------+-------------------------------------+--------------------------------+
   |                      | ``'mon_thousands_sep'``             | Group separator used for       |
   |                      |                                     | monetary values.               |
   +----------------------+-------------------------------------+--------------------------------+
   |                      | ``'mon_grouping'``                  | Equivalent to ``'grouping'``,  |
   |                      |                                     | used for monetary values.      |
   +----------------------+-------------------------------------+--------------------------------+
   |                      | ``'positive_sign'``                 | Symbol used to annotate a      |
   |                      |                                     | positive monetary value.       |
   +----------------------+-------------------------------------+--------------------------------+
   |                      | ``'negative_sign'``                 | Symbol used to annotate a      |
   |                      |                                     | negative monetary value.       |
   +----------------------+-------------------------------------+--------------------------------+
   |                      | ``'p_sign_posn/n_sign_posn'``       | The position of the sign (for  |
   |                      |                                     | positive resp. negative        |
   |                      |                                     | values), see below.            |
   +----------------------+-------------------------------------+--------------------------------+

   All numeric values can be set to :const:`CHAR_MAX` to indicate that there is no
   value specified in this locale.

   The possible values for ``'p_sign_posn'`` and ``'n_sign_posn'`` are given below.

   +--------------+-----------------------------------------+
   | Value        | Explanation                             |
   +==============+=========================================+
   | ``0``        | Currency and value are surrounded by    |
   |              | parentheses.                            |
   +--------------+-----------------------------------------+
   | ``1``        | The sign should precede the value and   |
   |              | currency symbol.                        |
   +--------------+-----------------------------------------+
   | ``2``        | The sign should follow the value and    |
   |              | currency symbol.                        |
   +--------------+-----------------------------------------+
   | ``3``        | The sign should immediately precede the |
   |              | value.                                  |
   +--------------+-----------------------------------------+
   | ``4``        | The sign should immediately follow the  |
   |              | value.                                  |
   +--------------+-----------------------------------------+
   | ``CHAR_MAX`` | Nothing is specified in this locale.    |
   +--------------+-----------------------------------------+

   The function temporarily sets the ``LC_CTYPE`` locale to the ``LC_NUMERIC``
   locale or the ``LC_MONETARY`` locale if locales are different and numeric or
   monetary strings are non-ASCII. This temporary change affects other threads.

   .. versionchanged:: 3.7
      The function now temporarily sets the ``LC_CTYPE`` locale to the
      ``LC_NUMERIC`` locale in some cases.


.. function:: nl_langinfo(option)

   Return some locale-specific information as a string.  This function is not
   available on all systems, and the set of possible options might also vary
   across platforms.  The possible argument values are numbers, for which
   symbolic constants are available in the locale module.

   The :func:`nl_langinfo` function accepts one of the following keys.  Most
   descriptions are taken from the corresponding description in the GNU C
   library.

   .. data:: CODESET

      Get a string with the name of the character encoding used in the
      selected locale.

   .. data:: D_T_FMT

      Get a string that can be used as a format string for :func:`time.strftime` to
      represent date and time in a locale-specific way.

   .. data:: D_FMT

      Get a string that can be used as a format string for :func:`time.strftime` to
      represent a date in a locale-specific way.

   .. data:: T_FMT

      Get a string that can be used as a format string for :func:`time.strftime` to
      represent a time in a locale-specific way.

   .. data:: T_FMT_AMPM

      Get a format string for :func:`time.strftime` to represent time in the am/pm
      format.

   .. data:: DAY_1
             DAY_2
             DAY_3
             DAY_4
             DAY_5
             DAY_6
             DAY_7

      Get the name of the n-th day of the week.

      .. note::

         This follows the US convention of :const:`DAY_1` being Sunday, not the
         international convention (ISO 8601) that Monday is the first day of the
         week.

   .. data:: ABDAY_1
             ABDAY_2
             ABDAY_3
             ABDAY_4
             ABDAY_5
             ABDAY_6
             ABDAY_7

      Get the abbreviated name of the n-th day of the week.

   .. data:: MON_1
             MON_2
             MON_3
             MON_4
             MON_5
             MON_6
             MON_7
             MON_8
             MON_9
             MON_10
             MON_11
             MON_12

      Get the name of the n-th month.

   .. data:: ABMON_1
             ABMON_2
             ABMON_3
             ABMON_4
             ABMON_5
             ABMON_6
             ABMON_7
             ABMON_8
             ABMON_9
             ABMON_10
             ABMON_11
             ABMON_12

      Get the abbreviated name of the n-th month.

   .. data:: RADIXCHAR

      Get the radix character (decimal dot, decimal comma, etc.).

   .. data:: THOUSEP

      Get the separator character for thousands (groups of three digits).

   .. data:: YESEXPR

      Get a regular expression that can be used with the regex function to
      recognize a positive response to a yes/no question.

   .. data:: NOEXPR

      Get a regular expression that can be used with the ``regex(3)`` function to
      recognize a negative response to a yes/no question.

      .. note::

         The regular expressions for :const:`YESEXPR` and
         :const:`NOEXPR` use syntax suitable for the
         ``regex`` function from the C library, which might
         differ from the syntax used in :mod:`re`.

   .. data:: CRNCYSTR

      Get the currency symbol, preceded by "-" if the symbol should appear before
      the value, "+" if the symbol should appear after the value, or "." if the
      symbol should replace the radix character.

   .. data:: ERA

      Get a string which describes how years are counted and displayed for
      each era in a locale.

      Most locales do not define this value.  An example of a locale which does
      define this value is the Japanese one.  In Japan, the traditional
      representation of dates includes the name of the era corresponding to the
      then-emperor's reign.

      Normally it should not be necessary to use this value directly. Specifying
      the ``E`` modifier in their format strings causes the :func:`time.strftime`
      function to use this information.
      The format of the returned string is specified in *The Open Group Base
      Specifications Issue 8*, paragraph `7.3.5.2 LC_TIME C-Language Access
      <https://pubs.opengroup.org/onlinepubs/9799919799/basedefs/V1_chap07.html#tag_07_03_05_02>`_.

   .. data:: ERA_D_T_FMT

      Get a format string for :func:`time.strftime` to represent date and time in a
      locale-specific era-based way.

   .. data:: ERA_D_FMT

      Get a format string for :func:`time.strftime` to represent a date in a
      locale-specific era-based way.

   .. data:: ERA_T_FMT

      Get a format string for :func:`time.strftime` to represent a time in a
      locale-specific era-based way.

   .. data:: ALT_DIGITS

      Get a string consisting of up to 100 semicolon-separated symbols used
      to represent the values 0 to 99 in a locale-specific way.
      In most locales this is an empty string.

   The function temporarily sets the ``LC_CTYPE`` locale to the locale
   of the category that determines the requested value (``LC_TIME``,
   ``LC_NUMERIC``, ``LC_MONETARY`` or ``LC_MESSAGES``) if locales are
   different and the resulting string is non-ASCII.
   This temporary change affects other threads.

   .. versionchanged:: 3.14
      The function now temporarily sets the ``LC_CTYPE`` locale in some cases.


.. function:: getdefaultlocale([envvars])

   Tries to determine the default locale settings and returns them as a tuple of
   the form ``(language code, encoding)``.

   According to POSIX, a program which has not called ``setlocale(LC_ALL, '')``
   runs using the portable ``'C'`` locale.  Calling ``setlocale(LC_ALL, '')`` lets
   it use the default locale as defined by the :envvar:`LANG` variable.  Since we
   do not want to interfere with the current locale setting we thus emulate the
   behavior in the way described above.

   To maintain compatibility with other platforms, not only the :envvar:`LANG`
   variable is tested, but a list of variables given as envvars parameter.  The
   first found to be defined will be used.  *envvars* defaults to the search
   path used in GNU gettext; it must always contain the variable name
   ``'LANG'``.  The GNU gettext search path contains ``'LC_ALL'``,
   ``'LC_CTYPE'``, ``'LANG'`` and ``'LANGUAGE'``, in that order.

   Except for the code ``'C'``, the language code corresponds to :rfc:`1766`.
   *language code* and *encoding* may be ``None`` if their values cannot be
   determined.

   .. deprecated-removed:: 3.11 3.15


.. function:: getlocale(category=LC_CTYPE)

   Returns the current setting for the given locale category as sequence containing
   *language code*, *encoding*. *category* may be one of the :const:`!LC_\*` values
   except :const:`LC_ALL`.  It defaults to :const:`LC_CTYPE`.

   Except for the code ``'C'``, the language code corresponds to :rfc:`1766`.
   *language code* and *encoding* may be ``None`` if their values cannot be
   determined.


.. function:: getpreferredencoding(do_setlocale=True)

   Return the :term:`locale encoding` used for text data, according to user
   preferences.  User preferences are expressed differently on different
   systems, and might not be available programmatically on some systems, so
   this function only returns a guess.

   On some systems, it is necessary to invoke :func:`setlocale` to obtain the
   user preferences, so this function is not thread-safe. If invoking setlocale
   is not necessary or desired, *do_setlocale* should be set to ``False``.

   On Android or if the :ref:`Python UTF-8 Mode <utf8-mode>` is enabled, always
   return ``'utf-8'``, the :term:`locale encoding` and the *do_setlocale*
   argument are ignored.

   The :ref:`Python preinitialization <c-preinit>` configures the LC_CTYPE
   locale. See also the :term:`filesystem encoding and error handler`.

   .. versionchanged:: 3.7
      The function now always returns ``"utf-8"`` on Android or if the
      :ref:`Python UTF-8 Mode <utf8-mode>` is enabled.


.. function:: getencoding()

   Get the current :term:`locale encoding`:

   * On Android and VxWorks, return ``"utf-8"``.
   * On Unix, return the encoding of the current :data:`LC_CTYPE` locale.
     Return ``"utf-8"`` if ``nl_langinfo(CODESET)`` returns an empty string:
     for example, if the current LC_CTYPE locale is not supported.
   * On Windows, return the ANSI code page.

   The :ref:`Python preinitialization <c-preinit>` configures the LC_CTYPE
   locale. See also the :term:`filesystem encoding and error handler`.

   This function is similar to
   :func:`getpreferredencoding(False) <getpreferredencoding>` except this
   function ignores the :ref:`Python UTF-8 Mode <utf8-mode>`.

   .. versionadded:: 3.11


.. function:: normalize(localename)

   Returns a normalized locale code for the given locale name.  The returned locale
   code is formatted for use with :func:`setlocale`.  If normalization fails, the
   original name is returned unchanged.

   If the given encoding is not known, the function defaults to the default
   encoding for the locale code just like :func:`setlocale`.


.. function:: strcoll(string1, string2)

   Compares two strings according to the current :const:`LC_COLLATE` setting. As
   any other compare function, returns a negative, or a positive value, or ``0``,
   depending on whether *string1* collates before or after *string2* or is equal to
   it.


.. function:: strxfrm(string)

   Transforms a string to one that can be used in locale-aware
   comparisons.  For example, ``strxfrm(s1) < strxfrm(s2)`` is
   equivalent to ``strcoll(s1, s2) < 0``.  This function can be used
   when the same string is compared repeatedly, e.g. when collating a
   sequence of strings.


.. function:: format_string(format, val, grouping=False, monetary=False)

   Formats a number *val* according to the current :const:`LC_NUMERIC` setting.
   The format follows the conventions of the ``%`` operator.  For floating-point
   values, the decimal point is modified if appropriate.  If *grouping* is ``True``,
   also takes the grouping into account.

   If *monetary* is true, the conversion uses monetary thousands separator and
   grouping strings.

   Processes formatting specifiers as in ``format % val``, but takes the current
   locale settings into account.

   .. versionchanged:: 3.7
      The *monetary* keyword parameter was added.


.. function:: currency(val, symbol=True, grouping=False, international=False)

   Formats a number *val* according to the current :const:`LC_MONETARY` settings.

   The returned string includes the currency symbol if *symbol* is true, which is
   the default. If *grouping* is ``True`` (which is not the default), grouping is done
   with the value. If *international* is ``True`` (which is not the default), the
   international currency symbol is used.

   .. note::

     This function will not work with the 'C' locale, so you have to set a
     locale via :func:`setlocale` first.


.. function:: str(float)

   Formats a floating-point number using the same format as the built-in function
   ``str(float)``, but takes the decimal point into account.


.. function:: delocalize(string)

    Converts a string into a normalized number string, following the
    :const:`LC_NUMERIC` settings.

    .. versionadded:: 3.5


.. function:: localize(string, grouping=False, monetary=False)

    Converts a normalized number string into a formatted string following the
    :const:`LC_NUMERIC` settings.

    .. versionadded:: 3.10


.. function:: atof(string, func=float)

   Converts a string to a number, following the :const:`LC_NUMERIC` settings,
   by calling *func* on the result of calling :func:`delocalize` on *string*.


.. function:: atoi(string)

   Converts a string to an integer, following the :const:`LC_NUMERIC` conventions.


.. data:: LC_CTYPE

   Locale category for the character type functions.  Most importantly, this
   category defines the text encoding, i.e. how bytes are interpreted as
   Unicode codepoints.  See :pep:`538` and :pep:`540` for how this variable
   might be automatically coerced to ``C.UTF-8`` to avoid issues created by
   invalid settings in containers or incompatible settings passed over remote
   SSH connections.

   Python doesn't internally use locale-dependent character transformation functions
   from ``ctype.h``. Instead, an internal ``pyctype.h`` provides locale-independent
   equivalents like :c:macro:`!Py_TOLOWER`.


.. data:: LC_COLLATE

   Locale category for sorting strings.  The functions :func:`strcoll` and
   :func:`strxfrm` of the :mod:`locale` module are affected.


.. data:: LC_TIME

   Locale category for the formatting of time.  The function :func:`time.strftime`
   follows these conventions.


.. data:: LC_MONETARY

   Locale category for formatting of monetary values.  The available options are
   available from the :func:`localeconv` function.


.. data:: LC_MESSAGES

   Locale category for message display. Python currently does not support
   application specific locale-aware messages.  Messages displayed by the operating
   system, like those returned by :func:`os.strerror` might be affected by this
   category.

   This value may not be available on operating systems not conforming to the
   POSIX standard, most notably Windows.


.. data:: LC_NUMERIC

   Locale category for formatting numbers.  The functions :func:`format_string`,
   :func:`atoi`, :func:`atof` and :func:`.str` of the :mod:`locale` module are
   affected by that category.  All other numeric formatting operations are not
   affected.


.. data:: LC_ALL

   Combination of all locale settings.  If this flag is used when the locale is
   changed, setting the locale for all categories is attempted. If that fails for
   any category, no category is changed at all.  When the locale is retrieved using
   this flag, a string indicating the setting for all categories is returned. This
   string can be later used to restore the settings.


.. data:: CHAR_MAX

   This is a symbolic constant used for different values returned by
   :func:`localeconv`.


Example::

   >>> import locale
   >>> loc = locale.getlocale()  # get current locale
   # use German locale; name might vary with platform
   >>> locale.setlocale(locale.LC_ALL, 'de_DE')
   >>> locale.strcoll('f\xe4n', 'foo')  # compare a string containing an umlaut
   >>> locale.setlocale(locale.LC_ALL, '')   # use user's preferred locale
   >>> locale.setlocale(locale.LC_ALL, 'C')  # use default (C) locale
   >>> locale.setlocale(locale.LC_ALL, loc)  # restore saved locale


Background, details, hints, tips and caveats
--------------------------------------------

The C standard defines the locale as a program-wide property that may be
relatively expensive to change.  On top of that, some implementations are broken
in such a way that frequent locale changes may cause core dumps.  This makes the
locale somewhat painful to use correctly.

Initially, when a program is started, the locale is the ``C`` locale, no matter
what the user's preferred locale is.  There is one exception: the
:data:`LC_CTYPE` category is changed at startup to set the current locale
encoding to the user's preferred locale encoding. The program must explicitly
say that it wants the user's preferred locale settings for other categories by
calling ``setlocale(LC_ALL, '')``.

It is generally a bad idea to call :func:`setlocale` in some library routine,
since as a side effect it affects the entire program.  Saving and restoring it
is almost as bad: it is expensive and affects other threads that happen to run
before the settings have been restored.

If, when coding a module for general use, you need a locale independent version
of an operation that is affected by the locale (such as
certain formats used with :func:`time.strftime`), you will have to find a way to
do it without using the standard library routine.  Even better is convincing
yourself that using locale settings is okay.  Only as a last resort should you
document that your module is not compatible with non-\ ``C`` locale settings.

The only way to perform numeric operations according to the locale is to use the
special functions defined by this module: :func:`atof`, :func:`atoi`,
:func:`format_string`, :func:`.str`.

There is no way to perform case conversions and character classifications
according to the locale.  For (Unicode) text strings these are done according
to the character value only, while for byte strings, the conversions and
classifications are done according to the ASCII value of the byte, and bytes
whose high bit is set (i.e., non-ASCII bytes) are never converted or considered
part of a character class such as letter or whitespace.


.. _embedding-locale:

For extension writers and programs that embed Python
----------------------------------------------------

Extension modules should never call :func:`setlocale`, except to find out what
the current locale is.  But since the return value can only be used portably to
restore it, that is not very useful (except perhaps to find out whether or not
the locale is ``C``).

When Python code uses the :mod:`locale` module to change the locale, this also
affects the embedding application.  If the embedding application doesn't want
this to happen, it should remove the :mod:`!_locale` extension module (which does
all the work) from the table of built-in modules in the :file:`config.c` file,
and make sure that the :mod:`!_locale` module is not accessible as a shared
library.


.. _locale-gettext:

Access to message catalogs
--------------------------

.. function:: gettext(msg)
.. function:: dgettext(domain, msg)
.. function:: dcgettext(domain, msg, category)
.. function:: textdomain(domain)
.. function:: bindtextdomain(domain, dir)
.. function:: bind_textdomain_codeset(domain, codeset)

The locale module exposes the C library's gettext interface on systems that
provide this interface.  It consists of the functions :func:`gettext`,
:func:`dgettext`, :func:`dcgettext`, :func:`textdomain`, :func:`bindtextdomain`,
and :func:`bind_textdomain_codeset`.  These are similar to the same functions in
the :mod:`gettext` module, but use the C library's binary format for message
catalogs, and the C library's search algorithms for locating message catalogs.

Python applications should normally find no need to invoke these functions, and
should use :mod:`gettext` instead.  A known exception to this rule are
applications that link with additional C libraries which internally invoke
C functions ``gettext`` or ``dcgettext``.  For these applications, it may be
necessary to bind the text domain, so that the libraries can properly locate
their message catalogs.


================================================
File: /Doc/library/logging.config.rst
================================================
:mod:`!logging.config` --- Logging configuration
================================================

.. module:: logging.config
   :synopsis: Configuration of the logging module.

.. moduleauthor:: Vinay Sajip <vinay_sajip@red-dove.com>
.. sectionauthor:: Vinay Sajip <vinay_sajip@red-dove.com>

**Source code:** :source:`Lib/logging/config.py`

.. sidebar:: Important

   This page contains only reference information. For tutorials,
   please see

   * :ref:`Basic Tutorial <logging-basic-tutorial>`
   * :ref:`Advanced Tutorial <logging-advanced-tutorial>`
   * :ref:`Logging Cookbook <logging-cookbook>`

--------------

This section describes the API for configuring the logging module.

.. _logging-config-api:

Configuration functions
^^^^^^^^^^^^^^^^^^^^^^^

The following functions configure the logging module. They are located in the
:mod:`logging.config` module.  Their use is optional --- you can configure the
logging module using these functions or by making calls to the main API (defined
in :mod:`logging` itself) and defining handlers which are declared either in
:mod:`logging` or :mod:`logging.handlers`.

.. function:: dictConfig(config)

   Takes the logging configuration from a dictionary.  The contents of
   this dictionary are described in :ref:`logging-config-dictschema`
   below.

   If an error is encountered during configuration, this function will
   raise a :exc:`ValueError`, :exc:`TypeError`, :exc:`AttributeError`
   or :exc:`ImportError` with a suitably descriptive message.  The
   following is a (possibly incomplete) list of conditions which will
   raise an error:

   * A ``level`` which is not a string or which is a string not
     corresponding to an actual logging level.
   * A ``propagate`` value which is not a boolean.
   * An id which does not have a corresponding destination.
   * A non-existent handler id found during an incremental call.
   * An invalid logger name.
   * Inability to resolve to an internal or external object.

   Parsing is performed by the :class:`DictConfigurator` class, whose
   constructor is passed the dictionary used for configuration, and
   has a :meth:`configure` method.  The :mod:`logging.config` module
   has a callable attribute :attr:`dictConfigClass`
   which is initially set to :class:`DictConfigurator`.
   You can replace the value of :attr:`dictConfigClass` with a
   suitable implementation of your own.

   :func:`dictConfig` calls :attr:`dictConfigClass` passing
   the specified dictionary, and then calls the :meth:`configure` method on
   the returned object to put the configuration into effect::

         def dictConfig(config):
             dictConfigClass(config).configure()

   For example, a subclass of :class:`DictConfigurator` could call
   ``DictConfigurator.__init__()`` in its own :meth:`__init__`, then
   set up custom prefixes which would be usable in the subsequent
   :meth:`configure` call. :attr:`dictConfigClass` would be bound to
   this new subclass, and then :func:`dictConfig` could be called exactly as
   in the default, uncustomized state.

   .. versionadded:: 3.2

.. function:: fileConfig(fname, defaults=None, disable_existing_loggers=True, encoding=None)

   Reads the logging configuration from a :mod:`configparser`\-format file. The
   format of the file should be as described in
   :ref:`logging-config-fileformat`.
   This function can be called several times from an application, allowing an
   end user to select from various pre-canned configurations (if the developer
   provides a mechanism to present the choices and load the chosen
   configuration).

   It will raise :exc:`FileNotFoundError` if the file
   doesn't exist and :exc:`RuntimeError` if the file is invalid or
   empty.

   :param fname: A filename, or a file-like object, or an instance derived
                 from :class:`~configparser.RawConfigParser`. If a
                 :class:`!RawConfigParser`-derived instance is passed, it is used as
                 is. Otherwise, a :class:`~configparser.ConfigParser` is
                 instantiated, and the configuration read by it from the
                 object passed in ``fname``. If that has a :meth:`readline`
                 method, it is assumed to be a file-like object and read using
                 :meth:`~configparser.ConfigParser.read_file`; otherwise,
                 it is assumed to be a filename and passed to
                 :meth:`~configparser.ConfigParser.read`.


   :param defaults: Defaults to be passed to the :class:`!ConfigParser` can be specified
                    in this argument.

   :param disable_existing_loggers: If specified as ``False``, loggers which
                                    exist when this call is made are left
                                    enabled. The default is ``True`` because this
                                    enables old behaviour in a
                                    backward-compatible way. This behaviour is to
                                    disable any existing non-root loggers unless
                                    they or their ancestors are explicitly named
                                    in the logging configuration.

   :param encoding: The encoding used to open file when *fname* is filename.

   .. versionchanged:: 3.4
      An instance of a subclass of :class:`~configparser.RawConfigParser` is
      now accepted as a value for ``fname``. This facilitates:

      * Use of a configuration file where logging configuration is just part
        of the overall application configuration.
      * Use of a configuration read from a file, and then modified by the using
        application (e.g. based on command-line parameters or other aspects
        of the runtime environment) before being passed to ``fileConfig``.

    .. versionchanged:: 3.10
       Added the *encoding* parameter.

    .. versionchanged:: 3.12
       An exception will be thrown if the provided file
       doesn't exist or is invalid or empty.

.. function:: listen(port=DEFAULT_LOGGING_CONFIG_PORT, verify=None)

   Starts up a socket server on the specified port, and listens for new
   configurations. If no port is specified, the module's default
   :const:`DEFAULT_LOGGING_CONFIG_PORT` is used. Logging configurations will be
   sent as a file suitable for processing by :func:`dictConfig` or
   :func:`fileConfig`. Returns a :class:`~threading.Thread` instance on which
   you can call :meth:`~threading.Thread.start` to start the server, and which
   you can :meth:`~threading.Thread.join` when appropriate. To stop the server,
   call :func:`stopListening`.

   The ``verify`` argument, if specified, should be a callable which should
   verify whether bytes received across the socket are valid and should be
   processed. This could be done by encrypting and/or signing what is sent
   across the socket, such that the ``verify`` callable can perform
   signature verification and/or decryption. The ``verify`` callable is called
   with a single argument - the bytes received across the socket - and should
   return the bytes to be processed, or ``None`` to indicate that the bytes should
   be discarded. The returned bytes could be the same as the passed in bytes
   (e.g. when only verification is done), or they could be completely different
   (perhaps if decryption were performed).

   To send a configuration to the socket, read in the configuration file and
   send it to the socket as a sequence of bytes preceded by a four-byte length
   string packed in binary using ``struct.pack('>L', n)``.

   .. _logging-eval-security:

   .. note::

      Because portions of the configuration are passed through
      :func:`eval`, use of this function may open its users to a security risk.
      While the function only binds to a socket on ``localhost``, and so does
      not accept connections from remote machines, there are scenarios where
      untrusted code could be run under the account of the process which calls
      :func:`listen`. Specifically, if the process calling :func:`listen` runs
      on a multi-user machine where users cannot trust each other, then a
      malicious user could arrange to run essentially arbitrary code in a
      victim user's process, simply by connecting to the victim's
      :func:`listen` socket and sending a configuration which runs whatever
      code the attacker wants to have executed in the victim's process. This is
      especially easy to do if the default port is used, but not hard even if a
      different port is used. To avoid the risk of this happening, use the
      ``verify`` argument to :func:`listen` to prevent unrecognised
      configurations from being applied.

   .. versionchanged:: 3.4
      The ``verify`` argument was added.

   .. note::

      If you want to send configurations to the listener which don't
      disable existing loggers, you will need to use a JSON format for
      the configuration, which will use :func:`dictConfig` for configuration.
      This method allows you to specify ``disable_existing_loggers`` as
      ``False`` in the configuration you send.


.. function:: stopListening()

   Stops the listening server which was created with a call to :func:`listen`.
   This is typically called before calling :meth:`join` on the return value from
   :func:`listen`.


Security considerations
^^^^^^^^^^^^^^^^^^^^^^^

The logging configuration functionality tries to offer convenience, and in part this
is done by offering the ability to convert text in configuration files into Python
objects used in logging configuration - for example, as described in
:ref:`logging-config-dict-userdef`. However, these same mechanisms (importing
callables from user-defined modules and calling them with parameters from the
configuration) could be used to invoke any code you like, and for this reason you
should treat configuration files from untrusted sources with *extreme caution* and
satisfy yourself that nothing bad can happen if you load them, before actually loading
them.


.. _logging-config-dictschema:

Configuration dictionary schema
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Describing a logging configuration requires listing the various
objects to create and the connections between them; for example, you
may create a handler named 'console' and then say that the logger
named 'startup' will send its messages to the 'console' handler.
These objects aren't limited to those provided by the :mod:`logging`
module because you might write your own formatter or handler class.
The parameters to these classes may also need to include external
objects such as ``sys.stderr``.  The syntax for describing these
objects and connections is defined in :ref:`logging-config-dict-connections`
below.

Dictionary Schema Details
"""""""""""""""""""""""""

The dictionary passed to :func:`dictConfig` must contain the following
keys:

* *version* - to be set to an integer value representing the schema
  version.  The only valid value at present is 1, but having this key
  allows the schema to evolve while still preserving backwards
  compatibility.

All other keys are optional, but if present they will be interpreted
as described below.  In all cases below where a 'configuring dict' is
mentioned, it will be checked for the special ``'()'`` key to see if a
custom instantiation is required.  If so, the mechanism described in
:ref:`logging-config-dict-userdef` below is used to create an instance;
otherwise, the context is used to determine what to instantiate.

.. _logging-config-dictschema-formatters:

* *formatters* - the corresponding value will be a dict in which each
  key is a formatter id and each value is a dict describing how to
  configure the corresponding :class:`~logging.Formatter` instance.

  The configuring dict is searched for the following optional keys
  which correspond to the arguments passed to create a
  :class:`~logging.Formatter` object:

  * ``format``
  * ``datefmt``
  * ``style``
  * ``validate`` (since version >=3.8)
  * ``defaults`` (since version >=3.12)

  An optional ``class`` key indicates the name of the formatter's
  class (as a dotted module and class name).  The instantiation
  arguments are as for :class:`~logging.Formatter`, thus this key is
  most useful for instantiating a customised subclass of
  :class:`~logging.Formatter`.  For example, the alternative class
  might present exception tracebacks in an expanded or condensed
  format.  If your formatter requires different or extra configuration
  keys, you should use :ref:`logging-config-dict-userdef`.

* *filters* - the corresponding value will be a dict in which each key
  is a filter id and each value is a dict describing how to configure
  the corresponding Filter instance.

  The configuring dict is searched for the key ``name`` (defaulting to the
  empty string) and this is used to construct a :class:`logging.Filter`
  instance.

* *handlers* - the corresponding value will be a dict in which each
  key is a handler id and each value is a dict describing how to
  configure the corresponding Handler instance.

  The configuring dict is searched for the following keys:

  * ``class`` (mandatory).  This is the fully qualified name of the
    handler class.

  * ``level`` (optional).  The level of the handler.

  * ``formatter`` (optional).  The id of the formatter for this
    handler.

  * ``filters`` (optional).  A list of ids of the filters for this
    handler.

    .. versionchanged:: 3.11
       ``filters`` can take filter instances in addition to ids.

  All *other* keys are passed through as keyword arguments to the
  handler's constructor.  For example, given the snippet:

  .. code-block:: yaml

      handlers:
        console:
          class : logging.StreamHandler
          formatter: brief
          level   : INFO
          filters: [allow_foo]
          stream  : ext://sys.stdout
        file:
          class : logging.handlers.RotatingFileHandler
          formatter: precise
          filename: logconfig.log
          maxBytes: 1024
          backupCount: 3

  the handler with id ``console`` is instantiated as a
  :class:`logging.StreamHandler`, using ``sys.stdout`` as the underlying
  stream.  The handler with id ``file`` is instantiated as a
  :class:`logging.handlers.RotatingFileHandler` with the keyword arguments
  ``filename='logconfig.log', maxBytes=1024, backupCount=3``.

* *loggers* - the corresponding value will be a dict in which each key
  is a logger name and each value is a dict describing how to
  configure the corresponding Logger instance.

  The configuring dict is searched for the following keys:

  * ``level`` (optional).  The level of the logger.

  * ``propagate`` (optional).  The propagation setting of the logger.

  * ``filters`` (optional).  A list of ids of the filters for this
    logger.

    .. versionchanged:: 3.11
       ``filters`` can take filter instances in addition to ids.

  * ``handlers`` (optional).  A list of ids of the handlers for this
    logger.

  The specified loggers will be configured according to the level,
  propagation, filters and handlers specified.

* *root* - this will be the configuration for the root logger.
  Processing of the configuration will be as for any logger, except
  that the ``propagate`` setting will not be applicable.

* *incremental* - whether the configuration is to be interpreted as
  incremental to the existing configuration.  This value defaults to
  ``False``, which means that the specified configuration replaces the
  existing configuration with the same semantics as used by the
  existing :func:`fileConfig` API.

  If the specified value is ``True``, the configuration is processed
  as described in the section on :ref:`logging-config-dict-incremental`.

* *disable_existing_loggers* - whether any existing non-root loggers are
  to be disabled. This setting mirrors the parameter of the same name in
  :func:`fileConfig`. If absent, this parameter defaults to ``True``.
  This value is ignored if *incremental* is ``True``.

.. _logging-config-dict-incremental:

Incremental Configuration
"""""""""""""""""""""""""

It is difficult to provide complete flexibility for incremental
configuration.  For example, because objects such as filters
and formatters are anonymous, once a configuration is set up, it is
not possible to refer to such anonymous objects when augmenting a
configuration.

Furthermore, there is not a compelling case for arbitrarily altering
the object graph of loggers, handlers, filters, formatters at
run-time, once a configuration is set up; the verbosity of loggers and
handlers can be controlled just by setting levels (and, in the case of
loggers, propagation flags).  Changing the object graph arbitrarily in
a safe way is problematic in a multi-threaded environment; while not
impossible, the benefits are not worth the complexity it adds to the
implementation.

Thus, when the ``incremental`` key of a configuration dict is present
and is ``True``, the system will completely ignore any ``formatters`` and
``filters`` entries, and process only the ``level``
settings in the ``handlers`` entries, and the ``level`` and
``propagate`` settings in the ``loggers`` and ``root`` entries.

Using a value in the configuration dict lets configurations to be sent
over the wire as pickled dicts to a socket listener. Thus, the logging
verbosity of a long-running application can be altered over time with
no need to stop and restart the application.

.. _logging-config-dict-connections:

Object connections
""""""""""""""""""

The schema describes a set of logging objects - loggers,
handlers, formatters, filters - which are connected to each other in
an object graph.  Thus, the schema needs to represent connections
between the objects.  For example, say that, once configured, a
particular logger has attached to it a particular handler.  For the
purposes of this discussion, we can say that the logger represents the
source, and the handler the destination, of a connection between the
two.  Of course in the configured objects this is represented by the
logger holding a reference to the handler.  In the configuration dict,
this is done by giving each destination object an id which identifies
it unambiguously, and then using the id in the source object's
configuration to indicate that a connection exists between the source
and the destination object with that id.

So, for example, consider the following YAML snippet:

.. code-block:: yaml

    formatters:
      brief:
        # configuration for formatter with id 'brief' goes here
      precise:
        # configuration for formatter with id 'precise' goes here
    handlers:
      h1: #This is an id
       # configuration of handler with id 'h1' goes here
       formatter: brief
      h2: #This is another id
       # configuration of handler with id 'h2' goes here
       formatter: precise
    loggers:
      foo.bar.baz:
        # other configuration for logger 'foo.bar.baz'
        handlers: [h1, h2]

(Note: YAML used here because it's a little more readable than the
equivalent Python source form for the dictionary.)

The ids for loggers are the logger names which would be used
programmatically to obtain a reference to those loggers, e.g.
``foo.bar.baz``.  The ids for Formatters and Filters can be any string
value (such as ``brief``, ``precise`` above) and they are transient,
in that they are only meaningful for processing the configuration
dictionary and used to determine connections between objects, and are
not persisted anywhere when the configuration call is complete.

The above snippet indicates that logger named ``foo.bar.baz`` should
have two handlers attached to it, which are described by the handler
ids ``h1`` and ``h2``. The formatter for ``h1`` is that described by id
``brief``, and the formatter for ``h2`` is that described by id
``precise``.


.. _logging-config-dict-userdef:

User-defined objects
""""""""""""""""""""

The schema supports user-defined objects for handlers, filters and
formatters.  (Loggers do not need to have different types for
different instances, so there is no support in this configuration
schema for user-defined logger classes.)

Objects to be configured are described by dictionaries
which detail their configuration.  In some places, the logging system
will be able to infer from the context how an object is to be
instantiated, but when a user-defined object is to be instantiated,
the system will not know how to do this.  In order to provide complete
flexibility for user-defined object instantiation, the user needs
to provide a 'factory' - a callable which is called with a
configuration dictionary and which returns the instantiated object.
This is signalled by an absolute import path to the factory being
made available under the special key ``'()'``.  Here's a concrete
example:

.. code-block:: yaml

    formatters:
      brief:
        format: '%(message)s'
      default:
        format: '%(asctime)s %(levelname)-8s %(name)-15s %(message)s'
        datefmt: '%Y-%m-%d %H:%M:%S'
      custom:
          (): my.package.customFormatterFactory
          bar: baz
          spam: 99.9
          answer: 42

The above YAML snippet defines three formatters.  The first, with id
``brief``, is a standard :class:`logging.Formatter` instance with the
specified format string.  The second, with id ``default``, has a
longer format and also defines the time format explicitly, and will
result in a :class:`logging.Formatter` initialized with those two format
strings.  Shown in Python source form, the ``brief`` and ``default``
formatters have configuration sub-dictionaries::

    {
      'format' : '%(message)s'
    }

and::

    {
      'format' : '%(asctime)s %(levelname)-8s %(name)-15s %(message)s',
      'datefmt' : '%Y-%m-%d %H:%M:%S'
    }

respectively, and as these dictionaries do not contain the special key
``'()'``, the instantiation is inferred from the context: as a result,
standard :class:`logging.Formatter` instances are created.  The
configuration sub-dictionary for the third formatter, with id
``custom``, is::

  {
    '()' : 'my.package.customFormatterFactory',
    'bar' : 'baz',
    'spam' : 99.9,
    'answer' : 42
  }

and this contains the special key ``'()'``, which means that
user-defined instantiation is wanted.  In this case, the specified
factory callable will be used. If it is an actual callable it will be
used directly - otherwise, if you specify a string (as in the example)
the actual callable will be located using normal import mechanisms.
The callable will be called with the **remaining** items in the
configuration sub-dictionary as keyword arguments.  In the above
example, the formatter with id ``custom`` will be assumed to be
returned by the call::

    my.package.customFormatterFactory(bar='baz', spam=99.9, answer=42)

.. warning:: The values for keys such as ``bar``, ``spam`` and ``answer`` in
   the above example should not be configuration dictionaries or references such
   as ``cfg://foo`` or ``ext://bar``, because they will not be processed by the
   configuration machinery, but passed to the callable as-is.

The key ``'()'`` has been used as the special key because it is not a
valid keyword parameter name, and so will not clash with the names of
the keyword arguments used in the call.  The ``'()'`` also serves as a
mnemonic that the corresponding value is a callable.

.. versionchanged:: 3.11
   The ``filters`` member of ``handlers`` and ``loggers`` can take
   filter instances in addition to ids.

You can also specify a special key ``'.'`` whose value is a dictionary is a
mapping of attribute names to values. If found, the specified attributes will
be set on the user-defined object before it is returned. Thus, with the
following configuration::

    {
      '()' : 'my.package.customFormatterFactory',
      'bar' : 'baz',
      'spam' : 99.9,
      'answer' : 42,
      '.' {
        'foo': 'bar',
        'baz': 'bozz'
      }
    }

the returned formatter will have attribute ``foo`` set to ``'bar'`` and
attribute ``baz`` set to ``'bozz'``.

.. warning:: The values for attributes such as ``foo`` and ``baz`` in
   the above example should not be configuration dictionaries or references such
   as ``cfg://foo`` or ``ext://bar``, because they will not be processed by the
   configuration machinery, but set as attribute values as-is.


.. _handler-config-dict-order:

Handler configuration order
"""""""""""""""""""""""""""

Handlers are configured in alphabetical order of their keys, and a configured
handler replaces the configuration dictionary in (a working copy of) the
``handlers`` dictionary in the schema. If you use a construct such as
``cfg://handlers.foo``, then initially ``handlers['foo']`` points to the
configuration dictionary for the handler named ``foo``, and later (once that
handler has been configured) it points to the configured handler instance.
Thus, ``cfg://handlers.foo`` could resolve to either a dictionary or a handler
instance. In general, it is wise to name handlers in a way such that dependent
handlers are configured _after_ any handlers they depend on; that allows
something like ``cfg://handlers.foo`` to be used in configuring a handler that
depends on handler ``foo``. If that dependent handler were named ``bar``,
problems would result, because the configuration of ``bar`` would be attempted
before that of ``foo``, and ``foo`` would not yet have been configured.
However, if the dependent handler were named ``foobar``, it would be configured
after ``foo``, with the result that ``cfg://handlers.foo`` would resolve to
configured handler ``foo``, and not its configuration dictionary.


.. _logging-config-dict-externalobj:

Access to external objects
""""""""""""""""""""""""""

There are times where a configuration needs to refer to objects
external to the configuration, for example ``sys.stderr``.  If the
configuration dict is constructed using Python code, this is
straightforward, but a problem arises when the configuration is
provided via a text file (e.g. JSON, YAML).  In a text file, there is
no standard way to distinguish ``sys.stderr`` from the literal string
``'sys.stderr'``.  To facilitate this distinction, the configuration
system looks for certain special prefixes in string values and
treat them specially.  For example, if the literal string
``'ext://sys.stderr'`` is provided as a value in the configuration,
then the ``ext://`` will be stripped off and the remainder of the
value processed using normal import mechanisms.

The handling of such prefixes is done in a way analogous to protocol
handling: there is a generic mechanism to look for prefixes which
match the regular expression ``^(?P<prefix>[a-z]+)://(?P<suffix>.*)$``
whereby, if the ``prefix`` is recognised, the ``suffix`` is processed
in a prefix-dependent manner and the result of the processing replaces
the string value.  If the prefix is not recognised, then the string
value will be left as-is.


.. _logging-config-dict-internalobj:

Access to internal objects
""""""""""""""""""""""""""

As well as external objects, there is sometimes also a need to refer
to objects in the configuration.  This will be done implicitly by the
configuration system for things that it knows about.  For example, the
string value ``'DEBUG'`` for a ``level`` in a logger or handler will
automatically be converted to the value ``logging.DEBUG``, and the
``handlers``, ``filters`` and ``formatter`` entries will take an
object id and resolve to the appropriate destination object.

However, a more generic mechanism is needed for user-defined
objects which are not known to the :mod:`logging` module.  For
example, consider :class:`logging.handlers.MemoryHandler`, which takes
a ``target`` argument which is another handler to delegate to. Since
the system already knows about this class, then in the configuration,
the given ``target`` just needs to be the object id of the relevant
target handler, and the system will resolve to the handler from the
id.  If, however, a user defines a ``my.package.MyHandler`` which has
an ``alternate`` handler, the configuration system would not know that
the ``alternate`` referred to a handler.  To cater for this, a generic
resolution system allows the user to specify:

.. code-block:: yaml

    handlers:
      file:
        # configuration of file handler goes here

      custom:
        (): my.package.MyHandler
        alternate: cfg://handlers.file

The literal string ``'cfg://handlers.file'`` will be resolved in an
analogous way to strings with the ``ext://`` prefix, but looking
in the configuration itself rather than the import namespace.  The
mechanism allows access by dot or by index, in a similar way to
that provided by ``str.format``.  Thus, given the following snippet:

.. code-block:: yaml

    handlers:
      email:
        class: logging.handlers.SMTPHandler
        mailhost: localhost
        fromaddr: my_app@domain.tld
        toaddrs:
          - support_team@domain.tld
          - dev_team@domain.tld
        subject: Houston, we have a problem.

in the configuration, the string ``'cfg://handlers'`` would resolve to
the dict with key ``handlers``, the string ``'cfg://handlers.email``
would resolve to the dict with key ``email`` in the ``handlers`` dict,
and so on.  The string ``'cfg://handlers.email.toaddrs[1]`` would
resolve to ``'dev_team@domain.tld'`` and the string
``'cfg://handlers.email.toaddrs[0]'`` would resolve to the value
``'support_team@domain.tld'``. The ``subject`` value could be accessed
using either ``'cfg://handlers.email.subject'`` or, equivalently,
``'cfg://handlers.email[subject]'``.  The latter form only needs to be
used if the key contains spaces or non-alphanumeric characters. Please note
that the characters ``[`` and ``]`` are not allowed in the keys. If an
index value consists only of decimal digits, access will be attempted
using the corresponding integer value, falling back to the string
value if needed.

Given a string ``cfg://handlers.myhandler.mykey.123``, this will
resolve to ``config_dict['handlers']['myhandler']['mykey']['123']``.
If the string is specified as ``cfg://handlers.myhandler.mykey[123]``,
the system will attempt to retrieve the value from
``config_dict['handlers']['myhandler']['mykey'][123]``, and fall back
to ``config_dict['handlers']['myhandler']['mykey']['123']`` if that
fails.


.. _logging-import-resolution:

Import resolution and custom importers
""""""""""""""""""""""""""""""""""""""

Import resolution, by default, uses the builtin :func:`__import__` function
to do its importing. You may want to replace this with your own importing
mechanism: if so, you can replace the :attr:`importer` attribute of the
:class:`DictConfigurator` or its superclass, the
:class:`BaseConfigurator` class. However, you need to be
careful because of the way functions are accessed from classes via
descriptors. If you are using a Python callable to do your imports, and you
want to define it at class level rather than instance level, you need to wrap
it with :func:`staticmethod`. For example::

   from importlib import import_module
   from logging.config import BaseConfigurator

   BaseConfigurator.importer = staticmethod(import_module)

You don't need to wrap with :func:`staticmethod` if you're setting the import
callable on a configurator *instance*.

.. _configure-queue:

Configuring QueueHandler and QueueListener
""""""""""""""""""""""""""""""""""""""""""

If you want to configure a :class:`~logging.handlers.QueueHandler`, noting that this
is normally used in conjunction with a :class:`~logging.handlers.QueueListener`, you
can configure both together. After the configuration, the ``QueueListener`` instance
will be available as the :attr:`~logging.handlers.QueueHandler.listener` attribute of
the created handler, and that in turn will be available to you using
:func:`~logging.getHandlerByName` and passing the name you have used for the
``QueueHandler`` in your configuration. The dictionary schema for configuring the pair
is shown in the example YAML snippet below.

.. code-block:: yaml

    handlers:
      qhand:
        class: logging.handlers.QueueHandler
        queue: my.module.queue_factory
        listener: my.package.CustomListener
        handlers:
          - hand_name_1
          - hand_name_2
          ...

The ``queue`` and ``listener`` keys are optional.

If the ``queue`` key is present, the corresponding value can be one of the following:

* An object implementing the :meth:`Queue.put_nowait <queue.Queue.put_nowait>`
  and :meth:`Queue.get <queue.Queue.get>` public API. For instance, this may be
  an actual instance of :class:`queue.Queue` or a subclass thereof, or a proxy
  obtained by :meth:`multiprocessing.managers.SyncManager.Queue`.

  This is of course only possible if you are constructing or modifying
  the configuration dictionary in code.

* A string that resolves to a callable which, when called with no arguments, returns
  the queue instance to use. That callable could be a :class:`queue.Queue` subclass
  or a function which returns a suitable queue instance,
  such as ``my.module.queue_factory()``.

* A dict with a ``'()'`` key which is constructed in the usual way as discussed in
  :ref:`logging-config-dict-userdef`. The result of this construction should be a
  :class:`queue.Queue` instance.

If the  ``queue`` key is absent, a standard unbounded :class:`queue.Queue` instance is
created and used.

If the ``listener`` key is present, the corresponding value can be one of the following:

* A subclass of :class:`logging.handlers.QueueListener`. This is of course only
  possible if you are constructing or modifying the configuration dictionary in
  code.

* A string which resolves to a class which is a subclass of ``QueueListener``, such as
  ``'my.package.CustomListener'``.

* A dict with a ``'()'`` key which is constructed in the usual way as discussed in
  :ref:`logging-config-dict-userdef`. The result of this construction should be a
  callable with the same signature as the ``QueueListener`` initializer.

If the ``listener`` key is absent, :class:`logging.handlers.QueueListener` is used.

The values under the ``handlers`` key are the names of other handlers in the
configuration (not shown in the above snippet) which will be passed to the queue
listener.

Any custom queue handler and listener classes will need to be defined with the same
initialization signatures as :class:`~logging.handlers.QueueHandler` and
:class:`~logging.handlers.QueueListener`.

.. versionadded:: 3.12

.. _logging-config-fileformat:

Configuration file format
^^^^^^^^^^^^^^^^^^^^^^^^^

The configuration file format understood by :func:`fileConfig` is based on
:mod:`configparser` functionality. The file must contain sections called
``[loggers]``, ``[handlers]`` and ``[formatters]`` which identify by name the
entities of each type which are defined in the file. For each such entity, there
is a separate section which identifies how that entity is configured.  Thus, for
a logger named ``log01`` in the ``[loggers]`` section, the relevant
configuration details are held in a section ``[logger_log01]``. Similarly, a
handler called ``hand01`` in the ``[handlers]`` section will have its
configuration held in a section called ``[handler_hand01]``, while a formatter
called ``form01`` in the ``[formatters]`` section will have its configuration
specified in a section called ``[formatter_form01]``. The root logger
configuration must be specified in a section called ``[logger_root]``.

.. note::

   The :func:`fileConfig` API is older than the :func:`dictConfig` API and does
   not provide functionality to cover certain aspects of logging. For example,
   you cannot configure :class:`~logging.Filter` objects, which provide for
   filtering of messages beyond simple integer levels, using :func:`fileConfig`.
   If you need to have instances of :class:`~logging.Filter` in your logging
   configuration, you will need to use :func:`dictConfig`. Note that future
   enhancements to configuration functionality will be added to
   :func:`dictConfig`, so it's worth considering transitioning to this newer
   API when it's convenient to do so.

Examples of these sections in the file are given below.

.. code-block:: ini

   [loggers]
   keys=root,log02,log03,log04,log05,log06,log07

   [handlers]
   keys=hand01,hand02,hand03,hand04,hand05,hand06,hand07,hand08,hand09

   [formatters]
   keys=form01,form02,form03,form04,form05,form06,form07,form08,form09

The root logger must specify a level and a list of handlers. An example of a
root logger section is given below.

.. code-block:: ini

   [logger_root]
   level=NOTSET
   handlers=hand01

The ``level`` entry can be one of ``DEBUG, INFO, WARNING, ERROR, CRITICAL`` or
``NOTSET``. For the root logger only, ``NOTSET`` means that all messages will be
logged. Level values are :ref:`evaluated <func-eval>` in the context of the ``logging``
package's namespace.

The ``handlers`` entry is a comma-separated list of handler names, which must
appear in the ``[handlers]`` section. These names must appear in the
``[handlers]`` section and have corresponding sections in the configuration
file.

For loggers other than the root logger, some additional information is required.
This is illustrated by the following example.

.. code-block:: ini

   [logger_parser]
   level=DEBUG
   handlers=hand01
   propagate=1
   qualname=compiler.parser

The ``level`` and ``handlers`` entries are interpreted as for the root logger,
except that if a non-root logger's level is specified as ``NOTSET``, the system
consults loggers higher up the hierarchy to determine the effective level of the
logger. The ``propagate`` entry is set to 1 to indicate that messages must
propagate to handlers higher up the logger hierarchy from this logger, or 0 to
indicate that messages are **not** propagated to handlers up the hierarchy. The
``qualname`` entry is the hierarchical channel name of the logger, that is to
say the name used by the application to get the logger.

Sections which specify handler configuration are exemplified by the following.

.. code-block:: ini

   [handler_hand01]
   class=StreamHandler
   level=NOTSET
   formatter=form01
   args=(sys.stdout,)

The ``class`` entry indicates the handler's class (as determined by :func:`eval`
in the ``logging`` package's namespace). The ``level`` is interpreted as for
loggers, and ``NOTSET`` is taken to mean 'log everything'.

The ``formatter`` entry indicates the key name of the formatter for this
handler. If blank, a default formatter (``logging._defaultFormatter``) is used.
If a name is specified, it must appear in the ``[formatters]`` section and have
a corresponding section in the configuration file.

The ``args`` entry, when :ref:`evaluated <func-eval>` in the context of the ``logging``
package's namespace, is the list of arguments to the constructor for the handler
class. Refer to the constructors for the relevant handlers, or to the examples
below, to see how typical entries are constructed. If not provided, it defaults
to ``()``.

The optional ``kwargs`` entry, when :ref:`evaluated <func-eval>` in the context of the
``logging`` package's namespace, is the keyword argument dict to the constructor
for the handler class. If not provided, it defaults to ``{}``.

.. code-block:: ini

   [handler_hand02]
   class=FileHandler
   level=DEBUG
   formatter=form02
   args=('python.log', 'w')

   [handler_hand03]
   class=handlers.SocketHandler
   level=INFO
   formatter=form03
   args=('localhost', handlers.DEFAULT_TCP_LOGGING_PORT)

   [handler_hand04]
   class=handlers.DatagramHandler
   level=WARN
   formatter=form04
   args=('localhost', handlers.DEFAULT_UDP_LOGGING_PORT)

   [handler_hand05]
   class=handlers.SysLogHandler
   level=ERROR
   formatter=form05
   args=(('localhost', handlers.SYSLOG_UDP_PORT), handlers.SysLogHandler.LOG_USER)

   [handler_hand06]
   class=handlers.NTEventLogHandler
   level=CRITICAL
   formatter=form06
   args=('Python Application', '', 'Application')

   [handler_hand07]
   class=handlers.SMTPHandler
   level=WARN
   formatter=form07
   args=('localhost', 'from@abc', ['user1@abc', 'user2@xyz'], 'Logger Subject')
   kwargs={'timeout': 10.0}

   [handler_hand08]
   class=handlers.MemoryHandler
   level=NOTSET
   formatter=form08
   target=
   args=(10, ERROR)

   [handler_hand09]
   class=handlers.HTTPHandler
   level=NOTSET
   formatter=form09
   args=('localhost:9022', '/log', 'GET')
   kwargs={'secure': True}

Sections which specify formatter configuration are typified by the following.

.. code-block:: ini

   [formatter_form01]
   format=F1 %(asctime)s %(levelname)s %(message)s %(customfield)s
   datefmt=
   style=%
   validate=True
   defaults={'customfield': 'defaultvalue'}
   class=logging.Formatter

The arguments for the formatter configuration are the same as the keys
in the dictionary schema :ref:`formatters section
<logging-config-dictschema-formatters>`.

The ``defaults`` entry, when :ref:`evaluated <func-eval>` in the context of
the ``logging`` package's namespace, is a dictionary of default values for
custom formatting fields. If not provided, it defaults to ``None``.


.. note::

   Due to the use of :func:`eval` as described above, there are
   potential security risks which result from using the :func:`listen` to send
   and receive configurations via sockets. The risks are limited to where
   multiple users with no mutual trust run code on the same machine; see the
   :func:`listen` documentation for more information.

.. seealso::

   Module :mod:`logging`
      API reference for the logging module.

   Module :mod:`logging.handlers`
      Useful handlers included with the logging module.


================================================
File: /Doc/library/logging.handlers.rst
================================================
:mod:`!logging.handlers` --- Logging handlers
=============================================

.. module:: logging.handlers
   :synopsis: Handlers for the logging module.

.. moduleauthor:: Vinay Sajip <vinay_sajip@red-dove.com>
.. sectionauthor:: Vinay Sajip <vinay_sajip@red-dove.com>

**Source code:** :source:`Lib/logging/handlers.py`

.. sidebar:: Important

   This page contains only reference information. For tutorials,
   please see

   * :ref:`Basic Tutorial <logging-basic-tutorial>`
   * :ref:`Advanced Tutorial <logging-advanced-tutorial>`
   * :ref:`Logging Cookbook <logging-cookbook>`

--------------

.. currentmodule:: logging

The following useful handlers are provided in the package. Note that three of
the handlers (:class:`StreamHandler`, :class:`FileHandler` and
:class:`NullHandler`) are actually defined in the :mod:`logging` module itself,
but have been documented here along with the other handlers.

.. _stream-handler:

StreamHandler
^^^^^^^^^^^^^

The :class:`StreamHandler` class, located in the core :mod:`logging` package,
sends logging output to streams such as *sys.stdout*, *sys.stderr* or any
file-like object (or, more precisely, any object which supports :meth:`write`
and :meth:`flush` methods).


.. class:: StreamHandler(stream=None)

   Returns a new instance of the :class:`StreamHandler` class. If *stream* is
   specified, the instance will use it for logging output; otherwise, *sys.stderr*
   will be used.


   .. method:: emit(record)

      If a formatter is specified, it is used to format the record. The record
      is then written to the stream followed by :attr:`terminator`. If exception information
      is present, it is formatted using :func:`traceback.print_exception` and
      appended to the stream.


   .. method:: flush()

      Flushes the stream by calling its :meth:`flush` method. Note that the
      :meth:`close` method is inherited from :class:`~logging.Handler` and so
      does no output, so an explicit :meth:`flush` call may be needed at times.

   .. method:: setStream(stream)

      Sets the instance's stream to the specified value, if it is different.
      The old stream is flushed before the new stream is set.

      :param stream: The stream that the handler should use.

      :return: the old stream, if the stream was changed, or ``None`` if it wasn't.

      .. versionadded:: 3.7

   .. attribute:: terminator

      String used as the terminator when writing a formatted record to a stream.
      Default value is ``'\n'``.

      If you don't want a newline termination, you can set the handler instance's
      ``terminator`` attribute to the empty string.

      In earlier versions, the terminator was hardcoded as ``'\n'``.

      .. versionadded:: 3.2


.. _file-handler:

FileHandler
^^^^^^^^^^^

The :class:`FileHandler` class, located in the core :mod:`logging` package,
sends logging output to a disk file.  It inherits the output functionality from
:class:`StreamHandler`.


.. class:: FileHandler(filename, mode='a', encoding=None, delay=False, errors=None)

   Returns a new instance of the :class:`FileHandler` class. The specified file is
   opened and used as the stream for logging. If *mode* is not specified,
   ``'a'`` is used.  If *encoding* is not ``None``, it is used to open the file
   with that encoding.  If *delay* is true, then file opening is deferred until the
   first call to :meth:`emit`. By default, the file grows indefinitely. If
   *errors* is specified, it's used to determine how encoding errors are handled.

   .. versionchanged:: 3.6
      As well as string values, :class:`~pathlib.Path` objects are also accepted
      for the *filename* argument.

   .. versionchanged:: 3.9
      The *errors* parameter was added.

   .. method:: close()

      Closes the file.

   .. method:: emit(record)

      Outputs the record to the file.

      Note that if the file was closed due to logging shutdown at exit and the file
      mode is 'w', the record will not be emitted (see :issue:`42378`).


.. _null-handler:

NullHandler
^^^^^^^^^^^

.. versionadded:: 3.1

The :class:`NullHandler` class, located in the core :mod:`logging` package,
does not do any formatting or output. It is essentially a 'no-op' handler
for use by library developers.

.. class:: NullHandler()

   Returns a new instance of the :class:`NullHandler` class.

   .. method:: emit(record)

      This method does nothing.

   .. method:: handle(record)

      This method does nothing.

   .. method:: createLock()

      This method returns ``None`` for the lock, since there is no
      underlying I/O to which access needs to be serialized.


See :ref:`library-config` for more information on how to use
:class:`NullHandler`.

.. _watched-file-handler:

WatchedFileHandler
^^^^^^^^^^^^^^^^^^

.. currentmodule:: logging.handlers

The :class:`WatchedFileHandler` class, located in the :mod:`logging.handlers`
module, is a :class:`FileHandler` which watches the file it is logging to. If
the file changes, it is closed and reopened using the file name.

A file change can happen because of usage of programs such as *newsyslog* and
*logrotate* which perform log file rotation. This handler, intended for use
under Unix/Linux, watches the file to see if it has changed since the last emit.
(A file is deemed to have changed if its device or inode have changed.) If the
file has changed, the old file stream is closed, and the file opened to get a
new stream.

This handler is not appropriate for use under Windows, because under Windows
open log files cannot be moved or renamed - logging opens the files with
exclusive locks - and so there is no need for such a handler. Furthermore,
*ST_INO* is not supported under Windows; :func:`~os.stat` always returns zero
for this value.


.. class:: WatchedFileHandler(filename, mode='a', encoding=None, delay=False, errors=None)

   Returns a new instance of the :class:`WatchedFileHandler` class. The specified
   file is opened and used as the stream for logging. If *mode* is not specified,
   ``'a'`` is used.  If *encoding* is not ``None``, it is used to open the file
   with that encoding.  If *delay* is true, then file opening is deferred until the
   first call to :meth:`emit`.  By default, the file grows indefinitely. If
   *errors* is provided, it determines how encoding errors are handled.

   .. versionchanged:: 3.6
      As well as string values, :class:`~pathlib.Path` objects are also accepted
      for the *filename* argument.

   .. versionchanged:: 3.9
      The *errors* parameter was added.

   .. method:: reopenIfNeeded()

      Checks to see if the file has changed.  If it has, the existing stream is
      flushed and closed and the file opened again, typically as a precursor to
      outputting the record to the file.

      .. versionadded:: 3.6


   .. method:: emit(record)

      Outputs the record to the file, but first calls :meth:`reopenIfNeeded` to
      reopen the file if it has changed.

.. _base-rotating-handler:

BaseRotatingHandler
^^^^^^^^^^^^^^^^^^^

The :class:`BaseRotatingHandler` class, located in the :mod:`logging.handlers`
module, is the base class for the rotating file handlers,
:class:`RotatingFileHandler` and :class:`TimedRotatingFileHandler`. You should
not need to instantiate this class, but it has attributes and methods you may
need to override.

.. class:: BaseRotatingHandler(filename, mode, encoding=None, delay=False, errors=None)

   The parameters are as for :class:`FileHandler`. The attributes are:

   .. attribute:: namer

      If this attribute is set to a callable, the :meth:`rotation_filename`
      method delegates to this callable. The parameters passed to the callable
      are those passed to :meth:`rotation_filename`.

      .. note:: The namer function is called quite a few times during rollover,
         so it should be as simple and as fast as possible. It should also
         return the same output every time for a given input, otherwise the
         rollover behaviour may not work as expected.

         It's also worth noting that care should be taken when using a namer to
         preserve certain attributes in the filename which are used during rotation.
         For example, :class:`RotatingFileHandler` expects to have a set of log files
         whose names contain successive integers, so that rotation works as expected,
         and :class:`TimedRotatingFileHandler` deletes old log files (based on the
         ``backupCount`` parameter passed to the handler's initializer) by determining
         the oldest files to delete. For this to happen, the filenames should be
         sortable using the date/time portion of the filename, and a namer needs to
         respect this. (If a namer is wanted that doesn't respect this scheme, it will
         need to be used in a subclass of :class:`TimedRotatingFileHandler` which
         overrides the :meth:`~TimedRotatingFileHandler.getFilesToDelete` method to
         fit in with the custom naming scheme.)

      .. versionadded:: 3.3


   .. attribute:: BaseRotatingHandler.rotator

      If this attribute is set to a callable, the :meth:`rotate` method
      delegates to this callable.  The parameters passed to the callable are
      those passed to :meth:`rotate`.

      .. versionadded:: 3.3

   .. method:: BaseRotatingHandler.rotation_filename(default_name)

      Modify the filename of a log file when rotating.

      This is provided so that a custom filename can be provided.

      The default implementation calls the 'namer' attribute of the handler,
      if it's callable, passing the default name to it. If the attribute isn't
      callable (the default is ``None``), the name is returned unchanged.

      :param default_name: The default name for the log file.

      .. versionadded:: 3.3


   .. method:: BaseRotatingHandler.rotate(source, dest)

      When rotating, rotate the current log.

      The default implementation calls the 'rotator' attribute of the handler,
      if it's callable, passing the source and dest arguments to it. If the
      attribute isn't callable (the default is ``None``), the source is simply
      renamed to the destination.

      :param source: The source filename. This is normally the base
                     filename, e.g. 'test.log'.
      :param dest:   The destination filename. This is normally
                     what the source is rotated to, e.g. 'test.log.1'.

      .. versionadded:: 3.3

The reason the attributes exist is to save you having to subclass - you can use
the same callables for instances of :class:`RotatingFileHandler` and
:class:`TimedRotatingFileHandler`. If either the namer or rotator callable
raises an exception, this will be handled in the same way as any other
exception during an :meth:`emit` call, i.e. via the :meth:`handleError` method
of the handler.

If you need to make more significant changes to rotation processing, you can
override the methods.

For an example, see :ref:`cookbook-rotator-namer`.


.. _rotating-file-handler:

RotatingFileHandler
^^^^^^^^^^^^^^^^^^^

The :class:`RotatingFileHandler` class, located in the :mod:`logging.handlers`
module, supports rotation of disk log files.


.. class:: RotatingFileHandler(filename, mode='a', maxBytes=0, backupCount=0, encoding=None, delay=False, errors=None)

   Returns a new instance of the :class:`RotatingFileHandler` class. The specified
   file is opened and used as the stream for logging. If *mode* is not specified,
   ``'a'`` is used.  If *encoding* is not ``None``, it is used to open the file
   with that encoding.  If *delay* is true, then file opening is deferred until the
   first call to :meth:`emit`.  By default, the file grows indefinitely. If
   *errors* is provided, it determines how encoding errors are handled.

   You can use the *maxBytes* and *backupCount* values to allow the file to
   :dfn:`rollover` at a predetermined size. When the size is about to be exceeded,
   the file is closed and a new file is silently opened for output. Rollover occurs
   whenever the current log file is nearly *maxBytes* in length; but if either of
   *maxBytes* or *backupCount* is zero, rollover never occurs, so you generally want
   to set *backupCount* to at least 1, and have a non-zero *maxBytes*.
   When *backupCount* is non-zero, the system will save old log files by appending
   the extensions '.1', '.2' etc., to the filename. For example, with a *backupCount*
   of 5 and a base file name of :file:`app.log`, you would get :file:`app.log`,
   :file:`app.log.1`, :file:`app.log.2`, up to :file:`app.log.5`. The file being
   written to is always :file:`app.log`.  When this file is filled, it is closed
   and renamed to :file:`app.log.1`, and if files :file:`app.log.1`,
   :file:`app.log.2`, etc. exist, then they are renamed to :file:`app.log.2`,
   :file:`app.log.3` etc. respectively.

   .. versionchanged:: 3.6
      As well as string values, :class:`~pathlib.Path` objects are also accepted
      for the *filename* argument.

   .. versionchanged:: 3.9
      The *errors* parameter was added.

   .. method:: doRollover()

      Does a rollover, as described above.


   .. method:: emit(record)

      Outputs the record to the file, catering for rollover as described
      previously.

.. _timed-rotating-file-handler:

TimedRotatingFileHandler
^^^^^^^^^^^^^^^^^^^^^^^^

The :class:`TimedRotatingFileHandler` class, located in the
:mod:`logging.handlers` module, supports rotation of disk log files at certain
timed intervals.


.. class:: TimedRotatingFileHandler(filename, when='h', interval=1, backupCount=0, encoding=None, delay=False, utc=False, atTime=None, errors=None)

   Returns a new instance of the :class:`TimedRotatingFileHandler` class. The
   specified file is opened and used as the stream for logging. On rotating it also
   sets the filename suffix. Rotating happens based on the product of *when* and
   *interval*.

   You can use the *when* to specify the type of *interval*. The list of possible
   values is below.  Note that they are not case sensitive.

   +----------------+----------------------------+-------------------------+
   | Value          | Type of interval           | If/how *atTime* is used |
   +================+============================+=========================+
   | ``'S'``        | Seconds                    | Ignored                 |
   +----------------+----------------------------+-------------------------+
   | ``'M'``        | Minutes                    | Ignored                 |
   +----------------+----------------------------+-------------------------+
   | ``'H'``        | Hours                      | Ignored                 |
   +----------------+----------------------------+-------------------------+
   | ``'D'``        | Days                       | Ignored                 |
   +----------------+----------------------------+-------------------------+
   | ``'W0'-'W6'``  | Weekday (0=Monday)         | Used to compute initial |
   |                |                            | rollover time           |
   +----------------+----------------------------+-------------------------+
   | ``'midnight'`` | Roll over at midnight, if  | Used to compute initial |
   |                | *atTime* not specified,    | rollover time           |
   |                | else at time *atTime*      |                         |
   +----------------+----------------------------+-------------------------+

   When using weekday-based rotation, specify 'W0' for Monday, 'W1' for
   Tuesday, and so on up to 'W6' for Sunday. In this case, the value passed for
   *interval* isn't used.

   The system will save old log files by appending extensions to the filename.
   The extensions are date-and-time based, using the strftime format
   ``%Y-%m-%d_%H-%M-%S`` or a leading portion thereof, depending on the
   rollover interval.

   When computing the next rollover time for the first time (when the handler
   is created), the last modification time of an existing log file, or else
   the current time, is used to compute when the next rotation will occur.

   If the *utc* argument is true, times in UTC will be used; otherwise
   local time is used.

   If *backupCount* is nonzero, at most *backupCount* files
   will be kept, and if more would be created when rollover occurs, the oldest
   one is deleted. The deletion logic uses the interval to determine which
   files to delete, so changing the interval may leave old files lying around.

   If *delay* is true, then file opening is deferred until the first call to
   :meth:`emit`.

   If *atTime* is not ``None``, it must be a ``datetime.time`` instance which
   specifies the time of day when rollover occurs, for the cases where rollover
   is set to happen "at midnight" or "on a particular weekday". Note that in
   these cases, the *atTime* value is effectively used to compute the *initial*
   rollover, and subsequent rollovers would be calculated via the normal
   interval calculation.

   If *errors* is specified, it's used to determine how encoding errors are
   handled.

   .. note:: Calculation of the initial rollover time is done when the handler
      is initialised. Calculation of subsequent rollover times is done only
      when rollover occurs, and rollover occurs only when emitting output. If
      this is not kept in mind, it might lead to some confusion. For example,
      if an interval of "every minute" is set, that does not mean you will
      always see log files with times (in the filename) separated by a minute;
      if, during application execution, logging output is generated more
      frequently than once a minute, *then* you can expect to see log files
      with times separated by a minute. If, on the other hand, logging messages
      are only output once every five minutes (say), then there will be gaps in
      the file times corresponding to the minutes where no output (and hence no
      rollover) occurred.

   .. versionchanged:: 3.4
      *atTime* parameter was added.

   .. versionchanged:: 3.6
      As well as string values, :class:`~pathlib.Path` objects are also accepted
      for the *filename* argument.

   .. versionchanged:: 3.9
      The *errors* parameter was added.

   .. method:: doRollover()

      Does a rollover, as described above.

   .. method:: emit(record)

      Outputs the record to the file, catering for rollover as described above.

   .. method:: getFilesToDelete()

      Returns a list of filenames which should be deleted as part of rollover. These
      are the absolute paths of the oldest backup log files written by the handler.

.. _socket-handler:

SocketHandler
^^^^^^^^^^^^^

The :class:`SocketHandler` class, located in the :mod:`logging.handlers` module,
sends logging output to a network socket. The base class uses a TCP socket.


.. class:: SocketHandler(host, port)

   Returns a new instance of the :class:`SocketHandler` class intended to
   communicate with a remote machine whose address is given by *host* and *port*.

   .. versionchanged:: 3.4
      If ``port`` is specified as ``None``, a Unix domain socket is created
      using the value in ``host`` - otherwise, a TCP socket is created.

   .. method:: close()

      Closes the socket.


   .. method:: emit()

      Pickles the record's attribute dictionary and writes it to the socket in
      binary format. If there is an error with the socket, silently drops the
      packet. If the connection was previously lost, re-establishes the
      connection. To unpickle the record at the receiving end into a
      :class:`~logging.LogRecord`, use the :func:`~logging.makeLogRecord`
      function.


   .. method:: handleError()

      Handles an error which has occurred during :meth:`emit`. The most likely
      cause is a lost connection. Closes the socket so that we can retry on the
      next event.


   .. method:: makeSocket()

      This is a factory method which allows subclasses to define the precise
      type of socket they want. The default implementation creates a TCP socket
      (:const:`socket.SOCK_STREAM`).


   .. method:: makePickle(record)

      Pickles the record's attribute dictionary in binary format with a length
      prefix, and returns it ready for transmission across the socket. The
      details of this operation are equivalent to::

          data = pickle.dumps(record_attr_dict, 1)
          datalen = struct.pack('>L', len(data))
          return datalen + data

      Note that pickles aren't completely secure. If you are concerned about
      security, you may want to override this method to implement a more secure
      mechanism. For example, you can sign pickles using HMAC and then verify
      them on the receiving end, or alternatively you can disable unpickling of
      global objects on the receiving end.


   .. method:: send(packet)

      Send a pickled byte-string *packet* to the socket. The format of the sent
      byte-string is as described in the documentation for
      :meth:`~SocketHandler.makePickle`.

      This function allows for partial sends, which can happen when the network
      is busy.


   .. method:: createSocket()

      Tries to create a socket; on failure, uses an exponential back-off
      algorithm.  On initial failure, the handler will drop the message it was
      trying to send.  When subsequent messages are handled by the same
      instance, it will not try connecting until some time has passed.  The
      default parameters are such that the initial delay is one second, and if
      after that delay the connection still can't be made, the handler will
      double the delay each time up to a maximum of 30 seconds.

      This behaviour is controlled by the following handler attributes:

      * ``retryStart`` (initial delay, defaulting to 1.0 seconds).
      * ``retryFactor`` (multiplier, defaulting to 2.0).
      * ``retryMax`` (maximum delay, defaulting to 30.0 seconds).

      This means that if the remote listener starts up *after* the handler has
      been used, you could lose messages (since the handler won't even attempt
      a connection until the delay has elapsed, but just silently drop messages
      during the delay period).


.. _datagram-handler:

DatagramHandler
^^^^^^^^^^^^^^^

The :class:`DatagramHandler` class, located in the :mod:`logging.handlers`
module, inherits from :class:`SocketHandler` to support sending logging messages
over UDP sockets.


.. class:: DatagramHandler(host, port)

   Returns a new instance of the :class:`DatagramHandler` class intended to
   communicate with a remote machine whose address is given by *host* and *port*.

   .. note:: As UDP is not a streaming protocol, there is no persistent connection
      between an instance of this handler and *host*. For this reason, when using a
      network socket, a DNS lookup might have to be made each time an event is
      logged, which can introduce some latency into the system. If this affects you,
      you can do a lookup yourself and initialize this handler using the looked-up IP
      address rather than the hostname.

   .. versionchanged:: 3.4
      If ``port`` is specified as ``None``, a Unix domain socket is created
      using the value in ``host`` - otherwise, a UDP socket is created.

   .. method:: emit()

      Pickles the record's attribute dictionary and writes it to the socket in
      binary format. If there is an error with the socket, silently drops the
      packet. To unpickle the record at the receiving end into a
      :class:`~logging.LogRecord`, use the :func:`~logging.makeLogRecord`
      function.


   .. method:: makeSocket()

      The factory method of :class:`SocketHandler` is here overridden to create
      a UDP socket (:const:`socket.SOCK_DGRAM`).


   .. method:: send(s)

      Send a pickled byte-string to a socket. The format of the sent byte-string
      is as described in the documentation for :meth:`SocketHandler.makePickle`.


.. _syslog-handler:

SysLogHandler
^^^^^^^^^^^^^

The :class:`SysLogHandler` class, located in the :mod:`logging.handlers` module,
supports sending logging messages to a remote or local Unix syslog.


.. class:: SysLogHandler(address=('localhost', SYSLOG_UDP_PORT), facility=LOG_USER, socktype=socket.SOCK_DGRAM)

   Returns a new instance of the :class:`SysLogHandler` class intended to
   communicate with a remote Unix machine whose address is given by *address* in
   the form of a ``(host, port)`` tuple.  If *address* is not specified,
   ``('localhost', 514)`` is used.  The address is used to open a socket.  An
   alternative to providing a ``(host, port)`` tuple is providing an address as a
   string, for example '/dev/log'. In this case, a Unix domain socket is used to
   send the message to the syslog. If *facility* is not specified,
   :const:`LOG_USER` is used. The type of socket opened depends on the
   *socktype* argument, which defaults to :const:`socket.SOCK_DGRAM` and thus
   opens a UDP socket. To open a TCP socket (for use with the newer syslog
   daemons such as rsyslog), specify a value of :const:`socket.SOCK_STREAM`.

   Note that if your server is not listening on UDP port 514,
   :class:`SysLogHandler` may appear not to work. In that case, check what
   address you should be using for a domain socket - it's system dependent.
   For example, on Linux it's usually '/dev/log' but on OS/X it's
   '/var/run/syslog'. You'll need to check your platform and use the
   appropriate address (you may need to do this check at runtime if your
   application needs to run on several platforms). On Windows, you pretty
   much have to use the UDP option.

   .. note:: On macOS 12.x (Monterey), Apple has changed the behaviour of their
      syslog daemon - it no longer listens on a domain socket. Therefore, you cannot
      expect :class:`SysLogHandler` to work on this system.

      See :gh:`91070` for more information.

   .. versionchanged:: 3.2
      *socktype* was added.


   .. method:: close()

      Closes the socket to the remote host.

   .. method:: createSocket()

      Tries to create a socket and, if it's not a datagram socket, connect it
      to the other end. This method is called during handler initialization,
      but it's not regarded as an error if the other end isn't listening at
      this point - the method will be called again when emitting an event, if
      there is no socket at that point.

      .. versionadded:: 3.11

   .. method:: emit(record)

      The record is formatted, and then sent to the syslog server. If exception
      information is present, it is *not* sent to the server.

      .. versionchanged:: 3.2.1
         (See: :issue:`12168`.) In earlier versions, the message sent to the
         syslog daemons was always terminated with a NUL byte, because early
         versions of these daemons expected a NUL terminated message - even
         though it's not in the relevant specification (:rfc:`5424`). More recent
         versions of these daemons don't expect the NUL byte but strip it off
         if it's there, and even more recent daemons (which adhere more closely
         to RFC 5424) pass the NUL byte on as part of the message.

         To enable easier handling of syslog messages in the face of all these
         differing daemon behaviours, the appending of the NUL byte has been
         made configurable, through the use of a class-level attribute,
         ``append_nul``. This defaults to ``True`` (preserving the existing
         behaviour) but can be set to ``False`` on a ``SysLogHandler`` instance
         in order for that instance to *not* append the NUL terminator.

      .. versionchanged:: 3.3
         (See: :issue:`12419`.) In earlier versions, there was no facility for
         an "ident" or "tag" prefix to identify the source of the message. This
         can now be specified using a class-level attribute, defaulting to
         ``""`` to preserve existing behaviour, but which can be overridden on
         a ``SysLogHandler`` instance in order for that instance to prepend
         the ident to every message handled. Note that the provided ident must
         be text, not bytes, and is prepended to the message exactly as is.

   .. method:: encodePriority(facility, priority)

      Encodes the facility and priority into an integer. You can pass in strings
      or integers - if strings are passed, internal mapping dictionaries are
      used to convert them to integers.

      The symbolic ``LOG_`` values are defined in :class:`SysLogHandler` and
      mirror the values defined in the ``sys/syslog.h`` header file.

      **Priorities**

      +--------------------------+---------------+
      | Name (string)            | Symbolic value|
      +==========================+===============+
      | ``alert``                | LOG_ALERT     |
      +--------------------------+---------------+
      | ``crit`` or ``critical`` | LOG_CRIT      |
      +--------------------------+---------------+
      | ``debug``                | LOG_DEBUG     |
      +--------------------------+---------------+
      | ``emerg`` or ``panic``   | LOG_EMERG     |
      +--------------------------+---------------+
      | ``err`` or ``error``     | LOG_ERR       |
      +--------------------------+---------------+
      | ``info``                 | LOG_INFO      |
      +--------------------------+---------------+
      | ``notice``               | LOG_NOTICE    |
      +--------------------------+---------------+
      | ``warn`` or ``warning``  | LOG_WARNING   |
      +--------------------------+---------------+

      **Facilities**

      +---------------+---------------+
      | Name (string) | Symbolic value|
      +===============+===============+
      | ``auth``      | LOG_AUTH      |
      +---------------+---------------+
      | ``authpriv``  | LOG_AUTHPRIV  |
      +---------------+---------------+
      | ``cron``      | LOG_CRON      |
      +---------------+---------------+
      | ``daemon``    | LOG_DAEMON    |
      +---------------+---------------+
      | ``ftp``       | LOG_FTP       |
      +---------------+---------------+
      | ``kern``      | LOG_KERN      |
      +---------------+---------------+
      | ``lpr``       | LOG_LPR       |
      +---------------+---------------+
      | ``mail``      | LOG_MAIL      |
      +---------------+---------------+
      | ``news``      | LOG_NEWS      |
      +---------------+---------------+
      | ``syslog``    | LOG_SYSLOG    |
      +---------------+---------------+
      | ``user``      | LOG_USER      |
      +---------------+---------------+
      | ``uucp``      | LOG_UUCP      |
      +---------------+---------------+
      | ``local0``    | LOG_LOCAL0    |
      +---------------+---------------+
      | ``local1``    | LOG_LOCAL1    |
      +---------------+---------------+
      | ``local2``    | LOG_LOCAL2    |
      +---------------+---------------+
      | ``local3``    | LOG_LOCAL3    |
      +---------------+---------------+
      | ``local4``    | LOG_LOCAL4    |
      +---------------+---------------+
      | ``local5``    | LOG_LOCAL5    |
      +---------------+---------------+
      | ``local6``    | LOG_LOCAL6    |
      +---------------+---------------+
      | ``local7``    | LOG_LOCAL7    |
      +---------------+---------------+

   .. method:: mapPriority(levelname)

      Maps a logging level name to a syslog priority name.
      You may need to override this if you are using custom levels, or
      if the default algorithm is not suitable for your needs. The
      default algorithm maps ``DEBUG``, ``INFO``, ``WARNING``, ``ERROR`` and
      ``CRITICAL`` to the equivalent syslog names, and all other level
      names to 'warning'.

.. _nt-eventlog-handler:

NTEventLogHandler
^^^^^^^^^^^^^^^^^

The :class:`NTEventLogHandler` class, located in the :mod:`logging.handlers`
module, supports sending logging messages to a local Windows NT, Windows 2000 or
Windows XP event log. Before you can use it, you need Mark Hammond's Win32
extensions for Python installed.


.. class:: NTEventLogHandler(appname, dllname=None, logtype='Application')

   Returns a new instance of the :class:`NTEventLogHandler` class. The *appname* is
   used to define the application name as it appears in the event log. An
   appropriate registry entry is created using this name. The *dllname* should give
   the fully qualified pathname of a .dll or .exe which contains message
   definitions to hold in the log (if not specified, ``'win32service.pyd'`` is used
   - this is installed with the Win32 extensions and contains some basic
   placeholder message definitions. Note that use of these placeholders will make
   your event logs big, as the entire message source is held in the log. If you
   want slimmer logs, you have to pass in the name of your own .dll or .exe which
   contains the message definitions you want to use in the event log). The
   *logtype* is one of ``'Application'``, ``'System'`` or ``'Security'``, and
   defaults to ``'Application'``.


   .. method:: close()

      At this point, you can remove the application name from the registry as a
      source of event log entries. However, if you do this, you will not be able
      to see the events as you intended in the Event Log Viewer - it needs to be
      able to access the registry to get the .dll name. The current version does
      not do this.


   .. method:: emit(record)

      Determines the message ID, event category and event type, and then logs
      the message in the NT event log.


   .. method:: getEventCategory(record)

      Returns the event category for the record. Override this if you want to
      specify your own categories. This version returns 0.


   .. method:: getEventType(record)

      Returns the event type for the record. Override this if you want to
      specify your own types. This version does a mapping using the handler's
      typemap attribute, which is set up in :meth:`__init__` to a dictionary
      which contains mappings for :const:`DEBUG`, :const:`INFO`,
      :const:`WARNING`, :const:`ERROR` and :const:`CRITICAL`. If you are using
      your own levels, you will either need to override this method or place a
      suitable dictionary in the handler's *typemap* attribute.


   .. method:: getMessageID(record)

      Returns the message ID for the record. If you are using your own messages,
      you could do this by having the *msg* passed to the logger being an ID
      rather than a format string. Then, in here, you could use a dictionary
      lookup to get the message ID. This version returns 1, which is the base
      message ID in :file:`win32service.pyd`.

.. _smtp-handler:

SMTPHandler
^^^^^^^^^^^

The :class:`SMTPHandler` class, located in the :mod:`logging.handlers` module,
supports sending logging messages to an email address via SMTP.


.. class:: SMTPHandler(mailhost, fromaddr, toaddrs, subject, credentials=None, secure=None, timeout=1.0)

   Returns a new instance of the :class:`SMTPHandler` class. The instance is
   initialized with the from and to addresses and subject line of the email. The
   *toaddrs* should be a list of strings. To specify a non-standard SMTP port, use
   the (host, port) tuple format for the *mailhost* argument. If you use a string,
   the standard SMTP port is used. If your SMTP server requires authentication, you
   can specify a (username, password) tuple for the *credentials* argument.

   To specify the use of a secure protocol (TLS), pass in a tuple to the
   *secure* argument. This will only be used when authentication credentials are
   supplied. The tuple should be either an empty tuple, or a single-value tuple
   with the name of a keyfile, or a 2-value tuple with the names of the keyfile
   and certificate file. (This tuple is passed to the
   :meth:`smtplib.SMTP.starttls` method.)

   A timeout can be specified for communication with the SMTP server using the
   *timeout* argument.

   .. versionchanged:: 3.3
      Added the *timeout* parameter.

   .. method:: emit(record)

      Formats the record and sends it to the specified addressees.


   .. method:: getSubject(record)

      If you want to specify a subject line which is record-dependent, override
      this method.

.. _memory-handler:

MemoryHandler
^^^^^^^^^^^^^

The :class:`MemoryHandler` class, located in the :mod:`logging.handlers` module,
supports buffering of logging records in memory, periodically flushing them to a
:dfn:`target` handler. Flushing occurs whenever the buffer is full, or when an
event of a certain severity or greater is seen.

:class:`MemoryHandler` is a subclass of the more general
:class:`BufferingHandler`, which is an abstract class. This buffers logging
records in memory. Whenever each record is added to the buffer, a check is made
by calling :meth:`shouldFlush` to see if the buffer should be flushed.  If it
should, then :meth:`flush` is expected to do the flushing.


.. class:: BufferingHandler(capacity)

   Initializes the handler with a buffer of the specified capacity. Here,
   *capacity* means the number of logging records buffered.


   .. method:: emit(record)

      Append the record to the buffer. If :meth:`shouldFlush` returns true,
      call :meth:`flush` to process the buffer.


   .. method:: flush()

      For a :class:`BufferingHandler` instance, flushing means that it sets the
      buffer to an empty list. This method can be overwritten to implement more useful
      flushing behavior.


   .. method:: shouldFlush(record)

      Return ``True`` if the buffer is up to capacity. This method can be
      overridden to implement custom flushing strategies.


.. class:: MemoryHandler(capacity, flushLevel=ERROR, target=None, flushOnClose=True)

   Returns a new instance of the :class:`MemoryHandler` class. The instance is
   initialized with a buffer size of *capacity* (number of records buffered).
   If *flushLevel* is not specified, :const:`ERROR` is used. If no *target* is
   specified, the target will need to be set using :meth:`setTarget` before this
   handler does anything useful. If *flushOnClose* is specified as ``False``,
   then the buffer is *not* flushed when the handler is closed. If not specified
   or specified as ``True``, the previous behaviour of flushing the buffer will
   occur when the handler is closed.

   .. versionchanged:: 3.6
      The *flushOnClose* parameter was added.


   .. method:: close()

      Calls :meth:`flush`, sets the target to ``None`` and clears the
      buffer.


   .. method:: flush()

      For a :class:`MemoryHandler` instance, flushing means just sending the buffered
      records to the target, if there is one. The buffer is also cleared when
      buffered records are sent to the target. Override if you want different behavior.


   .. method:: setTarget(target)

      Sets the target handler for this handler.


   .. method:: shouldFlush(record)

      Checks for buffer full or a record at the *flushLevel* or higher.


.. _http-handler:

HTTPHandler
^^^^^^^^^^^

The :class:`HTTPHandler` class, located in the :mod:`logging.handlers` module,
supports sending logging messages to a web server, using either ``GET`` or
``POST`` semantics.


.. class:: HTTPHandler(host, url, method='GET', secure=False, credentials=None, context=None)

   Returns a new instance of the :class:`HTTPHandler` class. The *host* can be
   of the form ``host:port``, should you need to use a specific port number.  If
   no *method* is specified, ``GET`` is used. If *secure* is true, a HTTPS
   connection will be used. The *context* parameter may be set to a
   :class:`ssl.SSLContext` instance to configure the SSL settings used for the
   HTTPS connection. If *credentials* is specified, it should be a 2-tuple
   consisting of userid and password, which will be placed in a HTTP
   'Authorization' header using Basic authentication. If you specify
   credentials, you should also specify secure=True so that your userid and
   password are not passed in cleartext across the wire.

   .. versionchanged:: 3.5
      The *context* parameter was added.

   .. method:: mapLogRecord(record)

      Provides a dictionary, based on ``record``, which is to be URL-encoded
      and sent to the web server. The default implementation just returns
      ``record.__dict__``. This method can be overridden if e.g. only a
      subset of :class:`~logging.LogRecord` is to be sent to the web server, or
      if more specific customization of what's sent to the server is required.

   .. method:: emit(record)

      Sends the record to the web server as a URL-encoded dictionary. The
      :meth:`mapLogRecord` method is used to convert the record to the
      dictionary to be sent.

   .. note:: Since preparing a record for sending it to a web server is not
      the same as a generic formatting operation, using
      :meth:`~logging.Handler.setFormatter` to specify a
      :class:`~logging.Formatter` for a :class:`HTTPHandler` has no effect.
      Instead of calling :meth:`~logging.Handler.format`, this handler calls
      :meth:`mapLogRecord` and then :func:`urllib.parse.urlencode` to encode the
      dictionary in a form suitable for sending to a web server.


.. _queue-handler:


QueueHandler
^^^^^^^^^^^^

.. versionadded:: 3.2

The :class:`QueueHandler` class, located in the :mod:`logging.handlers` module,
supports sending logging messages to a queue, such as those implemented in the
:mod:`queue` or :mod:`multiprocessing` modules.

Along with the :class:`QueueListener` class, :class:`QueueHandler` can be used
to let handlers do their work on a separate thread from the one which does the
logging. This is important in web applications and also other service
applications where threads servicing clients need to respond as quickly as
possible, while any potentially slow operations (such as sending an email via
:class:`SMTPHandler`) are done on a separate thread.

.. class:: QueueHandler(queue)

   Returns a new instance of the :class:`QueueHandler` class. The instance is
   initialized with the queue to send messages to. The *queue* can be any
   queue-like object; it's used as-is by the :meth:`enqueue` method, which
   needs to know how to send messages to it. The queue is not *required* to
   have the task tracking API, which means that you can use
   :class:`~queue.SimpleQueue` instances for *queue*.

   .. note:: If you are using :mod:`multiprocessing`, you should avoid using
      :class:`~queue.SimpleQueue` and instead use :class:`multiprocessing.Queue`.

   .. method:: emit(record)

      Enqueues the result of preparing the LogRecord. Should an exception
      occur (e.g. because a bounded queue has filled up), the
      :meth:`~logging.Handler.handleError` method is called to handle the
      error. This can result in the record silently being dropped (if
      :data:`logging.raiseExceptions` is ``False``) or a message printed to
      ``sys.stderr`` (if :data:`logging.raiseExceptions` is ``True``).

   .. method:: prepare(record)

      Prepares a record for queuing. The object returned by this
      method is enqueued.

      The base implementation formats the record to merge the message,
      arguments, exception and stack information, if present.  It also removes
      unpickleable items from the record in-place. Specifically, it overwrites
      the record's :attr:`msg` and :attr:`message` attributes with the merged
      message (obtained by calling the handler's :meth:`format` method), and
      sets the :attr:`args`, :attr:`exc_info` and :attr:`exc_text` attributes
      to ``None``.

      You might want to override this method if you want to convert
      the record to a dict or JSON string, or send a modified copy
      of the record while leaving the original intact.

      .. note:: The base implementation formats the message with arguments, sets
         the ``message`` and ``msg`` attributes to the formatted message and
         sets the ``args`` and ``exc_text`` attributes to ``None`` to allow
         pickling and to prevent further attempts at formatting. This means
         that a handler on the :class:`QueueListener` side won't have the
         information to do custom formatting, e.g. of exceptions. You may wish
         to subclass ``QueueHandler`` and override this method to e.g. avoid
         setting ``exc_text`` to ``None``. Note that the ``message`` / ``msg``
         / ``args`` changes are related to ensuring the record is pickleable,
         and you might or might not be able to avoid doing that depending on
         whether your ``args`` are pickleable. (Note that you may have to
         consider not only your own code but also code in any libraries that
         you use.)

   .. method:: enqueue(record)

      Enqueues the record on the queue using ``put_nowait()``; you may
      want to override this if you want to use blocking behaviour, or a
      timeout, or a customized queue implementation.

   .. attribute:: listener

      When created via configuration using :func:`~logging.config.dictConfig`, this
      attribute will contain a :class:`QueueListener` instance for use with this
      handler. Otherwise, it will be ``None``.

      .. versionadded:: 3.12

.. _queue-listener:

QueueListener
^^^^^^^^^^^^^

.. versionadded:: 3.2

The :class:`QueueListener` class, located in the :mod:`logging.handlers`
module, supports receiving logging messages from a queue, such as those
implemented in the :mod:`queue` or :mod:`multiprocessing` modules. The
messages are received from a queue in an internal thread and passed, on
the same thread, to one or more handlers for processing. While
:class:`QueueListener` is not itself a handler, it is documented here
because it works hand-in-hand with :class:`QueueHandler`.

Along with the :class:`QueueHandler` class, :class:`QueueListener` can be used
to let handlers do their work on a separate thread from the one which does the
logging. This is important in web applications and also other service
applications where threads servicing clients need to respond as quickly as
possible, while any potentially slow operations (such as sending an email via
:class:`SMTPHandler`) are done on a separate thread.

.. class:: QueueListener(queue, *handlers, respect_handler_level=False)

   Returns a new instance of the :class:`QueueListener` class. The instance is
   initialized with the queue to send messages to and a list of handlers which
   will handle entries placed on the queue. The queue can be any queue-like
   object; it's passed as-is to the :meth:`dequeue` method, which needs
   to know how to get messages from it. The queue is not *required* to have the
   task tracking API (though it's used if available), which means that you can
   use :class:`~queue.SimpleQueue` instances for *queue*.

   .. note:: If you are using :mod:`multiprocessing`, you should avoid using
      :class:`~queue.SimpleQueue` and instead use :class:`multiprocessing.Queue`.

   If ``respect_handler_level`` is ``True``, a handler's level is respected
   (compared with the level for the message) when deciding whether to pass
   messages to that handler; otherwise, the behaviour is as in previous Python
   versions - to always pass each message to each handler.

   .. versionchanged:: 3.5
      The ``respect_handler_level`` argument was added.

   .. method:: dequeue(block)

      Dequeues a record and return it, optionally blocking.

      The base implementation uses ``get()``. You may want to override this
      method if you want to use timeouts or work with custom queue
      implementations.

   .. method:: prepare(record)

      Prepare a record for handling.

      This implementation just returns the passed-in record. You may want to
      override this method if you need to do any custom marshalling or
      manipulation of the record before passing it to the handlers.

   .. method:: handle(record)

      Handle a record.

      This just loops through the handlers offering them the record
      to handle. The actual object passed to the handlers is that which
      is returned from :meth:`prepare`.

   .. method:: start()

      Starts the listener.

      This starts up a background thread to monitor the queue for
      LogRecords to process.

   .. method:: stop()

      Stops the listener.

      This asks the thread to terminate, and then waits for it to do so.
      Note that if you don't call this before your application exits, there
      may be some records still left on the queue, which won't be processed.

   .. method:: enqueue_sentinel()

      Writes a sentinel to the queue to tell the listener to quit. This
      implementation uses ``put_nowait()``.  You may want to override this
      method if you want to use timeouts or work with custom queue
      implementations.

      .. versionadded:: 3.3


.. seealso::

   Module :mod:`logging`
      API reference for the logging module.

   Module :mod:`logging.config`
      Configuration API for the logging module.




================================================
File: /Doc/library/lzma.rst
================================================
:mod:`!lzma` --- Compression using the LZMA algorithm
=====================================================

.. module:: lzma
   :synopsis: A Python wrapper for the liblzma compression library.

.. moduleauthor:: Nadeem Vawda <nadeem.vawda@gmail.com>
.. sectionauthor:: Nadeem Vawda <nadeem.vawda@gmail.com>

.. versionadded:: 3.3

**Source code:** :source:`Lib/lzma.py`

--------------

This module provides classes and convenience functions for compressing and
decompressing data using the LZMA compression algorithm. Also included is a file
interface supporting the ``.xz`` and legacy ``.lzma`` file formats used by the
:program:`xz` utility, as well as raw compressed streams.

The interface provided by this module is very similar to that of the :mod:`bz2`
module. Note that :class:`LZMAFile` and :class:`bz2.BZ2File` are *not*
thread-safe, so if you need to use a single :class:`LZMAFile` instance
from multiple threads, it is necessary to protect it with a lock.


.. exception:: LZMAError

   This exception is raised when an error occurs during compression or
   decompression, or while initializing the compressor/decompressor state.


Reading and writing compressed files
------------------------------------

.. function:: open(filename, mode="rb", *, format=None, check=-1, preset=None, filters=None, encoding=None, errors=None, newline=None)

   Open an LZMA-compressed file in binary or text mode, returning a :term:`file
   object`.

   The *filename* argument can be either an actual file name (given as a
   :class:`str`, :class:`bytes` or :term:`path-like <path-like object>` object), in
   which case the named file is opened, or it can be an existing file object
   to read from or write to.

   The *mode* argument can be any of ``"r"``, ``"rb"``, ``"w"``, ``"wb"``,
   ``"x"``, ``"xb"``, ``"a"`` or ``"ab"`` for binary mode, or ``"rt"``,
   ``"wt"``, ``"xt"``, or ``"at"`` for text mode. The default is ``"rb"``.

   When opening a file for reading, the *format* and *filters* arguments have
   the same meanings as for :class:`LZMADecompressor`. In this case, the *check*
   and *preset* arguments should not be used.

   When opening a file for writing, the *format*, *check*, *preset* and
   *filters* arguments have the same meanings as for :class:`LZMACompressor`.

   For binary mode, this function is equivalent to the :class:`LZMAFile`
   constructor: ``LZMAFile(filename, mode, ...)``. In this case, the *encoding*,
   *errors* and *newline* arguments must not be provided.

   For text mode, a :class:`LZMAFile` object is created, and wrapped in an
   :class:`io.TextIOWrapper` instance with the specified encoding, error
   handling behavior, and line ending(s).

   .. versionchanged:: 3.4
      Added support for the ``"x"``, ``"xb"`` and ``"xt"`` modes.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


.. class:: LZMAFile(filename=None, mode="r", *, format=None, check=-1, preset=None, filters=None)

   Open an LZMA-compressed file in binary mode.

   An :class:`LZMAFile` can wrap an already-open :term:`file object`, or operate
   directly on a named file. The *filename* argument specifies either the file
   object to wrap, or the name of the file to open (as a :class:`str`,
   :class:`bytes` or :term:`path-like <path-like object>` object). When wrapping an
   existing file object, the wrapped file will not be closed when the
   :class:`LZMAFile` is closed.

   The *mode* argument can be either ``"r"`` for reading (default), ``"w"`` for
   overwriting, ``"x"`` for exclusive creation, or ``"a"`` for appending. These
   can equivalently be given as ``"rb"``, ``"wb"``, ``"xb"`` and ``"ab"``
   respectively.

   If *filename* is a file object (rather than an actual file name), a mode of
   ``"w"`` does not truncate the file, and is instead equivalent to ``"a"``.

   When opening a file for reading, the input file may be the concatenation of
   multiple separate compressed streams. These are transparently decoded as a
   single logical stream.

   When opening a file for reading, the *format* and *filters* arguments have
   the same meanings as for :class:`LZMADecompressor`. In this case, the *check*
   and *preset* arguments should not be used.

   When opening a file for writing, the *format*, *check*, *preset* and
   *filters* arguments have the same meanings as for :class:`LZMACompressor`.

   :class:`LZMAFile` supports all the members specified by
   :class:`io.BufferedIOBase`, except for :meth:`~io.BufferedIOBase.detach`
   and :meth:`~io.IOBase.truncate`.
   Iteration and the :keyword:`with` statement are supported.

   The following method and attributes are also provided:

   .. method:: peek(size=-1)

      Return buffered data without advancing the file position. At least one
      byte of data will be returned, unless EOF has been reached. The exact
      number of bytes returned is unspecified (the *size* argument is ignored).

      .. note:: While calling :meth:`peek` does not change the file position of
         the :class:`LZMAFile`, it may change the position of the underlying
         file object (e.g. if the :class:`LZMAFile` was constructed by passing a
         file object for *filename*).

   .. attribute:: mode

      ``'rb'`` for reading and ``'wb'`` for writing.

      .. versionadded:: 3.13

   .. attribute:: name

      The lzma file name.  Equivalent to the :attr:`~io.FileIO.name`
      attribute of the underlying :term:`file object`.

      .. versionadded:: 3.13


   .. versionchanged:: 3.4
      Added support for the ``"x"`` and ``"xb"`` modes.

   .. versionchanged:: 3.5
      The :meth:`~io.BufferedIOBase.read` method now accepts an argument of
      ``None``.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


Compressing and decompressing data in memory
--------------------------------------------

.. class:: LZMACompressor(format=FORMAT_XZ, check=-1, preset=None, filters=None)

   Create a compressor object, which can be used to compress data incrementally.

   For a more convenient way of compressing a single chunk of data, see
   :func:`compress`.

   The *format* argument specifies what container format should be used.
   Possible values are:

   * :const:`FORMAT_XZ`: The ``.xz`` container format.
      This is the default format.

   * :const:`FORMAT_ALONE`: The legacy ``.lzma`` container format.
      This format is more limited than ``.xz`` -- it does not support integrity
      checks or multiple filters.

   * :const:`FORMAT_RAW`: A raw data stream, not using any container format.
      This format specifier does not support integrity checks, and requires that
      you always specify a custom filter chain (for both compression and
      decompression). Additionally, data compressed in this manner cannot be
      decompressed using :const:`FORMAT_AUTO` (see :class:`LZMADecompressor`).

   The *check* argument specifies the type of integrity check to include in the
   compressed data. This check is used when decompressing, to ensure that the
   data has not been corrupted. Possible values are:

   * :const:`CHECK_NONE`: No integrity check.
     This is the default (and the only acceptable value) for
     :const:`FORMAT_ALONE` and :const:`FORMAT_RAW`.

   * :const:`CHECK_CRC32`: 32-bit Cyclic Redundancy Check.

   * :const:`CHECK_CRC64`: 64-bit Cyclic Redundancy Check.
     This is the default for :const:`FORMAT_XZ`.

   * :const:`CHECK_SHA256`: 256-bit Secure Hash Algorithm.

   If the specified check is not supported, an :class:`LZMAError` is raised.

   The compression settings can be specified either as a preset compression
   level (with the *preset* argument), or in detail as a custom filter chain
   (with the *filters* argument).

   The *preset* argument (if provided) should be an integer between ``0`` and
   ``9`` (inclusive), optionally OR-ed with the constant
   :const:`PRESET_EXTREME`. If neither *preset* nor *filters* are given, the
   default behavior is to use :const:`PRESET_DEFAULT` (preset level ``6``).
   Higher presets produce smaller output, but make the compression process
   slower.

   .. note::

      In addition to being more CPU-intensive, compression with higher presets
      also requires much more memory (and produces output that needs more memory
      to decompress). With preset ``9`` for example, the overhead for an
      :class:`LZMACompressor` object can be as high as 800 MiB. For this reason,
      it is generally best to stick with the default preset.

   The *filters* argument (if provided) should be a filter chain specifier.
   See :ref:`filter-chain-specs` for details.

   .. method:: compress(data)

      Compress *data* (a :class:`bytes` object), returning a :class:`bytes`
      object containing compressed data for at least part of the input. Some of
      *data* may be buffered internally, for use in later calls to
      :meth:`compress` and :meth:`flush`. The returned data should be
      concatenated with the output of any previous calls to :meth:`compress`.

   .. method:: flush()

      Finish the compression process, returning a :class:`bytes` object
      containing any data stored in the compressor's internal buffers.

      The compressor cannot be used after this method has been called.


.. class:: LZMADecompressor(format=FORMAT_AUTO, memlimit=None, filters=None)

   Create a decompressor object, which can be used to decompress data
   incrementally.

   For a more convenient way of decompressing an entire compressed stream at
   once, see :func:`decompress`.

   The *format* argument specifies the container format that should be used. The
   default is :const:`FORMAT_AUTO`, which can decompress both ``.xz`` and
   ``.lzma`` files. Other possible values are :const:`FORMAT_XZ`,
   :const:`FORMAT_ALONE`, and :const:`FORMAT_RAW`.

   The *memlimit* argument specifies a limit (in bytes) on the amount of memory
   that the decompressor can use. When this argument is used, decompression will
   fail with an :class:`LZMAError` if it is not possible to decompress the input
   within the given memory limit.

   The *filters* argument specifies the filter chain that was used to create
   the stream being decompressed. This argument is required if *format* is
   :const:`FORMAT_RAW`, but should not be used for other formats.
   See :ref:`filter-chain-specs` for more information about filter chains.

   .. note::
      This class does not transparently handle inputs containing multiple
      compressed streams, unlike :func:`decompress` and :class:`LZMAFile`. To
      decompress a multi-stream input with :class:`LZMADecompressor`, you must
      create a new decompressor for each stream.

   .. method:: decompress(data, max_length=-1)

      Decompress *data* (a :term:`bytes-like object`), returning
      uncompressed data as bytes. Some of *data* may be buffered
      internally, for use in later calls to :meth:`decompress`. The
      returned data should be concatenated with the output of any
      previous calls to :meth:`decompress`.

      If *max_length* is nonnegative, returns at most *max_length*
      bytes of decompressed data. If this limit is reached and further
      output can be produced, the :attr:`~.needs_input` attribute will
      be set to ``False``. In this case, the next call to
      :meth:`~.decompress` may provide *data* as ``b''`` to obtain
      more of the output.

      If all of the input data was decompressed and returned (either
      because this was less than *max_length* bytes, or because
      *max_length* was negative), the :attr:`~.needs_input` attribute
      will be set to ``True``.

      Attempting to decompress data after the end of stream is reached
      raises an :exc:`EOFError`.  Any data found after the end of the
      stream is ignored and saved in the :attr:`~.unused_data` attribute.

      .. versionchanged:: 3.5
         Added the *max_length* parameter.

   .. attribute:: check

      The ID of the integrity check used by the input stream. This may be
      :const:`CHECK_UNKNOWN` until enough of the input has been decoded to
      determine what integrity check it uses.

   .. attribute:: eof

      ``True`` if the end-of-stream marker has been reached.

   .. attribute:: unused_data

      Data found after the end of the compressed stream.

      Before the end of the stream is reached, this will be ``b""``.

   .. attribute:: needs_input

      ``False`` if the :meth:`.decompress` method can provide more
      decompressed data before requiring new uncompressed input.

      .. versionadded:: 3.5

.. function:: compress(data, format=FORMAT_XZ, check=-1, preset=None, filters=None)

   Compress *data* (a :class:`bytes` object), returning the compressed data as a
   :class:`bytes` object.

   See :class:`LZMACompressor` above for a description of the *format*, *check*,
   *preset* and *filters* arguments.


.. function:: decompress(data, format=FORMAT_AUTO, memlimit=None, filters=None)

   Decompress *data* (a :class:`bytes` object), returning the uncompressed data
   as a :class:`bytes` object.

   If *data* is the concatenation of multiple distinct compressed streams,
   decompress all of these streams, and return the concatenation of the results.

   See :class:`LZMADecompressor` above for a description of the *format*,
   *memlimit* and *filters* arguments.


Miscellaneous
-------------

.. function:: is_check_supported(check)

   Return ``True`` if the given integrity check is supported on this system.

   :const:`CHECK_NONE` and :const:`CHECK_CRC32` are always supported.
   :const:`CHECK_CRC64` and :const:`CHECK_SHA256` may be unavailable if you are
   using a version of :program:`liblzma` that was compiled with a limited
   feature set.


.. _filter-chain-specs:

Specifying custom filter chains
-------------------------------

A filter chain specifier is a sequence of dictionaries, where each dictionary
contains the ID and options for a single filter. Each dictionary must contain
the key ``"id"``, and may contain additional keys to specify filter-dependent
options. Valid filter IDs are as follows:

* Compression filters:

  * :const:`FILTER_LZMA1` (for use with :const:`FORMAT_ALONE`)
  * :const:`FILTER_LZMA2` (for use with :const:`FORMAT_XZ` and :const:`FORMAT_RAW`)

* Delta filter:

  * :const:`FILTER_DELTA`

* Branch-Call-Jump (BCJ) filters:

  * :const:`FILTER_X86`
  * :const:`FILTER_IA64`
  * :const:`FILTER_ARM`
  * :const:`FILTER_ARMTHUMB`
  * :const:`FILTER_POWERPC`
  * :const:`FILTER_SPARC`

A filter chain can consist of up to 4 filters, and cannot be empty. The last
filter in the chain must be a compression filter, and any other filters must be
delta or BCJ filters.

Compression filters support the following options (specified as additional
entries in the dictionary representing the filter):

* ``preset``: A compression preset to use as a source of default values for
  options that are not specified explicitly.
* ``dict_size``: Dictionary size in bytes. This should be between 4 KiB and
  1.5 GiB (inclusive).
* ``lc``: Number of literal context bits.
* ``lp``: Number of literal position bits. The sum ``lc + lp`` must be at
  most 4.
* ``pb``: Number of position bits; must be at most 4.
* ``mode``: :const:`MODE_FAST` or :const:`MODE_NORMAL`.
* ``nice_len``: What should be considered a "nice length" for a match.
  This should be 273 or less.
* ``mf``: What match finder to use -- :const:`MF_HC3`, :const:`MF_HC4`,
  :const:`MF_BT2`, :const:`MF_BT3`, or :const:`MF_BT4`.
* ``depth``: Maximum search depth used by match finder. 0 (default) means to
  select automatically based on other filter options.

The delta filter stores the differences between bytes, producing more repetitive
input for the compressor in certain circumstances. It supports one option,
``dist``. This indicates the distance between bytes to be subtracted. The
default is 1, i.e. take the differences between adjacent bytes.

The BCJ filters are intended to be applied to machine code. They convert
relative branches, calls and jumps in the code to use absolute addressing, with
the aim of increasing the redundancy that can be exploited by the compressor.
These filters support one option, ``start_offset``. This specifies the address
that should be mapped to the beginning of the input data. The default is 0.


Examples
--------

Reading in a compressed file::

   import lzma
   with lzma.open("file.xz") as f:
       file_content = f.read()

Creating a compressed file::

   import lzma
   data = b"Insert Data Here"
   with lzma.open("file.xz", "w") as f:
       f.write(data)

Compressing data in memory::

   import lzma
   data_in = b"Insert Data Here"
   data_out = lzma.compress(data_in)

Incremental compression::

   import lzma
   lzc = lzma.LZMACompressor()
   out1 = lzc.compress(b"Some data\n")
   out2 = lzc.compress(b"Another piece of data\n")
   out3 = lzc.compress(b"Even more data\n")
   out4 = lzc.flush()
   # Concatenate all the partial results:
   result = b"".join([out1, out2, out3, out4])

Writing compressed data to an already-open file::
