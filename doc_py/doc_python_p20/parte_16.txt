
.. module:: token
   :synopsis: Constants representing terminal nodes of the parse tree.

.. sectionauthor:: Fred L. Drake, Jr. <fdrake@acm.org>

**Source code:** :source:`Lib/token.py`

--------------

This module provides constants which represent the numeric values of leaf nodes
of the parse tree (terminal tokens).  Refer to the file :file:`Grammar/Tokens`
in the Python distribution for the definitions of the names in the context of
the language grammar.  The specific numeric values which the names map to may
change between Python versions.

The module also provides a mapping from numeric codes to names and some
functions.  The functions mirror definitions in the Python C header files.


.. data:: tok_name

   Dictionary mapping the numeric values of the constants defined in this module
   back to name strings, allowing more human-readable representation of parse trees
   to be generated.


.. function:: ISTERMINAL(x)

   Return ``True`` for terminal token values.


.. function:: ISNONTERMINAL(x)

   Return ``True`` for non-terminal token values.


.. function:: ISEOF(x)

   Return ``True`` if *x* is the marker indicating the end of input.


The token constants are:

.. include:: token-list.inc

The following token type values aren't used by the C tokenizer but are needed for
the :mod:`tokenize` module.

.. data:: COMMENT
   :noindex:

   Token value used to indicate a comment.


.. data:: NL
   :noindex:

   Token value used to indicate a non-terminating newline.  The
   :data:`NEWLINE` token indicates the end of a logical line of Python code;
   ``NL`` tokens are generated when a logical line of code is continued over
   multiple physical lines.


.. data:: ENCODING

   Token value that indicates the encoding used to decode the source bytes
   into text. The first token returned by :func:`tokenize.tokenize` will
   always be an ``ENCODING`` token.


.. data:: TYPE_COMMENT
   :noindex:

   Token value indicating that a type comment was recognized.  Such
   tokens are only produced when :func:`ast.parse` is invoked with
   ``type_comments=True``.


.. data:: EXACT_TOKEN_TYPES

   A dictionary mapping the string representation of a token to its numeric code.

   .. versionadded:: 3.8


.. versionchanged:: 3.5
   Added :data:`!AWAIT` and :data:`!ASYNC` tokens.

.. versionchanged:: 3.7
   Added :data:`COMMENT`, :data:`NL` and :data:`ENCODING` tokens.

.. versionchanged:: 3.7
   Removed :data:`!AWAIT` and :data:`!ASYNC` tokens. "async" and "await" are
   now tokenized as :data:`NAME` tokens.

.. versionchanged:: 3.8
   Added :data:`TYPE_COMMENT`, :data:`TYPE_IGNORE`, :data:`COLONEQUAL`.
   Added :data:`!AWAIT` and :data:`!ASYNC` tokens back (they're needed
   to support parsing older Python versions for :func:`ast.parse` with
   ``feature_version`` set to 6 or lower).

.. versionchanged:: 3.13
   Removed :data:`!AWAIT` and :data:`!ASYNC` tokens again.



================================================
File: /Doc/library/tokenize.rst
================================================
:mod:`!tokenize` --- Tokenizer for Python source
================================================

.. module:: tokenize
   :synopsis: Lexical scanner for Python source code.

.. moduleauthor:: Ka Ping Yee
.. sectionauthor:: Fred L. Drake, Jr. <fdrake@acm.org>

**Source code:** :source:`Lib/tokenize.py`

--------------

The :mod:`tokenize` module provides a lexical scanner for Python source code,
implemented in Python.  The scanner in this module returns comments as tokens
as well, making it useful for implementing "pretty-printers", including
colorizers for on-screen displays.

To simplify token stream handling, all :ref:`operator <operators>` and
:ref:`delimiter <delimiters>` tokens and :data:`Ellipsis` are returned using
the generic :data:`~token.OP` token type.  The exact
type can be determined by checking the ``exact_type`` property on the
:term:`named tuple` returned from :func:`tokenize.tokenize`.


.. warning::

   Note that the functions in this module are only designed to parse
   syntactically valid Python code (code that does not raise when parsed
   using :func:`ast.parse`).  The behavior of the functions in this module is
   **undefined** when providing invalid Python code and it can change at any
   point.

Tokenizing Input
----------------

The primary entry point is a :term:`generator`:

.. function:: tokenize(readline)

   The :func:`.tokenize` generator requires one argument, *readline*, which
   must be a callable object which provides the same interface as the
   :meth:`io.IOBase.readline` method of file objects.  Each call to the
   function should return one line of input as bytes.

   The generator produces 5-tuples with these members: the token type; the
   token string; a 2-tuple ``(srow, scol)`` of ints specifying the row and
   column where the token begins in the source; a 2-tuple ``(erow, ecol)`` of
   ints specifying the row and column where the token ends in the source; and
   the line on which the token was found. The line passed (the last tuple item)
   is the *physical* line.  The 5 tuple is returned as a :term:`named tuple`
   with the field names:
   ``type string start end line``.

   The returned :term:`named tuple` has an additional property named
   ``exact_type`` that contains the exact operator type for
   :data:`~token.OP` tokens.  For all other token types ``exact_type``
   equals the named tuple ``type`` field.

   .. versionchanged:: 3.1
      Added support for named tuples.

   .. versionchanged:: 3.3
      Added support for ``exact_type``.

   :func:`.tokenize` determines the source encoding of the file by looking for a
   UTF-8 BOM or encoding cookie, according to :pep:`263`.

.. function:: generate_tokens(readline)

   Tokenize a source reading unicode strings instead of bytes.

   Like :func:`.tokenize`, the *readline* argument is a callable returning
   a single line of input. However, :func:`generate_tokens` expects *readline*
   to return a str object rather than bytes.

   The result is an iterator yielding named tuples, exactly like
   :func:`.tokenize`. It does not yield an :data:`~token.ENCODING` token.

All constants from the :mod:`token` module are also exported from
:mod:`tokenize`.

Another function is provided to reverse the tokenization process. This is
useful for creating tools that tokenize a script, modify the token stream, and
write back the modified script.


.. function:: untokenize(iterable)

    Converts tokens back into Python source code.  The *iterable* must return
    sequences with at least two elements, the token type and the token string.
    Any additional sequence elements are ignored.

    The reconstructed script is returned as a single string.  The result is
    guaranteed to tokenize back to match the input so that the conversion is
    lossless and round-trips are assured.  The guarantee applies only to the
    token type and token string as the spacing between tokens (column
    positions) may change.

    It returns bytes, encoded using the :data:`~token.ENCODING` token, which
    is the first token sequence output by :func:`.tokenize`. If there is no
    encoding token in the input, it returns a str instead.


:func:`.tokenize` needs to detect the encoding of source files it tokenizes. The
function it uses to do this is available:

.. function:: detect_encoding(readline)

    The :func:`detect_encoding` function is used to detect the encoding that
    should be used to decode a Python source file. It requires one argument,
    readline, in the same way as the :func:`.tokenize` generator.

    It will call readline a maximum of twice, and return the encoding used
    (as a string) and a list of any lines (not decoded from bytes) it has read
    in.

    It detects the encoding from the presence of a UTF-8 BOM or an encoding
    cookie as specified in :pep:`263`. If both a BOM and a cookie are present,
    but disagree, a :exc:`SyntaxError` will be raised. Note that if the BOM is found,
    ``'utf-8-sig'`` will be returned as an encoding.

    If no encoding is specified, then the default of ``'utf-8'`` will be
    returned.

    Use :func:`.open` to open Python source files: it uses
    :func:`detect_encoding` to detect the file encoding.


.. function:: open(filename)

   Open a file in read only mode using the encoding detected by
   :func:`detect_encoding`.

   .. versionadded:: 3.2

.. exception:: TokenError

   Raised when either a docstring or expression that may be split over several
   lines is not completed anywhere in the file, for example::

      """Beginning of
      docstring

   or::

      [1,
       2,
       3

.. _tokenize-cli:

Command-Line Usage
------------------

.. versionadded:: 3.3

The :mod:`tokenize` module can be executed as a script from the command line.
It is as simple as:

.. code-block:: sh

   python -m tokenize [-e] [filename.py]

The following options are accepted:

.. program:: tokenize

.. option:: -h, --help

   show this help message and exit

.. option:: -e, --exact

   display token names using the exact type

If :file:`filename.py` is specified its contents are tokenized to stdout.
Otherwise, tokenization is performed on stdin.

Examples
------------------

Example of a script rewriter that transforms float literals into Decimal
objects::

    from tokenize import tokenize, untokenize, NUMBER, STRING, NAME, OP
    from io import BytesIO

    def decistmt(s):
        """Substitute Decimals for floats in a string of statements.

        >>> from decimal import Decimal
        >>> s = 'print(+21.3e-5*-.1234/81.7)'
        >>> decistmt(s)
        "print (+Decimal ('21.3e-5')*-Decimal ('.1234')/Decimal ('81.7'))"

        The format of the exponent is inherited from the platform C library.
        Known cases are "e-007" (Windows) and "e-07" (not Windows).  Since
        we're only showing 12 digits, and the 13th isn't close to 5, the
        rest of the output should be platform-independent.

        >>> exec(s)  #doctest: +ELLIPSIS
        -3.21716034272e-0...7

        Output from calculations with Decimal should be identical across all
        platforms.

        >>> exec(decistmt(s))
        -3.217160342717258261933904529E-7
        """
        result = []
        g = tokenize(BytesIO(s.encode('utf-8')).readline)  # tokenize the string
        for toknum, tokval, _, _, _ in g:
            if toknum == NUMBER and '.' in tokval:  # replace NUMBER tokens
                result.extend([
                    (NAME, 'Decimal'),
                    (OP, '('),
                    (STRING, repr(tokval)),
                    (OP, ')')
                ])
            else:
                result.append((toknum, tokval))
        return untokenize(result).decode('utf-8')

Example of tokenizing from the command line.  The script::

    def say_hello():
        print("Hello, World!")

    say_hello()

will be tokenized to the following output where the first column is the range
of the line/column coordinates where the token is found, the second column is
the name of the token, and the final column is the value of the token (if any)

.. code-block:: shell-session

    $ python -m tokenize hello.py
    0,0-0,0:            ENCODING       'utf-8'
    1,0-1,3:            NAME           'def'
    1,4-1,13:           NAME           'say_hello'
    1,13-1,14:          OP             '('
    1,14-1,15:          OP             ')'
    1,15-1,16:          OP             ':'
    1,16-1,17:          NEWLINE        '\n'
    2,0-2,4:            INDENT         '    '
    2,4-2,9:            NAME           'print'
    2,9-2,10:           OP             '('
    2,10-2,25:          STRING         '"Hello, World!"'
    2,25-2,26:          OP             ')'
    2,26-2,27:          NEWLINE        '\n'
    3,0-3,1:            NL             '\n'
    4,0-4,0:            DEDENT         ''
    4,0-4,9:            NAME           'say_hello'
    4,9-4,10:           OP             '('
    4,10-4,11:          OP             ')'
    4,11-4,12:          NEWLINE        '\n'
    5,0-5,0:            ENDMARKER      ''

The exact token type names can be displayed using the :option:`-e` option:

.. code-block:: shell-session

    $ python -m tokenize -e hello.py
    0,0-0,0:            ENCODING       'utf-8'
    1,0-1,3:            NAME           'def'
    1,4-1,13:           NAME           'say_hello'
    1,13-1,14:          LPAR           '('
    1,14-1,15:          RPAR           ')'
    1,15-1,16:          COLON          ':'
    1,16-1,17:          NEWLINE        '\n'
    2,0-2,4:            INDENT         '    '
    2,4-2,9:            NAME           'print'
    2,9-2,10:           LPAR           '('
    2,10-2,25:          STRING         '"Hello, World!"'
    2,25-2,26:          RPAR           ')'
    2,26-2,27:          NEWLINE        '\n'
    3,0-3,1:            NL             '\n'
    4,0-4,0:            DEDENT         ''
    4,0-4,9:            NAME           'say_hello'
    4,9-4,10:           LPAR           '('
    4,10-4,11:          RPAR           ')'
    4,11-4,12:          NEWLINE        '\n'
    5,0-5,0:            ENDMARKER      ''

Example of tokenizing a file programmatically, reading unicode
strings instead of bytes with :func:`generate_tokens`::

    import tokenize

    with tokenize.open('hello.py') as f:
        tokens = tokenize.generate_tokens(f.readline)
        for token in tokens:
            print(token)

Or reading bytes directly with :func:`.tokenize`::

    import tokenize

    with open('hello.py', 'rb') as f:
        tokens = tokenize.tokenize(f.readline)
        for token in tokens:
            print(token)


================================================
File: /Doc/library/tomllib.rst
================================================
:mod:`!tomllib` --- Parse TOML files
====================================

.. module:: tomllib
   :synopsis: Parse TOML files.

.. versionadded:: 3.11

.. moduleauthor:: Taneli Hukkinen
.. sectionauthor:: Taneli Hukkinen

**Source code:** :source:`Lib/tomllib`

--------------

This module provides an interface for parsing TOML 1.0.0 (Tom's Obvious Minimal
Language, `https://toml.io <https://toml.io/en/>`_). This module does not
support writing TOML.

.. seealso::

    The :pypi:`Tomli-W package <tomli-w>`
    is a TOML writer that can be used in conjunction with this module,
    providing a write API familiar to users of the standard library
    :mod:`marshal` and :mod:`pickle` modules.

.. seealso::

    The :pypi:`TOML Kit package <tomlkit>`
    is a style-preserving TOML library with both read and write capability.
    It is a recommended replacement for this module for editing already
    existing TOML files.


This module defines the following functions:

.. function:: load(fp, /, *, parse_float=float)

   Read a TOML file. The first argument should be a readable and binary file object.
   Return a :class:`dict`. Convert TOML types to Python using this
   :ref:`conversion table <toml-to-py-table>`.

   *parse_float* will be called with the string of every TOML
   float to be decoded.  By default, this is equivalent to ``float(num_str)``.
   This can be used to use another datatype or parser for TOML floats
   (e.g. :class:`decimal.Decimal`). The callable must not return a
   :class:`dict` or a :class:`list`, else a :exc:`ValueError` is raised.

   A :exc:`TOMLDecodeError` will be raised on an invalid TOML document.


.. function:: loads(s, /, *, parse_float=float)

   Load TOML from a :class:`str` object. Return a :class:`dict`. Convert TOML
   types to Python using this :ref:`conversion table <toml-to-py-table>`. The
   *parse_float* argument has the same meaning as in :func:`load`.

   A :exc:`TOMLDecodeError` will be raised on an invalid TOML document.


The following exceptions are available:

.. exception:: TOMLDecodeError(msg, doc, pos)

   Subclass of :exc:`ValueError` with the following additional attributes:

   .. attribute:: msg

      The unformatted error message.

   .. attribute:: doc

      The TOML document being parsed.

   .. attribute:: pos

      The index of *doc* where parsing failed.

   .. attribute:: lineno

      The line corresponding to *pos*.

   .. attribute:: colno

      The column corresponding to *pos*.

   .. versionchanged:: 3.14
      Added the *msg*, *doc* and *pos* parameters.
      Added the :attr:`msg`, :attr:`doc`, :attr:`pos`, :attr:`lineno` and :attr:`colno` attributes.

   .. deprecated:: 3.14
      Passing free-form positional arguments is deprecated.


Examples
--------

Parsing a TOML file::

    import tomllib

    with open("pyproject.toml", "rb") as f:
        data = tomllib.load(f)

Parsing a TOML string::

    import tomllib

    toml_str = """
    python-version = "3.11.0"
    python-implementation = "CPython"
    """

    data = tomllib.loads(toml_str)


Conversion Table
----------------

.. _toml-to-py-table:

+------------------+--------------------------------------------------------------------------------------+
| TOML             | Python                                                                               |
+==================+======================================================================================+
| TOML document    | dict                                                                                 |
+------------------+--------------------------------------------------------------------------------------+
| string           | str                                                                                  |
+------------------+--------------------------------------------------------------------------------------+
| integer          | int                                                                                  |
+------------------+--------------------------------------------------------------------------------------+
| float            | float (configurable with *parse_float*)                                              |
+------------------+--------------------------------------------------------------------------------------+
| boolean          | bool                                                                                 |
+------------------+--------------------------------------------------------------------------------------+
| offset date-time | datetime.datetime (``tzinfo`` attribute set to an instance of ``datetime.timezone``) |
+------------------+--------------------------------------------------------------------------------------+
| local date-time  | datetime.datetime (``tzinfo`` attribute set to ``None``)                             |
+------------------+--------------------------------------------------------------------------------------+
| local date       | datetime.date                                                                        |
+------------------+--------------------------------------------------------------------------------------+
| local time       | datetime.time                                                                        |
+------------------+--------------------------------------------------------------------------------------+
| array            | list                                                                                 |
+------------------+--------------------------------------------------------------------------------------+
| table            | dict                                                                                 |
+------------------+--------------------------------------------------------------------------------------+
| inline table     | dict                                                                                 |
+------------------+--------------------------------------------------------------------------------------+
| array of tables  | list of dicts                                                                        |
+------------------+--------------------------------------------------------------------------------------+


================================================
File: /Doc/library/trace.rst
================================================
:mod:`!trace` --- Trace or track Python statement execution
===========================================================

.. module:: trace
   :synopsis: Trace or track Python statement execution.

**Source code:** :source:`Lib/trace.py`

--------------

The :mod:`trace` module allows you to trace program execution, generate
annotated statement coverage listings, print caller/callee relationships and
list functions executed during a program run.  It can be used in another program
or from the command line.

.. seealso::

   `Coverage.py <https://coverage.readthedocs.io/>`_
      A popular third-party coverage tool that provides HTML
      output along with advanced features such as branch coverage.

.. _trace-cli:

Command-Line Usage
------------------

The :mod:`trace` module can be invoked from the command line.  It can be as
simple as ::

   python -m trace --count -C . somefile.py ...

The above will execute :file:`somefile.py` and generate annotated listings of
all Python modules imported during the execution into the current directory.

.. program:: trace

.. option:: --help

   Display usage and exit.

.. option:: --version

   Display the version of the module and exit.

.. versionadded:: 3.8
    Added ``--module`` option that allows to run an executable module.

Main options
^^^^^^^^^^^^

At least one of the following options must be specified when invoking
:mod:`trace`.  The :option:`--listfuncs <-l>` option is mutually exclusive with
the :option:`--trace <-t>` and :option:`--count <-c>` options. When
:option:`--listfuncs <-l>` is provided, neither :option:`--count <-c>` nor
:option:`--trace <-t>` are accepted, and vice versa.

.. program:: trace

.. option:: -c, --count

   Produce a set of annotated listing files upon program completion that shows
   how many times each statement was executed.  See also
   :option:`--coverdir <-C>`, :option:`--file <-f>` and
   :option:`--no-report <-R>` below.

.. option:: -t, --trace

   Display lines as they are executed.

.. option:: -l, --listfuncs

   Display the functions executed by running the program.

.. option:: -r, --report

   Produce an annotated list from an earlier program run that used the
   :option:`--count <-c>` and :option:`--file <-f>` option.  This does not
   execute any code.

.. option:: -T, --trackcalls

   Display the calling relationships exposed by running the program.

Modifiers
^^^^^^^^^

.. program:: trace

.. option:: -f, --file=<file>

   Name of a file to accumulate counts over several tracing runs.  Should be
   used with the :option:`--count <-c>` option.

.. option:: -C, --coverdir=<dir>

   Directory where the report files go.  The coverage report for
   ``package.module`` is written to file :file:`{dir}/{package}/{module}.cover`.

.. option:: -m, --missing

   When generating annotated listings, mark lines which were not executed with
   ``>>>>>>``.

.. option:: -s, --summary

   When using :option:`--count <-c>` or :option:`--report <-r>`, write a brief
   summary to stdout for each file processed.

.. option:: -R, --no-report

   Do not generate annotated listings.  This is useful if you intend to make
   several runs with :option:`--count <-c>`, and then produce a single set of
   annotated listings at the end.

.. option:: -g, --timing

   Prefix each line with the time since the program started.  Only used while
   tracing.

Filters
^^^^^^^

These options may be repeated multiple times.

.. program:: trace

.. option:: --ignore-module=<mod>

   Ignore each of the given module names and its submodules (if it is a
   package).  The argument can be a list of names separated by a comma.

.. option:: --ignore-dir=<dir>

   Ignore all modules and packages in the named directory and subdirectories.
   The argument can be a list of directories separated by :data:`os.pathsep`.

.. _trace-api:

Programmatic Interface
----------------------

.. class:: Trace(count=1, trace=1, countfuncs=0, countcallers=0, ignoremods=(),\
                 ignoredirs=(), infile=None, outfile=None, timing=False)

   Create an object to trace execution of a single statement or expression.  All
   parameters are optional.  *count* enables counting of line numbers.  *trace*
   enables line execution tracing.  *countfuncs* enables listing of the
   functions called during the run.  *countcallers* enables call relationship
   tracking.  *ignoremods* is a list of modules or packages to ignore.
   *ignoredirs* is a list of directories whose modules or packages should be
   ignored.  *infile* is the name of the file from which to read stored count
   information.  *outfile* is the name of the file in which to write updated
   count information.  *timing* enables a timestamp relative to when tracing was
   started to be displayed.

   .. method:: run(cmd)

      Execute the command and gather statistics from the execution with
      the current tracing parameters.  *cmd* must be a string or code object,
      suitable for passing into :func:`exec`.

   .. method:: runctx(cmd, globals=None, locals=None)

      Execute the command and gather statistics from the execution with the
      current tracing parameters, in the defined global and local
      environments.  If not defined, *globals* and *locals* default to empty
      dictionaries.

   .. method:: runfunc(func, /, *args, **kwds)

      Call *func* with the given arguments under control of the :class:`Trace`
      object with the current tracing parameters.

   .. method:: results()

      Return a :class:`CoverageResults` object that contains the cumulative
      results of all previous calls to ``run``, ``runctx`` and ``runfunc``
      for the given :class:`Trace` instance.  Does not reset the accumulated
      trace results.

.. class:: CoverageResults

   A container for coverage results, created by :meth:`Trace.results`.  Should
   not be created directly by the user.

   .. method:: update(other)

      Merge in data from another :class:`CoverageResults` object.

   .. method:: write_results(show_missing=True, summary=False, coverdir=None,\
                             *, ignore_missing_files=False)

      Write coverage results.  Set *show_missing* to show lines that had no
      hits.  Set *summary* to include in the output the coverage summary per
      module.  *coverdir* specifies the directory into which the coverage
      result files will be output.  If ``None``, the results for each source
      file are placed in its directory.

      If *ignore_missing_files* is ``True``, coverage counts for files that no
      longer exist are silently ignored. Otherwise, a missing file will
      raise a :exc:`FileNotFoundError`.

      .. versionchanged:: 3.13
         Added *ignore_missing_files* parameter.

A simple example demonstrating the use of the programmatic interface::

   import sys
   import trace

   # create a Trace object, telling it what to ignore, and whether to
   # do tracing or line-counting or both.
   tracer = trace.Trace(
       ignoredirs=[sys.prefix, sys.exec_prefix],
       trace=0,
       count=1)

   # run the new command using the given tracer
   tracer.run('main()')

   # make a report, placing output in the current directory
   r = tracer.results()
   r.write_results(show_missing=True, coverdir=".")



================================================
File: /Doc/library/traceback.rst
================================================
:mod:`!traceback` --- Print or retrieve a stack traceback
=========================================================

.. module:: traceback
   :synopsis: Print or retrieve a stack traceback.

**Source code:** :source:`Lib/traceback.py`

--------------

This module provides a standard interface to extract, format and print
stack traces of Python programs. It is more flexible than the
interpreter's default traceback display, and therefore makes it
possible to configure certain aspects of the output. Finally,
it contains a utility for capturing enough information about an
exception to print it later, without the need to save a reference
to the actual exception. Since exceptions can be the roots of large
objects graph, this utility can significantly improve
memory management.

.. index:: pair: object; traceback

The module uses :ref:`traceback objects <traceback-objects>` --- these are
objects of type :class:`types.TracebackType`,
which are assigned to the :attr:`~BaseException.__traceback__` field of
:class:`BaseException` instances.

.. seealso::

   Module :mod:`faulthandler`
      Used to dump Python tracebacks explicitly, on a fault, after a timeout, or on a user signal.

   Module :mod:`pdb`
      Interactive source code debugger for Python programs.

The module's API can be divided into two parts:

* Module-level functions offering basic functionality, which are useful for interactive
  inspection of exceptions and tracebacks.

* :class:`TracebackException` class and its helper classes
  :class:`StackSummary` and :class:`FrameSummary`. These offer both more
  flexibility in the output generated and the ability to store the information
  necessary for later formatting without holding references to actual exception
  and traceback objects.

.. versionadded:: 3.13
   Output is colorized by default and can be
   :ref:`controlled using environment variables <using-on-controlling-color>`.


Module-Level Functions
----------------------

.. function:: print_tb(tb, limit=None, file=None)

   Print up to *limit* stack trace entries from
   :ref:`traceback object <traceback-objects>` *tb* (starting
   from the caller's frame) if *limit* is positive.  Otherwise, print the last
   ``abs(limit)`` entries.  If *limit* is omitted or ``None``, all entries are
   printed.  If *file* is omitted or ``None``, the output goes to
   :data:`sys.stderr`; otherwise it should be an open
   :term:`file <file object>` or :term:`file-like object` to
   receive the output.

   .. note::

      The meaning of the *limit* parameter is different than the meaning
      of :const:`sys.tracebacklimit`. A negative *limit* value corresponds to
      a positive value of :const:`!sys.tracebacklimit`, whereas the behaviour of
      a positive *limit* value cannot be achieved with
      :const:`!sys.tracebacklimit`.

   .. versionchanged:: 3.5
       Added negative *limit* support.


.. function:: print_exception(exc, /[, value, tb], limit=None, \
                              file=None, chain=True)

   Print exception information and stack trace entries from
   :ref:`traceback object <traceback-objects>`
   *tb* to *file*. This differs from :func:`print_tb` in the following
   ways:

   * if *tb* is not ``None``, it prints a header ``Traceback (most recent
     call last):``

   * it prints the exception type and *value* after the stack trace

   .. index:: single: ^ (caret); marker

   * if *type(value)* is :exc:`SyntaxError` and *value* has the appropriate
     format, it prints the line where the syntax error occurred with a caret
     indicating the approximate position of the error.

   Since Python 3.10, instead of passing *value* and *tb*, an exception object
   can be passed as the first argument. If *value* and *tb* are provided, the
   first argument is ignored in order to provide backwards compatibility.

   The optional *limit* argument has the same meaning as for :func:`print_tb`.
   If *chain* is true (the default), then chained exceptions (the
   :attr:`~BaseException.__cause__` or :attr:`~BaseException.__context__`
   attributes of the exception) will be
   printed as well, like the interpreter itself does when printing an unhandled
   exception.

   .. versionchanged:: 3.5
      The *etype* argument is ignored and inferred from the type of *value*.

   .. versionchanged:: 3.10
      The *etype* parameter has been renamed to *exc* and is now
      positional-only.


.. function:: print_exc(limit=None, file=None, chain=True)

   This is a shorthand for ``print_exception(sys.exception(), limit, file,
   chain)``.


.. function:: print_last(limit=None, file=None, chain=True)

   This is a shorthand for ``print_exception(sys.last_exc, limit, file,
   chain)``.  In general it will work only after an exception has reached
   an interactive prompt (see :data:`sys.last_exc`).


.. function:: print_stack(f=None, limit=None, file=None)

   Print up to *limit* stack trace entries (starting from the invocation
   point) if *limit* is positive.  Otherwise, print the last ``abs(limit)``
   entries.  If *limit* is omitted or ``None``, all entries are printed.
   The optional *f* argument can be used to specify an alternate
   :ref:`stack frame <frame-objects>`
   to start.  The optional *file* argument has the same meaning as for
   :func:`print_tb`.

   .. versionchanged:: 3.5
          Added negative *limit* support.


.. function:: extract_tb(tb, limit=None)

   Return a :class:`StackSummary` object representing a list of "pre-processed"
   stack trace entries extracted from the
   :ref:`traceback object <traceback-objects>` *tb*.  It is useful
   for alternate formatting of stack traces.  The optional *limit* argument has
   the same meaning as for :func:`print_tb`.  A "pre-processed" stack trace
   entry is a :class:`FrameSummary` object containing attributes
   :attr:`~FrameSummary.filename`, :attr:`~FrameSummary.lineno`,
   :attr:`~FrameSummary.name`, and :attr:`~FrameSummary.line` representing the
   information that is usually printed for a stack trace.


.. function:: extract_stack(f=None, limit=None)

   Extract the raw traceback from the current
   :ref:`stack frame <frame-objects>`.  The return value has
   the same format as for :func:`extract_tb`.  The optional *f* and *limit*
   arguments have the same meaning as for :func:`print_stack`.


.. function:: print_list(extracted_list, file=None)

   Print the list of tuples as returned by :func:`extract_tb` or
   :func:`extract_stack` as a formatted stack trace to the given file.
   If *file* is ``None``, the output is written to :data:`sys.stderr`.


.. function:: format_list(extracted_list)

   Given a list of tuples or :class:`FrameSummary` objects as returned by
   :func:`extract_tb` or :func:`extract_stack`, return a list of strings ready
   for printing.  Each string in the resulting list corresponds to the item with
   the same index in the argument list.  Each string ends in a newline; the
   strings may contain internal newlines as well, for those items whose source
   text line is not ``None``.


.. function:: format_exception_only(exc, /[, value], *, show_group=False)

   Format the exception part of a traceback using an exception value such as
   given by :data:`sys.last_value`.  The return value is a list of strings, each
   ending in a newline.  The list contains the exception's message, which is
   normally a single string; however, for :exc:`SyntaxError` exceptions, it
   contains several lines that (when printed) display detailed information
   about where the syntax error occurred. Following the message, the list
   contains the exception's :attr:`notes <BaseException.__notes__>`.

   Since Python 3.10, instead of passing *value*, an exception object
   can be passed as the first argument.  If *value* is provided, the first
   argument is ignored in order to provide backwards compatibility.

   When *show_group* is ``True``, and the exception is an instance of
   :exc:`BaseExceptionGroup`, the nested exceptions are included as
   well, recursively, with indentation relative to their nesting depth.

   .. versionchanged:: 3.10
      The *etype* parameter has been renamed to *exc* and is now
      positional-only.

   .. versionchanged:: 3.11
      The returned list now includes any
      :attr:`notes <BaseException.__notes__>` attached to the exception.

   .. versionchanged:: 3.13
      *show_group* parameter was added.


.. function:: format_exception(exc, /[, value, tb], limit=None, chain=True)

   Format a stack trace and the exception information.  The arguments  have the
   same meaning as the corresponding arguments to :func:`print_exception`.  The
   return value is a list of strings, each ending in a newline and some
   containing internal newlines.  When these lines are concatenated and printed,
   exactly the same text is printed as does :func:`print_exception`.

   .. versionchanged:: 3.5
      The *etype* argument is ignored and inferred from the type of *value*.

   .. versionchanged:: 3.10
      This function's behavior and signature were modified to match
      :func:`print_exception`.


.. function:: format_exc(limit=None, chain=True)

   This is like ``print_exc(limit)`` but returns a string instead of printing to
   a file.


.. function:: format_tb(tb, limit=None)

   A shorthand for ``format_list(extract_tb(tb, limit))``.


.. function:: format_stack(f=None, limit=None)

   A shorthand for ``format_list(extract_stack(f, limit))``.

.. function:: clear_frames(tb)

   Clears the local variables of all the stack frames in a
   :ref:`traceback <traceback-objects>` *tb*
   by calling the :meth:`~frame.clear` method of each
   :ref:`frame object <frame-objects>`.

   .. versionadded:: 3.4

.. function:: walk_stack(f)

   Walk a stack following :attr:`f.f_back <frame.f_back>` from the given frame,
   yielding the frame
   and line number for each frame. If *f* is ``None``, the current stack is
   used. This helper is used with :meth:`StackSummary.extract`.

   .. versionadded:: 3.5

.. function:: walk_tb(tb)

   Walk a traceback following :attr:`~traceback.tb_next` yielding the frame and
   line number
   for each frame. This helper is used with :meth:`StackSummary.extract`.

   .. versionadded:: 3.5


:class:`!TracebackException` Objects
------------------------------------

.. versionadded:: 3.5

:class:`!TracebackException` objects are created from actual exceptions to
capture data for later printing.  They offer a more lightweight method of
storing this information by avoiding holding references to
:ref:`traceback<traceback-objects>` and :ref:`frame<frame-objects>` objects.
In addition, they expose more options to configure the output compared to
the module-level functions described above.

.. class:: TracebackException(exc_type, exc_value, exc_traceback, *, limit=None, lookup_lines=True, capture_locals=False, compact=False, max_group_width=15, max_group_depth=10)

   Capture an exception for later rendering. The meaning of *limit*,
   *lookup_lines* and *capture_locals* are as for the :class:`StackSummary`
   class.

   If *compact* is true, only data that is required by
   :class:`!TracebackException`'s :meth:`format` method
   is saved in the class attributes. In particular, the
   :attr:`__context__` field is calculated only if :attr:`__cause__` is
   ``None`` and :attr:`__suppress_context__` is false.

   Note that when locals are captured, they are also shown in the traceback.

   *max_group_width* and *max_group_depth* control the formatting of exception
   groups (see :exc:`BaseExceptionGroup`). The depth refers to the nesting
   level of the group, and the width refers to the size of a single exception
   group's exceptions array. The formatted output is truncated when either
   limit is exceeded.

   .. versionchanged:: 3.10
      Added the *compact* parameter.

   .. versionchanged:: 3.11
      Added the *max_group_width* and *max_group_depth* parameters.

   .. attribute:: __cause__

      A :class:`!TracebackException` of the original
      :attr:`~BaseException.__cause__`.

   .. attribute:: __context__

      A :class:`!TracebackException` of the original
      :attr:`~BaseException.__context__`.

   .. attribute:: exceptions

      If ``self`` represents an :exc:`ExceptionGroup`, this field holds a list of
      :class:`!TracebackException` instances representing the nested exceptions.
      Otherwise it is ``None``.

      .. versionadded:: 3.11

   .. attribute:: __suppress_context__

      The :attr:`~BaseException.__suppress_context__` value from the original
      exception.

   .. attribute:: __notes__

      The :attr:`~BaseException.__notes__` value from the original exception,
      or ``None``
      if the exception does not have any notes. If it is not ``None``
      is it formatted in the traceback after the exception string.

      .. versionadded:: 3.11

   .. attribute:: stack

      A :class:`StackSummary` representing the traceback.

   .. attribute:: exc_type

      The class of the original traceback.

      .. deprecated:: 3.13

   .. attribute:: exc_type_str

      String display of the class of the original exception.

      .. versionadded:: 3.13

   .. attribute:: filename

      For syntax errors - the file name where the error occurred.

   .. attribute:: lineno

      For syntax errors - the line number where the error occurred.

   .. attribute:: end_lineno

      For syntax errors - the end line number where the error occurred.
      Can be ``None`` if not present.

      .. versionadded:: 3.10

   .. attribute:: text

      For syntax errors - the text where the error occurred.

   .. attribute:: offset

      For syntax errors - the offset into the text where the error occurred.

   .. attribute:: end_offset

      For syntax errors - the end offset into the text where the error occurred.
      Can be ``None`` if not present.

      .. versionadded:: 3.10

   .. attribute:: msg

      For syntax errors - the compiler error message.

   .. classmethod:: from_exception(exc, *, limit=None, lookup_lines=True, capture_locals=False)

      Capture an exception for later rendering. *limit*, *lookup_lines* and
      *capture_locals* are as for the :class:`StackSummary` class.

      Note that when locals are captured, they are also shown in the traceback.

   .. method::  print(*, file=None, chain=True)

      Print to *file* (default ``sys.stderr``) the exception information returned by
      :meth:`format`.

      .. versionadded:: 3.11

   .. method:: format(*, chain=True)

      Format the exception.

      If *chain* is not ``True``, :attr:`__cause__` and :attr:`__context__`
      will not be formatted.

      The return value is a generator of strings, each ending in a newline and
      some containing internal newlines. :func:`~traceback.print_exception`
      is a wrapper around this method which just prints the lines to a file.

   .. method::  format_exception_only(*, show_group=False)

      Format the exception part of the traceback.

      The return value is a generator of strings, each ending in a newline.

      When *show_group* is ``False``, the generator emits the exception's
      message followed by its notes (if it has any). The exception message
      is normally a single string; however, for :exc:`SyntaxError` exceptions,
      it consists of several lines that (when printed) display detailed
      information about where the syntax error occurred.

      When *show_group* is ``True``, and the exception is an instance of
      :exc:`BaseExceptionGroup`, the nested exceptions are included as
      well, recursively, with indentation relative to their nesting depth.

      .. versionchanged:: 3.11
         The exception's :attr:`notes <BaseException.__notes__>` are now
         included in the output.

      .. versionchanged:: 3.13
         Added the *show_group* parameter.


:class:`!StackSummary` Objects
------------------------------

.. versionadded:: 3.5

:class:`!StackSummary` objects represent a call stack ready for formatting.

.. class:: StackSummary

   .. classmethod:: extract(frame_gen, *, limit=None, lookup_lines=True, capture_locals=False)

      Construct a :class:`!StackSummary` object from a frame generator (such as
      is returned by :func:`~traceback.walk_stack` or
      :func:`~traceback.walk_tb`).

      If *limit* is supplied, only this many frames are taken from *frame_gen*.
      If *lookup_lines* is ``False``, the returned :class:`FrameSummary`
      objects will not have read their lines in yet, making the cost of
      creating the :class:`!StackSummary` cheaper (which may be valuable if it
      may not actually get formatted). If *capture_locals* is ``True`` the
      local variables in each :class:`!FrameSummary` are captured as object
      representations.

      .. versionchanged:: 3.12
         Exceptions raised from :func:`repr` on a local variable (when
         *capture_locals* is ``True``) are no longer propagated to the caller.

   .. classmethod:: from_list(a_list)

      Construct a :class:`!StackSummary` object from a supplied list of
      :class:`FrameSummary` objects or old-style list of tuples.  Each tuple
      should be a 4-tuple with *filename*, *lineno*, *name*, *line* as the
      elements.

   .. method:: format()

      Returns a list of strings ready for printing.  Each string in the
      resulting list corresponds to a single :ref:`frame <frame-objects>` from
      the stack.
      Each string ends in a newline; the strings may contain internal
      newlines as well, for those items with source text lines.

      For long sequences of the same frame and line, the first few
      repetitions are shown, followed by a summary line stating the exact
      number of further repetitions.

      .. versionchanged:: 3.6
         Long sequences of repeated frames are now abbreviated.

   .. method:: format_frame_summary(frame_summary)

      Returns a string for printing one of the :ref:`frames <frame-objects>`
      involved in the stack.
      This method is called for each :class:`FrameSummary` object to be
      printed by :meth:`StackSummary.format`. If it returns ``None``, the
      frame is omitted from the output.

      .. versionadded:: 3.11


:class:`!FrameSummary` Objects
------------------------------

.. versionadded:: 3.5

A :class:`!FrameSummary` object represents a single :ref:`frame <frame-objects>`
in a :ref:`traceback <traceback-objects>`.

.. class:: FrameSummary(filename, lineno, name, lookup_line=True, locals=None, line=None)

   Represents a single :ref:`frame <frame-objects>` in the
   :ref:`traceback <traceback-objects>` or stack that is being formatted
   or printed. It may optionally have a stringified version of the frame's
   locals included in it. If *lookup_line* is ``False``, the source code is not
   looked up until the :class:`!FrameSummary` has the :attr:`~FrameSummary.line`
   attribute accessed (which also happens when casting it to a :class:`tuple`).
   :attr:`~FrameSummary.line` may be directly provided, and will prevent line
   lookups happening at all. *locals* is an optional local variable
   mapping, and if supplied the variable representations are stored in the
   summary for later display.

   :class:`!FrameSummary` instances have the following attributes:

   .. attribute:: FrameSummary.filename

      The filename of the source code for this frame. Equivalent to accessing
      :attr:`f.f_code.co_filename <codeobject.co_filename>` on a
      :ref:`frame object <frame-objects>` *f*.

   .. attribute:: FrameSummary.lineno

      The line number of the source code for this frame.

   .. attribute:: FrameSummary.name

      Equivalent to accessing :attr:`f.f_code.co_name <codeobject.co_name>` on
      a :ref:`frame object <frame-objects>` *f*.

   .. attribute:: FrameSummary.line

      A string representing the source code for this frame, with leading and
      trailing whitespace stripped.
      If the source is not available, it is ``None``.

.. _traceback-example:

Examples of Using the Module-Level Functions
--------------------------------------------

This simple example implements a basic read-eval-print loop, similar to (but
less useful than) the standard Python interactive interpreter loop.  For a more
complete implementation of the interpreter loop, refer to the :mod:`code`
module. ::

   import sys, traceback

   def run_user_code(envdir):
       source = input(">>> ")
       try:
           exec(source, envdir)
       except Exception:
           print("Exception in user code:")
           print("-"*60)
           traceback.print_exc(file=sys.stdout)
           print("-"*60)

   envdir = {}
   while True:
       run_user_code(envdir)


The following example demonstrates the different ways to print and format the
exception and traceback:

.. testcode::

   import sys, traceback

   def lumberjack():
       bright_side_of_life()

   def bright_side_of_life():
       return tuple()[0]

   try:
       lumberjack()
   except IndexError as exc:
       print("*** print_tb:")
       traceback.print_tb(exc.__traceback__, limit=1, file=sys.stdout)
       print("*** print_exception:")
       traceback.print_exception(exc, limit=2, file=sys.stdout)
       print("*** print_exc:")
       traceback.print_exc(limit=2, file=sys.stdout)
       print("*** format_exc, first and last line:")
       formatted_lines = traceback.format_exc().splitlines()
       print(formatted_lines[0])
       print(formatted_lines[-1])
       print("*** format_exception:")
       print(repr(traceback.format_exception(exc)))
       print("*** extract_tb:")
       print(repr(traceback.extract_tb(exc.__traceback__)))
       print("*** format_tb:")
       print(repr(traceback.format_tb(exc.__traceback__)))
       print("*** tb_lineno:", exc.__traceback__.tb_lineno)

The output for the example would look similar to this:

.. testoutput::
   :options: +NORMALIZE_WHITESPACE

   *** print_tb:
     File "<doctest...>", line 10, in <module>
       lumberjack()
       ~~~~~~~~~~^^
   *** print_exception:
   Traceback (most recent call last):
     File "<doctest...>", line 10, in <module>
       lumberjack()
       ~~~~~~~~~~^^
     File "<doctest...>", line 4, in lumberjack
       bright_side_of_life()
       ~~~~~~~~~~~~~~~~~~~^^
   IndexError: tuple index out of range
   *** print_exc:
   Traceback (most recent call last):
     File "<doctest...>", line 10, in <module>
       lumberjack()
       ~~~~~~~~~~^^
     File "<doctest...>", line 4, in lumberjack
       bright_side_of_life()
       ~~~~~~~~~~~~~~~~~~~^^
   IndexError: tuple index out of range
   *** format_exc, first and last line:
   Traceback (most recent call last):
   IndexError: tuple index out of range
   *** format_exception:
   ['Traceback (most recent call last):\n',
    '  File "<doctest default[0]>", line 10, in <module>\n    lumberjack()\n    ~~~~~~~~~~^^\n',
    '  File "<doctest default[0]>", line 4, in lumberjack\n    bright_side_of_life()\n    ~~~~~~~~~~~~~~~~~~~^^\n',
    '  File "<doctest default[0]>", line 7, in bright_side_of_life\n    return tuple()[0]\n           ~~~~~~~^^^\n',
    'IndexError: tuple index out of range\n']
   *** extract_tb:
   [<FrameSummary file <doctest...>, line 10 in <module>>,
    <FrameSummary file <doctest...>, line 4 in lumberjack>,
    <FrameSummary file <doctest...>, line 7 in bright_side_of_life>]
   *** format_tb:
   ['  File "<doctest default[0]>", line 10, in <module>\n    lumberjack()\n    ~~~~~~~~~~^^\n',
    '  File "<doctest default[0]>", line 4, in lumberjack\n    bright_side_of_life()\n    ~~~~~~~~~~~~~~~~~~~^^\n',
    '  File "<doctest default[0]>", line 7, in bright_side_of_life\n    return tuple()[0]\n           ~~~~~~~^^^\n']
   *** tb_lineno: 10


The following example shows the different ways to print and format the stack::

   >>> import traceback
   >>> def another_function():
   ...     lumberstack()
   ...
   >>> def lumberstack():
   ...     traceback.print_stack()
   ...     print(repr(traceback.extract_stack()))
   ...     print(repr(traceback.format_stack()))
   ...
   >>> another_function()
     File "<doctest>", line 10, in <module>
       another_function()
     File "<doctest>", line 3, in another_function
       lumberstack()
     File "<doctest>", line 6, in lumberstack
       traceback.print_stack()
   [('<doctest>', 10, '<module>', 'another_function()'),
    ('<doctest>', 3, 'another_function', 'lumberstack()'),
    ('<doctest>', 7, 'lumberstack', 'print(repr(traceback.extract_stack()))')]
   ['  File "<doctest>", line 10, in <module>\n    another_function()\n',
    '  File "<doctest>", line 3, in another_function\n    lumberstack()\n',
    '  File "<doctest>", line 8, in lumberstack\n    print(repr(traceback.format_stack()))\n']


This last example demonstrates the final few formatting functions:

.. doctest::
   :options: +NORMALIZE_WHITESPACE

   >>> import traceback
   >>> traceback.format_list([('spam.py', 3, '<module>', 'spam.eggs()'),
   ...                        ('eggs.py', 42, 'eggs', 'return "bacon"')])
   ['  File "spam.py", line 3, in <module>\n    spam.eggs()\n',
    '  File "eggs.py", line 42, in eggs\n    return "bacon"\n']
   >>> an_error = IndexError('tuple index out of range')
   >>> traceback.format_exception_only(an_error)
   ['IndexError: tuple index out of range\n']


Examples of Using :class:`TracebackException`
---------------------------------------------

With the helper class, we have more options::

   >>> import sys
   >>> from traceback import TracebackException
   >>>
   >>> def lumberjack():
   ...     bright_side_of_life()
   ...
   >>> def bright_side_of_life():
   ...     t = "bright", "side", "of", "life"
   ...     return t[5]
   ...
   >>> try:
   ...     lumberjack()
   ... except IndexError as e:
   ...     exc = e
   ...
   >>> try:
   ...     try:
   ...         lumberjack()
   ...     except:
   ...         1/0
   ... except Exception as e:
   ...     chained_exc = e
   ...
   >>> # limit works as with the module-level functions
   >>> TracebackException.from_exception(exc, limit=-2).print()
   Traceback (most recent call last):
     File "<python-input-1>", line 6, in lumberjack
       bright_side_of_life()
       ~~~~~~~~~~~~~~~~~~~^^
     File "<python-input-1>", line 10, in bright_side_of_life
       return t[5]
              ~^^^
   IndexError: tuple index out of range

   >>> # capture_locals adds local variables in frames
   >>> TracebackException.from_exception(exc, limit=-2, capture_locals=True).print()
   Traceback (most recent call last):
     File "<python-input-1>", line 6, in lumberjack
       bright_side_of_life()
       ~~~~~~~~~~~~~~~~~~~^^
     File "<python-input-1>", line 10, in bright_side_of_life
       return t[5]
              ~^^^
       t = ("bright", "side", "of", "life")
   IndexError: tuple index out of range

   >>> # The *chain* kwarg to print() controls whether chained
   >>> # exceptions are displayed
   >>> TracebackException.from_exception(chained_exc).print()
   Traceback (most recent call last):
     File "<python-input-19>", line 4, in <module>
       lumberjack()
       ~~~~~~~~~~^^
     File "<python-input-8>", line 7, in lumberjack
       bright_side_of_life()
       ~~~~~~~~~~~~~~~~~~~^^
     File "<python-input-8>", line 11, in bright_side_of_life
       return t[5]
              ~^^^
   IndexError: tuple index out of range

   During handling of the above exception, another exception occurred:

   Traceback (most recent call last):
     File "<python-input-19>", line 6, in <module>
       1/0
       ~^~
   ZeroDivisionError: division by zero

   >>> TracebackException.from_exception(chained_exc).print(chain=False)
   Traceback (most recent call last):
     File "<python-input-19>", line 6, in <module>
       1/0
       ~^~
   ZeroDivisionError: division by zero



================================================
File: /Doc/library/tracemalloc.rst
================================================
:mod:`!tracemalloc` --- Trace memory allocations
================================================

.. module:: tracemalloc
   :synopsis: Trace memory allocations.

.. versionadded:: 3.4

**Source code:** :source:`Lib/tracemalloc.py`

--------------

The tracemalloc module is a debug tool to trace memory blocks allocated by
Python. It provides the following information:

* Traceback where an object was allocated
* Statistics on allocated memory blocks per filename and per line number:
  total size, number and average size of allocated memory blocks
* Compute the differences between two snapshots to detect memory leaks

To trace most memory blocks allocated by Python, the module should be started
as early as possible by setting the :envvar:`PYTHONTRACEMALLOC` environment
variable to ``1``, or by using :option:`-X` ``tracemalloc`` command line
option. The :func:`tracemalloc.start` function can be called at runtime to
start tracing Python memory allocations.

By default, a trace of an allocated memory block only stores the most recent
frame (1 frame). To store 25 frames at startup: set the
:envvar:`PYTHONTRACEMALLOC` environment variable to ``25``, or use the
:option:`-X` ``tracemalloc=25`` command line option.


Examples
--------

Display the top 10
^^^^^^^^^^^^^^^^^^

Display the 10 files allocating the most memory::

    import tracemalloc

    tracemalloc.start()

    # ... run your application ...

    snapshot = tracemalloc.take_snapshot()
    top_stats = snapshot.statistics('lineno')

    print("[ Top 10 ]")
    for stat in top_stats[:10]:
        print(stat)


Example of output of the Python test suite::

    [ Top 10 ]
    <frozen importlib._bootstrap>:716: size=4855 KiB, count=39328, average=126 B
    <frozen importlib._bootstrap>:284: size=521 KiB, count=3199, average=167 B
    /usr/lib/python3.4/collections/__init__.py:368: size=244 KiB, count=2315, average=108 B
    /usr/lib/python3.4/unittest/case.py:381: size=185 KiB, count=779, average=243 B
    /usr/lib/python3.4/unittest/case.py:402: size=154 KiB, count=378, average=416 B
    /usr/lib/python3.4/abc.py:133: size=88.7 KiB, count=347, average=262 B
    <frozen importlib._bootstrap>:1446: size=70.4 KiB, count=911, average=79 B
    <frozen importlib._bootstrap>:1454: size=52.0 KiB, count=25, average=2131 B
    <string>:5: size=49.7 KiB, count=148, average=344 B
    /usr/lib/python3.4/sysconfig.py:411: size=48.0 KiB, count=1, average=48.0 KiB

We can see that Python loaded ``4855 KiB`` data (bytecode and constants) from
modules and that the :mod:`collections` module allocated ``244 KiB`` to build
:class:`~collections.namedtuple` types.

See :meth:`Snapshot.statistics` for more options.


Compute differences
^^^^^^^^^^^^^^^^^^^

Take two snapshots and display the differences::

    import tracemalloc
    tracemalloc.start()
    # ... start your application ...

    snapshot1 = tracemalloc.take_snapshot()
    # ... call the function leaking memory ...
    snapshot2 = tracemalloc.take_snapshot()

    top_stats = snapshot2.compare_to(snapshot1, 'lineno')

    print("[ Top 10 differences ]")
    for stat in top_stats[:10]:
        print(stat)

Example of output before/after running some tests of the Python test suite::

    [ Top 10 differences ]
    <frozen importlib._bootstrap>:716: size=8173 KiB (+4428 KiB), count=71332 (+39369), average=117 B
    /usr/lib/python3.4/linecache.py:127: size=940 KiB (+940 KiB), count=8106 (+8106), average=119 B
    /usr/lib/python3.4/unittest/case.py:571: size=298 KiB (+298 KiB), count=589 (+589), average=519 B
    <frozen importlib._bootstrap>:284: size=1005 KiB (+166 KiB), count=7423 (+1526), average=139 B
    /usr/lib/python3.4/mimetypes.py:217: size=112 KiB (+112 KiB), count=1334 (+1334), average=86 B
    /usr/lib/python3.4/http/server.py:848: size=96.0 KiB (+96.0 KiB), count=1 (+1), average=96.0 KiB
    /usr/lib/python3.4/inspect.py:1465: size=83.5 KiB (+83.5 KiB), count=109 (+109), average=784 B
    /usr/lib/python3.4/unittest/mock.py:491: size=77.7 KiB (+77.7 KiB), count=143 (+143), average=557 B
    /usr/lib/python3.4/urllib/parse.py:476: size=71.8 KiB (+71.8 KiB), count=969 (+969), average=76 B
    /usr/lib/python3.4/contextlib.py:38: size=67.2 KiB (+67.2 KiB), count=126 (+126), average=546 B

We can see that Python has loaded ``8173 KiB`` of module data (bytecode and
constants), and that this is ``4428 KiB`` more than had been loaded before the
tests, when the previous snapshot was taken. Similarly, the :mod:`linecache`
module has cached ``940 KiB`` of Python source code to format tracebacks, all
of it since the previous snapshot.

If the system has little free memory, snapshots can be written on disk using
the :meth:`Snapshot.dump` method to analyze the snapshot offline. Then use the
:meth:`Snapshot.load` method reload the snapshot.


Get the traceback of a memory block
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

Code to display the traceback of the biggest memory block::

    import tracemalloc

    # Store 25 frames
    tracemalloc.start(25)

    # ... run your application ...

    snapshot = tracemalloc.take_snapshot()
    top_stats = snapshot.statistics('traceback')

    # pick the biggest memory block
    stat = top_stats[0]
    print("%s memory blocks: %.1f KiB" % (stat.count, stat.size / 1024))
    for line in stat.traceback.format():
        print(line)

Example of output of the Python test suite (traceback limited to 25 frames)::

    903 memory blocks: 870.1 KiB
      File "<frozen importlib._bootstrap>", line 716
      File "<frozen importlib._bootstrap>", line 1036
      File "<frozen importlib._bootstrap>", line 934
      File "<frozen importlib._bootstrap>", line 1068
      File "<frozen importlib._bootstrap>", line 619
      File "<frozen importlib._bootstrap>", line 1581
      File "<frozen importlib._bootstrap>", line 1614
      File "/usr/lib/python3.4/doctest.py", line 101
        import pdb
      File "<frozen importlib._bootstrap>", line 284
      File "<frozen importlib._bootstrap>", line 938
      File "<frozen importlib._bootstrap>", line 1068
      File "<frozen importlib._bootstrap>", line 619
      File "<frozen importlib._bootstrap>", line 1581
      File "<frozen importlib._bootstrap>", line 1614
      File "/usr/lib/python3.4/test/support/__init__.py", line 1728
        import doctest
      File "/usr/lib/python3.4/test/test_pickletools.py", line 21
        support.run_doctest(pickletools)
      File "/usr/lib/python3.4/test/regrtest.py", line 1276
        test_runner()
      File "/usr/lib/python3.4/test/regrtest.py", line 976
        display_failure=not verbose)
      File "/usr/lib/python3.4/test/regrtest.py", line 761
        match_tests=ns.match_tests)
      File "/usr/lib/python3.4/test/regrtest.py", line 1563
        main()
      File "/usr/lib/python3.4/test/__main__.py", line 3
        regrtest.main_in_temp_cwd()
      File "/usr/lib/python3.4/runpy.py", line 73
        exec(code, run_globals)
      File "/usr/lib/python3.4/runpy.py", line 160
        "__main__", fname, loader, pkg_name)

We can see that the most memory was allocated in the :mod:`importlib` module to
load data (bytecode and constants) from modules: ``870.1 KiB``. The traceback is
where the :mod:`importlib` loaded data most recently: on the ``import pdb``
line of the :mod:`doctest` module. The traceback may change if a new module is
loaded.


Pretty top
^^^^^^^^^^

Code to display the 10 lines allocating the most memory with a pretty output,
ignoring ``<frozen importlib._bootstrap>`` and ``<unknown>`` files::

    import linecache
    import os
    import tracemalloc

    def display_top(snapshot, key_type='lineno', limit=10):
        snapshot = snapshot.filter_traces((
            tracemalloc.Filter(False, "<frozen importlib._bootstrap>"),
            tracemalloc.Filter(False, "<unknown>"),
        ))
        top_stats = snapshot.statistics(key_type)

        print("Top %s lines" % limit)
        for index, stat in enumerate(top_stats[:limit], 1):
            frame = stat.traceback[0]
            print("#%s: %s:%s: %.1f KiB"
                  % (index, frame.filename, frame.lineno, stat.size / 1024))
            line = linecache.getline(frame.filename, frame.lineno).strip()
            if line:
                print('    %s' % line)

        other = top_stats[limit:]
        if other:
            size = sum(stat.size for stat in other)
            print("%s other: %.1f KiB" % (len(other), size / 1024))
        total = sum(stat.size for stat in top_stats)
        print("Total allocated size: %.1f KiB" % (total / 1024))

    tracemalloc.start()

    # ... run your application ...

    snapshot = tracemalloc.take_snapshot()
    display_top(snapshot)

Example of output of the Python test suite::

    Top 10 lines
    #1: Lib/base64.py:414: 419.8 KiB
        _b85chars2 = [(a + b) for a in _b85chars for b in _b85chars]
    #2: Lib/base64.py:306: 419.8 KiB
        _a85chars2 = [(a + b) for a in _a85chars for b in _a85chars]
    #3: collections/__init__.py:368: 293.6 KiB
        exec(class_definition, namespace)
    #4: Lib/abc.py:133: 115.2 KiB
        cls = super().__new__(mcls, name, bases, namespace)
    #5: unittest/case.py:574: 103.1 KiB
        testMethod()
    #6: Lib/linecache.py:127: 95.4 KiB
        lines = fp.readlines()
    #7: urllib/parse.py:476: 71.8 KiB
        for a in _hexdig for b in _hexdig}
    #8: <string>:5: 62.0 KiB
    #9: Lib/_weakrefset.py:37: 60.0 KiB
        self.data = set()
    #10: Lib/base64.py:142: 59.8 KiB
        _b32tab2 = [a + b for a in _b32tab for b in _b32tab]
    6220 other: 3602.8 KiB
    Total allocated size: 5303.1 KiB

See :meth:`Snapshot.statistics` for more options.

Record the current and peak size of all traced memory blocks
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The following code computes two sums like ``0 + 1 + 2 + ...`` inefficiently, by
creating a list of those numbers. This list consumes a lot of memory
temporarily. We can use :func:`get_traced_memory` and :func:`reset_peak` to
observe the small memory usage after the sum is computed as well as the peak
memory usage during the computations::

  import tracemalloc

  tracemalloc.start()

  # Example code: compute a sum with a large temporary list
  large_sum = sum(list(range(100000)))

  first_size, first_peak = tracemalloc.get_traced_memory()

  tracemalloc.reset_peak()

  # Example code: compute a sum with a small temporary list
  small_sum = sum(list(range(1000)))

  second_size, second_peak = tracemalloc.get_traced_memory()

  print(f"{first_size=}, {first_peak=}")
  print(f"{second_size=}, {second_peak=}")

Output::

  first_size=664, first_peak=3592984
  second_size=804, second_peak=29704

Using :func:`reset_peak` ensured we could accurately record the peak during the
computation of ``small_sum``, even though it is much smaller than the overall
peak size of memory blocks since the :func:`start` call. Without the call to
:func:`reset_peak`, ``second_peak`` would still be the peak from the
computation ``large_sum`` (that is, equal to ``first_peak``). In this case,
both peaks are much higher than the final memory usage, and which suggests we
could optimise (by removing the unnecessary call to :class:`list`, and writing
``sum(range(...))``).

API
---

Functions
^^^^^^^^^

.. function:: clear_traces()

   Clear traces of memory blocks allocated by Python.

   See also :func:`stop`.


.. function:: get_object_traceback(obj)

   Get the traceback where the Python object *obj* was allocated.
   Return a :class:`Traceback` instance, or ``None`` if the :mod:`tracemalloc`
   module is not tracing memory allocations or did not trace the allocation of
   the object.

   See also :func:`gc.get_referrers` and :func:`sys.getsizeof` functions.


.. function:: get_traceback_limit()

   Get the maximum number of frames stored in the traceback of a trace.

   The :mod:`tracemalloc` module must be tracing memory allocations to
   get the limit, otherwise an exception is raised.

   The limit is set by the :func:`start` function.


.. function:: get_traced_memory()

   Get the current size and peak size of memory blocks traced by the
   :mod:`tracemalloc` module as a tuple: ``(current: int, peak: int)``.


.. function:: reset_peak()

   Set the peak size of memory blocks traced by the :mod:`tracemalloc` module
   to the current size.

   Do nothing if the :mod:`tracemalloc` module is not tracing memory
   allocations.

   This function only modifies the recorded peak size, and does not modify or
   clear any traces, unlike :func:`clear_traces`. Snapshots taken with
   :func:`take_snapshot` before a call to :func:`reset_peak` can be
   meaningfully compared to snapshots taken after the call.

   See also :func:`get_traced_memory`.

   .. versionadded:: 3.9


.. function:: get_tracemalloc_memory()

   Get the memory usage in bytes of the :mod:`tracemalloc` module used to store
   traces of memory blocks.
   Return an :class:`int`.


.. function:: is_tracing()

    ``True`` if the :mod:`tracemalloc` module is tracing Python memory
    allocations, ``False`` otherwise.

    See also :func:`start` and :func:`stop` functions.


.. function:: start(nframe: int=1)

   Start tracing Python memory allocations: install hooks on Python memory
   allocators. Collected tracebacks of traces will be limited to *nframe*
   frames. By default, a trace of a memory block only stores the most recent
   frame: the limit is ``1``. *nframe* must be greater or equal to ``1``.

   You can still read the original number of total frames that composed the
   traceback by looking at the :attr:`Traceback.total_nframe` attribute.

   Storing more than ``1`` frame is only useful to compute statistics grouped
   by ``'traceback'`` or to compute cumulative statistics: see the
   :meth:`Snapshot.compare_to` and :meth:`Snapshot.statistics` methods.

   Storing more frames increases the memory and CPU overhead of the
   :mod:`tracemalloc` module. Use the :func:`get_tracemalloc_memory` function
   to measure how much memory is used by the :mod:`tracemalloc` module.

   The :envvar:`PYTHONTRACEMALLOC` environment variable
   (``PYTHONTRACEMALLOC=NFRAME``) and the :option:`-X` ``tracemalloc=NFRAME``
   command line option can be used to start tracing at startup.

   See also :func:`stop`, :func:`is_tracing` and :func:`get_traceback_limit`
   functions.


.. function:: stop()

   Stop tracing Python memory allocations: uninstall hooks on Python memory
   allocators. Also clears all previously collected traces of memory blocks
   allocated by Python.

   Call :func:`take_snapshot` function to take a snapshot of traces before
   clearing them.

   See also :func:`start`, :func:`is_tracing` and :func:`clear_traces`
   functions.


.. function:: take_snapshot()

   Take a snapshot of traces of memory blocks allocated by Python. Return a new
   :class:`Snapshot` instance.

   The snapshot does not include memory blocks allocated before the
   :mod:`tracemalloc` module started to trace memory allocations.

   Tracebacks of traces are limited to :func:`get_traceback_limit` frames. Use
   the *nframe* parameter of the :func:`start` function to store more frames.

   The :mod:`tracemalloc` module must be tracing memory allocations to take a
   snapshot, see the :func:`start` function.

   See also the :func:`get_object_traceback` function.


DomainFilter
^^^^^^^^^^^^

.. class:: DomainFilter(inclusive: bool, domain: int)

   Filter traces of memory blocks by their address space (domain).

   .. versionadded:: 3.6

   .. attribute:: inclusive

      If *inclusive* is ``True`` (include), match memory blocks allocated
      in the address space :attr:`domain`.

      If *inclusive* is ``False`` (exclude), match memory blocks not allocated
      in the address space :attr:`domain`.

   .. attribute:: domain

      Address space of a memory block (``int``). Read-only property.


Filter
^^^^^^

.. class:: Filter(inclusive: bool, filename_pattern: str, lineno: int=None, all_frames: bool=False, domain: int=None)

   Filter on traces of memory blocks.

   See the :func:`fnmatch.fnmatch` function for the syntax of
   *filename_pattern*. The ``'.pyc'`` file extension is
   replaced with ``'.py'``.

   Examples:

   * ``Filter(True, subprocess.__file__)`` only includes traces of the
     :mod:`subprocess` module
   * ``Filter(False, tracemalloc.__file__)`` excludes traces of the
     :mod:`tracemalloc` module
   * ``Filter(False, "<unknown>")`` excludes empty tracebacks


   .. versionchanged:: 3.5
      The ``'.pyo'`` file extension is no longer replaced with ``'.py'``.

   .. versionchanged:: 3.6
      Added the :attr:`domain` attribute.


   .. attribute:: domain

      Address space of a memory block (``int`` or ``None``).

      tracemalloc uses the domain ``0`` to trace memory allocations made by
      Python. C extensions can use other domains to trace other resources.

   .. attribute:: inclusive

      If *inclusive* is ``True`` (include), only match memory blocks allocated
      in a file with a name matching :attr:`filename_pattern` at line number
      :attr:`lineno`.

      If *inclusive* is ``False`` (exclude), ignore memory blocks allocated in
      a file with a name matching :attr:`filename_pattern` at line number
      :attr:`lineno`.

   .. attribute:: lineno

      Line number (``int``) of the filter. If *lineno* is ``None``, the filter
      matches any line number.

   .. attribute:: filename_pattern

      Filename pattern of the filter (``str``). Read-only property.

   .. attribute:: all_frames

      If *all_frames* is ``True``, all frames of the traceback are checked. If
      *all_frames* is ``False``, only the most recent frame is checked.

      This attribute has no effect if the traceback limit is ``1``.  See the
      :func:`get_traceback_limit` function and :attr:`Snapshot.traceback_limit`
      attribute.


Frame
^^^^^

.. class:: Frame

   Frame of a traceback.

   The :class:`Traceback` class is a sequence of :class:`Frame` instances.

   .. attribute:: filename

      Filename (``str``).

   .. attribute:: lineno

      Line number (``int``).


Snapshot
^^^^^^^^

.. class:: Snapshot

   Snapshot of traces of memory blocks allocated by Python.

   The :func:`take_snapshot` function creates a snapshot instance.

   .. method:: compare_to(old_snapshot: Snapshot, key_type: str, cumulative: bool=False)

      Compute the differences with an old snapshot. Get statistics as a sorted
      list of :class:`StatisticDiff` instances grouped by *key_type*.

      See the :meth:`Snapshot.statistics` method for *key_type* and *cumulative*
      parameters.

      The result is sorted from the biggest to the smallest by: absolute value
      of :attr:`StatisticDiff.size_diff`, :attr:`StatisticDiff.size`, absolute
      value of :attr:`StatisticDiff.count_diff`, :attr:`Statistic.count` and
      then by :attr:`StatisticDiff.traceback`.


   .. method:: dump(filename)

      Write the snapshot into a file.

      Use :meth:`load` to reload the snapshot.


   .. method:: filter_traces(filters)

      Create a new :class:`Snapshot` instance with a filtered :attr:`traces`
      sequence, *filters* is a list of :class:`DomainFilter` and
      :class:`Filter` instances.  If *filters* is an empty list, return a new
      :class:`Snapshot` instance with a copy of the traces.

      All inclusive filters are applied at once, a trace is ignored if no
      inclusive filters match it. A trace is ignored if at least one exclusive
      filter matches it.

      .. versionchanged:: 3.6
         :class:`DomainFilter` instances are now also accepted in *filters*.


   .. classmethod:: load(filename)

      Load a snapshot from a file.

      See also :meth:`dump`.


   .. method:: statistics(key_type: str, cumulative: bool=False)

      Get statistics as a sorted list of :class:`Statistic` instances grouped
      by *key_type*:

      =====================  ========================
      key_type               description
      =====================  ========================
      ``'filename'``         filename
      ``'lineno'``           filename and line number
      ``'traceback'``        traceback
      =====================  ========================

      If *cumulative* is ``True``, cumulate size and count of memory blocks of
      all frames of the traceback of a trace, not only the most recent frame.
      The cumulative mode can only be used with *key_type* equals to
      ``'filename'`` and ``'lineno'``.

      The result is sorted from the biggest to the smallest by:
      :attr:`Statistic.size`, :attr:`Statistic.count` and then by
      :attr:`Statistic.traceback`.


   .. attribute:: traceback_limit

      Maximum number of frames stored in the traceback of :attr:`traces`:
      result of the :func:`get_traceback_limit` when the snapshot was taken.

   .. attribute:: traces

      Traces of all memory blocks allocated by Python: sequence of
      :class:`Trace` instances.

      The sequence has an undefined order. Use the :meth:`Snapshot.statistics`
      method to get a sorted list of statistics.


Statistic
^^^^^^^^^

.. class:: Statistic

   Statistic on memory allocations.

   :func:`Snapshot.statistics` returns a list of :class:`Statistic` instances.

   See also the :class:`StatisticDiff` class.

   .. attribute:: count

      Number of memory blocks (``int``).

   .. attribute:: size

      Total size of memory blocks in bytes (``int``).

   .. attribute:: traceback

      Traceback where the memory block was allocated, :class:`Traceback`
      instance.


StatisticDiff
^^^^^^^^^^^^^

.. class:: StatisticDiff

   Statistic difference on memory allocations between an old and a new
   :class:`Snapshot` instance.

   :func:`Snapshot.compare_to` returns a list of :class:`StatisticDiff`
   instances. See also the :class:`Statistic` class.

   .. attribute:: count

      Number of memory blocks in the new snapshot (``int``): ``0`` if
      the memory blocks have been released in the new snapshot.

   .. attribute:: count_diff

      Difference of number of memory blocks between the old and the new
      snapshots (``int``): ``0`` if the memory blocks have been allocated in
      the new snapshot.

   .. attribute:: size

      Total size of memory blocks in bytes in the new snapshot (``int``):
      ``0`` if the memory blocks have been released in the new snapshot.

   .. attribute:: size_diff

      Difference of total size of memory blocks in bytes between the old and
      the new snapshots (``int``): ``0`` if the memory blocks have been
      allocated in the new snapshot.

   .. attribute:: traceback

      Traceback where the memory blocks were allocated, :class:`Traceback`
      instance.


Trace
^^^^^

.. class:: Trace

   Trace of a memory block.

   The :attr:`Snapshot.traces` attribute is a sequence of :class:`Trace`
   instances.

   .. versionchanged:: 3.6
      Added the :attr:`domain` attribute.

   .. attribute:: domain

      Address space of a memory block (``int``). Read-only property.

      tracemalloc uses the domain ``0`` to trace memory allocations made by
      Python. C extensions can use other domains to trace other resources.

   .. attribute:: size

      Size of the memory block in bytes (``int``).

   .. attribute:: traceback

      Traceback where the memory block was allocated, :class:`Traceback`
      instance.


Traceback
^^^^^^^^^

.. class:: Traceback

   Sequence of :class:`Frame` instances sorted from the oldest frame to the
   most recent frame.

   A traceback contains at least ``1`` frame. If the ``tracemalloc`` module
   failed to get a frame, the filename ``"<unknown>"`` at line number ``0`` is
   used.

   When a snapshot is taken, tracebacks of traces are limited to
   :func:`get_traceback_limit` frames. See the :func:`take_snapshot` function.
   The original number of frames of the traceback is stored in the
   :attr:`Traceback.total_nframe` attribute. That allows to know if a traceback
   has been truncated by the traceback limit.

   The :attr:`Trace.traceback` attribute is an instance of :class:`Traceback`
   instance.

   .. versionchanged:: 3.7
      Frames are now sorted from the oldest to the most recent, instead of most recent to oldest.

   .. attribute:: total_nframe

      Total number of frames that composed the traceback before truncation.
      This attribute can be set to ``None`` if the information is not
      available.

   .. versionchanged:: 3.9
      The :attr:`Traceback.total_nframe` attribute was added.

   .. method:: format(limit=None, most_recent_first=False)

      Format the traceback as a list of lines. Use the :mod:`linecache` module to
      retrieve lines from the source code. If *limit* is set, format the *limit*
      most recent frames if *limit* is positive. Otherwise, format the
      ``abs(limit)`` oldest frames. If *most_recent_first* is ``True``, the order
      of the formatted frames is reversed, returning the most recent frame first
      instead of last.

      Similar to the :func:`traceback.format_tb` function, except that
      :meth:`.format` does not include newlines.

      Example::

          print("Traceback (most recent call first):")
          for line in traceback:
              print(line)

      Output::

          Traceback (most recent call first):
            File "test.py", line 9
              obj = Object()
            File "test.py", line 12
              tb = tracemalloc.get_object_traceback(f())


================================================
File: /Doc/library/tty.rst
================================================
:mod:`!tty` --- Terminal control functions
==========================================

.. module:: tty
   :platform: Unix
   :synopsis: Utility functions that perform common terminal control operations.

.. moduleauthor:: Steen Lumholt
.. sectionauthor:: Moshe Zadka <moshez@zadka.site.co.il>

**Source code:** :source:`Lib/tty.py`

--------------

The :mod:`tty` module defines functions for putting the tty into cbreak and raw
modes.

.. availability:: Unix.

Because it requires the :mod:`termios` module, it will work only on Unix.

The :mod:`tty` module defines the following functions:


.. function:: cfmakeraw(mode)

   Convert the tty attribute list *mode*, which is a list like the one returned
   by :func:`termios.tcgetattr`, to that of a tty in raw mode.

   .. versionadded:: 3.12


.. function:: cfmakecbreak(mode)

   Convert the tty attribute list *mode*, which is a list like the one returned
   by :func:`termios.tcgetattr`, to that of a tty in cbreak mode.

   This clears the ``ECHO`` and ``ICANON`` local mode flags in *mode* as well
   as setting the minimum input to 1 byte with no delay.

   .. versionadded:: 3.12

   .. versionchanged:: 3.12.2
      The ``ICRNL`` flag is no longer cleared. This matches Linux and macOS
      ``stty cbreak`` behavior and what :func:`setcbreak` historically did.


.. function:: setraw(fd, when=termios.TCSAFLUSH)

   Change the mode of the file descriptor *fd* to raw. If *when* is omitted, it
   defaults to :const:`termios.TCSAFLUSH`, and is passed to
   :func:`termios.tcsetattr`. The return value of :func:`termios.tcgetattr`
   is saved before setting *fd* to raw mode; this value is returned.

   .. versionchanged:: 3.12
      The return value is now the original tty attributes, instead of ``None``.


.. function:: setcbreak(fd, when=termios.TCSAFLUSH)

   Change the mode of file descriptor *fd* to cbreak. If *when* is omitted, it
   defaults to :const:`termios.TCSAFLUSH`, and is passed to
   :func:`termios.tcsetattr`. The return value of :func:`termios.tcgetattr`
   is saved before setting *fd* to cbreak mode; this value is returned.

   This clears the ``ECHO`` and ``ICANON`` local mode flags as well as setting
   the minimum input to 1 byte with no delay.

   .. versionchanged:: 3.12
      The return value is now the original tty attributes, instead of ``None``.

   .. versionchanged:: 3.12.2
      The ``ICRNL`` flag is no longer cleared. This restores the behavior
      of Python 3.11 and earlier as well as matching what Linux, macOS, & BSDs
      describe in their ``stty(1)`` man pages regarding cbreak mode.


.. seealso::

   Module :mod:`termios`
      Low-level terminal control interface.



================================================
File: /Doc/library/turtle-star.ps
================================================
%!PS-Adobe-3.0 EPSF-3.0
%%Creator: Tk Canvas Widget
%%For: Alexander Belopolsky
%%Title: Window .4315905424
%%CreationDate: Tue Nov  9 12:54:06 2010
%%XBoundingBox: -172 -52 785 845
%%BoundingBox: 290 290 520 520
%%Pages: 1
%%DocumentData: Clean7Bit
%%Orientation: Portrait
%%EndComments

%%BeginProlog
/CurrentEncoding [
/space/space/space/space/space/space/space/space
/space/space/space/space/space/space/space/space
/space/space/space/space/space/space/space/space
/space/space/space/space/space/space/space/space
/space/exclam/quotedbl/numbersign/dollar/percent/ampersand/quotesingle
/parenleft/parenright/asterisk/plus/comma/hyphen/period/slash
/zero/one/two/three/four/five/six/seven
/eight/nine/colon/semicolon/less/equal/greater/question
/at/A/B/C/D/E/F/G
/H/I/J/K/L/M/N/O
/P/Q/R/S/T/U/V/W
/X/Y/Z/bracketleft/backslash/bracketright/asciicircum/underscore
/grave/a/b/c/d/e/f/g
/h/i/j/k/l/m/n/o
/p/q/r/s/t/u/v/w
/x/y/z/braceleft/bar/braceright/asciitilde/space
/space/space/space/space/space/space/space/space
/space/space/space/space/space/space/space/space
/space/space/space/space/space/space/space/space
/space/space/space/space/space/space/space/space
/space/exclamdown/cent/sterling/currency/yen/brokenbar/section
/dieresis/copyright/ordfeminine/guillemotleft/logicalnot/hyphen/registered/macron
/degree/plusminus/twosuperior/threesuperior/acute/mu/paragraph/periodcentered
/cedilla/onesuperior/ordmasculine/guillemotright/onequarter/onehalf/threequarters/questiondown
/Agrave/Aacute/Acircumflex/Atilde/Adieresis/Aring/AE/Ccedilla
/Egrave/Eacute/Ecircumflex/Edieresis/Igrave/Iacute/Icircumflex/Idieresis
/Eth/Ntilde/Ograve/Oacute/Ocircumflex/Otilde/Odieresis/multiply
/Oslash/Ugrave/Uacute/Ucircumflex/Udieresis/Yacute/Thorn/germandbls
/agrave/aacute/acircumflex/atilde/adieresis/aring/ae/ccedilla
/egrave/eacute/ecircumflex/edieresis/igrave/iacute/icircumflex/idieresis
/eth/ntilde/ograve/oacute/ocircumflex/otilde/odieresis/divide
/oslash/ugrave/uacute/ucircumflex/udieresis/yacute/thorn/ydieresis
] def

50 dict begin
% This is a standard prolog for Postscript generated by Tk's canvas
% widget.
% RCS: @(#) $Id$

% The definitions below just define all of the variables used in
% any of the procedures here.  This is needed for obscure reasons
% explained on p. 716 of the Postscript manual (Section H.2.7,
% "Initializing Variables," in the section on Encapsulated Postscript).

/baseline 0 def
/stipimage 0 def
/height 0 def
/justify 0 def
/lineLength 0 def
/spacing 0 def
/stipple 0 def
/strings 0 def
/xoffset 0 def
/yoffset 0 def
/tmpstip null def


/cstringshow {
    {
	dup type /stringtype eq
	{ show } { glyphshow }
	ifelse
    }
    forall
} bind def



/cstringwidth {
    0 exch 0 exch
    {
	dup type /stringtype eq
	{ stringwidth } { 
	    currentfont /Encoding get exch 1 exch put (\001) stringwidth 
        }
	ifelse 
	exch 3 1 roll add 3 1 roll add exch
    }
    forall
} bind def

% font ISOEncode font
% This procedure changes the encoding of a font from the default
% Postscript encoding to current system encoding.  It's typically invoked just
% before invoking "setfont".  The body of this procedure comes from
% Section 5.6.1 of the Postscript book.

/ISOEncode {
    dup length dict begin
	{1 index /FID ne {def} {pop pop} ifelse} forall
	/Encoding CurrentEncoding def
	currentdict
    end

    % I'm not sure why it's necessary to use "definefont" on this new
    % font, but it seems to be important; just use the name "Temporary"
    % for the font.

    /Temporary exch definefont
} bind def

% StrokeClip
%
% This procedure converts the current path into a clip area under
% the assumption of stroking.  It's a bit tricky because some Postscript
% interpreters get errors during strokepath for dashed lines.  If
% this happens then turn off dashes and try again.

/StrokeClip {
    {strokepath} stopped {
	(This Postscript printer gets limitcheck overflows when) =
	(stippling dashed lines;  lines will be printed solid instead.) =
	[] 0 setdash strokepath} if
    clip
} bind def

% desiredSize EvenPixels closestSize
%
% The procedure below is used for stippling.  Given the optimal size
% of a dot in a stipple pattern in the current user coordinate system,
% compute the closest size that is an exact multiple of the device's
% pixel size.  This allows stipple patterns to be displayed without
% aliasing effects.

/EvenPixels {
    % Compute exact number of device pixels per stipple dot.
    dup 0 matrix currentmatrix dtransform
    dup mul exch dup mul add sqrt

    % Round to an integer, make sure the number is at least 1, and compute
    % user coord distance corresponding to this.
    dup round dup 1 lt {pop 1} if
    exch div mul
} bind def

% width height string StippleFill --
%
% Given a path already set up and a clipping region generated from
% it, this procedure will fill the clipping region with a stipple
% pattern.  "String" contains a proper image description of the
% stipple pattern and "width" and "height" give its dimensions.  Each
% stipple dot is assumed to be about one unit across in the current
% user coordinate system.  This procedure trashes the graphics state.

/StippleFill {
    % The following code is needed to work around a NeWSprint bug.

    /tmpstip 1 index def

    % Change the scaling so that one user unit in user coordinates
    % corresponds to the size of one stipple dot.
    1 EvenPixels dup scale

    % Compute the bounding box occupied by the path (which is now
    % the clipping region), and round the lower coordinates down
    % to the nearest starting point for the stipple pattern.  Be
    % careful about negative numbers, since the rounding works
    % differently on them.

    pathbbox
    4 2 roll
    5 index div dup 0 lt {1 sub} if cvi 5 index mul 4 1 roll
    6 index div dup 0 lt {1 sub} if cvi 6 index mul 3 2 roll

    % Stack now: width height string y1 y2 x1 x2
    % Below is a doubly-nested for loop to iterate across this area
    % in units of the stipple pattern size, going up columns then
    % across rows, blasting out a stipple-pattern-sized rectangle at
    % each position

    6 index exch {
	2 index 5 index 3 index {
	    % Stack now: width height string y1 y2 x y

	    gsave
	    1 index exch translate
	    5 index 5 index true matrix tmpstip imagemask
	    grestore
	} for
	pop
    } for
    pop pop pop pop pop
} bind def

% -- AdjustColor --
% Given a color value already set for output by the caller, adjusts
% that value to a grayscale or mono value if requested by the CL
% variable.

/AdjustColor {
    CL 2 lt {
	currentgray
	CL 0 eq {
	    .5 lt {0} {1} ifelse
	} if
	setgray
    } if
} bind def

% x y strings spacing xoffset yoffset justify stipple DrawText --
% This procedure does all of the real work of drawing text.  The
% color and font must already have been set by the caller, and the
% following arguments must be on the stack:
%
% x, y -	Coordinates at which to draw text.
% strings -	An array of strings, one for each line of the text item,
%		in order from top to bottom.
% spacing -	Spacing between lines.
% xoffset -	Horizontal offset for text bbox relative to x and y: 0 for
%		nw/w/sw anchor, -0.5 for n/center/s, and -1.0 for ne/e/se.
% yoffset -	Vertical offset for text bbox relative to x and y: 0 for
%		nw/n/ne anchor, +0.5 for w/center/e, and +1.0 for sw/s/se.
% justify -	0 for left justification, 0.5 for center, 1 for right justify.
% stipple -	Boolean value indicating whether or not text is to be
%		drawn in stippled fashion.  If text is stippled,
%		procedure StippleText must have been defined to call
%		StippleFill in the right way.
%
% Also, when this procedure is invoked, the color and font must already
% have been set for the text.

/DrawText {
    /stipple exch def
    /justify exch def
    /yoffset exch def
    /xoffset exch def
    /spacing exch def
    /strings exch def

    % First scan through all of the text to find the widest line.

    /lineLength 0 def
    strings {
	cstringwidth pop
	dup lineLength gt {/lineLength exch def} {pop} ifelse
	newpath
    } forall

    % Compute the baseline offset and the actual font height.

    0 0 moveto (TXygqPZ) false charpath
    pathbbox dup /baseline exch def
    exch pop exch sub /height exch def pop
    newpath

    % Translate coordinates first so that the origin is at the upper-left
    % corner of the text's bounding box. Remember that x and y for
    % positioning are still on the stack.

    translate
    lineLength xoffset mul
    strings length 1 sub spacing mul height add yoffset mul translate

    % Now use the baseline and justification information to translate so
    % that the origin is at the baseline and positioning point for the
    % first line of text.

    justify lineLength mul baseline neg translate

    % Iterate over each of the lines to output it.  For each line,
    % compute its width again so it can be properly justified, then
    % display it.

    strings {
	dup cstringwidth pop
	justify neg mul 0 moveto
	stipple {
	   
 
	    % The text is stippled, so turn it into a path and print
	    % by calling StippledText, which in turn calls StippleFill.
	    % Unfortunately, many Postscript interpreters will get
	    % overflow errors if we try to do the whole string at
	    % once, so do it a character at a time.

	    gsave
	    /char (X) def
	    {
		dup type /stringtype eq {
		    % This segment is a string.
		    {
		        char 0 3 -1 roll put
		        currentpoint
		        gsave
		        char true charpath clip StippleText
		        grestore
		        char stringwidth translate
		        moveto
		    } forall
		} {
		    % This segment is glyph name
		    % Temporary override
		    currentfont /Encoding get exch 1 exch put
		    currentpoint
		    gsave (\001) true charpath clip StippleText
		    grestore
	            (\001) stringwidth translate
		    moveto
		} ifelse
	    } forall
	    grestore 
	} {cstringshow} ifelse
	0 spacing neg translate
    } forall
} bind def

%%EndProlog
%%BeginSetup
/CL 2 def
%%EndSetup

%%Page: 1 1
save
306.0 396.0 translate
0.9995 0.9995 scale
4 -449 translate
-483 898 moveto 475 898 lineto 475 0 lineto -483 0 lineto closepath clip newpath
gsave
grestore
gsave
0 445 moveto
200 445 lineto
3.03844939755837 479.729635533386 lineto
190.97697355474 411.325606868252 lineto
17.7718927978523 511.325606868252 lineto
170.980781421648 382.768084930944 lineto
42.42325948434 535.97697355474 lineto
142.42325948434 362.771892797852 lineto
74.0192308192062 550.710416955034 lineto
108.748866352592 353.748866352592 lineto
108.748866352592 553.748866352592 lineto
74.0192308192064 356.787315750151 lineto
142.42325948434 544.725839907333 lineto
42.4232594843401 371.520759150445 lineto
170.980781421648 524.72964777424 lineto
17.7718927978524 396.172125836932 lineto
190.97697355474 496.172125836933 lineto
3.03844939755834 427.768097171799 lineto
200 462.497732705185 lineto
-1.13686837721616e-13 462.497732705185 lineto
196.961550602442 427.768097171799 lineto
9.02302644525972 496.172125836932 lineto
182.228107202148 396.172125836933 lineto
29.0192185783518 524.72964777424 lineto
157.57674051566 371.520759150445 lineto
57.5767405156596 544.725839907332 lineto
125.980769180794 356.787315750151 lineto
91.2511336474073 553.748866352592 lineto
91.2511336474079 353.748866352592 lineto
125.980769180793 550.710416955034 lineto
57.5767405156601 362.771892797852 lineto
157.57674051566 535.97697355474 lineto
29.0192185783522 382.768084930944 lineto
182.228107202148 511.325606868253 lineto
9.02302644525994 411.325606868252 lineto
196.961550602442 479.729635533386 lineto
-1.70530256582424e-13 445 lineto
0 445 lineto
1.000 1.000 0.000 setrgbcolor AdjustColor
eofill
grestore
gsave
0 445 moveto
200 445 lineto
3.03844939755837 479.729635533386 lineto
190.97697355474 411.325606868252 lineto
17.7718927978523 511.325606868252 lineto
170.980781421648 382.768084930944 lineto
42.42325948434 535.97697355474 lineto
142.42325948434 362.771892797852 lineto
74.0192308192062 550.710416955034 lineto
108.748866352592 353.748866352592 lineto
108.748866352592 553.748866352592 lineto
74.0192308192064 356.787315750151 lineto
142.42325948434 544.725839907333 lineto
42.4232594843401 371.520759150445 lineto
170.980781421648 524.72964777424 lineto
17.7718927978524 396.172125836932 lineto
190.97697355474 496.172125836933 lineto
3.03844939755834 427.768097171799 lineto
200 462.497732705185 lineto
-1.13686837721616e-13 462.497732705185 lineto
196.961550602442 427.768097171799 lineto
9.02302644525972 496.172125836932 lineto
182.228107202148 396.172125836933 lineto
29.0192185783518 524.72964777424 lineto
157.57674051566 371.520759150445 lineto
57.5767405156596 544.725839907332 lineto
125.980769180794 356.787315750151 lineto
91.2511336474073 553.748866352592 lineto
91.2511336474079 353.748866352592 lineto
125.980769180793 550.710416955034 lineto
57.5767405156601 362.771892797852 lineto
157.57674051566 535.97697355474 lineto
29.0192185783522 382.768084930944 lineto
182.228107202148 511.325606868253 lineto
9.02302644525994 411.325606868252 lineto
196.961550602442 479.729635533386 lineto
-1.70530256582424e-13 445 lineto
1 setlinecap
1 setlinejoin
1 setlinewidth
[] 0 setdash
1.000 0.000 0.000 setrgbcolor AdjustColor
stroke
grestore
gsave
grestore
gsave
-1.70530256582424e-13 445 moveto
-9.00000000000019 450 lineto
-7.00000000000017 445 lineto
-9.00000000000015 440 lineto
-1.70530256582424e-13 445 lineto
1.000 1.000 0.000 setrgbcolor AdjustColor
eofill
-1.70530256582424e-13 445 moveto
-9.00000000000019 450 lineto
-7.00000000000017 445 lineto
-9.00000000000015 440 lineto
-1.70530256582424e-13 445 lineto
1 setlinejoin 1 setlinecap
1 setlinewidth
[] 0 setdash
1.000 0.000 0.000 setrgbcolor AdjustColor
stroke
grestore
restore showpage

%%Trailer
end
%%EOF



================================================
File: /Doc/library/types.rst
================================================
:mod:`!types` --- Dynamic type creation and names for built-in types
====================================================================

.. module:: types
   :synopsis: Names for built-in types.

**Source code:** :source:`Lib/types.py`

--------------

This module defines utility functions to assist in dynamic creation of
new types.

It also defines names for some object types that are used by the standard
Python interpreter, but not exposed as builtins like :class:`int` or
:class:`str` are.

Finally, it provides some additional type-related utility classes and functions
that are not fundamental enough to be builtins.


Dynamic Type Creation
---------------------

.. function:: new_class(name, bases=(), kwds=None, exec_body=None)

   Creates a class object dynamically using the appropriate metaclass.

   The first three arguments are the components that make up a class
   definition header: the class name, the base classes (in order), the
   keyword arguments (such as ``metaclass``).

   The *exec_body* argument is a callback that is used to populate the
   freshly created class namespace. It should accept the class namespace
   as its sole argument and update the namespace directly with the class
   contents. If no callback is provided, it has the same effect as passing
   in ``lambda ns: None``.

   .. versionadded:: 3.3

.. function:: prepare_class(name, bases=(), kwds=None)

   Calculates the appropriate metaclass and creates the class namespace.

   The arguments are the components that make up a class definition header:
   the class name, the base classes (in order) and the keyword arguments
   (such as ``metaclass``).

   The return value is a 3-tuple: ``metaclass, namespace, kwds``

   *metaclass* is the appropriate metaclass, *namespace* is the
   prepared class namespace and *kwds* is an updated copy of the passed
   in *kwds* argument with any ``'metaclass'`` entry removed. If no *kwds*
   argument is passed in, this will be an empty dict.

   .. versionadded:: 3.3

   .. versionchanged:: 3.6

      The default value for the ``namespace`` element of the returned
      tuple has changed.  Now an insertion-order-preserving mapping is
      used when the metaclass does not have a ``__prepare__`` method.

.. seealso::

   :ref:`metaclasses`
      Full details of the class creation process supported by these functions

   :pep:`3115` - Metaclasses in Python 3000
      Introduced the ``__prepare__`` namespace hook

.. function:: resolve_bases(bases)

   Resolve MRO entries dynamically as specified by :pep:`560`.

   This function looks for items in *bases* that are not instances of
   :class:`type`, and returns a tuple where each such object that has
   an :meth:`~object.__mro_entries__` method is replaced with an unpacked result of
   calling this method.  If a *bases* item is an instance of :class:`type`,
   or it doesn't have an :meth:`!__mro_entries__` method, then it is included in
   the return tuple unchanged.

   .. versionadded:: 3.7

.. function:: get_original_bases(cls, /)

    Return the tuple of objects originally given as the bases of *cls* before
    the :meth:`~object.__mro_entries__` method has been called on any bases
    (following the mechanisms laid out in :pep:`560`). This is useful for
    introspecting :ref:`Generics <user-defined-generics>`.

    For classes that have an ``__orig_bases__`` attribute, this
    function returns the value of ``cls.__orig_bases__``.
    For classes without the ``__orig_bases__`` attribute,
    :attr:`cls.__bases__ <type.__bases__>` is returned.

    Examples::

        from typing import TypeVar, Generic, NamedTuple, TypedDict

        T = TypeVar("T")
        class Foo(Generic[T]): ...
        class Bar(Foo[int], float): ...
        class Baz(list[str]): ...
        Eggs = NamedTuple("Eggs", [("a", int), ("b", str)])
        Spam = TypedDict("Spam", {"a": int, "b": str})

        assert Bar.__bases__ == (Foo, float)
        assert get_original_bases(Bar) == (Foo[int], float)

        assert Baz.__bases__ == (list,)
        assert get_original_bases(Baz) == (list[str],)

        assert Eggs.__bases__ == (tuple,)
        assert get_original_bases(Eggs) == (NamedTuple,)

        assert Spam.__bases__ == (dict,)
        assert get_original_bases(Spam) == (TypedDict,)

        assert int.__bases__ == (object,)
        assert get_original_bases(int) == (object,)

    .. versionadded:: 3.12

.. seealso::

   :pep:`560` - Core support for typing module and generic types


Standard Interpreter Types
--------------------------

This module provides names for many of the types that are required to
implement a Python interpreter. It deliberately avoids including some of
the types that arise only incidentally during processing such as the
``listiterator`` type.

Typical use of these names is for :func:`isinstance` or
:func:`issubclass` checks.


If you instantiate any of these types, note that signatures may vary between Python versions.

Standard names are defined for the following types:

.. data:: NoneType

   The type of :data:`None`.

   .. versionadded:: 3.10


.. data:: FunctionType
          LambdaType

   The type of user-defined functions and functions created by
   :keyword:`lambda`  expressions.

   .. audit-event:: function.__new__ code types.FunctionType

   The audit event only occurs for direct instantiation of function objects,
   and is not raised for normal compilation.


.. data:: GeneratorType

   The type of :term:`generator`-iterator objects, created by
   generator functions.


.. data:: CoroutineType

   The type of :term:`coroutine` objects, created by
   :keyword:`async def` functions.

   .. versionadded:: 3.5


.. data:: AsyncGeneratorType

   The type of :term:`asynchronous generator`-iterator objects, created by
   asynchronous generator functions.

   .. versionadded:: 3.6


.. class:: CodeType(**kwargs)

   .. index:: pair: built-in function; compile

   The type of :ref:`code objects <code-objects>` such as returned by :func:`compile`.

   .. audit-event:: code.__new__ code,filename,name,argcount,posonlyargcount,kwonlyargcount,nlocals,stacksize,flags types.CodeType

   Note that the audited arguments may not match the names or positions
   required by the initializer.  The audit event only occurs for direct
   instantiation of code objects, and is not raised for normal compilation.

.. data:: CellType

   The type for cell objects: such objects are used as containers for
   a function's :term:`closure variables <closure variable>`.

   .. versionadded:: 3.8


.. data:: MethodType

   The type of methods of user-defined class instances.


.. data:: BuiltinFunctionType
          BuiltinMethodType

   The type of built-in functions like :func:`len` or :func:`sys.exit`, and
   methods of built-in classes.  (Here, the term "built-in" means "written in
   C".)


.. data:: WrapperDescriptorType

   The type of methods of some built-in data types and base classes such as
   :meth:`object.__init__` or :meth:`object.__lt__`.

   .. versionadded:: 3.7


.. data:: MethodWrapperType

   The type of *bound* methods of some built-in data types and base classes.
   For example it is the type of :code:`object().__str__`.

   .. versionadded:: 3.7


.. data:: NotImplementedType

   The type of :data:`NotImplemented`.

   .. versionadded:: 3.10


.. data:: MethodDescriptorType

   The type of methods of some built-in data types such as :meth:`str.join`.

   .. versionadded:: 3.7


.. data:: ClassMethodDescriptorType

   The type of *unbound* class methods of some built-in data types such as
   ``dict.__dict__['fromkeys']``.

   .. versionadded:: 3.7


.. class:: ModuleType(name, doc=None)

   The type of :term:`modules <module>`. The constructor takes the name of the
   module to be created and optionally its :term:`docstring`.

   .. seealso::

      :ref:`Documentation on module objects <module-objects>`
         Provides details on the special attributes that can be found on
         instances of :class:`!ModuleType`.

      :func:`importlib.util.module_from_spec`
         Modules created using the :class:`!ModuleType` constructor are
         created with many of their special attributes unset or set to default
         values. :func:`!module_from_spec` provides a more robust way of
         creating :class:`!ModuleType` instances which ensures the various
         attributes are set appropriately.

.. data:: EllipsisType

   The type of :data:`Ellipsis`.

   .. versionadded:: 3.10

.. class:: GenericAlias(t_origin, t_args)

   The type of :ref:`parameterized generics <types-genericalias>` such as
   ``list[int]``.

   ``t_origin`` should be a non-parameterized generic class, such as ``list``,
   ``tuple`` or ``dict``.  ``t_args`` should be a :class:`tuple` (possibly of
   length 1) of types which parameterize ``t_origin``::

      >>> from types import GenericAlias

      >>> list[int] == GenericAlias(list, (int,))
      True
      >>> dict[str, int] == GenericAlias(dict, (str, int))
      True

   .. versionadded:: 3.9

   .. versionchanged:: 3.9.2
      This type can now be subclassed.

   .. seealso::

      :ref:`Generic Alias Types<types-genericalias>`
         In-depth documentation on instances of :class:`!types.GenericAlias`

      :pep:`585` - Type Hinting Generics In Standard Collections
         Introducing the :class:`!types.GenericAlias` class

.. class:: UnionType

   The type of :ref:`union type expressions<types-union>`.

   .. versionadded:: 3.10

.. class:: TracebackType(tb_next, tb_frame, tb_lasti, tb_lineno)

   The type of traceback objects such as found in ``sys.exception().__traceback__``.

   See :ref:`the language reference <traceback-objects>` for details of the
   available attributes and operations, and guidance on creating tracebacks
   dynamically.


.. data:: FrameType

   The type of :ref:`frame objects <frame-objects>` such as found in
   :attr:`tb.tb_frame <traceback.tb_frame>` if ``tb`` is a traceback object.


.. data:: GetSetDescriptorType

   The type of objects defined in extension modules with ``PyGetSetDef``, such
   as :attr:`FrameType.f_locals <frame.f_locals>` or ``array.array.typecode``.
   This type is used as
   descriptor for object attributes; it has the same purpose as the
   :class:`property` type, but for classes defined in extension modules.


.. data:: MemberDescriptorType

   The type of objects defined in extension modules with ``PyMemberDef``, such
   as ``datetime.timedelta.days``.  This type is used as descriptor for simple C
   data members which use standard conversion functions; it has the same purpose
   as the :class:`property` type, but for classes defined in extension modules.

   In addition, when a class is defined with a :attr:`~object.__slots__` attribute, then for
   each slot, an instance of :class:`!MemberDescriptorType` will be added as an attribute
   on the class. This allows the slot to appear in the class's :attr:`~type.__dict__`.

   .. impl-detail::

      In other implementations of Python, this type may be identical to
      ``GetSetDescriptorType``.

.. class:: MappingProxyType(mapping)

   Read-only proxy of a mapping. It provides a dynamic view on the mapping's
   entries, which means that when the mapping changes, the view reflects these
   changes.

   .. versionadded:: 3.3

   .. versionchanged:: 3.9

      Updated to support the new union (``|``) operator from :pep:`584`, which
      simply delegates to the underlying mapping.

   .. describe:: key in proxy

      Return ``True`` if the underlying mapping has a key *key*, else
      ``False``.

   .. describe:: proxy[key]

      Return the item of the underlying mapping with key *key*.  Raises a
      :exc:`KeyError` if *key* is not in the underlying mapping.

   .. describe:: iter(proxy)

      Return an iterator over the keys of the underlying mapping.  This is a
      shortcut for ``iter(proxy.keys())``.

   .. describe:: len(proxy)

      Return the number of items in the underlying mapping.

   .. method:: copy()

      Return a shallow copy of the underlying mapping.

   .. method:: get(key[, default])

      Return the value for *key* if *key* is in the underlying mapping, else
      *default*.  If *default* is not given, it defaults to ``None``, so that
      this method never raises a :exc:`KeyError`.

   .. method:: items()

      Return a new view of the underlying mapping's items (``(key, value)``
      pairs).

   .. method:: keys()

      Return a new view of the underlying mapping's keys.

   .. method:: values()

      Return a new view of the underlying mapping's values.

   .. describe:: reversed(proxy)

      Return a reverse iterator over the keys of the underlying mapping.

      .. versionadded:: 3.9

   .. describe:: hash(proxy)

      Return a hash of the underlying mapping.

      .. versionadded:: 3.12

.. class:: CapsuleType

   The type of :ref:`capsule objects <capsules>`.

   .. versionadded:: 3.13


Additional Utility Classes and Functions
----------------------------------------

.. class:: SimpleNamespace

   A simple :class:`object` subclass that provides attribute access to its
   namespace, as well as a meaningful repr.

   Unlike :class:`object`, with :class:`!SimpleNamespace` you can add and remove
   attributes.

   :py:class:`SimpleNamespace` objects may be initialized
   in the same way as :class:`dict`: either with keyword arguments,
   with a single positional argument, or with both.
   When initialized with keyword arguments,
   those are directly added to the underlying namespace.
   Alternatively, when initialized with a positional argument,
   the underlying namespace will be updated with key-value pairs
   from that argument (either a mapping object or
   an :term:`iterable` object producing key-value pairs).
   All such keys must be strings.

   The type is roughly equivalent to the following code::

       class SimpleNamespace:
           def __init__(self, mapping_or_iterable=(), /, **kwargs):
               self.__dict__.update(mapping_or_iterable)
               self.__dict__.update(kwargs)

           def __repr__(self):
               items = (f"{k}={v!r}" for k, v in self.__dict__.items())
               return "{}({})".format(type(self).__name__, ", ".join(items))

           def __eq__(self, other):
               if isinstance(self, SimpleNamespace) and isinstance(other, SimpleNamespace):
                  return self.__dict__ == other.__dict__
               return NotImplemented

   ``SimpleNamespace`` may be useful as a replacement for ``class NS: pass``.
   However, for a structured record type use :func:`~collections.namedtuple`
   instead.

   :class:`!SimpleNamespace` objects are supported by :func:`copy.replace`.

   .. versionadded:: 3.3

   .. versionchanged:: 3.9
      Attribute order in the repr changed from alphabetical to insertion (like
      ``dict``).

   .. versionchanged:: 3.13
      Added support for an optional positional argument.

.. function:: DynamicClassAttribute(fget=None, fset=None, fdel=None, doc=None)

   Route attribute access on a class to __getattr__.

   This is a descriptor, used to define attributes that act differently when
   accessed through an instance and through a class.  Instance access remains
   normal, but access to an attribute through a class will be routed to the
   class's __getattr__ method; this is done by raising AttributeError.

   This allows one to have properties active on an instance, and have virtual
   attributes on the class with the same name (see :class:`enum.Enum` for an example).

   .. versionadded:: 3.4


Coroutine Utility Functions
---------------------------

.. function:: coroutine(gen_func)

   This function transforms a :term:`generator` function into a
   :term:`coroutine function` which returns a generator-based coroutine.
   The generator-based coroutine is still a :term:`generator iterator`,
   but is also considered to be a :term:`coroutine` object and is
   :term:`awaitable`.  However, it may not necessarily implement
   the :meth:`~object.__await__` method.

   If *gen_func* is a generator function, it will be modified in-place.

   If *gen_func* is not a generator function, it will be wrapped. If it
   returns an instance of :class:`collections.abc.Generator`, the instance
   will be wrapped in an *awaitable* proxy object.  All other types
   of objects will be returned as is.

   .. versionadded:: 3.5


================================================
File: /Doc/library/unicodedata.rst
================================================
:mod:`!unicodedata` --- Unicode Database
========================================

.. module:: unicodedata
   :synopsis: Access the Unicode Database.

.. moduleauthor:: Marc-Andr Lemburg <mal@lemburg.com>
.. sectionauthor:: Marc-Andr Lemburg <mal@lemburg.com>
.. sectionauthor:: Martin v. Lwis <martin@v.loewis.de>

.. index::
   single: Unicode
   single: character
   pair: Unicode; database

--------------

This module provides access to the Unicode Character Database (UCD) which
defines character properties for all Unicode characters. The data contained in
this database is compiled from the `UCD version 16.0.0
<https://www.unicode.org/Public/16.0.0/ucd>`_.

The module uses the same names and symbols as defined by Unicode
Standard Annex #44, `"Unicode Character Database"
<https://www.unicode.org/reports/tr44/>`_.  It defines the
following functions:


.. function:: lookup(name)

   Look up character by name.  If a character with the given name is found, return
   the corresponding character.  If not found, :exc:`KeyError` is raised.

   .. versionchanged:: 3.3
      Support for name aliases [#]_ and named sequences [#]_ has been added.


.. function:: name(chr[, default])

   Returns the name assigned to the character *chr* as a string. If no
   name is defined, *default* is returned, or, if not given, :exc:`ValueError` is
   raised.


.. function:: decimal(chr[, default])

   Returns the decimal value assigned to the character *chr* as integer.
   If no such value is defined, *default* is returned, or, if not given,
   :exc:`ValueError` is raised.


.. function:: digit(chr[, default])

   Returns the digit value assigned to the character *chr* as integer.
   If no such value is defined, *default* is returned, or, if not given,
   :exc:`ValueError` is raised.


.. function:: numeric(chr[, default])

   Returns the numeric value assigned to the character *chr* as float.
   If no such value is defined, *default* is returned, or, if not given,
   :exc:`ValueError` is raised.


.. function:: category(chr)

   Returns the general category assigned to the character *chr* as
   string.


.. function:: bidirectional(chr)

   Returns the bidirectional class assigned to the character *chr* as
   string. If no such value is defined, an empty string is returned.


.. function:: combining(chr)

   Returns the canonical combining class assigned to the character *chr*
   as integer. Returns ``0`` if no combining class is defined.


.. function:: east_asian_width(chr)

   Returns the east asian width assigned to the character *chr* as
   string.


.. function:: mirrored(chr)

   Returns the mirrored property assigned to the character *chr* as
   integer. Returns ``1`` if the character has been identified as a "mirrored"
   character in bidirectional text, ``0`` otherwise.


.. function:: decomposition(chr)

   Returns the character decomposition mapping assigned to the character
   *chr* as string. An empty string is returned in case no such mapping is
   defined.


.. function:: normalize(form, unistr)

   Return the normal form *form* for the Unicode string *unistr*. Valid values for
   *form* are 'NFC', 'NFKC', 'NFD', and 'NFKD'.

   The Unicode standard defines various normalization forms of a Unicode string,
   based on the definition of canonical equivalence and compatibility equivalence.
   In Unicode, several characters can be expressed in various way. For example, the
   character U+00C7 (LATIN CAPITAL LETTER C WITH CEDILLA) can also be expressed as
   the sequence U+0043 (LATIN CAPITAL LETTER C) U+0327 (COMBINING CEDILLA).

   For each character, there are two normal forms: normal form C and normal form D.
   Normal form D (NFD) is also known as canonical decomposition, and translates
   each character into its decomposed form. Normal form C (NFC) first applies a
   canonical decomposition, then composes pre-combined characters again.

   In addition to these two forms, there are two additional normal forms based on
   compatibility equivalence. In Unicode, certain characters are supported which
   normally would be unified with other characters. For example, U+2160 (ROMAN
   NUMERAL ONE) is really the same thing as U+0049 (LATIN CAPITAL LETTER I).
   However, it is supported in Unicode for compatibility with existing character
   sets (e.g. gb2312).

   The normal form KD (NFKD) will apply the compatibility decomposition, i.e.
   replace all compatibility characters with their equivalents. The normal form KC
   (NFKC) first applies the compatibility decomposition, followed by the canonical
   composition.

   Even if two unicode strings are normalized and look the same to
   a human reader, if one has combining characters and the other
   doesn't, they may not compare equal.

.. function:: is_normalized(form, unistr)

   Return whether the Unicode string *unistr* is in the normal form *form*. Valid
   values for *form* are 'NFC', 'NFKC', 'NFD', and 'NFKD'.

   .. versionadded:: 3.8


In addition, the module exposes the following constant:

.. data:: unidata_version

   The version of the Unicode database used in this module.


.. data:: ucd_3_2_0

   This is an object that has the same methods as the entire module, but uses the
   Unicode database version 3.2 instead, for applications that require this
   specific version of the Unicode database (such as IDNA).

Examples:

   >>> import unicodedata
   >>> unicodedata.lookup('LEFT CURLY BRACKET')
   '{'
   >>> unicodedata.name('/')
   'SOLIDUS'
   >>> unicodedata.decimal('9')
   9
   >>> unicodedata.decimal('a')
   Traceback (most recent call last):
     File "<stdin>", line 1, in <module>
   ValueError: not a decimal
   >>> unicodedata.category('A')  # 'L'etter, 'u'ppercase
   'Lu'
   >>> unicodedata.bidirectional('\u0660') # 'A'rabic, 'N'umber
   'AN'


.. rubric:: Footnotes

.. [#] https://www.unicode.org/Public/16.0.0/ucd/NameAliases.txt

.. [#] https://www.unicode.org/Public/16.0.0/ucd/NamedSequences.txt


================================================
File: /Doc/library/unittest.mock-examples.rst
================================================
:mod:`!unittest.mock` --- getting started
=========================================

.. moduleauthor:: Michael Foord <michael@python.org>
.. currentmodule:: unittest.mock

.. versionadded:: 3.3


.. _getting-started:


.. testsetup::

    import asyncio
    import unittest
    from unittest.mock import Mock, MagicMock, AsyncMock, patch, call, sentinel

    class SomeClass:
        attribute = 'this is a doctest'

        @staticmethod
        def static_method():
            pass

Using Mock
----------

Mock Patching Methods
~~~~~~~~~~~~~~~~~~~~~

Common uses for :class:`Mock` objects include:

* Patching methods
* Recording method calls on objects

You might want to replace a method on an object to check that
it is called with the correct arguments by another part of the system:

    >>> real = SomeClass()
    >>> real.method = MagicMock(name='method')
    >>> real.method(3, 4, 5, key='value')
    <MagicMock name='method()' id='...'>

Once our mock has been used (``real.method`` in this example) it has methods
and attributes that allow you to make assertions about how it has been used.

.. note::

    In most of these examples the :class:`Mock` and :class:`MagicMock` classes
    are interchangeable. As the ``MagicMock`` is the more capable class it makes
    a sensible one to use by default.

Once the mock has been called its :attr:`~Mock.called` attribute is set to
``True``. More importantly we can use the :meth:`~Mock.assert_called_with` or
:meth:`~Mock.assert_called_once_with` method to check that it was called with
the correct arguments.

This example tests that calling ``ProductionClass().method`` results in a call to
the ``something`` method:

    >>> class ProductionClass:
    ...     def method(self):
    ...         self.something(1, 2, 3)
    ...     def something(self, a, b, c):
    ...         pass
    ...
    >>> real = ProductionClass()
    >>> real.something = MagicMock()
    >>> real.method()
    >>> real.something.assert_called_once_with(1, 2, 3)



Mock for Method Calls on an Object
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

In the last example we patched a method directly on an object to check that it
was called correctly. Another common use case is to pass an object into a
method (or some part of the system under test) and then check that it is used
in the correct way.

The simple ``ProductionClass`` below has a ``closer`` method. If it is called with
an object then it calls ``close`` on it.

    >>> class ProductionClass:
    ...     def closer(self, something):
    ...         something.close()
    ...

So to test it we need to pass in an object with a ``close`` method and check
that it was called correctly.

    >>> real = ProductionClass()
    >>> mock = Mock()
    >>> real.closer(mock)
    >>> mock.close.assert_called_with()

We don't have to do any work to provide the 'close' method on our mock.
Accessing close creates it. So, if 'close' hasn't already been called then
accessing it in the test will create it, but :meth:`~Mock.assert_called_with`
will raise a failure exception.


Mocking Classes
~~~~~~~~~~~~~~~

A common use case is to mock out classes instantiated by your code under test.
When you patch a class, then that class is replaced with a mock. Instances
are created by *calling the class*. This means you access the "mock instance"
by looking at the return value of the mocked class.

In the example below we have a function ``some_function`` that instantiates ``Foo``
and calls a method on it. The call to :func:`patch` replaces the class ``Foo`` with a
mock. The ``Foo`` instance is the result of calling the mock, so it is configured
by modifying the mock :attr:`~Mock.return_value`. ::

    >>> def some_function():
    ...     instance = module.Foo()
    ...     return instance.method()
    ...
    >>> with patch('module.Foo') as mock:
    ...     instance = mock.return_value
    ...     instance.method.return_value = 'the result'
    ...     result = some_function()
    ...     assert result == 'the result'


Naming your mocks
~~~~~~~~~~~~~~~~~

It can be useful to give your mocks a name. The name is shown in the repr of
the mock and can be helpful when the mock appears in test failure messages. The
name is also propagated to attributes or methods of the mock:

    >>> mock = MagicMock(name='foo')
    >>> mock
    <MagicMock name='foo' id='...'>
    >>> mock.method
    <MagicMock name='foo.method' id='...'>


Tracking all Calls
~~~~~~~~~~~~~~~~~~

Often you want to track more than a single call to a method. The
:attr:`~Mock.mock_calls` attribute records all calls
to child attributes of the mock - and also to their children.

    >>> mock = MagicMock()
    >>> mock.method()
    <MagicMock name='mock.method()' id='...'>
    >>> mock.attribute.method(10, x=53)
    <MagicMock name='mock.attribute.method()' id='...'>
    >>> mock.mock_calls
    [call.method(), call.attribute.method(10, x=53)]

If you make an assertion about ``mock_calls`` and any unexpected methods
have been called, then the assertion will fail. This is useful because as well
as asserting that the calls you expected have been made, you are also checking
that they were made in the right order and with no additional calls:

You use the :data:`call` object to construct lists for comparing with
``mock_calls``:

    >>> expected = [call.method(), call.attribute.method(10, x=53)]
    >>> mock.mock_calls == expected
    True

However, parameters to calls that return mocks are not recorded, which means it is not
possible to track nested calls where the parameters used to create ancestors are important:

    >>> m = Mock()
    >>> m.factory(important=True).deliver()
    <Mock name='mock.factory().deliver()' id='...'>
    >>> m.mock_calls[-1] == call.factory(important=False).deliver()
    True


Setting Return Values and Attributes
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Setting the return values on a mock object is trivially easy:

    >>> mock = Mock()
    >>> mock.return_value = 3
    >>> mock()
    3

Of course you can do the same for methods on the mock:

    >>> mock = Mock()
    >>> mock.method.return_value = 3
    >>> mock.method()
    3

The return value can also be set in the constructor:

    >>> mock = Mock(return_value=3)
    >>> mock()
    3

If you need an attribute setting on your mock, just do it:

    >>> mock = Mock()
    >>> mock.x = 3
    >>> mock.x
    3

Sometimes you want to mock up a more complex situation, like for example
``mock.connection.cursor().execute("SELECT 1")``. If we wanted this call to
return a list, then we have to configure the result of the nested call.

We can use :data:`call` to construct the set of calls in a "chained call" like
this for easy assertion afterwards:

    >>> mock = Mock()
    >>> cursor = mock.connection.cursor.return_value
    >>> cursor.execute.return_value = ['foo']
    >>> mock.connection.cursor().execute("SELECT 1")
    ['foo']
    >>> expected = call.connection.cursor().execute("SELECT 1").call_list()
    >>> mock.mock_calls
    [call.connection.cursor(), call.connection.cursor().execute('SELECT 1')]
    >>> mock.mock_calls == expected
    True

It is the call to ``.call_list()`` that turns our call object into a list of
calls representing the chained calls.


Raising exceptions with mocks
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

A useful attribute is :attr:`~Mock.side_effect`. If you set this to an
exception class or instance then the exception will be raised when the mock
is called.

    >>> mock = Mock(side_effect=Exception('Boom!'))
    >>> mock()
    Traceback (most recent call last):
      ...
    Exception: Boom!


Side effect functions and iterables
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

``side_effect`` can also be set to a function or an iterable. The use case for
``side_effect`` as an iterable is where your mock is going to be called several
times, and you want each call to return a different value. When you set
``side_effect`` to an iterable every call to the mock returns the next value
from the iterable:

    >>> mock = MagicMock(side_effect=[4, 5, 6])
    >>> mock()
    4
    >>> mock()
    5
    >>> mock()
    6


For more advanced use cases, like dynamically varying the return values
depending on what the mock is called with, ``side_effect`` can be a function.
The function will be called with the same arguments as the mock. Whatever the
function returns is what the call returns:

    >>> vals = {(1, 2): 1, (2, 3): 2}
    >>> def side_effect(*args):
    ...     return vals[args]
    ...
    >>> mock = MagicMock(side_effect=side_effect)
    >>> mock(1, 2)
    1
    >>> mock(2, 3)
    2


Mocking asynchronous iterators
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Since Python 3.8, ``AsyncMock`` and ``MagicMock`` have support to mock
:ref:`async-iterators` through ``__aiter__``. The :attr:`~Mock.return_value`
attribute of ``__aiter__`` can be used to set the return values to be used for
iteration.

    >>> mock = MagicMock()  # AsyncMock also works here
    >>> mock.__aiter__.return_value = [1, 2, 3]
    >>> async def main():
    ...     return [i async for i in mock]
    ...
    >>> asyncio.run(main())
    [1, 2, 3]


Mocking asynchronous context manager
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Since Python 3.8, ``AsyncMock`` and ``MagicMock`` have support to mock
:ref:`async-context-managers` through ``__aenter__`` and ``__aexit__``.
By default, ``__aenter__`` and ``__aexit__`` are ``AsyncMock`` instances that
return an async function.

    >>> class AsyncContextManager:
    ...     async def __aenter__(self):
    ...         return self
    ...     async def __aexit__(self, exc_type, exc, tb):
    ...         pass
    ...
    >>> mock_instance = MagicMock(AsyncContextManager())  # AsyncMock also works here
    >>> async def main():
    ...     async with mock_instance as result:
    ...         pass
    ...
    >>> asyncio.run(main())
    >>> mock_instance.__aenter__.assert_awaited_once()
    >>> mock_instance.__aexit__.assert_awaited_once()


Creating a Mock from an Existing Object
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

One problem with over use of mocking is that it couples your tests to the
implementation of your mocks rather than your real code. Suppose you have a
class that implements ``some_method``. In a test for another class, you
provide a mock of this object that *also* provides ``some_method``. If later
you refactor the first class, so that it no longer has ``some_method`` - then
your tests will continue to pass even though your code is now broken!

:class:`Mock` allows you to provide an object as a specification for the mock,
using the *spec* keyword argument. Accessing methods / attributes on the
mock that don't exist on your specification object will immediately raise an
attribute error. If you change the implementation of your specification, then
tests that use that class will start failing immediately without you having to
instantiate the class in those tests.

    >>> mock = Mock(spec=SomeClass)
    >>> mock.old_method()
    Traceback (most recent call last):
       ...
    AttributeError: Mock object has no attribute 'old_method'. Did you mean: 'class_method'?

Using a specification also enables a smarter matching of calls made to the
mock, regardless of whether some parameters were passed as positional or
named arguments::

   >>> def f(a, b, c): pass
   ...
   >>> mock = Mock(spec=f)
   >>> mock(1, 2, 3)
   <Mock name='mock()' id='140161580456576'>
   >>> mock.assert_called_with(a=1, b=2, c=3)

If you want this smarter matching to also work with method calls on the mock,
you can use :ref:`auto-speccing <auto-speccing>`.

If you want a stronger form of specification that prevents the setting
of arbitrary attributes as well as the getting of them then you can use
*spec_set* instead of *spec*.


Using side_effect to return per file content
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

:func:`mock_open` is used to patch :func:`open` method. :attr:`~Mock.side_effect`
can be used to return a new Mock object per call. This can be used to return different
contents per file stored in a dictionary::

   DEFAULT = "default"
   data_dict = {"file1": "data1",
                "file2": "data2"}

   def open_side_effect(name):
       return mock_open(read_data=data_dict.get(name, DEFAULT))()

   with patch("builtins.open", side_effect=open_side_effect):
       with open("file1") as file1:
           assert file1.read() == "data1"

       with open("file2") as file2:
           assert file2.read() == "data2"

       with open("file3") as file2:
           assert file2.read() == "default"


Patch Decorators
----------------

.. note::

   With :func:`patch` it matters that you patch objects in the namespace where
   they are looked up. This is normally straightforward, but for a quick guide
   read :ref:`where to patch <where-to-patch>`.


A common need in tests is to patch a class attribute or a module attribute,
for example patching a builtin or patching a class in a module to test that it
is instantiated. Modules and classes are effectively global, so patching on
them has to be undone after the test or the patch will persist into other
tests and cause hard to diagnose problems.

mock provides three convenient decorators for this: :func:`patch`, :func:`patch.object` and
:func:`patch.dict`. ``patch`` takes a single string, of the form
``package.module.Class.attribute`` to specify the attribute you are patching. It
also optionally takes a value that you want the attribute (or class or
whatever) to be replaced with. 'patch.object' takes an object and the name of
the attribute you would like patched, plus optionally the value to patch it
with.

``patch.object``::

    >>> original = SomeClass.attribute
    >>> @patch.object(SomeClass, 'attribute', sentinel.attribute)
    ... def test():
    ...     assert SomeClass.attribute == sentinel.attribute
    ...
    >>> test()
    >>> assert SomeClass.attribute == original

    >>> @patch('package.module.attribute', sentinel.attribute)
    ... def test():
    ...     from package.module import attribute
    ...     assert attribute is sentinel.attribute
    ...
    >>> test()

If you are patching a module (including :mod:`builtins`) then use :func:`patch`
instead of :func:`patch.object`:

    >>> mock = MagicMock(return_value=sentinel.file_handle)
    >>> with patch('builtins.open', mock):
    ...     handle = open('filename', 'r')
    ...
    >>> mock.assert_called_with('filename', 'r')
    >>> assert handle == sentinel.file_handle, "incorrect file handle returned"

The module name can be 'dotted', in the form ``package.module`` if needed::

    >>> @patch('package.module.ClassName.attribute', sentinel.attribute)
    ... def test():
    ...     from package.module import ClassName
    ...     assert ClassName.attribute == sentinel.attribute
    ...
    >>> test()

A nice pattern is to actually decorate test methods themselves:

    >>> class MyTest(unittest.TestCase):
    ...     @patch.object(SomeClass, 'attribute', sentinel.attribute)
    ...     def test_something(self):
    ...         self.assertEqual(SomeClass.attribute, sentinel.attribute)
    ...
    >>> original = SomeClass.attribute
    >>> MyTest('test_something').test_something()
    >>> assert SomeClass.attribute == original

If you want to patch with a Mock, you can use :func:`patch` with only one argument
(or :func:`patch.object` with two arguments). The mock will be created for you and
passed into the test function / method:

    >>> class MyTest(unittest.TestCase):
    ...     @patch.object(SomeClass, 'static_method')
    ...     def test_something(self, mock_method):
    ...         SomeClass.static_method()
    ...         mock_method.assert_called_with()
    ...
    >>> MyTest('test_something').test_something()

You can stack up multiple patch decorators using this pattern::

    >>> class MyTest(unittest.TestCase):
    ...     @patch('package.module.ClassName1')
    ...     @patch('package.module.ClassName2')
    ...     def test_something(self, MockClass2, MockClass1):
    ...         self.assertIs(package.module.ClassName1, MockClass1)
    ...         self.assertIs(package.module.ClassName2, MockClass2)
    ...
    >>> MyTest('test_something').test_something()

When you nest patch decorators the mocks are passed in to the decorated
function in the same order they applied (the normal *Python* order that
decorators are applied). This means from the bottom up, so in the example
above the mock for ``test_module.ClassName2`` is passed in first.

There is also :func:`patch.dict` for setting values in a dictionary just
during a scope and restoring the dictionary to its original state when the test
ends:

   >>> foo = {'key': 'value'}
   >>> original = foo.copy()
   >>> with patch.dict(foo, {'newkey': 'newvalue'}, clear=True):
   ...     assert foo == {'newkey': 'newvalue'}
   ...
   >>> assert foo == original

``patch``, ``patch.object`` and ``patch.dict`` can all be used as context managers.

Where you use :func:`patch` to create a mock for you, you can get a reference to the
mock using the "as" form of the with statement:

    >>> class ProductionClass:
    ...     def method(self):
    ...         pass
    ...
    >>> with patch.object(ProductionClass, 'method') as mock_method:
    ...     mock_method.return_value = None
    ...     real = ProductionClass()
    ...     real.method(1, 2, 3)
    ...
    >>> mock_method.assert_called_with(1, 2, 3)


As an alternative ``patch``, ``patch.object`` and ``patch.dict`` can be used as
class decorators. When used in this way it is the same as applying the
decorator individually to every method whose name starts with "test".


.. _further-examples:

Further Examples
----------------


Here are some more examples for some slightly more advanced scenarios.


Mocking chained calls
~~~~~~~~~~~~~~~~~~~~~

Mocking chained calls is actually straightforward with mock once you
understand the :attr:`~Mock.return_value` attribute. When a mock is called for
the first time, or you fetch its ``return_value`` before it has been called, a
new :class:`Mock` is created.

This means that you can see how the object returned from a call to a mocked
object has been used by interrogating the ``return_value`` mock:

    >>> mock = Mock()
    >>> mock().foo(a=2, b=3)
    <Mock name='mock().foo()' id='...'>
    >>> mock.return_value.foo.assert_called_with(a=2, b=3)

From here it is a simple step to configure and then make assertions about
chained calls. Of course another alternative is writing your code in a more
testable way in the first place...

So, suppose we have some code that looks a little bit like this:

    >>> class Something:
    ...     def __init__(self):
    ...         self.backend = BackendProvider()
    ...     def method(self):
    ...         response = self.backend.get_endpoint('foobar').create_call('spam', 'eggs').start_call()
    ...         # more code

Assuming that ``BackendProvider`` is already well tested, how do we test
``method()``? Specifically, we want to test that the code section ``# more
code`` uses the response object in the correct way.

As this chain of calls is made from an instance attribute we can monkey patch
the ``backend`` attribute on a ``Something`` instance. In this particular case
we are only interested in the return value from the final call to
``start_call`` so we don't have much configuration to do. Let's assume the
object it returns is 'file-like', so we'll ensure that our response object
uses the builtin :func:`open` as its ``spec``.

To do this we create a mock instance as our mock backend and create a mock
response object for it. To set the response as the return value for that final
``start_call`` we could do this::

    mock_backend.get_endpoint.return_value.create_call.return_value.start_call.return_value = mock_response

We can do that in a slightly nicer way using the :meth:`~Mock.configure_mock`
method to directly set the return value for us::

    >>> something = Something()
    >>> mock_response = Mock(spec=open)
    >>> mock_backend = Mock()
    >>> config = {'get_endpoint.return_value.create_call.return_value.start_call.return_value': mock_response}
    >>> mock_backend.configure_mock(**config)

With these we monkey patch the "mock backend" in place and can make the real
call::

    >>> something.backend = mock_backend
    >>> something.method()

Using :attr:`~Mock.mock_calls` we can check the chained call with a single
assert. A chained call is several calls in one line of code, so there will be
several entries in ``mock_calls``. We can use :meth:`call.call_list` to create
this list of calls for us::

    >>> chained = call.get_endpoint('foobar').create_call('spam', 'eggs').start_call()
    >>> call_list = chained.call_list()
    >>> assert mock_backend.mock_calls == call_list


Partial mocking
~~~~~~~~~~~~~~~

In some tests I wanted to mock out a call to :meth:`datetime.date.today`
to return a known date, but I didn't want to prevent the code under test from
creating new date objects. Unfortunately :class:`datetime.date` is written in C, and
so I couldn't just monkey-patch out the static :meth:`datetime.date.today` method.

I found a simple way of doing this that involved effectively wrapping the date
class with a mock, but passing through calls to the constructor to the real
class (and returning real instances).

The :func:`patch decorator <patch>` is used here to
mock out the ``date`` class in the module under test. The :attr:`~Mock.side_effect`
attribute on the mock date class is then set to a lambda function that returns
a real date. When the mock date class is called a real date will be
constructed and returned by ``side_effect``. ::

    >>> from datetime import date
    >>> with patch('mymodule.date') as mock_date:
    ...     mock_date.today.return_value = date(2010, 10, 8)
    ...     mock_date.side_effect = lambda *args, **kw: date(*args, **kw)
    ...
    ...     assert mymodule.date.today() == date(2010, 10, 8)
    ...     assert mymodule.date(2009, 6, 8) == date(2009, 6, 8)

Note that we don't patch :class:`datetime.date` globally, we patch ``date`` in the
module that *uses* it. See :ref:`where to patch <where-to-patch>`.

When ``date.today()`` is called a known date is returned, but calls to the
``date(...)`` constructor still return normal dates. Without this you can find
yourself having to calculate an expected result using exactly the same
algorithm as the code under test, which is a classic testing anti-pattern.

Calls to the date constructor are recorded in the ``mock_date`` attributes
(``call_count`` and friends) which may also be useful for your tests.

An alternative way of dealing with mocking dates, or other builtin classes,
is discussed in `this blog entry
<https://williambert.online/2011/07/how-to-unit-testing-in-django-with-mocking-and-patching/>`_.


Mocking a Generator Method
~~~~~~~~~~~~~~~~~~~~~~~~~~

A Python generator is a function or method that uses the :keyword:`yield` statement
to return a series of values when iterated over [#]_.

A generator method / function is called to return the generator object. It is
the generator object that is then iterated over. The protocol method for
iteration is :meth:`~container.__iter__`, so we can
mock this using a :class:`MagicMock`.

Here's an example class with an "iter" method implemented as a generator:

    >>> class Foo:
    ...     def iter(self):
    ...         for i in [1, 2, 3]:
    ...             yield i
    ...
    >>> foo = Foo()
    >>> list(foo.iter())
    [1, 2, 3]


How would we mock this class, and in particular its "iter" method?

To configure the values returned from the iteration (implicit in the call to
:class:`list`), we need to configure the object returned by the call to ``foo.iter()``.

    >>> mock_foo = MagicMock()
    >>> mock_foo.iter.return_value = iter([1, 2, 3])
    >>> list(mock_foo.iter())
    [1, 2, 3]

.. [#] There are also generator expressions and more `advanced uses
    <http://www.dabeaz.com/coroutines/index.html>`_ of generators, but we aren't
    concerned about them here. A very good introduction to generators and how
    powerful they are is: `Generator Tricks for Systems Programmers
    <http://www.dabeaz.com/generators/>`_.


Applying the same patch to every test method
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

If you want several patches in place for multiple test methods the obvious way
is to apply the patch decorators to every method. This can feel like unnecessary
repetition. Instead, you can use :func:`patch` (in all its
various forms) as a class decorator. This applies the patches to all test
methods on the class. A test method is identified by methods whose names start
with ``test``::

    >>> @patch('mymodule.SomeClass')
    ... class MyTest(unittest.TestCase):
    ...
    ...     def test_one(self, MockSomeClass):
    ...         self.assertIs(mymodule.SomeClass, MockSomeClass)
    ...
    ...     def test_two(self, MockSomeClass):
    ...         self.assertIs(mymodule.SomeClass, MockSomeClass)
    ...
    ...     def not_a_test(self):
    ...         return 'something'
    ...
    >>> MyTest('test_one').test_one()
    >>> MyTest('test_two').test_two()
    >>> MyTest('test_two').not_a_test()
    'something'

An alternative way of managing patches is to use the :ref:`start-and-stop`.
These allow you to move the patching into your ``setUp`` and ``tearDown`` methods.
::

    >>> class MyTest(unittest.TestCase):
    ...     def setUp(self):
    ...         self.patcher = patch('mymodule.foo')
    ...         self.mock_foo = self.patcher.start()
    ...
    ...     def test_foo(self):
    ...         self.assertIs(mymodule.foo, self.mock_foo)
    ...
    ...     def tearDown(self):
    ...         self.patcher.stop()
    ...
    >>> MyTest('test_foo').run()

If you use this technique you must ensure that the patching is "undone" by
calling ``stop``. This can be fiddlier than you might think, because if an
exception is raised in the setUp then tearDown is not called.
:meth:`unittest.TestCase.addCleanup` makes this easier::

    >>> class MyTest(unittest.TestCase):
    ...     def setUp(self):
    ...         patcher = patch('mymodule.foo')
    ...         self.addCleanup(patcher.stop)
    ...         self.mock_foo = patcher.start()
    ...
    ...     def test_foo(self):
    ...         self.assertIs(mymodule.foo, self.mock_foo)
    ...
    >>> MyTest('test_foo').run()


Mocking Unbound Methods
~~~~~~~~~~~~~~~~~~~~~~~

Whilst writing tests today I needed to patch an *unbound method* (patching the
method on the class rather than on the instance). I needed self to be passed
in as the first argument because I want to make asserts about which objects
were calling this particular method. The issue is that you can't patch with a
mock for this, because if you replace an unbound method with a mock it doesn't
become a bound method when fetched from the instance, and so it doesn't get
self passed in. The workaround is to patch the unbound method with a real
function instead. The :func:`patch` decorator makes it so simple to
patch out methods with a mock that having to create a real function becomes a
nuisance.

If you pass ``autospec=True`` to patch then it does the patching with a
*real* function object. This function object has the same signature as the one
it is replacing, but delegates to a mock under the hood. You still get your
mock auto-created in exactly the same way as before. What it means though, is
that if you use it to patch out an unbound method on a class the mocked
function will be turned into a bound method if it is fetched from an instance.
It will have ``self`` passed in as the first argument, which is exactly what I
wanted:

    >>> class Foo:
    ...   def foo(self):
    ...     pass
    ...
    >>> with patch.object(Foo, 'foo', autospec=True) as mock_foo:
    ...   mock_foo.return_value = 'foo'
    ...   foo = Foo()
    ...   foo.foo()
    ...
    'foo'
    >>> mock_foo.assert_called_once_with(foo)

If we don't use ``autospec=True`` then the unbound method is patched out
with a Mock instance instead, and isn't called with ``self``.


Checking multiple calls with mock
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

mock has a nice API for making assertions about how your mock objects are used.

    >>> mock = Mock()
    >>> mock.foo_bar.return_value = None
    >>> mock.foo_bar('baz', spam='eggs')
    >>> mock.foo_bar.assert_called_with('baz', spam='eggs')

If your mock is only being called once you can use the
:meth:`~Mock.assert_called_once_with` method that also asserts that the
:attr:`~Mock.call_count` is one.

    >>> mock.foo_bar.assert_called_once_with('baz', spam='eggs')
    >>> mock.foo_bar()
    >>> mock.foo_bar.assert_called_once_with('baz', spam='eggs')
    Traceback (most recent call last):
        ...
    AssertionError: Expected 'foo_bar' to be called once. Called 2 times.
    Calls: [call('baz', spam='eggs'), call()].

Both ``assert_called_with`` and ``assert_called_once_with`` make assertions about
the *most recent* call. If your mock is going to be called several times, and
you want to make assertions about *all* those calls you can use
:attr:`~Mock.call_args_list`:

    >>> mock = Mock(return_value=None)
    >>> mock(1, 2, 3)
    >>> mock(4, 5, 6)
    >>> mock()
    >>> mock.call_args_list
    [call(1, 2, 3), call(4, 5, 6), call()]

The :data:`call` helper makes it easy to make assertions about these calls. You
can build up a list of expected calls and compare it to ``call_args_list``. This
looks remarkably similar to the repr of the ``call_args_list``:

    >>> expected = [call(1, 2, 3), call(4, 5, 6), call()]
    >>> mock.call_args_list == expected
    True


Coping with mutable arguments
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Another situation is rare, but can bite you, is when your mock is called with
mutable arguments. ``call_args`` and ``call_args_list`` store *references* to the
arguments. If the arguments are mutated by the code under test then you can no
longer make assertions about what the values were when the mock was called.

Here's some example code that shows the problem. Imagine the following functions
defined in 'mymodule'::

    def frob(val):
        pass

    def grob(val):
        "First frob and then clear val"
        frob(val)
        val.clear()

When we try to test that ``grob`` calls ``frob`` with the correct argument look
what happens::

    >>> with patch('mymodule.frob') as mock_frob:
    ...     val = {6}
    ...     mymodule.grob(val)
    ...
    >>> val
    set()
    >>> mock_frob.assert_called_with({6})
    Traceback (most recent call last):
        ...
    AssertionError: Expected: (({6},), {})
    Called with: ((set(),), {})

One possibility would be for mock to copy the arguments you pass in. This
could then cause problems if you do assertions that rely on object identity
for equality.

Here's one solution that uses the :attr:`~Mock.side_effect`
functionality. If you provide a ``side_effect`` function for a mock then
``side_effect`` will be called with the same args as the mock. This gives us an
opportunity to copy the arguments and store them for later assertions. In this
example I'm using *another* mock to store the arguments so that I can use the
mock methods for doing the assertion. Again a helper function sets this up for
me. ::

    >>> from copy import deepcopy
    >>> from unittest.mock import Mock, patch, DEFAULT
    >>> def copy_call_args(mock):
    ...     new_mock = Mock()
    ...     def side_effect(*args, **kwargs):
    ...         args = deepcopy(args)
    ...         kwargs = deepcopy(kwargs)
    ...         new_mock(*args, **kwargs)
    ...         return DEFAULT
    ...     mock.side_effect = side_effect
    ...     return new_mock
    ...
    >>> with patch('mymodule.frob') as mock_frob:
    ...     new_mock = copy_call_args(mock_frob)
    ...     val = {6}
    ...     mymodule.grob(val)
    ...
    >>> new_mock.assert_called_with({6})
    >>> new_mock.call_args
    call({6})

``copy_call_args`` is called with the mock that will be called. It returns a new
mock that we do the assertion on. The ``side_effect`` function makes a copy of
the args and calls our ``new_mock`` with the copy.

.. note::

    If your mock is only going to be used once there is an easier way of
    checking arguments at the point they are called. You can simply do the
    checking inside a ``side_effect`` function.

        >>> def side_effect(arg):
        ...     assert arg == {6}
        ...
        >>> mock = Mock(side_effect=side_effect)
        >>> mock({6})
        >>> mock(set())
        Traceback (most recent call last):
            ...
        AssertionError

An alternative approach is to create a subclass of :class:`Mock` or
:class:`MagicMock` that copies (using :func:`copy.deepcopy`) the arguments.
Here's an example implementation:

    >>> from copy import deepcopy
    >>> class CopyingMock(MagicMock):
    ...     def __call__(self, /, *args, **kwargs):
    ...         args = deepcopy(args)
    ...         kwargs = deepcopy(kwargs)
    ...         return super().__call__(*args, **kwargs)
    ...
    >>> c = CopyingMock(return_value=None)
    >>> arg = set()
    >>> c(arg)
    >>> arg.add(1)
    >>> c.assert_called_with(set())
    >>> c.assert_called_with(arg)
    Traceback (most recent call last):
        ...
    AssertionError: expected call not found.
    Expected: mock({1})
    Actual: mock(set())
    >>> c.foo
    <CopyingMock name='mock.foo' id='...'>

When you subclass ``Mock`` or ``MagicMock`` all dynamically created attributes,
and the ``return_value`` will use your subclass automatically. That means all
children of a ``CopyingMock`` will also have the type ``CopyingMock``.


Nesting Patches
~~~~~~~~~~~~~~~

Using patch as a context manager is nice, but if you do multiple patches you
can end up with nested with statements indenting further and further to the
right::

    >>> class MyTest(unittest.TestCase):
    ...
    ...     def test_foo(self):
    ...         with patch('mymodule.Foo') as mock_foo:
    ...             with patch('mymodule.Bar') as mock_bar:
    ...                 with patch('mymodule.Spam') as mock_spam:
    ...                     assert mymodule.Foo is mock_foo
    ...                     assert mymodule.Bar is mock_bar
    ...                     assert mymodule.Spam is mock_spam
    ...
    >>> original = mymodule.Foo
    >>> MyTest('test_foo').test_foo()
    >>> assert mymodule.Foo is original

With unittest ``cleanup`` functions and the :ref:`start-and-stop` we can
achieve the same effect without the nested indentation. A simple helper
method, ``create_patch``, puts the patch in place and returns the created mock
for us::

    >>> class MyTest(unittest.TestCase):
    ...
    ...     def create_patch(self, name):
    ...         patcher = patch(name)
    ...         thing = patcher.start()
    ...         self.addCleanup(patcher.stop)
    ...         return thing
    ...
    ...     def test_foo(self):
    ...         mock_foo = self.create_patch('mymodule.Foo')
    ...         mock_bar = self.create_patch('mymodule.Bar')
    ...         mock_spam = self.create_patch('mymodule.Spam')
    ...
    ...         assert mymodule.Foo is mock_foo
    ...         assert mymodule.Bar is mock_bar
    ...         assert mymodule.Spam is mock_spam
    ...
    >>> original = mymodule.Foo
    >>> MyTest('test_foo').run()
    >>> assert mymodule.Foo is original


Mocking a dictionary with MagicMock
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

You may want to mock a dictionary, or other container object, recording all
access to it whilst having it still behave like a dictionary.

We can do this with :class:`MagicMock`, which will behave like a dictionary,
and using :data:`~Mock.side_effect` to delegate dictionary access to a real
underlying dictionary that is under our control.

When the :meth:`~object.__getitem__` and :meth:`~object.__setitem__` methods
of our ``MagicMock`` are called
(normal dictionary access) then ``side_effect`` is called with the key (and in
the case of ``__setitem__`` the value too). We can also control what is returned.

After the ``MagicMock`` has been used we can use attributes like
:data:`~Mock.call_args_list` to assert about how the dictionary was used:

    >>> my_dict = {'a': 1, 'b': 2, 'c': 3}
    >>> def getitem(name):
    ...      return my_dict[name]
    ...
    >>> def setitem(name, val):
    ...     my_dict[name] = val
    ...
    >>> mock = MagicMock()
    >>> mock.__getitem__.side_effect = getitem
    >>> mock.__setitem__.side_effect = setitem

.. note::

    An alternative to using ``MagicMock`` is to use ``Mock`` and *only* provide
    the magic methods you specifically want:

        >>> mock = Mock()
        >>> mock.__getitem__ = Mock(side_effect=getitem)
        >>> mock.__setitem__ = Mock(side_effect=setitem)

    A *third* option is to use ``MagicMock`` but passing in ``dict`` as the *spec*
    (or *spec_set*) argument so that the ``MagicMock`` created only has
    dictionary magic methods available:

        >>> mock = MagicMock(spec_set=dict)
        >>> mock.__getitem__.side_effect = getitem
        >>> mock.__setitem__.side_effect = setitem

With these side effect functions in place, the ``mock`` will behave like a normal
dictionary but recording the access. It even raises a :exc:`KeyError` if you try
to access a key that doesn't exist.

    >>> mock['a']
    1
    >>> mock['c']
    3
    >>> mock['d']
    Traceback (most recent call last):
        ...
    KeyError: 'd'
    >>> mock['b'] = 'fish'
    >>> mock['d'] = 'eggs'
    >>> mock['b']
    'fish'
    >>> mock['d']
    'eggs'

After it has been used you can make assertions about the access using the normal
mock methods and attributes:

    >>> mock.__getitem__.call_args_list
    [call('a'), call('c'), call('d'), call('b'), call('d')]
    >>> mock.__setitem__.call_args_list
    [call('b', 'fish'), call('d', 'eggs')]
    >>> my_dict
    {'a': 1, 'b': 'fish', 'c': 3, 'd': 'eggs'}


Mock subclasses and their attributes
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

There are various reasons why you might want to subclass :class:`Mock`. One
reason might be to add helper methods. Here's a silly example:

    >>> class MyMock(MagicMock):
    ...     def has_been_called(self):
    ...         return self.called
    ...
    >>> mymock = MyMock(return_value=None)
    >>> mymock
    <MyMock id='...'>
    >>> mymock.has_been_called()
    False
    >>> mymock()
    >>> mymock.has_been_called()
    True

The standard behaviour for ``Mock`` instances is that attributes and the return
value mocks are of the same type as the mock they are accessed on. This ensures
that ``Mock`` attributes are ``Mocks`` and ``MagicMock`` attributes are ``MagicMocks``
[#]_. So if you're subclassing to add helper methods then they'll also be
available on the attributes and return value mock of instances of your
subclass.

    >>> mymock.foo
    <MyMock name='mock.foo' id='...'>
    >>> mymock.foo.has_been_called()
    False
    >>> mymock.foo()
    <MyMock name='mock.foo()' id='...'>
    >>> mymock.foo.has_been_called()
    True

Sometimes this is inconvenient. For example, `one user
<https://code.google.com/archive/p/mock/issues/105>`_ is subclassing mock to
created a `Twisted adaptor
<https://twisted.org/documents/11.0.0/api/twisted.python.components.html>`_.
Having this applied to attributes too actually causes errors.

``Mock`` (in all its flavours) uses a method called ``_get_child_mock`` to create
these "sub-mocks" for attributes and return values. You can prevent your
subclass being used for attributes by overriding this method. The signature is
that it takes arbitrary keyword arguments (``**kwargs``) which are then passed
onto the mock constructor:

    >>> class Subclass(MagicMock):
    ...     def _get_child_mock(self, /, **kwargs):
    ...         return MagicMock(**kwargs)
    ...
    >>> mymock = Subclass()
    >>> mymock.foo
    <MagicMock name='mock.foo' id='...'>
    >>> assert isinstance(mymock, Subclass)
    >>> assert not isinstance(mymock.foo, Subclass)
    >>> assert not isinstance(mymock(), Subclass)

.. [#] An exception to this rule are the non-callable mocks. Attributes use the
    callable variant because otherwise non-callable mocks couldn't have callable
    methods.


Mocking imports with patch.dict
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

One situation where mocking can be hard is where you have a local import inside
a function. These are harder to mock because they aren't using an object from
the module namespace that we can patch out.

Generally local imports are to be avoided. They are sometimes done to prevent
circular dependencies, for which there is *usually* a much better way to solve
the problem (refactor the code) or to prevent "up front costs" by delaying the
import. This can also be solved in better ways than an unconditional local
import (store the module as a class or module attribute and only do the import
on first use).

That aside there is a way to use ``mock`` to affect the results of an import.
Importing fetches an *object* from the :data:`sys.modules` dictionary. Note that it
fetches an *object*, which need not be a module. Importing a module for the
first time results in a module object being put in ``sys.modules``, so usually
when you import something you get a module back. This need not be the case
however.

This means you can use :func:`patch.dict` to *temporarily* put a mock in place
in :data:`sys.modules`. Any imports whilst this patch is active will fetch the mock.
When the patch is complete (the decorated function exits, the with statement
body is complete or ``patcher.stop()`` is called) then whatever was there
previously will be restored safely.

Here's an example that mocks out the 'fooble' module.

    >>> import sys
    >>> mock = Mock()
    >>> with patch.dict('sys.modules', {'fooble': mock}):
    ...    import fooble
    ...    fooble.blob()
    ...
    <Mock name='mock.blob()' id='...'>
    >>> assert 'fooble' not in sys.modules
    >>> mock.blob.assert_called_once_with()

As you can see the ``import fooble`` succeeds, but on exit there is no 'fooble'
left in :data:`sys.modules`.

This also works for the ``from module import name`` form:

    >>> mock = Mock()
    >>> with patch.dict('sys.modules', {'fooble': mock}):
    ...    from fooble import blob
    ...    blob.blip()
    ...
    <Mock name='mock.blob.blip()' id='...'>
    >>> mock.blob.blip.assert_called_once_with()

With slightly more work you can also mock package imports:

    >>> mock = Mock()
    >>> modules = {'package': mock, 'package.module': mock.module}
    >>> with patch.dict('sys.modules', modules):
    ...    from package.module import fooble
    ...    fooble()
    ...
    <Mock name='mock.module.fooble()' id='...'>
    >>> mock.module.fooble.assert_called_once_with()


Tracking order of calls and less verbose call assertions
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The :class:`Mock` class allows you to track the *order* of method calls on
your mock objects through the :attr:`~Mock.method_calls` attribute. This
doesn't allow you to track the order of calls between separate mock objects,
however we can use :attr:`~Mock.mock_calls` to achieve the same effect.

Because mocks track calls to child mocks in ``mock_calls``, and accessing an
arbitrary attribute of a mock creates a child mock, we can create our separate
mocks from a parent one. Calls to those child mock will then all be recorded,
in order, in the ``mock_calls`` of the parent:

    >>> manager = Mock()
    >>> mock_foo = manager.foo
    >>> mock_bar = manager.bar

    >>> mock_foo.something()
    <Mock name='mock.foo.something()' id='...'>
    >>> mock_bar.other.thing()
    <Mock name='mock.bar.other.thing()' id='...'>

    >>> manager.mock_calls
    [call.foo.something(), call.bar.other.thing()]

We can then assert about the calls, including the order, by comparing with
the ``mock_calls`` attribute on the manager mock:

    >>> expected_calls = [call.foo.something(), call.bar.other.thing()]
    >>> manager.mock_calls == expected_calls
    True

If ``patch`` is creating, and putting in place, your mocks then you can attach
them to a manager mock using the :meth:`~Mock.attach_mock` method. After
attaching calls will be recorded in ``mock_calls`` of the manager. ::

    >>> manager = MagicMock()
    >>> with patch('mymodule.Class1') as MockClass1:
    ...     with patch('mymodule.Class2') as MockClass2:
    ...         manager.attach_mock(MockClass1, 'MockClass1')
    ...         manager.attach_mock(MockClass2, 'MockClass2')
    ...         MockClass1().foo()
    ...         MockClass2().bar()
    <MagicMock name='mock.MockClass1().foo()' id='...'>
    <MagicMock name='mock.MockClass2().bar()' id='...'>
    >>> manager.mock_calls
    [call.MockClass1(),
    call.MockClass1().foo(),
    call.MockClass2(),
    call.MockClass2().bar()]

If many calls have been made, but you're only interested in a particular
sequence of them then an alternative is to use the
:meth:`~Mock.assert_has_calls` method. This takes a list of calls (constructed
with the :data:`call` object). If that sequence of calls are in
:attr:`~Mock.mock_calls` then the assert succeeds.

    >>> m = MagicMock()
    >>> m().foo().bar().baz()
    <MagicMock name='mock().foo().bar().baz()' id='...'>
    >>> m.one().two().three()
    <MagicMock name='mock.one().two().three()' id='...'>
    >>> calls = call.one().two().three().call_list()
    >>> m.assert_has_calls(calls)

Even though the chained call ``m.one().two().three()`` aren't the only calls that
have been made to the mock, the assert still succeeds.

Sometimes a mock may have several calls made to it, and you are only interested
in asserting about *some* of those calls. You may not even care about the
order. In this case you can pass ``any_order=True`` to ``assert_has_calls``:

    >>> m = MagicMock()
    >>> m(1), m.two(2, 3), m.seven(7), m.fifty('50')
    (...)
    >>> calls = [call.fifty('50'), call(1), call.seven(7)]
    >>> m.assert_has_calls(calls, any_order=True)


More complex argument matching
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Using the same basic concept as :data:`ANY` we can implement matchers to do more
complex assertions on objects used as arguments to mocks.

Suppose we expect some object to be passed to a mock that by default
compares equal based on object identity (which is the Python default for user
defined classes). To use :meth:`~Mock.assert_called_with` we would need to pass
in the exact same object. If we are only interested in some of the attributes
of this object then we can create a matcher that will check these attributes
for us.

You can see in this example how a 'standard' call to ``assert_called_with`` isn't
sufficient:

    >>> class Foo:
    ...     def __init__(self, a, b):
    ...         self.a, self.b = a, b
    ...
    >>> mock = Mock(return_value=None)
    >>> mock(Foo(1, 2))
    >>> mock.assert_called_with(Foo(1, 2))
    Traceback (most recent call last):
        ...
    AssertionError: expected call not found.
    Expected: mock(<__main__.Foo object at 0x...>)
    Actual: mock(<__main__.Foo object at 0x...>)

A comparison function for our ``Foo`` class might look something like this:

    >>> def compare(self, other):
    ...     if not type(self) == type(other):
    ...         return False
    ...     if self.a != other.a:
    ...         return False
    ...     if self.b != other.b:
    ...         return False
    ...     return True
    ...

And a matcher object that can use comparison functions like this for its
equality operation would look something like this:

    >>> class Matcher:
    ...     def __init__(self, compare, some_obj):
    ...         self.compare = compare
    ...         self.some_obj = some_obj
    ...     def __eq__(self, other):
    ...         return self.compare(self.some_obj, other)
    ...

Putting all this together:

    >>> match_foo = Matcher(compare, Foo(1, 2))
    >>> mock.assert_called_with(match_foo)

The ``Matcher`` is instantiated with our compare function and the ``Foo`` object
we want to compare against. In ``assert_called_with`` the ``Matcher`` equality
method will be called, which compares the object the mock was called with
against the one we created our matcher with. If they match then
``assert_called_with`` passes, and if they don't an :exc:`AssertionError` is raised:

    >>> match_wrong = Matcher(compare, Foo(3, 4))
    >>> mock.assert_called_with(match_wrong)
    Traceback (most recent call last):
        ...
    AssertionError: Expected: ((<Matcher object at 0x...>,), {})
    Called with: ((<Foo object at 0x...>,), {})

With a bit of tweaking you could have the comparison function raise the
:exc:`AssertionError` directly and provide a more useful failure message.

As of version 1.5, the Python testing library `PyHamcrest
<https://pyhamcrest.readthedocs.io/>`_ provides similar functionality,
that may be useful here, in the form of its equality matcher
(`hamcrest.library.integration.match_equality
<https://pyhamcrest.readthedocs.io/en/release-1.8/integration/#module-hamcrest.library.integration.match_equality>`_).


================================================
File: /Doc/library/unix.rst
================================================
.. _unix:

**********************
Unix Specific Services
**********************

The modules described in this chapter provide interfaces to features that are
unique to the Unix operating system, or in some cases to some or many variants
of it.  Here's an overview:


.. toctree::

   posix.rst
   pwd.rst
   grp.rst
   termios.rst
   tty.rst
   pty.rst
   fcntl.rst
   resource.rst
   syslog.rst


================================================
File: /Doc/library/urllib.error.rst
================================================
:mod:`!urllib.error` --- Exception classes raised by urllib.request
===================================================================

.. module:: urllib.error
   :synopsis: Exception classes raised by urllib.request.

.. moduleauthor:: Jeremy Hylton <jeremy@alum.mit.edu>
.. sectionauthor:: Senthil Kumaran <orsenthil@gmail.com>

**Source code:** :source:`Lib/urllib/error.py`

--------------

The :mod:`urllib.error` module defines the exception classes for exceptions
raised by :mod:`urllib.request`.  The base exception class is :exc:`URLError`.

The following exceptions are raised by :mod:`urllib.error` as appropriate:

.. exception:: URLError

   The handlers raise this exception (or derived exceptions) when they run into
   a problem.  It is a subclass of :exc:`OSError`.

   .. attribute:: reason

      The reason for this error.  It can be a message string or another
      exception instance.

   .. versionchanged:: 3.3
      :exc:`URLError` used to be a subtype of :exc:`IOError`, which is now an
      alias of :exc:`OSError`.


.. exception:: HTTPError(url, code, msg, hdrs, fp)

   Though being an exception (a subclass of :exc:`URLError`), an
   :exc:`HTTPError` can also function as a non-exceptional file-like return
   value (the same thing that :func:`~urllib.request.urlopen` returns).  This
   is useful when handling exotic HTTP errors, such as requests for
   authentication.

   .. attribute:: url

      Contains the request URL.
      An alias for *filename* attribute.

   .. attribute:: code

      An HTTP status code as defined in :rfc:`2616`.  This numeric value corresponds
      to a value found in the dictionary of codes as found in
      :attr:`http.server.BaseHTTPRequestHandler.responses`.

   .. attribute:: reason

      This is usually a string explaining the reason for this error.
      An alias for *msg* attribute.

   .. attribute:: headers

      The HTTP response headers for the HTTP request that caused the
      :exc:`HTTPError`.
      An alias for *hdrs* attribute.

      .. versionadded:: 3.4

   .. attribute:: fp

      A file-like object where the HTTP error body can be read from.

.. exception:: ContentTooShortError(msg, content)

   This exception is raised when the :func:`~urllib.request.urlretrieve`
   function detects that
   the amount of the downloaded data is less than the expected amount (given by
   the *Content-Length* header).

   .. attribute:: content

      The downloaded (and supposedly truncated) data.


================================================
File: /Doc/library/urllib.parse.rst
================================================
:mod:`!urllib.parse` --- Parse URLs into components
===================================================

.. module:: urllib.parse
   :synopsis: Parse URLs into or assemble them from components.

**Source code:** :source:`Lib/urllib/parse.py`

.. index::
   single: WWW
   single: World Wide Web
   single: URL
   pair: URL; parsing
   pair: relative; URL

--------------

This module defines a standard interface to break Uniform Resource Locator (URL)
strings up in components (addressing scheme, network location, path etc.), to
combine the components back into a URL string, and to convert a "relative URL"
to an absolute URL given a "base URL."

The module has been designed to match the internet RFC on Relative Uniform
Resource Locators. It supports the following URL schemes: ``file``, ``ftp``,
``gopher``, ``hdl``, ``http``, ``https``, ``imap``, ``itms-services``, ``mailto``, ``mms``,
``news``, ``nntp``, ``prospero``, ``rsync``, ``rtsp``, ``rtsps``, ``rtspu``,
``sftp``, ``shttp``, ``sip``, ``sips``, ``snews``, ``svn``, ``svn+ssh``,
``telnet``, ``wais``, ``ws``, ``wss``.

.. impl-detail::

   The inclusion of the ``itms-services`` URL scheme can prevent an app from
   passing Apple's App Store review process for the macOS and iOS App Stores.
   Handling for the ``itms-services`` scheme is always removed on iOS; on
   macOS, it *may* be removed if CPython has been built with the
   :option:`--with-app-store-compliance` option.

The :mod:`urllib.parse` module defines functions that fall into two broad
categories: URL parsing and URL quoting. These are covered in detail in
the following sections.

This module's functions use the deprecated term ``netloc`` (or ``net_loc``),
which was introduced in :rfc:`1808`. However, this term has been obsoleted by
:rfc:`3986`, which introduced the term ``authority`` as its replacement.
The use of ``netloc`` is continued for backward compatibility.

URL Parsing
-----------

The URL parsing functions focus on splitting a URL string into its components,
or on combining URL components into a URL string.

.. function:: urlparse(urlstring, scheme='', allow_fragments=True)

   Parse a URL into six components, returning a 6-item :term:`named tuple`.  This
   corresponds to the general structure of a URL:
   ``scheme://netloc/path;parameters?query#fragment``.
   Each tuple item is a string, possibly empty. The components are not broken up
   into smaller parts (for example, the network location is a single string), and %
   escapes are not expanded. The delimiters as shown above are not part of the
   result, except for a leading slash in the *path* component, which is retained if
   present.  For example:

   .. doctest::
      :options: +NORMALIZE_WHITESPACE

      >>> from urllib.parse import urlparse
      >>> urlparse("scheme://netloc/path;parameters?query#fragment")
      ParseResult(scheme='scheme', netloc='netloc', path='/path;parameters', params='',
                  query='query', fragment='fragment')
      >>> o = urlparse("http://docs.python.org:80/3/library/urllib.parse.html?"
      ...              "highlight=params#url-parsing")
      >>> o
      ParseResult(scheme='http', netloc='docs.python.org:80',
                  path='/3/library/urllib.parse.html', params='',
                  query='highlight=params', fragment='url-parsing')
      >>> o.scheme
      'http'
      >>> o.netloc
      'docs.python.org:80'
      >>> o.hostname
      'docs.python.org'
      >>> o.port
      80
      >>> o._replace(fragment="").geturl()
      'http://docs.python.org:80/3/library/urllib.parse.html?highlight=params'

   Following the syntax specifications in :rfc:`1808`, urlparse recognizes
   a netloc only if it is properly introduced by '//'.  Otherwise the
   input is presumed to be a relative URL and thus to start with
   a path component.

   .. doctest::
      :options: +NORMALIZE_WHITESPACE

      >>> from urllib.parse import urlparse
      >>> urlparse('//www.cwi.nl:80/%7Eguido/Python.html')
      ParseResult(scheme='', netloc='www.cwi.nl:80', path='/%7Eguido/Python.html',
                  params='', query='', fragment='')
      >>> urlparse('www.cwi.nl/%7Eguido/Python.html')
      ParseResult(scheme='', netloc='', path='www.cwi.nl/%7Eguido/Python.html',
                  params='', query='', fragment='')
      >>> urlparse('help/Python.html')
      ParseResult(scheme='', netloc='', path='help/Python.html', params='',
                  query='', fragment='')

   The *scheme* argument gives the default addressing scheme, to be
   used only if the URL does not specify one.  It should be the same type
   (text or bytes) as *urlstring*, except that the default value ``''`` is
   always allowed, and is automatically converted to ``b''`` if appropriate.

   If the *allow_fragments* argument is false, fragment identifiers are not
   recognized.  Instead, they are parsed as part of the path, parameters
   or query component, and :attr:`fragment` is set to the empty string in
   the return value.

   The return value is a :term:`named tuple`, which means that its items can
   be accessed by index or as named attributes, which are:

   +------------------+-------+-------------------------+------------------------+
   | Attribute        | Index | Value                   | Value if not present   |
   +==================+=======+=========================+========================+
   | :attr:`scheme`   | 0     | URL scheme specifier    | *scheme* parameter     |
   +------------------+-------+-------------------------+------------------------+
   | :attr:`netloc`   | 1     | Network location part   | empty string           |
   +------------------+-------+-------------------------+------------------------+
   | :attr:`path`     | 2     | Hierarchical path       | empty string           |
   +------------------+-------+-------------------------+------------------------+
   | :attr:`params`   | 3     | Parameters for last     | empty string           |
   |                  |       | path element            |                        |
   +------------------+-------+-------------------------+------------------------+
   | :attr:`query`    | 4     | Query component         | empty string           |
   +------------------+-------+-------------------------+------------------------+
   | :attr:`fragment` | 5     | Fragment identifier     | empty string           |
   +------------------+-------+-------------------------+------------------------+
   | :attr:`username` |       | User name               | :const:`None`          |
   +------------------+-------+-------------------------+------------------------+
   | :attr:`password` |       | Password                | :const:`None`          |
   +------------------+-------+-------------------------+------------------------+
   | :attr:`hostname` |       | Host name (lower case)  | :const:`None`          |
   +------------------+-------+-------------------------+------------------------+
   | :attr:`port`     |       | Port number as integer, | :const:`None`          |
   |                  |       | if present              |                        |
   +------------------+-------+-------------------------+------------------------+

   Reading the :attr:`port` attribute will raise a :exc:`ValueError` if
   an invalid port is specified in the URL.  See section
   :ref:`urlparse-result-object` for more information on the result object.

   Unmatched square brackets in the :attr:`netloc` attribute will raise a
   :exc:`ValueError`.

   Characters in the :attr:`netloc` attribute that decompose under NFKC
   normalization (as used by the IDNA encoding) into any of ``/``, ``?``,
   ``#``, ``@``, or ``:`` will raise a :exc:`ValueError`. If the URL is
   decomposed before parsing, no error will be raised.

   As is the case with all named tuples, the subclass has a few additional methods
   and attributes that are particularly useful. One such method is :meth:`_replace`.
   The :meth:`_replace` method will return a new ParseResult object replacing specified
   fields with new values.

   .. doctest::
      :options: +NORMALIZE_WHITESPACE

      >>> from urllib.parse import urlparse
      >>> u = urlparse('//www.cwi.nl:80/%7Eguido/Python.html')
      >>> u
      ParseResult(scheme='', netloc='www.cwi.nl:80', path='/%7Eguido/Python.html',
                  params='', query='', fragment='')
      >>> u._replace(scheme='http')
      ParseResult(scheme='http', netloc='www.cwi.nl:80', path='/%7Eguido/Python.html',
                  params='', query='', fragment='')

   .. warning::

      :func:`urlparse` does not perform validation.  See :ref:`URL parsing
      security <url-parsing-security>` for details.

   .. versionchanged:: 3.2
      Added IPv6 URL parsing capabilities.

   .. versionchanged:: 3.3
      The fragment is now parsed for all URL schemes (unless *allow_fragments* is
      false), in accordance with :rfc:`3986`.  Previously, an allowlist of
      schemes that support fragments existed.

   .. versionchanged:: 3.6
      Out-of-range port numbers now raise :exc:`ValueError`, instead of
      returning :const:`None`.

   .. versionchanged:: 3.8
      Characters that affect netloc parsing under NFKC normalization will
      now raise :exc:`ValueError`.


.. function:: parse_qs(qs, keep_blank_values=False, strict_parsing=False, encoding='utf-8', errors='replace', max_num_fields=None, separator='&')

   Parse a query string given as a string argument (data of type
   :mimetype:`application/x-www-form-urlencoded`).  Data are returned as a
   dictionary.  The dictionary keys are the unique query variable names and the
   values are lists of values for each name.

   The optional argument *keep_blank_values* is a flag indicating whether blank
   values in percent-encoded queries should be treated as blank strings. A true value
   indicates that blanks should be retained as  blank strings.  The default false
   value indicates that blank values are to be ignored and treated as if they were
   not included.

   The optional argument *strict_parsing* is a flag indicating what to do with
   parsing errors.  If false (the default), errors are silently ignored.  If true,
   errors raise a :exc:`ValueError` exception.

   The optional *encoding* and *errors* parameters specify how to decode
   percent-encoded sequences into Unicode characters, as accepted by the
   :meth:`bytes.decode` method.

   The optional argument *max_num_fields* is the maximum number of fields to
   read. If set, then throws a :exc:`ValueError` if there are more than
   *max_num_fields* fields read.

   The optional argument *separator* is the symbol to use for separating the
   query arguments. It defaults to ``&``.

   Use the :func:`urllib.parse.urlencode` function (with the ``doseq``
   parameter set to ``True``) to convert such dictionaries into query
   strings.


   .. versionchanged:: 3.2
      Add *encoding* and *errors* parameters.

   .. versionchanged:: 3.8
      Added *max_num_fields* parameter.

   .. versionchanged:: 3.10
      Added *separator* parameter with the default value of ``&``. Python
      versions earlier than Python 3.10 allowed using both ``;`` and ``&`` as
      query parameter separator. This has been changed to allow only a single
      separator key, with ``&`` as the default separator.

   .. deprecated:: 3.14
      Accepting objects with false values (like ``0`` and ``[]``) except empty
      strings and byte-like objects and ``None`` is now deprecated.


.. function:: parse_qsl(qs, keep_blank_values=False, strict_parsing=False, encoding='utf-8', errors='replace', max_num_fields=None, separator='&')

   Parse a query string given as a string argument (data of type
   :mimetype:`application/x-www-form-urlencoded`).  Data are returned as a list of
   name, value pairs.

   The optional argument *keep_blank_values* is a flag indicating whether blank
   values in percent-encoded queries should be treated as blank strings. A true value
   indicates that blanks should be retained as  blank strings.  The default false
   value indicates that blank values are to be ignored and treated as if they were
   not included.

   The optional argument *strict_parsing* is a flag indicating what to do with
   parsing errors.  If false (the default), errors are silently ignored.  If true,
   errors raise a :exc:`ValueError` exception.

   The optional *encoding* and *errors* parameters specify how to decode
   percent-encoded sequences into Unicode characters, as accepted by the
   :meth:`bytes.decode` method.

   The optional argument *max_num_fields* is the maximum number of fields to
   read. If set, then throws a :exc:`ValueError` if there are more than
   *max_num_fields* fields read.

   The optional argument *separator* is the symbol to use for separating the
   query arguments. It defaults to ``&``.

   Use the :func:`urllib.parse.urlencode` function to convert such lists of pairs into
   query strings.

   .. versionchanged:: 3.2
      Add *encoding* and *errors* parameters.

   .. versionchanged:: 3.8
      Added *max_num_fields* parameter.

   .. versionchanged:: 3.10
      Added *separator* parameter with the default value of ``&``. Python
      versions earlier than Python 3.10 allowed using both ``;`` and ``&`` as
      query parameter separator. This has been changed to allow only a single
      separator key, with ``&`` as the default separator.


.. function:: urlunparse(parts)

   Construct a URL from a tuple as returned by ``urlparse()``. The *parts*
   argument can be any six-item iterable. This may result in a slightly
   different, but equivalent URL, if the URL that was parsed originally had
   unnecessary delimiters (for example, a ``?`` with an empty query; the RFC
   states that these are equivalent).


.. function:: urlsplit(urlstring, scheme='', allow_fragments=True)

   This is similar to :func:`urlparse`, but does not split the params from the URL.
   This should generally be used instead of :func:`urlparse` if the more recent URL
   syntax allowing parameters to be applied to each segment of the *path* portion
   of the URL (see :rfc:`2396`) is wanted.  A separate function is needed to
   separate the path segments and parameters.  This function returns a 5-item
   :term:`named tuple`::

      (addressing scheme, network location, path, query, fragment identifier).

   The return value is a :term:`named tuple`, its items can be accessed by index
   or as named attributes:

   +------------------+-------+-------------------------+----------------------+
   | Attribute        | Index | Value                   | Value if not present |
   +==================+=======+=========================+======================+
   | :attr:`scheme`   | 0     | URL scheme specifier    | *scheme* parameter   |
   +------------------+-------+-------------------------+----------------------+
   | :attr:`netloc`   | 1     | Network location part   | empty string         |
   +------------------+-------+-------------------------+----------------------+
   | :attr:`path`     | 2     | Hierarchical path       | empty string         |
   +------------------+-------+-------------------------+----------------------+
   | :attr:`query`    | 3     | Query component         | empty string         |
   +------------------+-------+-------------------------+----------------------+
   | :attr:`fragment` | 4     | Fragment identifier     | empty string         |
   +------------------+-------+-------------------------+----------------------+
   | :attr:`username` |       | User name               | :const:`None`        |
   +------------------+-------+-------------------------+----------------------+
   | :attr:`password` |       | Password                | :const:`None`        |
   +------------------+-------+-------------------------+----------------------+
   | :attr:`hostname` |       | Host name (lower case)  | :const:`None`        |
   +------------------+-------+-------------------------+----------------------+
   | :attr:`port`     |       | Port number as integer, | :const:`None`        |
   |                  |       | if present              |                      |
   +------------------+-------+-------------------------+----------------------+

   Reading the :attr:`port` attribute will raise a :exc:`ValueError` if
   an invalid port is specified in the URL.  See section
   :ref:`urlparse-result-object` for more information on the result object.

   Unmatched square brackets in the :attr:`netloc` attribute will raise a
   :exc:`ValueError`.

   Characters in the :attr:`netloc` attribute that decompose under NFKC
   normalization (as used by the IDNA encoding) into any of ``/``, ``?``,
   ``#``, ``@``, or ``:`` will raise a :exc:`ValueError`. If the URL is
   decomposed before parsing, no error will be raised.

   Following some of the `WHATWG spec`_ that updates RFC 3986, leading C0
   control and space characters are stripped from the URL. ``\n``,
   ``\r`` and tab ``\t`` characters are removed from the URL at any position.

   .. warning::

      :func:`urlsplit` does not perform validation.  See :ref:`URL parsing
      security <url-parsing-security>` for details.

   .. versionchanged:: 3.6
      Out-of-range port numbers now raise :exc:`ValueError`, instead of
      returning :const:`None`.

   .. versionchanged:: 3.8
      Characters that affect netloc parsing under NFKC normalization will
      now raise :exc:`ValueError`.

   .. versionchanged:: 3.10
      ASCII newline and tab characters are stripped from the URL.

   .. versionchanged:: 3.12
      Leading WHATWG C0 control and space characters are stripped from the URL.

.. _WHATWG spec: https://url.spec.whatwg.org/#concept-basic-url-parser

.. function:: urlunsplit(parts)

   Combine the elements of a tuple as returned by :func:`urlsplit` into a
   complete URL as a string. The *parts* argument can be any five-item
   iterable. This may result in a slightly different, but equivalent URL, if the
   URL that was parsed originally had unnecessary delimiters (for example, a ?
   with an empty query; the RFC states that these are equivalent).


.. function:: urljoin(base, url, allow_fragments=True)

   Construct a full ("absolute") URL by combining a "base URL" (*base*) with
   another URL (*url*).  Informally, this uses components of the base URL, in
   particular the addressing scheme, the network location and (part of) the
   path, to provide missing components in the relative URL.  For example:

      >>> from urllib.parse import urljoin
      >>> urljoin('http://www.cwi.nl/%7Eguido/Python.html', 'FAQ.html')
      'http://www.cwi.nl/%7Eguido/FAQ.html'

   The *allow_fragments* argument has the same meaning and default as for
   :func:`urlparse`.

   .. note::

      If *url* is an absolute URL (that is, it starts with ``//`` or ``scheme://``),
      the *url*'s hostname and/or scheme will be present in the result.  For example:

      .. doctest::

         >>> urljoin('http://www.cwi.nl/%7Eguido/Python.html',
         ...         '//www.python.org/%7Eguido')
         'http://www.python.org/%7Eguido'

      If you do not want that behavior, preprocess the *url* with :func:`urlsplit` and
      :func:`urlunsplit`, removing possible *scheme* and *netloc* parts.

   .. warning::

      Because an absolute URL may be passed as the ``url`` parameter, it is
      generally **not secure** to use ``urljoin`` with an attacker-controlled
      ``url``. For example in,
      ``urljoin("https://website.com/users/", username)``, if ``username`` can
      contain an absolute URL, the result of ``urljoin`` will be the absolute
      URL.


   .. versionchanged:: 3.5

      Behavior updated to match the semantics defined in :rfc:`3986`.


.. function:: urldefrag(url)

   If *url* contains a fragment identifier, return a modified version of *url*
   with no fragment identifier, and the fragment identifier as a separate
   string.  If there is no fragment identifier in *url*, return *url* unmodified
   and an empty string.

   The return value is a :term:`named tuple`, its items can be accessed by index
   or as named attributes:

   +------------------+-------+-------------------------+----------------------+
   | Attribute        | Index | Value                   | Value if not present |
   +==================+=======+=========================+======================+
   | :attr:`url`      | 0     | URL with no fragment    | empty string         |
   +------------------+-------+-------------------------+----------------------+
   | :attr:`fragment` | 1     | Fragment identifier     | empty string         |
   +------------------+-------+-------------------------+----------------------+

   See section :ref:`urlparse-result-object` for more information on the result
   object.

   .. versionchanged:: 3.2
      Result is a structured object rather than a simple 2-tuple.

.. function:: unwrap(url)

   Extract the url from a wrapped URL (that is, a string formatted as
   ``<URL:scheme://host/path>``, ``<scheme://host/path>``, ``URL:scheme://host/path``
   or ``scheme://host/path``). If *url* is not a wrapped URL, it is returned
   without changes.

.. _url-parsing-security:

URL parsing security
--------------------

The :func:`urlsplit` and :func:`urlparse` APIs do not perform **validation** of
inputs.  They may not raise errors on inputs that other applications consider
invalid.  They may also succeed on some inputs that might not be considered
URLs elsewhere.  Their purpose is for practical functionality rather than
purity.

Instead of raising an exception on unusual input, they may instead return some
component parts as empty strings. Or components may contain more than perhaps
they should.

We recommend that users of these APIs where the values may be used anywhere
with security implications code defensively. Do some verification within your
code before trusting a returned component part.  Does that ``scheme`` make
sense?  Is that a sensible ``path``?  Is there anything strange about that
``hostname``?  etc.

What constitutes a URL is not universally well defined.  Different applications
have different needs and desired constraints.  For instance the living `WHATWG
spec`_ describes what user facing web clients such as a web browser require.
While :rfc:`3986` is more general.  These functions incorporate some aspects of
both, but cannot be claimed compliant with either.  The APIs and existing user
code with expectations on specific behaviors predate both standards leading us
to be very cautious about making API behavior changes.

.. _parsing-ascii-encoded-bytes:

Parsing ASCII Encoded Bytes
---------------------------

The URL parsing functions were originally designed to operate on character
strings only. In practice, it is useful to be able to manipulate properly
quoted and encoded URLs as sequences of ASCII bytes. Accordingly, the
URL parsing functions in this module all operate on :class:`bytes` and
:class:`bytearray` objects in addition to :class:`str` objects.

If :class:`str` data is passed in, the result will also contain only
:class:`str` data. If :class:`bytes` or :class:`bytearray` data is
passed in, the result will contain only :class:`bytes` data.

Attempting to mix :class:`str` data with :class:`bytes` or
:class:`bytearray` in a single function call will result in a
:exc:`TypeError` being raised, while attempting to pass in non-ASCII
byte values will trigger :exc:`UnicodeDecodeError`.

To support easier conversion of result objects between :class:`str` and
:class:`bytes`, all return values from URL parsing functions provide
either an :meth:`encode` method (when the result contains :class:`str`
data) or a :meth:`decode` method (when the result contains :class:`bytes`
data). The signatures of these methods match those of the corresponding
:class:`str` and :class:`bytes` methods (except that the default encoding
is ``'ascii'`` rather than ``'utf-8'``). Each produces a value of a
corresponding type that contains either :class:`bytes` data (for
:meth:`encode` methods) or :class:`str` data (for
:meth:`decode` methods).

Applications that need to operate on potentially improperly quoted URLs
that may contain non-ASCII data will need to do their own decoding from
bytes to characters before invoking the URL parsing methods.

The behaviour described in this section applies only to the URL parsing
functions. The URL quoting functions use their own rules when producing
or consuming byte sequences as detailed in the documentation of the
individual URL quoting functions.

.. versionchanged:: 3.2
   URL parsing functions now accept ASCII encoded byte sequences


.. _urlparse-result-object:

Structured Parse Results
------------------------

The result objects from the :func:`urlparse`, :func:`urlsplit`  and
:func:`urldefrag` functions are subclasses of the :class:`tuple` type.
These subclasses add the attributes listed in the documentation for
those functions, the encoding and decoding support described in the
previous section, as well as an additional method:

.. method:: urllib.parse.SplitResult.geturl()

   Return the re-combined version of the original URL as a string. This may
   differ from the original URL in that the scheme may be normalized to lower
   case and empty components may be dropped. Specifically, empty parameters,
   queries, and fragment identifiers will be removed.

   For :func:`urldefrag` results, only empty fragment identifiers will be removed.
   For :func:`urlsplit` and :func:`urlparse` results, all noted changes will be
   made to the URL returned by this method.

   The result of this method remains unchanged if passed back through the original
   parsing function:

      >>> from urllib.parse import urlsplit
      >>> url = 'HTTP://www.Python.org/doc/#'
      >>> r1 = urlsplit(url)
      >>> r1.geturl()
      'http://www.Python.org/doc/'
      >>> r2 = urlsplit(r1.geturl())
      >>> r2.geturl()
      'http://www.Python.org/doc/'


The following classes provide the implementations of the structured parse
results when operating on :class:`str` objects:

.. class:: DefragResult(url, fragment)

   Concrete class for :func:`urldefrag` results containing :class:`str`
   data. The :meth:`encode` method returns a :class:`DefragResultBytes`
   instance.

   .. versionadded:: 3.2

.. class:: ParseResult(scheme, netloc, path, params, query, fragment)

   Concrete class for :func:`urlparse` results containing :class:`str`
   data. The :meth:`encode` method returns a :class:`ParseResultBytes`
   instance.

.. class:: SplitResult(scheme, netloc, path, query, fragment)

   Concrete class for :func:`urlsplit` results containing :class:`str`
   data. The :meth:`encode` method returns a :class:`SplitResultBytes`
   instance.


The following classes provide the implementations of the parse results when
operating on :class:`bytes` or :class:`bytearray` objects:

.. class:: DefragResultBytes(url, fragment)

   Concrete class for :func:`urldefrag` results containing :class:`bytes`
   data. The :meth:`decode` method returns a :class:`DefragResult`
   instance.

   .. versionadded:: 3.2

.. class:: ParseResultBytes(scheme, netloc, path, params, query, fragment)

   Concrete class for :func:`urlparse` results containing :class:`bytes`
   data. The :meth:`decode` method returns a :class:`ParseResult`
   instance.

   .. versionadded:: 3.2

.. class:: SplitResultBytes(scheme, netloc, path, query, fragment)

   Concrete class for :func:`urlsplit` results containing :class:`bytes`
   data. The :meth:`decode` method returns a :class:`SplitResult`
   instance.

   .. versionadded:: 3.2


URL Quoting
-----------

The URL quoting functions focus on taking program data and making it safe
for use as URL components by quoting special characters and appropriately
encoding non-ASCII text. They also support reversing these operations to
recreate the original data from the contents of a URL component if that
task isn't already covered by the URL parsing functions above.

.. function:: quote(string, safe='/', encoding=None, errors=None)

   Replace special characters in *string* using the :samp:`%{xx}` escape. Letters,
   digits, and the characters ``'_.-~'`` are never quoted. By default, this
   function is intended for quoting the path section of a URL. The optional
   *safe* parameter specifies additional ASCII characters that should not be
   quoted --- its default value is ``'/'``.

   *string* may be either a :class:`str` or a :class:`bytes` object.

   .. versionchanged:: 3.7
      Moved from :rfc:`2396` to :rfc:`3986` for quoting URL strings. "~" is now
      included in the set of unreserved characters.

   The optional *encoding* and *errors* parameters specify how to deal with
   non-ASCII characters, as accepted by the :meth:`str.encode` method.
   *encoding* defaults to ``'utf-8'``.
   *errors* defaults to ``'strict'``, meaning unsupported characters raise a
   :class:`UnicodeEncodeError`.
   *encoding* and *errors* must not be supplied if *string* is a
   :class:`bytes`, or a :class:`TypeError` is raised.

   Note that ``quote(string, safe, encoding, errors)`` is equivalent to
   ``quote_from_bytes(string.encode(encoding, errors), safe)``.

   Example: ``quote('/El Nio/')`` yields ``'/El%20Ni%C3%B1o/'``.


.. function:: quote_plus(string, safe='', encoding=None, errors=None)

   Like :func:`quote`, but also replace spaces with plus signs, as required for
   quoting HTML form values when building up a query string to go into a URL.
   Plus signs in the original string are escaped unless they are included in
   *safe*.  It also does not have *safe* default to ``'/'``.

   Example: ``quote_plus('/El Nio/')`` yields ``'%2FEl+Ni%C3%B1o%2F'``.


.. function:: quote_from_bytes(bytes, safe='/')

   Like :func:`quote`, but accepts a :class:`bytes` object rather than a
   :class:`str`, and does not perform string-to-bytes encoding.

   Example: ``quote_from_bytes(b'a&\xef')`` yields
   ``'a%26%EF'``.


.. function:: unquote(string, encoding='utf-8', errors='replace')

   Replace :samp:`%{xx}` escapes with their single-character equivalent.
   The optional *encoding* and *errors* parameters specify how to decode
   percent-encoded sequences into Unicode characters, as accepted by the
   :meth:`bytes.decode` method.

   *string* may be either a :class:`str` or a :class:`bytes` object.

   *encoding* defaults to ``'utf-8'``.
   *errors* defaults to ``'replace'``, meaning invalid sequences are replaced
   by a placeholder character.

   Example: ``unquote('/El%20Ni%C3%B1o/')`` yields ``'/El Nio/'``.

   .. versionchanged:: 3.9
      *string* parameter supports bytes and str objects (previously only str).




.. function:: unquote_plus(string, encoding='utf-8', errors='replace')

   Like :func:`unquote`, but also replace plus signs with spaces, as required
   for unquoting HTML form values.

   *string* must be a :class:`str`.

   Example: ``unquote_plus('/El+Ni%C3%B1o/')`` yields ``'/El Nio/'``.


.. function:: unquote_to_bytes(string)

   Replace :samp:`%{xx}` escapes with their single-octet equivalent, and return a
   :class:`bytes` object.

   *string* may be either a :class:`str` or a :class:`bytes` object.

   If it is a :class:`str`, unescaped non-ASCII characters in *string*
   are encoded into UTF-8 bytes.

   Example: ``unquote_to_bytes('a%26%EF')`` yields ``b'a&\xef'``.


.. function:: urlencode(query, doseq=False, safe='', encoding=None, \
                        errors=None, quote_via=quote_plus)

   Convert a mapping object or a sequence of two-element tuples, which may
   contain :class:`str` or :class:`bytes` objects, to a percent-encoded ASCII
   text string.  If the resultant string is to be used as a *data* for POST
   operation with the :func:`~urllib.request.urlopen` function, then
   it should be encoded to bytes, otherwise it would result in a
   :exc:`TypeError`.

   The resulting string is a series of ``key=value`` pairs separated by ``'&'``
   characters, where both *key* and *value* are quoted using the *quote_via*
   function.  By default, :func:`quote_plus` is used to quote the values, which
   means spaces are quoted as a ``'+'`` character and '/' characters are
   encoded as ``%2F``, which follows the standard for GET requests
   (``application/x-www-form-urlencoded``).  An alternate function that can be
   passed as *quote_via* is :func:`quote`, which will encode spaces as ``%20``
   and not encode '/' characters.  For maximum control of what is quoted, use
   ``quote`` and specify a value for *safe*.

   When a sequence of two-element tuples is used as the *query*
   argument, the first element of each tuple is a key and the second is a
   value. The value element in itself can be a sequence and in that case, if
   the optional parameter *doseq* evaluates to ``True``, individual
   ``key=value`` pairs separated by ``'&'`` are generated for each element of
   the value sequence for the key.  The order of parameters in the encoded
   string will match the order of parameter tuples in the sequence.

   The *safe*, *encoding*, and *errors* parameters are passed down to
   *quote_via* (the *encoding* and *errors* parameters are only passed
   when a query element is a :class:`str`).

   To reverse this encoding process, :func:`parse_qs` and :func:`parse_qsl` are
   provided in this module to parse query strings into Python data structures.

   Refer to :ref:`urllib examples <urllib-examples>` to find out how the
   :func:`urllib.parse.urlencode` method can be used for generating the query
   string of a URL or data for a POST request.

   .. versionchanged:: 3.2
      *query* supports bytes and string objects.

   .. versionchanged:: 3.5
      Added the *quote_via* parameter.

   .. deprecated:: 3.14
      Accepting objects with false values (like ``0`` and ``[]``) except empty
      strings and byte-like objects and ``None`` is now deprecated.


.. seealso::

   `WHATWG`_ -  URL Living standard
      Working Group for the URL Standard that defines URLs, domains, IP addresses, the
      application/x-www-form-urlencoded format, and their API.

   :rfc:`3986` - Uniform Resource Identifiers
      This is the current standard (STD66). Any changes to urllib.parse module
      should conform to this. Certain deviations could be observed, which are
      mostly for backward compatibility purposes and for certain de-facto
      parsing requirements as commonly observed in major browsers.

   :rfc:`2732` - Format for Literal IPv6 Addresses in URL's.
      This specifies the parsing requirements of IPv6 URLs.

   :rfc:`2396` - Uniform Resource Identifiers (URI): Generic Syntax
      Document describing the generic syntactic requirements for both Uniform Resource
      Names (URNs) and Uniform Resource Locators (URLs).

   :rfc:`2368` - The mailto URL scheme.
      Parsing requirements for mailto URL schemes.

   :rfc:`1808` - Relative Uniform Resource Locators
      This Request For Comments includes the rules for joining an absolute and a
      relative URL, including a fair number of "Abnormal Examples" which govern the
      treatment of border cases.

   :rfc:`1738` - Uniform Resource Locators (URL)
      This specifies the formal syntax and semantics of absolute URLs.

.. _WHATWG: https://url.spec.whatwg.org/


================================================
File: /Doc/library/urllib.robotparser.rst
================================================
:mod:`!urllib.robotparser` ---  Parser for robots.txt
=====================================================

.. module:: urllib.robotparser
   :synopsis: Load a robots.txt file and answer questions about
              fetchability of other URLs.

.. sectionauthor:: Skip Montanaro <skip.montanaro@gmail.com>

**Source code:** :source:`Lib/urllib/robotparser.py`

.. index::
   single: WWW
   single: World Wide Web
   single: URL
   single: robots.txt

--------------

This module provides a single class, :class:`RobotFileParser`, which answers
questions about whether or not a particular user agent can fetch a URL on the
web site that published the :file:`robots.txt` file.  For more details on the
structure of :file:`robots.txt` files, see http://www.robotstxt.org/orig.html.


.. class:: RobotFileParser(url='')

   This class provides methods to read, parse and answer questions about the
   :file:`robots.txt` file at *url*.

   .. method:: set_url(url)

      Sets the URL referring to a :file:`robots.txt` file.

   .. method:: read()

      Reads the :file:`robots.txt` URL and feeds it to the parser.

   .. method:: parse(lines)

      Parses the lines argument.

   .. method:: can_fetch(useragent, url)

      Returns ``True`` if the *useragent* is allowed to fetch the *url*
      according to the rules contained in the parsed :file:`robots.txt`
      file.

   .. method:: mtime()

      Returns the time the ``robots.txt`` file was last fetched.  This is
      useful for long-running web spiders that need to check for new
      ``robots.txt`` files periodically.

   .. method:: modified()

      Sets the time the ``robots.txt`` file was last fetched to the current
      time.

   .. method:: crawl_delay(useragent)

      Returns the value of the ``Crawl-delay`` parameter from ``robots.txt``
      for the *useragent* in question.  If there is no such parameter or it
      doesn't apply to the *useragent* specified or the ``robots.txt`` entry
      for this parameter has invalid syntax, return ``None``.

      .. versionadded:: 3.6

   .. method:: request_rate(useragent)

      Returns the contents of the ``Request-rate`` parameter from
      ``robots.txt`` as a :term:`named tuple` ``RequestRate(requests, seconds)``.
      If there is no such parameter or it doesn't apply to the *useragent*
      specified or the ``robots.txt`` entry for this parameter has invalid
      syntax, return ``None``.

      .. versionadded:: 3.6

   .. method:: site_maps()

      Returns the contents of the ``Sitemap`` parameter from
      ``robots.txt`` in the form of a :func:`list`. If there is no such
      parameter or the ``robots.txt`` entry for this parameter has
      invalid syntax, return ``None``.

      .. versionadded:: 3.8


The following example demonstrates basic use of the :class:`RobotFileParser`
class::

   >>> import urllib.robotparser
   >>> rp = urllib.robotparser.RobotFileParser()
   >>> rp.set_url("http://www.musi-cal.com/robots.txt")
   >>> rp.read()
   >>> rrate = rp.request_rate("*")
   >>> rrate.requests
   3
   >>> rrate.seconds
   20
   >>> rp.crawl_delay("*")
   6
   >>> rp.can_fetch("*", "http://www.musi-cal.com/cgi-bin/search?city=San+Francisco")
   False
   >>> rp.can_fetch("*", "http://www.musi-cal.com/")
   True


================================================
File: /Doc/library/urllib.rst
================================================
:mod:`!urllib` --- URL handling modules
=======================================

.. module:: urllib

**Source code:** :source:`Lib/urllib/`

--------------

``urllib`` is a package that collects several modules for working with URLs:

* :mod:`urllib.request` for opening and reading URLs
* :mod:`urllib.error` containing the exceptions raised by :mod:`urllib.request`
* :mod:`urllib.parse` for parsing URLs
* :mod:`urllib.robotparser` for parsing ``robots.txt`` files


================================================
File: /Doc/library/uu.rst
================================================
:mod:`!uu` --- Encode and decode uuencode files
===============================================

.. module:: uu
   :synopsis: Removed in 3.13.
   :deprecated:

.. deprecated-removed:: 3.11 3.13

This module is no longer part of the Python standard library.
It was :ref:`removed in Python 3.13 <whatsnew313-pep594>` after
being deprecated in Python 3.11.  The removal was decided in :pep:`594`.

The last version of Python that provided the :mod:`!uu` module was
`Python 3.12 <https://docs.python.org/3.12/library/uu.html>`_.


================================================
File: /Doc/library/uuid.rst
================================================
:mod:`!uuid` --- UUID objects according to :rfc:`9562`
======================================================

.. module:: uuid
   :synopsis: UUID objects (universally unique identifiers) according to RFC 9562
.. moduleauthor:: Ka-Ping Yee <ping@zesty.ca>
.. sectionauthor:: George Yoshida <quiver@users.sourceforge.net>

**Source code:** :source:`Lib/uuid.py`

--------------

This module provides immutable :class:`UUID` objects (the :class:`UUID` class)
and the functions :func:`uuid1`, :func:`uuid3`, :func:`uuid4`, :func:`uuid5`,
and :func:`uuid.uuid8` for generating version 1, 3, 4, 5, and 8 UUIDs as
specified in :rfc:`9562` (which supersedes :rfc:`4122`).

If all you want is a unique ID, you should probably call :func:`uuid1` or
:func:`uuid4`.  Note that :func:`uuid1` may compromise privacy since it creates
a UUID containing the computer's network address.  :func:`uuid4` creates a
random UUID.

Depending on support from the underlying platform, :func:`uuid1` may or may
not return a "safe" UUID.  A safe UUID is one which is generated using
synchronization methods that ensure no two processes can obtain the same
UUID.  All instances of :class:`UUID` have an :attr:`~UUID.is_safe` attribute
which relays any information about the UUID's safety, using this enumeration:

.. class:: SafeUUID

   .. versionadded:: 3.7

   .. attribute:: SafeUUID.safe

      The UUID was generated by the platform in a multiprocessing-safe way.

   .. attribute:: SafeUUID.unsafe

      The UUID was not generated in a multiprocessing-safe way.

   .. attribute:: SafeUUID.unknown

      The platform does not provide information on whether the UUID was
      generated safely or not.

.. class:: UUID(hex=None, bytes=None, bytes_le=None, fields=None, int=None, version=None, *, is_safe=SafeUUID.unknown)

   Create a UUID from either a string of 32 hexadecimal digits, a string of 16
   bytes in big-endian order as the *bytes* argument, a string of 16 bytes in
   little-endian order as the *bytes_le* argument, a tuple of six integers
   (32-bit *time_low*, 16-bit *time_mid*, 16-bit *time_hi_version*,
   8-bit *clock_seq_hi_variant*, 8-bit *clock_seq_low*, 48-bit *node*) as the
   *fields* argument, or a single 128-bit integer as the *int* argument.
   When a string of hex digits is given, curly braces, hyphens,
   and a URN prefix are all optional.  For example, these
   expressions all yield the same UUID::

      UUID('{12345678-1234-5678-1234-567812345678}')
      UUID('12345678123456781234567812345678')
      UUID('urn:uuid:12345678-1234-5678-1234-567812345678')
      UUID(bytes=b'\x12\x34\x56\x78'*4)
      UUID(bytes_le=b'\x78\x56\x34\x12\x34\x12\x78\x56' +
                    b'\x12\x34\x56\x78\x12\x34\x56\x78')
      UUID(fields=(0x12345678, 0x1234, 0x5678, 0x12, 0x34, 0x567812345678))
      UUID(int=0x12345678123456781234567812345678)

   Exactly one of *hex*, *bytes*, *bytes_le*, *fields*, or *int* must be given.
   The *version* argument is optional; if given, the resulting UUID will have its
   variant and version number set according to :rfc:`9562`, overriding bits in the
   given *hex*, *bytes*, *bytes_le*, *fields*, or *int*.

   Comparison of UUID objects are made by way of comparing their
   :attr:`UUID.int` attributes.  Comparison with a non-UUID object
   raises a :exc:`TypeError`.

   ``str(uuid)`` returns a string in the form
   ``12345678-1234-5678-1234-567812345678`` where the 32 hexadecimal digits
   represent the UUID.

:class:`UUID` instances have these read-only attributes:

.. attribute:: UUID.bytes

   The UUID as a 16-byte string (containing the six integer fields in big-endian
   byte order).


.. attribute:: UUID.bytes_le

   The UUID as a 16-byte string (with *time_low*, *time_mid*, and *time_hi_version*
   in little-endian byte order).


.. attribute:: UUID.fields

   A tuple of the six integer fields of the UUID, which are also available as six
   individual attributes and two derived attributes:

.. list-table::

   * - Field
     - Meaning

   * - .. attribute:: UUID.time_low
     - The first 32 bits of the UUID.

   * - .. attribute:: UUID.time_mid
     - The next 16 bits of the UUID.

   * - .. attribute:: UUID.time_hi_version
     - The next 16 bits of the UUID.

   * - .. attribute:: UUID.clock_seq_hi_variant
     - The next 8 bits of the UUID.

   * - .. attribute:: UUID.clock_seq_low
     - The next 8 bits of the UUID.

   * - .. attribute:: UUID.node
     - The last 48 bits of the UUID.

   * - .. attribute:: UUID.time
     - The 60-bit timestamp.

   * - .. attribute:: UUID.clock_seq
     - The 14-bit sequence number.


.. attribute:: UUID.hex

   The UUID as a 32-character lowercase hexadecimal string.


.. attribute:: UUID.int

   The UUID as a 128-bit integer.


.. attribute:: UUID.urn

   The UUID as a URN as specified in :rfc:`9562`.


.. attribute:: UUID.variant

   The UUID variant, which determines the internal layout of the UUID. This will be
   one of the constants :const:`RESERVED_NCS`, :const:`RFC_4122`,
   :const:`RESERVED_MICROSOFT`, or :const:`RESERVED_FUTURE`.


.. attribute:: UUID.version

   The UUID version number (1 through 8, meaningful only when the variant is
   :const:`RFC_4122`).

   .. versionchanged:: 3.14
      Added UUID version 8.


.. attribute:: UUID.is_safe

   An enumeration of :class:`SafeUUID` which indicates whether the platform
   generated the UUID in a multiprocessing-safe way.

   .. versionadded:: 3.7

The :mod:`uuid` module defines the following functions:


.. function:: getnode()

   Get the hardware address as a 48-bit positive integer.  The first time this
   runs, it may launch a separate program, which could be quite slow.  If all
   attempts to obtain the hardware address fail, we choose a random 48-bit
   number with the multicast bit (least significant bit of the first octet)
   set to 1 as recommended in :rfc:`4122`.  "Hardware address" means the MAC
   address of a network interface.  On a machine with multiple network
   interfaces, universally administered MAC addresses (i.e. where the second
   least significant bit of the first octet is *unset*) will be preferred over
   locally administered MAC addresses, but with no other ordering guarantees.

   .. versionchanged:: 3.7
      Universally administered MAC addresses are preferred over locally
      administered MAC addresses, since the former are guaranteed to be
      globally unique, while the latter are not.

.. index:: single: getnode


.. function:: uuid1(node=None, clock_seq=None)

   Generate a UUID from a host ID, sequence number, and the current time. If *node*
   is not given, :func:`getnode` is used to obtain the hardware address. If
   *clock_seq* is given, it is used as the sequence number; otherwise a random
   14-bit sequence number is chosen.

.. index:: single: uuid1


.. function:: uuid3(namespace, name)

   Generate a UUID based on the MD5 hash of a namespace identifier (which is a
   UUID) and a name (which is a :class:`bytes` object or a string
   that will be encoded using UTF-8).

.. index:: single: uuid3


.. function:: uuid4()

   Generate a random UUID.

.. index:: single: uuid4


.. function:: uuid5(namespace, name)

   Generate a UUID based on the SHA-1 hash of a namespace identifier (which is a
   UUID) and a name (which is a :class:`bytes` object or a string
   that will be encoded using UTF-8).

.. index:: single: uuid5


.. function:: uuid8(a=None, b=None, c=None)

   Generate a pseudo-random UUID according to
   :rfc:`RFC 9562, 5.8 <9562#section-5.8>`.

   When specified, the parameters *a*, *b* and *c* are expected to be
   positive integers of 48, 12 and 62 bits respectively. If they exceed
   their expected bit count, only their least significant bits are kept;
   non-specified arguments are substituted for a pseudo-random integer of
   appropriate size.

   .. versionadded:: 3.14

.. index:: single: uuid8


The :mod:`uuid` module defines the following namespace identifiers for use with
:func:`uuid3` or :func:`uuid5`.


.. data:: NAMESPACE_DNS

   When this namespace is specified, the *name* string is a fully qualified domain
   name.


.. data:: NAMESPACE_URL

   When this namespace is specified, the *name* string is a URL.


.. data:: NAMESPACE_OID

   When this namespace is specified, the *name* string is an ISO OID.


.. data:: NAMESPACE_X500

   When this namespace is specified, the *name* string is an X.500 DN in DER or a
   text output format.

The :mod:`uuid` module defines the following constants for the possible values
of the :attr:`~UUID.variant` attribute:


.. data:: RESERVED_NCS

   Reserved for NCS compatibility.


.. data:: RFC_4122

   Specifies the UUID layout given in :rfc:`4122`. This constant is kept
   for backward compatibility even though :rfc:`4122` has been superseded
   by :rfc:`9562`.


.. data:: RESERVED_MICROSOFT

   Reserved for Microsoft compatibility.


.. data:: RESERVED_FUTURE

   Reserved for future definition.


.. seealso::

   :rfc:`9562` - A Universally Unique IDentifier (UUID) URN Namespace
      This specification defines a Uniform Resource Name namespace for UUIDs, the
      internal format of UUIDs, and methods of generating UUIDs.


.. _uuid-cli:

Command-Line Usage
------------------

.. versionadded:: 3.12

The :mod:`uuid` module can be executed as a script from the command line.

.. code-block:: sh

   python -m uuid [-h] [-u {uuid1,uuid3,uuid4,uuid5,uuid8}] [-n NAMESPACE] [-N NAME]

The following options are accepted:

.. program:: uuid

.. option:: -h, --help

   Show the help message and exit.

.. option:: -u <uuid>
            --uuid <uuid>

   Specify the function name to use to generate the uuid. By default :func:`uuid4`
   is used.

   .. versionadded:: 3.14
      Allow generating UUID version 8.

.. option:: -n <namespace>
            --namespace <namespace>

   The namespace is a ``UUID``, or ``@ns`` where ``ns`` is a well-known predefined UUID
   addressed by namespace name. Such as ``@dns``, ``@url``, ``@oid``, and ``@x500``.
   Only required for :func:`uuid3` / :func:`uuid5` functions.

.. option:: -N <name>
            --name <name>

   The name used as part of generating the uuid. Only required for
   :func:`uuid3` / :func:`uuid5` functions.


.. _uuid-example:

Example
-------

Here are some examples of typical usage of the :mod:`uuid` module::

   >>> import uuid

   >>> # make a UUID based on the host ID and current time
   >>> uuid.uuid1()
   UUID('a8098c1a-f86e-11da-bd1a-00112444be1e')

   >>> # make a UUID using an MD5 hash of a namespace UUID and a name
   >>> uuid.uuid3(uuid.NAMESPACE_DNS, 'python.org')
   UUID('6fa459ea-ee8a-3ca4-894e-db77e160355e')

   >>> # make a random UUID
   >>> uuid.uuid4()
   UUID('16fd2706-8baf-433b-82eb-8c7fada847da')

   >>> # make a UUID using a SHA-1 hash of a namespace UUID and a name
   >>> uuid.uuid5(uuid.NAMESPACE_DNS, 'python.org')
   UUID('886313e1-3b8a-5372-9b90-0c9aee199e5d')

   >>> # make a UUID from a string of hex digits (braces and hyphens ignored)
   >>> x = uuid.UUID('{00010203-0405-0607-0809-0a0b0c0d0e0f}')

   >>> # convert a UUID to a string of hex digits in standard form
   >>> str(x)
   '00010203-0405-0607-0809-0a0b0c0d0e0f'

   >>> # get the raw 16 bytes of the UUID
   >>> x.bytes
   b'\x00\x01\x02\x03\x04\x05\x06\x07\x08\t\n\x0b\x0c\r\x0e\x0f'

   >>> # make a UUID from a 16-byte string
   >>> uuid.UUID(bytes=x.bytes)
   UUID('00010203-0405-0607-0809-0a0b0c0d0e0f')


.. _uuid-cli-example:

Command-Line Example
--------------------

Here are some examples of typical usage of the :mod:`uuid` command line interface:

.. code-block:: shell

   # generate a random uuid - by default uuid4() is used
   $ python -m uuid

   # generate a uuid using uuid1()
   $ python -m uuid -u uuid1

   # generate a uuid using uuid5
   $ python -m uuid -u uuid5 -n @url -N example.com



================================================
File: /Doc/library/venv.rst
================================================
:mod:`!venv` --- Creation of virtual environments
=================================================

.. module:: venv
   :synopsis: Creation of virtual environments.

.. moduleauthor:: Vinay Sajip <vinay_sajip@yahoo.co.uk>
.. sectionauthor:: Vinay Sajip <vinay_sajip@yahoo.co.uk>

.. versionadded:: 3.3

**Source code:** :source:`Lib/venv/`

.. index:: pair: Environments; virtual

--------------

.. _venv-def:
.. _venv-intro:

The :mod:`!venv` module supports creating lightweight "virtual environments",
each with their own independent set of Python packages installed in
their :mod:`site` directories.
A virtual environment is created on top of an existing
Python installation, known as the virtual environment's "base" Python, and may
optionally be isolated from the packages in the base environment,
so only those explicitly installed in the virtual environment are available.
See :ref:`sys-path-init-virtual-environments` and :mod:`site`'s
:ref:`virtual environments documentation <site-virtual-environments-configuration>`
for more information.

When used from within a virtual environment, common installation tools such as
:pypi:`pip` will install Python packages into a virtual environment
without needing to be told to do so explicitly.

A virtual environment is (amongst other things):

* Used to contain a specific Python interpreter and software libraries and
  binaries which are needed to support a project (library or application). These
  are by default isolated from software in other virtual environments and Python
  interpreters and libraries installed in the operating system.

* Contained in a directory, conventionally named ``.venv`` or ``venv`` in
  the project directory, or under a container directory for lots of virtual
  environments, such as ``~/.virtualenvs``.

* Not checked into source control systems such as Git.

* Considered as disposable -- it should be simple to delete and recreate it from
  scratch. You don't place any project code in the environment.

* Not considered as movable or copyable -- you just recreate the same
  environment in the target location.

See :pep:`405` for more background on Python virtual environments.

.. seealso::

   `Python Packaging User Guide: Creating and using virtual environments
   <https://packaging.python.org/guides/installing-using-pip-and-virtual-environments/#create-and-use-virtual-environments>`__

.. include:: ../includes/wasm-mobile-notavail.rst

Creating virtual environments
-----------------------------

:ref:`Virtual environments <venv-def>` are created by executing the ``venv``
module:

.. code-block:: shell

    python -m venv /path/to/new/virtual/environment

This creates the target directory (including parent directories as needed)
and places a :file:`pyvenv.cfg` file in it with a ``home`` key
pointing to the Python installation from which the command was run.
It also creates a :file:`bin` (or :file:`Scripts` on Windows) subdirectory
containing a copy or symlink of the Python executable
(as appropriate for the platform or arguments used at environment creation time).
It also creates a :file:`lib/pythonX.Y/site-packages` subdirectory
(on Windows, this is :file:`Lib\site-packages`).
If an existing directory is specified, it will be re-used.

.. versionchanged:: 3.5
   The use of ``venv`` is now recommended for creating virtual environments.

.. deprecated-removed:: 3.6 3.8
   :program:`pyvenv` was the recommended tool for creating virtual environments
   for Python 3.3 and 3.4, and replaced in 3.5 by executing ``venv`` directly.

.. highlight:: none

On Windows, invoke the ``venv`` command as follows:

.. code-block:: ps1con

   PS> python -m venv C:\path\to\new\virtual\environment

The command, if run with ``-h``, will show the available options::

   usage: venv [-h] [--system-site-packages] [--symlinks | --copies] [--clear]
               [--upgrade] [--without-pip] [--prompt PROMPT] [--upgrade-deps]
               [--without-scm-ignore-files]
               ENV_DIR [ENV_DIR ...]

   Creates virtual Python environments in one or more target directories.

   positional arguments:
     ENV_DIR               A directory to create the environment in.

   options:
     -h, --help            show this help message and exit
     --system-site-packages
                           Give the virtual environment access to the system
                           site-packages dir.
     --symlinks            Try to use symlinks rather than copies, when
                           symlinks are not the default for the platform.
     --copies              Try to use copies rather than symlinks, even when
                           symlinks are the default for the platform.
     --clear               Delete the contents of the environment directory
                           if it already exists, before environment creation.
     --upgrade             Upgrade the environment directory to use this
                           version of Python, assuming Python has been
                           upgraded in-place.
     --without-pip         Skips installing or upgrading pip in the virtual
                           environment (pip is bootstrapped by default)
     --prompt PROMPT       Provides an alternative prompt prefix for this
                           environment.
     --upgrade-deps        Upgrade core dependencies (pip) to the latest
                           version in PyPI
     --without-scm-ignore-files
                           Skips adding SCM ignore files to the environment
                           directory (Git is supported by default).

   Once an environment has been created, you may wish to activate it, e.g. by
   sourcing an activate script in its bin directory.


.. versionchanged:: 3.4
   Installs pip by default, added the ``--without-pip``  and ``--copies``
   options.

.. versionchanged:: 3.4
   In earlier versions, if the target directory already existed, an error was
   raised, unless the ``--clear`` or ``--upgrade`` option was provided.

.. versionchanged:: 3.9
   Add ``--upgrade-deps`` option to upgrade pip + setuptools to the latest on PyPI.

.. versionchanged:: 3.12

   ``setuptools`` is no longer a core venv dependency.

.. versionchanged:: 3.13

   Added the ``--without-scm-ignore-files`` option.
.. versionchanged:: 3.13
   ``venv`` now creates a :file:`.gitignore` file for Git by default.

.. note::
   While symlinks are supported on Windows, they are not recommended. Of
   particular note is that double-clicking ``python.exe`` in File Explorer
   will resolve the symlink eagerly and ignore the virtual environment.

.. note::
   On Microsoft Windows, it may be required to enable the ``Activate.ps1``
   script by setting the execution policy for the user. You can do this by
   issuing the following PowerShell command:

   .. code-block:: powershell

      PS C:\> Set-ExecutionPolicy -ExecutionPolicy RemoteSigned -Scope CurrentUser

   See `About Execution Policies
   <https://go.microsoft.com/fwlink/?LinkID=135170>`_
   for more information.

The created :file:`pyvenv.cfg` file also includes the
``include-system-site-packages`` key, set to ``true`` if ``venv`` is
run with the ``--system-site-packages`` option, ``false`` otherwise.

Unless the ``--without-pip`` option is given, :mod:`ensurepip` will be
invoked to bootstrap ``pip`` into the virtual environment.

Multiple paths can be given to ``venv``, in which case an identical virtual
environment will be created, according to the given options, at each provided
path.

.. _venv-explanation:

How venvs work
--------------

When a Python interpreter is running from a virtual environment,
:data:`sys.prefix` and :data:`sys.exec_prefix`
point to the directories of the virtual environment,
whereas :data:`sys.base_prefix` and :data:`sys.base_exec_prefix`
point to those of the base Python used to create the environment.
It is sufficient to check
``sys.prefix != sys.base_prefix`` to determine if the current interpreter is
running from a virtual environment.

A virtual environment may be "activated" using a script in its binary directory
(``bin`` on POSIX; ``Scripts`` on Windows).
This will prepend that directory to your :envvar:`PATH`, so that running
:program:`python` will invoke the environment's Python interpreter
and you can run installed scripts without having to use their full path.
The invocation of the activation script is platform-specific
(:samp:`{<venv>}` must be replaced by the path to the directory
containing the virtual environment):

+-------------+------------+--------------------------------------------------+
| Platform    | Shell      | Command to activate virtual environment          |
+=============+============+==================================================+
| POSIX       | bash/zsh   | :samp:`$ source {<venv>}/bin/activate`           |
|             +------------+--------------------------------------------------+
|             | fish       | :samp:`$ source {<venv>}/bin/activate.fish`      |
|             +------------+--------------------------------------------------+
|             | csh/tcsh   | :samp:`$ source {<venv>}/bin/activate.csh`       |
|             +------------+--------------------------------------------------+
|             | pwsh       | :samp:`$ {<venv>}/bin/Activate.ps1`              |
+-------------+------------+--------------------------------------------------+
| Windows     | cmd.exe    | :samp:`C:\\> {<venv>}\\Scripts\\activate.bat`    |
|             +------------+--------------------------------------------------+
|             | PowerShell | :samp:`PS C:\\> {<venv>}\\Scripts\\Activate.ps1` |
+-------------+------------+--------------------------------------------------+

.. versionadded:: 3.4
   :program:`fish` and :program:`csh` activation scripts.

.. versionadded:: 3.8
   PowerShell activation scripts installed under POSIX for PowerShell Core
   support.

You don't specifically *need* to activate a virtual environment,
as you can just specify the full path to that environment's
Python interpreter when invoking Python.
Furthermore, all scripts installed in the environment
should be runnable without activating it.

In order to achieve this, scripts installed into virtual environments have
a "shebang" line which points to the environment's Python interpreter,
:samp:`#!/{<path-to-venv>}/bin/python`.
This means that the script will run with that interpreter regardless of the
value of :envvar:`PATH`. On Windows, "shebang" line processing is supported if
you have the :ref:`launcher` installed. Thus, double-clicking an installed
script in a Windows Explorer window should run it with the correct interpreter
without the environment needing to be activated or on the :envvar:`PATH`.

When a virtual environment has been activated, the :envvar:`!VIRTUAL_ENV`
environment variable is set to the path of the environment.
Since explicitly activating a virtual environment is not required to use it,
:envvar:`!VIRTUAL_ENV` cannot be relied upon to determine
whether a virtual environment is being used.

.. warning:: Because scripts installed in environments should not expect the
   environment to be activated, their shebang lines contain the absolute paths
   to their environment's interpreters. Because of this, environments are
   inherently non-portable, in the general case. You should always have a
   simple means of recreating an environment (for example, if you have a
   requirements file ``requirements.txt``, you can invoke ``pip install -r
   requirements.txt`` using the environment's ``pip`` to install all of the
   packages needed by the environment). If for any reason you need to move the
   environment to a new location, you should recreate it at the desired
   location and delete the one at the old location. If you move an environment
   because you moved a parent directory of it, you should recreate the
   environment in its new location. Otherwise, software installed into the
   environment may not work as expected.

You can deactivate a virtual environment by typing ``deactivate`` in your shell.
The exact mechanism is platform-specific and is an internal implementation
detail (typically, a script or shell function will be used).


.. _venv-api:

API
---

.. highlight:: python

The high-level method described above makes use of a simple API which provides
mechanisms for third-party virtual environment creators to customize environment
creation according to their needs, the :class:`EnvBuilder` class.

.. class:: EnvBuilder(system_site_packages=False, clear=False, \
                      symlinks=False, upgrade=False, with_pip=False, \
                      prompt=None, upgrade_deps=False, \
                      *, scm_ignore_files=frozenset())

    The :class:`EnvBuilder` class accepts the following keyword arguments on
    instantiation:

    * *system_site_packages* -- a boolean value indicating that the system Python
      site-packages should be available to the environment (defaults to ``False``).

    * *clear* -- a boolean value which, if true, will delete the contents of
      any existing target directory, before creating the environment.

    * *symlinks* -- a boolean value indicating whether to attempt to symlink the
      Python binary rather than copying.

    * *upgrade* -- a boolean value which, if true, will upgrade an existing
      environment with the running Python - for use when that Python has been
      upgraded in-place (defaults to ``False``).

    * *with_pip* -- a boolean value which, if true, ensures pip is
      installed in the virtual environment. This uses :mod:`ensurepip` with
      the ``--default-pip`` option.

    * *prompt* -- a string to be used after virtual environment is activated
      (defaults to ``None`` which means directory name of the environment would
      be used). If the special string ``"."`` is provided, the basename of the
      current directory is used as the prompt.

    * *upgrade_deps* -- Update the base venv modules to the latest on PyPI

    * *scm_ignore_files* -- Create ignore files based for the specified source
      control managers (SCM) in the iterable. Support is defined by having a
      method named ``create_{scm}_ignore_file``. The only value supported by
      default is ``"git"`` via :meth:`create_git_ignore_file`.


    .. versionchanged:: 3.4
       Added the ``with_pip`` parameter

    .. versionchanged:: 3.6
       Added the ``prompt`` parameter

    .. versionchanged:: 3.9
       Added the ``upgrade_deps`` parameter

    .. versionchanged:: 3.13
       Added the ``scm_ignore_files`` parameter

    :class:`EnvBuilder` may be used as a base class.

    .. method:: create(env_dir)

        Create a virtual environment by specifying the target directory
        (absolute or relative to the current directory) which is to contain the
        virtual environment.  The ``create`` method will either create the
        environment in the specified directory, or raise an appropriate
        exception.

        The ``create`` method of the :class:`EnvBuilder` class illustrates the
        hooks available for subclass customization::

            def create(self, env_dir):
                """
                Create a virtualized Python environment in a directory.
                env_dir is the target directory to create an environment in.
                """
                env_dir = os.path.abspath(env_dir)
                context = self.ensure_directories(env_dir)
                self.create_configuration(context)
                self.setup_python(context)
                self.setup_scripts(context)
                self.post_setup(context)

        Each of the methods :meth:`ensure_directories`,
        :meth:`create_configuration`, :meth:`setup_python`,
        :meth:`setup_scripts` and :meth:`post_setup` can be overridden.

    .. method:: ensure_directories(env_dir)

        Creates the environment directory and all necessary subdirectories that
        don't already exist, and returns a context object.  This context object
        is just a holder for attributes (such as paths) for use by the other
        methods.  If the :class:`EnvBuilder` is created with the arg
        ``clear=True``, contents of the environment directory will be cleared
        and then all necessary subdirectories will be recreated.

        The returned context object is a :class:`types.SimpleNamespace` with the
        following attributes:

        * ``env_dir`` - The location of the virtual environment. Used for
          ``__VENV_DIR__`` in activation scripts (see :meth:`install_scripts`).

        * ``env_name`` - The name of the virtual environment. Used for
          ``__VENV_NAME__`` in activation scripts (see :meth:`install_scripts`).

        * ``prompt`` - The prompt to be used by the activation scripts. Used for
          ``__VENV_PROMPT__`` in activation scripts (see :meth:`install_scripts`).

        * ``executable`` - The underlying Python executable used by the virtual
          environment. This takes into account the case where a virtual environment
          is created from another virtual environment.

        * ``inc_path`` - The include path for the virtual environment.

        * ``lib_path`` - The purelib path for the virtual environment.

        * ``bin_path`` - The script path for the virtual environment.

        * ``bin_name`` - The name of the script path relative to the virtual
          environment location. Used for ``__VENV_BIN_NAME__`` in activation
          scripts (see :meth:`install_scripts`).

        * ``env_exe`` - The name of the Python interpreter in the virtual
          environment. Used for ``__VENV_PYTHON__`` in activation scripts
          (see :meth:`install_scripts`).

        * ``env_exec_cmd`` - The name of the Python interpreter, taking into
          account filesystem redirections. This can be used to run Python in
          the virtual environment.


        .. versionchanged:: 3.11
           The *venv*
           :ref:`sysconfig installation scheme <installation_paths>`
           is used to construct the paths of the created directories.

        .. versionchanged:: 3.12
           The attribute ``lib_path`` was added to the context, and the context
           object was documented.

    .. method:: create_configuration(context)

        Creates the ``pyvenv.cfg`` configuration file in the environment.

    .. method:: setup_python(context)

        Creates a copy or symlink to the Python executable in the environment.
        On POSIX systems, if a specific executable ``python3.x`` was used,
        symlinks to ``python`` and ``python3`` will be created pointing to that
        executable, unless files with those names already exist.

    .. method:: setup_scripts(context)

        Installs activation scripts appropriate to the platform into the virtual
        environment.

    .. method:: upgrade_dependencies(context)

       Upgrades the core venv dependency packages (currently :pypi:`pip`)
       in the environment. This is done by shelling out to the
       ``pip`` executable in the environment.

       .. versionadded:: 3.9
       .. versionchanged:: 3.12

          :pypi:`setuptools` is no longer a core venv dependency.

    .. method:: post_setup(context)

        A placeholder method which can be overridden in third party
        implementations to pre-install packages in the virtual environment or
        perform other post-creation steps.

    .. method:: install_scripts(context, path)

        This method can be
        called from :meth:`setup_scripts` or :meth:`post_setup` in subclasses to
        assist in installing custom scripts into the virtual environment.

        *path* is the path to a directory that should contain subdirectories
        ``common``, ``posix``, ``nt``; each containing scripts destined for the
        ``bin`` directory in the environment.  The contents of ``common`` and the
        directory corresponding to :data:`os.name` are copied after some text
        replacement of placeholders:

        * ``__VENV_DIR__`` is replaced with the absolute path of the environment
          directory.

        * ``__VENV_NAME__`` is replaced with the environment name (final path
          segment of environment directory).

        * ``__VENV_PROMPT__`` is replaced with the prompt (the environment
          name surrounded by parentheses and with a following space)

        * ``__VENV_BIN_NAME__`` is replaced with the name of the bin directory
          (either ``bin`` or ``Scripts``).

        * ``__VENV_PYTHON__`` is replaced with the absolute path of the
          environment's executable.

        The directories are allowed to exist (for when an existing environment
        is being upgraded).

    .. method:: create_git_ignore_file(context)

       Creates a ``.gitignore`` file within the virtual environment that causes
       the entire directory to be ignored by the Git source control manager.

       .. versionadded:: 3.13

    .. versionchanged:: 3.7.2
       Windows now uses redirector scripts for ``python[w].exe`` instead of
       copying the actual binaries. In 3.7.2 only :meth:`setup_python` does
       nothing unless running from a build in the source tree.

    .. versionchanged:: 3.7.3
       Windows copies the redirector scripts as part of :meth:`setup_python`
       instead of :meth:`setup_scripts`. This was not the case in 3.7.2.
       When using symlinks, the original executables will be linked.

There is also a module-level convenience function:

.. function:: create(env_dir, system_site_packages=False, clear=False, \
                     symlinks=False, with_pip=False, prompt=None, \
                     upgrade_deps=False, *, scm_ignore_files=frozenset())

    Create an :class:`EnvBuilder` with the given keyword arguments, and call its
    :meth:`~EnvBuilder.create` method with the *env_dir* argument.

    .. versionadded:: 3.3

    .. versionchanged:: 3.4
       Added the *with_pip* parameter

    .. versionchanged:: 3.6
       Added the *prompt* parameter

    .. versionchanged:: 3.9
       Added the *upgrade_deps* parameter

    .. versionchanged:: 3.13
       Added the *scm_ignore_files* parameter

An example of extending ``EnvBuilder``
--------------------------------------

The following script shows how to extend :class:`EnvBuilder` by implementing a
subclass which installs setuptools and pip into a created virtual environment::

    import os
    import os.path
    from subprocess import Popen, PIPE
    import sys
    from threading import Thread
    from urllib.parse import urlparse
    from urllib.request import urlretrieve
    import venv

    class ExtendedEnvBuilder(venv.EnvBuilder):
        """
        This builder installs setuptools and pip so that you can pip or
        easy_install other packages into the created virtual environment.

        :param nodist: If true, setuptools and pip are not installed into the
                       created virtual environment.
        :param nopip: If true, pip is not installed into the created
                      virtual environment.
        :param progress: If setuptools or pip are installed, the progress of the
                         installation can be monitored by passing a progress
                         callable. If specified, it is called with two
                         arguments: a string indicating some progress, and a
                         context indicating where the string is coming from.
                         The context argument can have one of three values:
                         'main', indicating that it is called from virtualize()
                         itself, and 'stdout' and 'stderr', which are obtained
                         by reading lines from the output streams of a subprocess
                         which is used to install the app.

                         If a callable is not specified, default progress
                         information is output to sys.stderr.
        """

        def __init__(self, *args, **kwargs):
            self.nodist = kwargs.pop('nodist', False)
            self.nopip = kwargs.pop('nopip', False)
            self.progress = kwargs.pop('progress', None)
            self.verbose = kwargs.pop('verbose', False)
            super().__init__(*args, **kwargs)

        def post_setup(self, context):
            """
            Set up any packages which need to be pre-installed into the
            virtual environment being created.

            :param context: The information for the virtual environment
                            creation request being processed.
            """
            os.environ['VIRTUAL_ENV'] = context.env_dir
            if not self.nodist:
                self.install_setuptools(context)
            # Can't install pip without setuptools
            if not self.nopip and not self.nodist:
                self.install_pip(context)

        def reader(self, stream, context):
            """
            Read lines from a subprocess' output stream and either pass to a progress
            callable (if specified) or write progress information to sys.stderr.
            """
            progress = self.progress
            while True:
                s = stream.readline()
                if not s:
                    break
                if progress is not None:
                    progress(s, context)
                else:
                    if not self.verbose:
                        sys.stderr.write('.')
                    else:
                        sys.stderr.write(s.decode('utf-8'))
                    sys.stderr.flush()
            stream.close()

        def install_script(self, context, name, url):
            _, _, path, _, _, _ = urlparse(url)
            fn = os.path.split(path)[-1]
            binpath = context.bin_path
            distpath = os.path.join(binpath, fn)
            # Download script into the virtual environment's binaries folder
            urlretrieve(url, distpath)
            progress = self.progress
            if self.verbose:
                term = '\n'
            else:
                term = ''
            if progress is not None:
                progress('Installing %s ...%s' % (name, term), 'main')
            else:
                sys.stderr.write('Installing %s ...%s' % (name, term))
                sys.stderr.flush()
            # Install in the virtual environment
            args = [context.env_exe, fn]
            p = Popen(args, stdout=PIPE, stderr=PIPE, cwd=binpath)
            t1 = Thread(target=self.reader, args=(p.stdout, 'stdout'))
            t1.start()
            t2 = Thread(target=self.reader, args=(p.stderr, 'stderr'))
            t2.start()
            p.wait()
            t1.join()
            t2.join()
            if progress is not None:
                progress('done.', 'main')
            else:
                sys.stderr.write('done.\n')
            # Clean up - no longer needed
            os.unlink(distpath)

        def install_setuptools(self, context):
            """
            Install setuptools in the virtual environment.

            :param context: The information for the virtual environment
                            creation request being processed.
            """
            url = "https://bootstrap.pypa.io/ez_setup.py"
            self.install_script(context, 'setuptools', url)
            # clear up the setuptools archive which gets downloaded
            pred = lambda o: o.startswith('setuptools-') and o.endswith('.tar.gz')
            files = filter(pred, os.listdir(context.bin_path))
            for f in files:
                f = os.path.join(context.bin_path, f)
                os.unlink(f)

        def install_pip(self, context):
            """
            Install pip in the virtual environment.

            :param context: The information for the virtual environment
                            creation request being processed.
            """
            url = 'https://bootstrap.pypa.io/get-pip.py'
            self.install_script(context, 'pip', url)


    def main(args=None):
        import argparse

        parser = argparse.ArgumentParser(prog=__name__,
                                         description='Creates virtual Python '
                                                     'environments in one or '
                                                     'more target '
                                                     'directories.')
        parser.add_argument('dirs', metavar='ENV_DIR', nargs='+',
                            help='A directory in which to create the '
                                 'virtual environment.')
        parser.add_argument('--no-setuptools', default=False,
                            action='store_true', dest='nodist',
                            help="Don't install setuptools or pip in the "
                                 "virtual environment.")
        parser.add_argument('--no-pip', default=False,
                            action='store_true', dest='nopip',
                            help="Don't install pip in the virtual "
                                 "environment.")
        parser.add_argument('--system-site-packages', default=False,
                            action='store_true', dest='system_site',
                            help='Give the virtual environment access to the '
                                 'system site-packages dir.')
        if os.name == 'nt':
            use_symlinks = False
        else:
            use_symlinks = True
        parser.add_argument('--symlinks', default=use_symlinks,
                            action='store_true', dest='symlinks',
                            help='Try to use symlinks rather than copies, '
                                 'when symlinks are not the default for '
                                 'the platform.')
        parser.add_argument('--clear', default=False, action='store_true',
                            dest='clear', help='Delete the contents of the '
                                               'virtual environment '
                                               'directory if it already '
                                               'exists, before virtual '
                                               'environment creation.')
        parser.add_argument('--upgrade', default=False, action='store_true',
                            dest='upgrade', help='Upgrade the virtual '
                                                 'environment directory to '
                                                 'use this version of '
                                                 'Python, assuming Python '
                                                 'has been upgraded '
                                                 'in-place.')
        parser.add_argument('--verbose', default=False, action='store_true',
                            dest='verbose', help='Display the output '
                                                 'from the scripts which '
                                                 'install setuptools and pip.')
        options = parser.parse_args(args)
        if options.upgrade and options.clear:
            raise ValueError('you cannot supply --upgrade and --clear together.')
        builder = ExtendedEnvBuilder(system_site_packages=options.system_site,
                                       clear=options.clear,
                                       symlinks=options.symlinks,
                                       upgrade=options.upgrade,
                                       nodist=options.nodist,
                                       nopip=options.nopip,
                                       verbose=options.verbose)
        for d in options.dirs:
            builder.create(d)

    if __name__ == '__main__':
        rc = 1
        try:
            main()
            rc = 0
        except Exception as e:
            print('Error: %s' % e, file=sys.stderr)
        sys.exit(rc)


This script is also available for download `online
<https://gist.github.com/vsajip/4673395>`_.


================================================
File: /Doc/library/warnings.rst
================================================
:mod:`!warnings` --- Warning control
====================================

.. module:: warnings
   :synopsis: Issue warning messages and control their disposition.

**Source code:** :source:`Lib/warnings.py`

.. index:: single: warnings

--------------

Warning messages are typically issued in situations where it is useful to alert
the user of some condition in a program, where that condition (normally) doesn't
warrant raising an exception and terminating the program.  For example, one
might want to issue a warning when a program uses an obsolete module.

Python programmers issue warnings by calling the :func:`warn` function defined
in this module.  (C programmers use :c:func:`PyErr_WarnEx`; see
:ref:`exceptionhandling` for details).

Warning messages are normally written to :data:`sys.stderr`, but their disposition
can be changed flexibly, from ignoring all warnings to turning them into
exceptions.  The disposition of warnings can vary based on the :ref:`warning category
<warning-categories>`, the text of the warning message, and the source location where it
is issued.  Repetitions of a particular warning for the same source location are
typically suppressed.

There are two stages in warning control: first, each time a warning is issued, a
determination is made whether a message should be issued or not; next, if a
message is to be issued, it is formatted and printed using a user-settable hook.

The determination whether to issue a warning message is controlled by the
:ref:`warning filter <warning-filter>`, which is a sequence of matching rules and actions. Rules can be
added to the filter by calling :func:`filterwarnings` and reset to its default
state by calling :func:`resetwarnings`.

The printing of warning messages is done by calling :func:`showwarning`, which
may be overridden; the default implementation of this function formats the
message by calling :func:`formatwarning`, which is also available for use by
custom implementations.

.. seealso::
   :func:`logging.captureWarnings` allows you to handle all warnings with
   the standard logging infrastructure.


.. _warning-categories:

Warning Categories
------------------

There are a number of built-in exceptions that represent warning categories.
This categorization is useful to be able to filter out groups of warnings.

While these are technically
:ref:`built-in exceptions <warning-categories-as-exceptions>`, they are
documented here, because conceptually they belong to the warnings mechanism.

User code can define additional warning categories by subclassing one of the
standard warning categories.  A warning category must always be a subclass of
the :exc:`Warning` class.

The following warnings category classes are currently defined:

.. tabularcolumns:: |l|p{0.6\linewidth}|

+----------------------------------+-----------------------------------------------+
| Class                            | Description                                   |
+==================================+===============================================+
| :exc:`Warning`                   | This is the base class of all warning         |
|                                  | category classes.  It is a subclass of        |
|                                  | :exc:`Exception`.                             |
+----------------------------------+-----------------------------------------------+
| :exc:`UserWarning`               | The default category for :func:`warn`.        |
+----------------------------------+-----------------------------------------------+
| :exc:`DeprecationWarning`        | Base category for warnings about deprecated   |
|                                  | features when those warnings are intended for |
|                                  | other Python developers (ignored by default,  |
|                                  | unless triggered by code in ``__main__``).    |
+----------------------------------+-----------------------------------------------+
| :exc:`SyntaxWarning`             | Base category for warnings about dubious      |
|                                  | syntactic features.                           |
+----------------------------------+-----------------------------------------------+
| :exc:`RuntimeWarning`            | Base category for warnings about dubious      |
|                                  | runtime features.                             |
+----------------------------------+-----------------------------------------------+
| :exc:`FutureWarning`             | Base category for warnings about deprecated   |
|                                  | features when those warnings are intended for |
|                                  | end users of applications that are written in |
|                                  | Python.                                       |
+----------------------------------+-----------------------------------------------+
| :exc:`PendingDeprecationWarning` | Base category for warnings about features     |
|                                  | that will be deprecated in the future         |
|                                  | (ignored by default).                         |
+----------------------------------+-----------------------------------------------+
| :exc:`ImportWarning`             | Base category for warnings triggered during   |
|                                  | the process of importing a module (ignored by |
|                                  | default).                                     |
+----------------------------------+-----------------------------------------------+
| :exc:`UnicodeWarning`            | Base category for warnings related to         |
|                                  | Unicode.                                      |
+----------------------------------+-----------------------------------------------+
| :exc:`BytesWarning`              | Base category for warnings related to         |
|                                  | :class:`bytes` and :class:`bytearray`.        |
+----------------------------------+-----------------------------------------------+
| :exc:`ResourceWarning`           | Base category for warnings related to         |
|                                  | resource usage (ignored by default).          |
+----------------------------------+-----------------------------------------------+

.. versionchanged:: 3.7
   Previously :exc:`DeprecationWarning` and :exc:`FutureWarning` were
   distinguished based on whether a feature was being removed entirely or
   changing its behaviour. They are now distinguished based on their
   intended audience and the way they're handled by the default warnings
   filters.


.. _warning-filter:

The Warnings Filter
-------------------

The warnings filter controls whether warnings are ignored, displayed, or turned
into errors (raising an exception).

Conceptually, the warnings filter maintains an ordered list of filter
specifications; any specific warning is matched against each filter
specification in the list in turn until a match is found; the filter determines
the disposition of the match.  Each entry is a tuple of the form (*action*,
*message*, *category*, *module*, *lineno*), where:

* *action* is one of the following strings:

  +---------------+----------------------------------------------+
  | Value         | Disposition                                  |
  +===============+==============================================+
  | ``"default"`` | print the first occurrence of matching       |
  |               | warnings for each location (module +         |
  |               | line number) where the warning is issued     |
  +---------------+----------------------------------------------+
  | ``"error"``   | turn matching warnings into exceptions       |
  +---------------+----------------------------------------------+
  | ``"ignore"``  | never print matching warnings                |
  +---------------+----------------------------------------------+
  | ``"always"``  | always print matching warnings               |
  +---------------+----------------------------------------------+
  | ``"all"``     | alias to "always"                            |
  +---------------+----------------------------------------------+
  | ``"module"``  | print the first occurrence of matching       |
  |               | warnings for each module where the warning   |
  |               | is issued (regardless of line number)        |
  +---------------+----------------------------------------------+
  | ``"once"``    | print only the first occurrence of matching  |
  |               | warnings, regardless of location             |
  +---------------+----------------------------------------------+

* *message* is a string containing a regular expression that the start of
  the warning message must match, case-insensitively.  In :option:`-W` and
  :envvar:`PYTHONWARNINGS`, *message* is a literal string that the start of the
  warning message must contain (case-insensitively), ignoring any whitespace at
  the start or end of *message*.

* *category* is a class (a subclass of :exc:`Warning`) of which the warning
  category must be a subclass in order to match.

* *module* is a string containing a regular expression that the start of the
  fully qualified module name must match, case-sensitively.  In :option:`-W` and
  :envvar:`PYTHONWARNINGS`, *module* is a literal string that the
  fully qualified module name must be equal to (case-sensitively), ignoring any
  whitespace at the start or end of *module*.

* *lineno* is an integer that the line number where the warning occurred must
  match, or ``0`` to match all line numbers.

Since the :exc:`Warning` class is derived from the built-in :exc:`Exception`
class, to turn a warning into an error we simply raise ``category(message)``.

If a warning is reported and doesn't match any registered filter then the
"default" action is applied (hence its name).



.. _repeated-warning-suppression-criteria:

Repeated Warning Suppression Criteria
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

The filters that suppress repeated warnings apply the following criteria to determine if a warning is considered a repeat:

- ``"default"``: A warning is considered a repeat only if the (*message*, *category*, *module*, *lineno*) are all the same.
- ``"module"``: A warning is considered a repeat if the (*message*, *category*, *module*) are the same, ignoring the line number.
- ``"once"``: A warning is considered a repeat if the (*message*, *category*) are the same, ignoring the module and line number.


.. _describing-warning-filters:

Describing Warning Filters
~~~~~~~~~~~~~~~~~~~~~~~~~~

The warnings filter is initialized by :option:`-W` options passed to the Python
interpreter command line and the :envvar:`PYTHONWARNINGS` environment variable.
The interpreter saves the arguments for all supplied entries without
interpretation in :data:`sys.warnoptions`; the :mod:`warnings` module parses these
when it is first imported (invalid options are ignored, after printing a
message to :data:`sys.stderr`).

Individual warnings filters are specified as a sequence of fields separated by
colons::

   action:message:category:module:line

The meaning of each of these fields is as described in :ref:`warning-filter`.
When listing multiple filters on a single line (as for
:envvar:`PYTHONWARNINGS`), the individual filters are separated by commas and
the filters listed later take precedence over those listed before them (as
they're applied left-to-right, and the most recently applied filters take
precedence over earlier ones).

Commonly used warning filters apply to either all warnings, warnings in a
particular category, or warnings raised by particular modules or packages.
Some examples::

   default                      # Show all warnings (even those ignored by default)
   ignore                       # Ignore all warnings
   error                        # Convert all warnings to errors
   error::ResourceWarning       # Treat ResourceWarning messages as errors
   default::DeprecationWarning  # Show DeprecationWarning messages
   ignore,default:::mymodule    # Only report warnings triggered by "mymodule"
   error:::mymodule             # Convert warnings to errors in "mymodule"


.. _default-warning-filter:

Default Warning Filter
~~~~~~~~~~~~~~~~~~~~~~

By default, Python installs several warning filters, which can be overridden by
the :option:`-W` command-line option, the :envvar:`PYTHONWARNINGS` environment
variable and calls to :func:`filterwarnings`.

In regular release builds, the default warning filter has the following entries
(in order of precedence)::

    default::DeprecationWarning:__main__
    ignore::DeprecationWarning
    ignore::PendingDeprecationWarning
    ignore::ImportWarning
    ignore::ResourceWarning

In a :ref:`debug build <debug-build>`, the list of default warning filters is empty.

.. versionchanged:: 3.2
   :exc:`DeprecationWarning` is now ignored by default in addition to
   :exc:`PendingDeprecationWarning`.

.. versionchanged:: 3.7
  :exc:`DeprecationWarning` is once again shown by default when triggered
  directly by code in ``__main__``.

.. versionchanged:: 3.7
  :exc:`BytesWarning` no longer appears in the default filter list and is
  instead configured via :data:`sys.warnoptions` when :option:`-b` is specified
  twice.


.. _warning-disable:

Overriding the default filter
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Developers of applications written in Python may wish to hide *all* Python level
warnings from their users by default, and only display them when running tests
or otherwise working on the application. The :data:`sys.warnoptions` attribute
used to pass filter configurations to the interpreter can be used as a marker to
indicate whether or not warnings should be disabled::

    import sys

    if not sys.warnoptions:
        import warnings
        warnings.simplefilter("ignore")

Developers of test runners for Python code are advised to instead ensure that
*all* warnings are displayed by default for the code under test, using code
like::

    import sys

    if not sys.warnoptions:
        import os, warnings
        warnings.simplefilter("default") # Change the filter in this process
        os.environ["PYTHONWARNINGS"] = "default" # Also affect subprocesses

Finally, developers of interactive shells that run user code in a namespace
other than ``__main__`` are advised to ensure that :exc:`DeprecationWarning`
messages are made visible by default, using code like the following (where
``user_ns`` is the module used to execute code entered interactively)::

    import warnings
    warnings.filterwarnings("default", category=DeprecationWarning,
                                       module=user_ns.get("__name__"))


.. _warning-suppress:

Temporarily Suppressing Warnings
--------------------------------

If you are using code that you know will raise a warning, such as a deprecated
function, but do not want to see the warning (even when warnings have been
explicitly configured via the command line), then it is possible to suppress
the warning using the :class:`catch_warnings` context manager::

    import warnings

    def fxn():
        warnings.warn("deprecated", DeprecationWarning)

    with warnings.catch_warnings():
        warnings.simplefilter("ignore")
        fxn()

While within the context manager all warnings will simply be ignored. This
allows you to use known-deprecated code without having to see the warning while
not suppressing the warning for other code that might not be aware of its use
of deprecated code.  Note: this can only be guaranteed in a single-threaded
application. If two or more threads use the :class:`catch_warnings` context
manager at the same time, the behavior is undefined.



.. _warning-testing:

Testing Warnings
----------------

To test warnings raised by code, use the :class:`catch_warnings` context
manager. With it you can temporarily mutate the warnings filter to facilitate
your testing. For instance, do the following to capture all raised warnings to
check::

    import warnings

    def fxn():
        warnings.warn("deprecated", DeprecationWarning)

    with warnings.catch_warnings(record=True) as w:
        # Cause all warnings to always be triggered.
        warnings.simplefilter("always")
        # Trigger a warning.
        fxn()
        # Verify some things
        assert len(w) == 1
        assert issubclass(w[-1].category, DeprecationWarning)
        assert "deprecated" in str(w[-1].message)

One can also cause all warnings to be exceptions by using ``error`` instead of
``always``. One thing to be aware of is that if a warning has already been
raised because of a ``once``/``default`` rule, then no matter what filters are
set the warning will not be seen again unless the warnings registry related to
the warning has been cleared.

Once the context manager exits, the warnings filter is restored to its state
when the context was entered. This prevents tests from changing the warnings
filter in unexpected ways between tests and leading to indeterminate test
results. The :func:`showwarning` function in the module is also restored to
its original value.  Note: this can only be guaranteed in a single-threaded
application. If two or more threads use the :class:`catch_warnings` context
manager at the same time, the behavior is undefined.

When testing multiple operations that raise the same kind of warning, it
is important to test them in a manner that confirms each operation is raising
a new warning (e.g. set warnings to be raised as exceptions and check the
operations raise exceptions, check that the length of the warning list
continues to increase after each operation, or else delete the previous
entries from the warnings list before each new operation).


.. _warning-ignored:

Updating Code For New Versions of Dependencies
----------------------------------------------

Warning categories that are primarily of interest to Python developers (rather
than end users of applications written in Python) are ignored by default.

Notably, this "ignored by default" list includes :exc:`DeprecationWarning`
(for every module except ``__main__``), which means developers should make sure
to test their code with typically ignored warnings made visible in order to
receive timely notifications of future breaking API changes (whether in the
standard library or third party packages).

In the ideal case, the code will have a suitable test suite, and the test runner
will take care of implicitly enabling all warnings when running tests
(the test runner provided by the :mod:`unittest` module does this).

In less ideal cases, applications can be checked for use of deprecated
interfaces by passing :option:`-Wd <-W>` to the Python interpreter (this is
shorthand for :option:`!-W default`) or setting ``PYTHONWARNINGS=default`` in
the environment. This enables default handling for all warnings, including those
that are ignored by default. To change what action is taken for encountered
warnings you can change what argument is passed to :option:`-W` (e.g.
:option:`!-W error`). See the :option:`-W` flag for more details on what is
possible.


.. _warning-functions:

Available Functions
-------------------


.. function:: warn(message, category=None, stacklevel=1, source=None, *, skip_file_prefixes=())

   Issue a warning, or maybe ignore it or raise an exception.  The *category*
   argument, if given, must be a :ref:`warning category class <warning-categories>`; it
   defaults to :exc:`UserWarning`.  Alternatively, *message* can be a :exc:`Warning` instance,
   in which case *category* will be ignored and ``message.__class__`` will be used.
   In this case, the message text will be ``str(message)``. This function raises an
   exception if the particular warning issued is changed into an error by the
   :ref:`warnings filter <warning-filter>`.  The *stacklevel* argument can be used by wrapper
   functions written in Python, like this::

      def deprecated_api(message):
          warnings.warn(message, DeprecationWarning, stacklevel=2)

   This makes the warning refer to ``deprecated_api``'s caller, rather than to
   the source of ``deprecated_api`` itself (since the latter would defeat the
   purpose of the warning message).

   The *skip_file_prefixes* keyword argument can be used to indicate which
   stack frames are ignored when counting stack levels. This can be useful when
   you want the warning to always appear at call sites outside of a package
   when a constant *stacklevel* does not fit all call paths or is otherwise
   challenging to maintain. If supplied, it must be a tuple of strings. When
   prefixes are supplied, stacklevel is implicitly overridden to be ``max(2,
   stacklevel)``. To cause a warning to be attributed to the caller from
   outside of the current package you might write::

      # example/lower.py
      _warn_skips = (os.path.dirname(__file__),)

      def one_way(r_luxury_yacht=None, t_wobbler_mangrove=None):
          if r_luxury_yacht:
              warnings.warn("Please migrate to t_wobbler_mangrove=.",
                            skip_file_prefixes=_warn_skips)

      # example/higher.py
      from . import lower

      def another_way(**kw):
          lower.one_way(**kw)

   This makes the warning refer to both the ``example.lower.one_way()`` and
   ``package.higher.another_way()`` call sites only from calling code living
   outside of ``example`` package.

   *source*, if supplied, is the destroyed object which emitted a
   :exc:`ResourceWarning`.

   .. versionchanged:: 3.6
      Added *source* parameter.

   .. versionchanged:: 3.12
      Added *skip_file_prefixes*.
