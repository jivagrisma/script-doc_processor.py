^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

``__main__`` is the name of the environment where top-level code is run.
"Top-level code" is the first user-specified Python module that starts running.
It's "top-level" because it imports all other modules that the program needs.
Sometimes "top-level code" is called an *entry point* to the application.

The top-level code environment can be:

* the scope of an interactive prompt::

   >>> __name__
   '__main__'

* the Python module passed to the Python interpreter as a file argument:

  .. code-block:: shell-session

     $ python helloworld.py
     Hello, world!

* the Python module or package passed to the Python interpreter with the
  :option:`-m` argument:

  .. code-block:: shell-session

     $ python -m tarfile
     usage: tarfile.py [-h] [-v] (...)

* Python code read by the Python interpreter from standard input:

  .. code-block:: shell-session

     $ echo "import this" | python
     The Zen of Python, by Tim Peters

     Beautiful is better than ugly.
     Explicit is better than implicit.
     ...

* Python code passed to the Python interpreter with the :option:`-c` argument:

  .. code-block:: shell-session

     $ python -c "import this"
     The Zen of Python, by Tim Peters

     Beautiful is better than ugly.
     Explicit is better than implicit.
     ...

In each of these situations, the top-level module's ``__name__`` is set to
``'__main__'``.

As a result, a module can discover whether or not it is running in the
top-level environment by checking its own ``__name__``, which allows a common
idiom for conditionally executing code when the module is not initialized from
an import statement::

   if __name__ == '__main__':
       # Execute when the module is not initialized from an import statement.
       ...

.. seealso::

   For a more detailed look at how ``__name__`` is set in all situations, see
   the tutorial section :ref:`tut-modules`.


Idiomatic Usage
^^^^^^^^^^^^^^^

Some modules contain code that is intended for script use only, like parsing
command-line arguments or fetching data from standard input.  If a module
like this was imported from a different module, for example to unit test
it, the script code would unintentionally execute as well.

This is where using the ``if __name__ == '__main__'`` code block comes in
handy. Code within this block won't run unless the module is executed in the
top-level environment.

Putting as few statements as possible in the block below ``if __name__ ==
'__main__'`` can improve code clarity and correctness. Most often, a function
named ``main`` encapsulates the program's primary behavior::

    # echo.py

    import shlex
    import sys

    def echo(phrase: str) -> None:
       """A dummy wrapper around print."""
       # for demonstration purposes, you can imagine that there is some
       # valuable and reusable logic inside this function
       print(phrase)

    def main() -> int:
        """Echo the input arguments to standard output"""
        phrase = shlex.join(sys.argv)
        echo(phrase)
        return 0

    if __name__ == '__main__':
        sys.exit(main())  # next section explains the use of sys.exit

Note that if the module didn't encapsulate code inside the ``main`` function
but instead put it directly within the ``if __name__ == '__main__'`` block,
the ``phrase`` variable would be global to the entire module.  This is
error-prone as other functions within the module could be unintentionally using
the global variable instead of a local name.  A ``main`` function solves this
problem.

Using a ``main`` function has the added benefit of the ``echo`` function itself
being isolated and importable elsewhere. When ``echo.py`` is imported, the
``echo`` and ``main`` functions will be defined, but neither of them will be
called, because ``__name__ != '__main__'``.


Packaging Considerations
^^^^^^^^^^^^^^^^^^^^^^^^

``main`` functions are often used to create command-line tools by specifying
them as entry points for console scripts.  When this is done,
`pip <https://pip.pypa.io/>`_ inserts the function call into a template script,
where the return value of ``main`` is passed into :func:`sys.exit`.
For example::

    sys.exit(main())

Since the call to ``main`` is wrapped in :func:`sys.exit`, the expectation is
that your function will return some value acceptable as an input to
:func:`sys.exit`; typically, an integer or ``None`` (which is implicitly
returned if your function does not have a return statement).

By proactively following this convention ourselves, our module will have the
same behavior when run directly (i.e. ``python echo.py``) as it will have if
we later package it as a console script entry-point in a pip-installable
package.

In particular, be careful about returning strings from your ``main`` function.
:func:`sys.exit` will interpret a string argument as a failure message, so
your program will have an exit code of ``1``, indicating failure, and the
string will be written to :data:`sys.stderr`.  The ``echo.py`` example from
earlier exemplifies using the ``sys.exit(main())`` convention.

.. seealso::

   `Python Packaging User Guide <https://packaging.python.org/>`_
   contains a collection of tutorials and references on how to distribute and
   install Python packages with modern tools.


``__main__.py`` in Python Packages
----------------------------------

If you are not familiar with Python packages, see section :ref:`tut-packages`
of the tutorial.  Most commonly, the ``__main__.py`` file is used to provide
a command-line interface for a package. Consider the following hypothetical
package, "bandclass":

.. code-block:: text

   bandclass
     ├── __init__.py
     ├── __main__.py
     └── student.py

``__main__.py`` will be executed when the package itself is invoked
directly from the command line using the :option:`-m` flag. For example:

.. code-block:: shell-session

   $ python -m bandclass

This command will cause ``__main__.py`` to run. How you utilize this mechanism
will depend on the nature of the package you are writing, but in this
hypothetical case, it might make sense to allow the teacher to search for
students::

    # bandclass/__main__.py

    import sys
    from .student import search_students

    student_name = sys.argv[1] if len(sys.argv) >= 2 else ''
    print(f'Found student: {search_students(student_name)}')

Note that ``from .student import search_students`` is an example of a relative
import.  This import style can be used when referencing modules within a
package.  For more details, see :ref:`intra-package-references` in the
:ref:`tut-modules` section of the tutorial.

Idiomatic Usage
^^^^^^^^^^^^^^^

The content of ``__main__.py`` typically isn't fenced with an
``if __name__ == '__main__'`` block.  Instead, those files are kept
short and import functions to execute from other modules.  Those other modules can then be
easily unit-tested and are properly reusable.

If used, an ``if __name__ == '__main__'`` block will still work as expected
for a ``__main__.py`` file within a package, because its ``__name__``
attribute will include the package's path if imported::

    >>> import asyncio.__main__
    >>> asyncio.__main__.__name__
    'asyncio.__main__'

This won't work for ``__main__.py`` files in the root directory of a
``.zip`` file though.  Hence, for consistency, a minimal ``__main__.py``
without a ``__name__`` check is preferred.

.. seealso::

   See :mod:`venv` for an example of a package with a minimal ``__main__.py``
   in the standard library. It doesn't contain a ``if __name__ == '__main__'``
   block. You can invoke it with ``python -m venv [directory]``.

   See :mod:`runpy` for more details on the :option:`-m` flag to the
   interpreter executable.

   See :mod:`zipapp` for how to run applications packaged as *.zip* files. In
   this case Python looks for a ``__main__.py`` file in the root directory of
   the archive.



``import __main__``
-------------------

Regardless of which module a Python program was started with, other modules
running within that same program can import the top-level environment's scope
(:term:`namespace`) by importing the ``__main__`` module.  This doesn't import
a ``__main__.py`` file but rather whichever module that received the special
name ``'__main__'``.

Here is an example module that consumes the ``__main__`` namespace::

    # namely.py

    import __main__

    def did_user_define_their_name():
        return 'my_name' in dir(__main__)

    def print_user_name():
        if not did_user_define_their_name():
            raise ValueError('Define the variable `my_name`!')

        if '__file__' in dir(__main__):
            print(__main__.my_name, "found in file", __main__.__file__)
        else:
            print(__main__.my_name)

Example usage of this module could be as follows::

    # start.py

    import sys

    from namely import print_user_name

    # my_name = "Dinsdale"

    def main():
        try:
            print_user_name()
        except ValueError as ve:
            return str(ve)

    if __name__ == "__main__":
        sys.exit(main())

Now, if we started our program, the result would look like this:

.. code-block:: shell-session

   $ python start.py
   Define the variable `my_name`!

The exit code of the program would be 1, indicating an error. Uncommenting the
line with ``my_name = "Dinsdale"`` fixes the program and now it exits with
status code 0, indicating success:

.. code-block:: shell-session

   $ python start.py
   Dinsdale found in file /path/to/start.py

Note that importing ``__main__`` doesn't cause any issues with unintentionally
running top-level code meant for script use which is put in the
``if __name__ == "__main__"`` block of the ``start`` module. Why does this work?

Python inserts an empty ``__main__`` module in :data:`sys.modules` at
interpreter startup, and populates it by running top-level code. In our example
this is the ``start`` module which runs line by line and imports ``namely``.
In turn, ``namely`` imports ``__main__`` (which is really ``start``). That's an
import cycle! Fortunately, since the partially populated ``__main__``
module is present in :data:`sys.modules`, Python passes that to ``namely``.
See :ref:`Special considerations for __main__ <import-dunder-main>` in the
import system's reference for details on how this works.

The Python REPL is another example of a "top-level environment", so anything
defined in the REPL becomes part of the ``__main__`` scope::

    >>> import namely
    >>> namely.did_user_define_their_name()
    False
    >>> namely.print_user_name()
    Traceback (most recent call last):
    ...
    ValueError: Define the variable `my_name`!
    >>> my_name = 'Jabberwocky'
    >>> namely.did_user_define_their_name()
    True
    >>> namely.print_user_name()
    Jabberwocky

Note that in this case the ``__main__`` scope doesn't contain a ``__file__``
attribute as it's interactive.

The ``__main__`` scope is used in the implementation of :mod:`pdb` and
:mod:`rlcompleter`.


================================================
File: /Doc/library/_thread.rst
================================================
:mod:`!_thread` --- Low-level threading API
===========================================

.. module:: _thread
   :synopsis: Low-level threading API.

.. index::
   single: light-weight processes
   single: processes, light-weight
   single: binary semaphores
   single: semaphores, binary

--------------

This module provides low-level primitives for working with multiple threads
(also called :dfn:`light-weight processes` or :dfn:`tasks`) --- multiple threads of
control sharing their global data space.  For synchronization, simple locks
(also called :dfn:`mutexes` or :dfn:`binary semaphores`) are provided.
The :mod:`threading` module provides an easier to use and higher-level
threading API built on top of this module.

.. index::
   single: pthreads
   pair: threads; POSIX

.. versionchanged:: 3.7
   This module used to be optional, it is now always available.

This module defines the following constants and functions:

.. exception:: error

   Raised on thread-specific errors.

   .. versionchanged:: 3.3
      This is now a synonym of the built-in :exc:`RuntimeError`.


.. data:: LockType

   This is the type of lock objects.


.. function:: start_new_thread(function, args[, kwargs])

   Start a new thread and return its identifier.  The thread executes the
   function *function* with the argument list *args* (which must be a tuple).
   The optional *kwargs* argument specifies a dictionary of keyword arguments.

   When the function returns, the thread silently exits.

   When the function terminates with an unhandled exception,
   :func:`sys.unraisablehook` is called to handle the exception. The *object*
   attribute of the hook argument is *function*. By default, a stack trace is
   printed and then the thread exits (but other threads continue to run).

   When the function raises a :exc:`SystemExit` exception, it is silently
   ignored.

   .. audit-event:: _thread.start_new_thread function,args,kwargs start_new_thread

   .. versionchanged:: 3.8
      :func:`sys.unraisablehook` is now used to handle unhandled exceptions.


.. function:: interrupt_main(signum=signal.SIGINT, /)

   Simulate the effect of a signal arriving in the main thread.
   A thread can use this function to interrupt the main thread, though
   there is no guarantee that the interruption will happen immediately.

   If given, *signum* is the number of the signal to simulate.
   If *signum* is not given, :const:`signal.SIGINT` is simulated.

   If the given signal isn't handled by Python (it was set to
   :const:`signal.SIG_DFL` or :const:`signal.SIG_IGN`), this function does
   nothing.

   .. versionchanged:: 3.10
      The *signum* argument is added to customize the signal number.

   .. note::
      This does not emit the corresponding signal but schedules a call to
      the associated handler (if it exists).
      If you want to truly emit the signal, use :func:`signal.raise_signal`.


.. function:: exit()

   Raise the :exc:`SystemExit` exception.  When not caught, this will cause the
   thread to exit silently.

..
   function:: exit_prog(status)

      Exit all threads and report the value of the integer argument
      *status* as the exit status of the entire program.
      **Caveat:** code in pending :keyword:`finally` clauses, in this thread
      or in other threads, is not executed.


.. function:: allocate_lock()

   Return a new lock object.  Methods of locks are described below.  The lock is
   initially unlocked.


.. function:: get_ident()

   Return the 'thread identifier' of the current thread.  This is a nonzero
   integer.  Its value has no direct meaning; it is intended as a magic cookie to
   be used e.g. to index a dictionary of thread-specific data.  Thread identifiers
   may be recycled when a thread exits and another thread is created.


.. function:: get_native_id()

   Return the native integral Thread ID of the current thread assigned by the kernel.
   This is a non-negative integer.
   Its value may be used to uniquely identify this particular thread system-wide
   (until the thread terminates, after which the value may be recycled by the OS).

   .. availability:: Windows, FreeBSD, Linux, macOS, OpenBSD, NetBSD, AIX, DragonFlyBSD, GNU/kFreeBSD.

   .. versionadded:: 3.8

   .. versionchanged:: 3.13
      Added support for GNU/kFreeBSD.


.. function:: stack_size([size])

   Return the thread stack size used when creating new threads.  The optional
   *size* argument specifies the stack size to be used for subsequently created
   threads, and must be 0 (use platform or configured default) or a positive
   integer value of at least 32,768 (32 KiB). If *size* is not specified,
   0 is used.  If changing the thread stack size is
   unsupported, a :exc:`RuntimeError` is raised.  If the specified stack size is
   invalid, a :exc:`ValueError` is raised and the stack size is unmodified.  32 KiB
   is currently the minimum supported stack size value to guarantee sufficient
   stack space for the interpreter itself.  Note that some platforms may have
   particular restrictions on values for the stack size, such as requiring a
   minimum stack size > 32 KiB or requiring allocation in multiples of the system
   memory page size - platform documentation should be referred to for more
   information (4 KiB pages are common; using multiples of 4096 for the stack size is
   the suggested approach in the absence of more specific information).

   .. availability:: Windows, pthreads.

      Unix platforms with POSIX threads support.


.. data:: TIMEOUT_MAX

   The maximum value allowed for the *timeout* parameter of
   :meth:`Lock.acquire <threading.Lock.acquire>`. Specifying a timeout greater
   than this value will raise an :exc:`OverflowError`.

   .. versionadded:: 3.2


Lock objects have the following methods:


.. method:: lock.acquire(blocking=True, timeout=-1)

   Without any optional argument, this method acquires the lock unconditionally, if
   necessary waiting until it is released by another thread (only one thread at a
   time can acquire a lock --- that's their reason for existence).

   If the *blocking* argument is present, the action depends on its
   value: if it is false, the lock is only acquired if it can be acquired
   immediately without waiting, while if it is true, the lock is acquired
   unconditionally as above.

   If the floating-point *timeout* argument is present and positive, it
   specifies the maximum wait time in seconds before returning.  A negative
   *timeout* argument specifies an unbounded wait.  You cannot specify
   a *timeout* if *blocking* is false.

   The return value is ``True`` if the lock is acquired successfully,
   ``False`` if not.

   .. versionchanged:: 3.2
      The *timeout* parameter is new.

   .. versionchanged:: 3.2
      Lock acquires can now be interrupted by signals on POSIX.

   .. versionchanged:: 3.14
      Lock acquires can now be interrupted by signals on Windows.


.. method:: lock.release()

   Releases the lock.  The lock must have been acquired earlier, but not
   necessarily by the same thread.


.. method:: lock.locked()

   Return the status of the lock: ``True`` if it has been acquired by some thread,
   ``False`` if not.

In addition to these methods, lock objects can also be used via the
:keyword:`with` statement, e.g.::

   import _thread

   a_lock = _thread.allocate_lock()

   with a_lock:
       print("a_lock is locked while this executes")

**Caveats:**

.. index:: pair: module; signal

* Interrupts always go to the main thread (the :exc:`KeyboardInterrupt`
  exception will be received by that thread.)

* Calling :func:`sys.exit` or raising the :exc:`SystemExit` exception is
  equivalent to calling :func:`_thread.exit`.

* When the main thread exits, it is system defined whether the other threads
  survive.  On most systems, they are killed without executing
  :keyword:`try` ... :keyword:`finally` clauses or executing object
  destructors.



================================================
File: /Doc/library/abc.rst
================================================
:mod:`!abc` --- Abstract Base Classes
=====================================

.. module:: abc
   :synopsis: Abstract base classes according to :pep:`3119`.

.. moduleauthor:: Guido van Rossum
.. sectionauthor:: Georg Brandl
.. much of the content adapted from docstrings

**Source code:** :source:`Lib/abc.py`

--------------

This module provides the infrastructure for defining :term:`abstract base
classes <abstract base class>` (ABCs) in Python, as outlined in :pep:`3119`;
see the PEP for why this was added to Python. (See also :pep:`3141` and the
:mod:`numbers` module regarding a type hierarchy for numbers based on ABCs.)

The :mod:`collections` module has some concrete classes that derive from
ABCs; these can, of course, be further derived. In addition, the
:mod:`collections.abc` submodule has some ABCs that can be used to test whether
a class or instance provides a particular interface, for example, if it is
:term:`hashable` or if it is a :term:`mapping`.


This module provides the metaclass :class:`ABCMeta` for defining ABCs and
a helper class :class:`ABC` to alternatively define ABCs through inheritance:

.. class:: ABC

   A helper class that has :class:`ABCMeta` as its metaclass.  With this class,
   an abstract base class can be created by simply deriving from :class:`!ABC`
   avoiding sometimes confusing metaclass usage, for example::

     from abc import ABC

     class MyABC(ABC):
         pass

   Note that the type of :class:`!ABC` is still :class:`ABCMeta`, therefore
   inheriting from :class:`!ABC` requires the usual precautions regarding
   metaclass usage, as multiple inheritance may lead to metaclass conflicts.
   One may also define an abstract base class by passing the metaclass
   keyword and using :class:`!ABCMeta` directly, for example::

     from abc import ABCMeta

     class MyABC(metaclass=ABCMeta):
         pass

   .. versionadded:: 3.4


.. class:: ABCMeta

   Metaclass for defining Abstract Base Classes (ABCs).

   Use this metaclass to create an ABC.  An ABC can be subclassed directly, and
   then acts as a mix-in class.  You can also register unrelated concrete
   classes (even built-in classes) and unrelated ABCs as "virtual subclasses" --
   these and their descendants will be considered subclasses of the registering
   ABC by the built-in :func:`issubclass` function, but the registering ABC
   won't show up in their MRO (Method Resolution Order) nor will method
   implementations defined by the registering ABC be callable (not even via
   :func:`super`). [#]_

   Classes created with a metaclass of :class:`!ABCMeta` have the following method:

   .. method:: register(subclass)

      Register *subclass* as a "virtual subclass" of this ABC. For
      example::

         from abc import ABC

         class MyABC(ABC):
             pass

         MyABC.register(tuple)

         assert issubclass(tuple, MyABC)
         assert isinstance((), MyABC)

      .. versionchanged:: 3.3
         Returns the registered subclass, to allow usage as a class decorator.

      .. versionchanged:: 3.4
         To detect calls to :meth:`!register`, you can use the
         :func:`get_cache_token` function.

   You can also override this method in an abstract base class:

   .. method:: __subclasshook__(subclass)

      (Must be defined as a class method.)

      Check whether *subclass* is considered a subclass of this ABC.  This means
      that you can customize the behavior of :func:`issubclass` further without the
      need to call :meth:`register` on every class you want to consider a
      subclass of the ABC.  (This class method is called from the
      :meth:`~type.__subclasscheck__` method of the ABC.)

      This method should return ``True``, ``False`` or :data:`NotImplemented`.  If
      it returns ``True``, the *subclass* is considered a subclass of this ABC.
      If it returns ``False``, the *subclass* is not considered a subclass of
      this ABC, even if it would normally be one.  If it returns
      :data:`!NotImplemented`, the subclass check is continued with the usual
      mechanism.

      .. XXX explain the "usual mechanism"


   For a demonstration of these concepts, look at this example ABC definition::

      class Foo:
          def __getitem__(self, index):
              ...
          def __len__(self):
              ...
          def get_iterator(self):
              return iter(self)

      class MyIterable(ABC):

          @abstractmethod
          def __iter__(self):
              while False:
                  yield None

          def get_iterator(self):
              return self.__iter__()

          @classmethod
          def __subclasshook__(cls, C):
              if cls is MyIterable:
                  if any("__iter__" in B.__dict__ for B in C.__mro__):
                      return True
              return NotImplemented

      MyIterable.register(Foo)

   The ABC ``MyIterable`` defines the standard iterable method,
   :meth:`~iterator.__iter__`, as an abstract method.  The implementation given
   here can still be called from subclasses.  The :meth:`!get_iterator` method
   is also part of the ``MyIterable`` abstract base class, but it does not have
   to be overridden in non-abstract derived classes.

   The :meth:`__subclasshook__` class method defined here says that any class
   that has an :meth:`~iterator.__iter__` method in its
   :attr:`~object.__dict__` (or in that of one of its base classes, accessed
   via the :attr:`~type.__mro__` list) is considered a ``MyIterable`` too.

   Finally, the last line makes ``Foo`` a virtual subclass of ``MyIterable``,
   even though it does not define an :meth:`~iterator.__iter__` method (it uses
   the old-style iterable protocol, defined in terms of :meth:`~object.__len__` and
   :meth:`~object.__getitem__`).  Note that this will not make ``get_iterator``
   available as a method of ``Foo``, so it is provided separately.




The :mod:`!abc` module also provides the following decorator:

.. decorator:: abstractmethod

   A decorator indicating abstract methods.

   Using this decorator requires that the class's metaclass is :class:`ABCMeta`
   or is derived from it.  A class that has a metaclass derived from
   :class:`!ABCMeta` cannot be instantiated unless all of its abstract methods
   and properties are overridden.  The abstract methods can be called using any
   of the normal 'super' call mechanisms.  :func:`!abstractmethod` may be used
   to declare abstract methods for properties and descriptors.

   Dynamically adding abstract methods to a class, or attempting to modify the
   abstraction status of a method or class once it is created, are only
   supported using the :func:`update_abstractmethods` function.  The
   :func:`!abstractmethod` only affects subclasses derived using regular
   inheritance; "virtual subclasses" registered with the ABC's
   :meth:`~ABCMeta.register` method are not affected.

   When :func:`!abstractmethod` is applied in combination with other method
   descriptors, it should be applied as the innermost decorator, as shown in
   the following usage examples::

      class C(ABC):
          @abstractmethod
          def my_abstract_method(self, arg1):
              ...
          @classmethod
          @abstractmethod
          def my_abstract_classmethod(cls, arg2):
              ...
          @staticmethod
          @abstractmethod
          def my_abstract_staticmethod(arg3):
              ...

          @property
          @abstractmethod
          def my_abstract_property(self):
              ...
          @my_abstract_property.setter
          @abstractmethod
          def my_abstract_property(self, val):
              ...

          @abstractmethod
          def _get_x(self):
              ...
          @abstractmethod
          def _set_x(self, val):
              ...
          x = property(_get_x, _set_x)

   In order to correctly interoperate with the abstract base class machinery,
   the descriptor must identify itself as abstract using
   :attr:`!__isabstractmethod__`. In general, this attribute should be ``True``
   if any of the methods used to compose the descriptor are abstract. For
   example, Python's built-in :class:`property` does the equivalent of::

      class Descriptor:
          ...
          @property
          def __isabstractmethod__(self):
              return any(getattr(f, '__isabstractmethod__', False) for
                         f in (self._fget, self._fset, self._fdel))

   .. note::

      Unlike Java abstract methods, these abstract
      methods may have an implementation. This implementation can be
      called via the :func:`super` mechanism from the class that
      overrides it.  This could be useful as an end-point for a
      super-call in a framework that uses cooperative
      multiple-inheritance.

The :mod:`!abc` module also supports the following legacy decorators:

.. decorator:: abstractclassmethod

   .. versionadded:: 3.2
   .. deprecated:: 3.3
       It is now possible to use :class:`classmethod` with
       :func:`abstractmethod`, making this decorator redundant.

   A subclass of the built-in :func:`classmethod`, indicating an abstract
   classmethod. Otherwise it is similar to :func:`abstractmethod`.

   This special case is deprecated, as the :func:`classmethod` decorator
   is now correctly identified as abstract when applied to an abstract
   method::

      class C(ABC):
          @classmethod
          @abstractmethod
          def my_abstract_classmethod(cls, arg):
              ...


.. decorator:: abstractstaticmethod

   .. versionadded:: 3.2
   .. deprecated:: 3.3
       It is now possible to use :class:`staticmethod` with
       :func:`abstractmethod`, making this decorator redundant.

   A subclass of the built-in :func:`staticmethod`, indicating an abstract
   staticmethod. Otherwise it is similar to :func:`abstractmethod`.

   This special case is deprecated, as the :func:`staticmethod` decorator
   is now correctly identified as abstract when applied to an abstract
   method::

      class C(ABC):
          @staticmethod
          @abstractmethod
          def my_abstract_staticmethod(arg):
              ...


.. decorator:: abstractproperty

   .. deprecated:: 3.3
       It is now possible to use :class:`property`, :meth:`property.getter`,
       :meth:`property.setter` and :meth:`property.deleter` with
       :func:`abstractmethod`, making this decorator redundant.

   A subclass of the built-in :func:`property`, indicating an abstract
   property.

   This special case is deprecated, as the :func:`property` decorator
   is now correctly identified as abstract when applied to an abstract
   method::

      class C(ABC):
          @property
          @abstractmethod
          def my_abstract_property(self):
              ...

   The above example defines a read-only property; you can also define a
   read-write abstract property by appropriately marking one or more of the
   underlying methods as abstract::

      class C(ABC):
          @property
          def x(self):
              ...

          @x.setter
          @abstractmethod
          def x(self, val):
              ...

   If only some components are abstract, only those components need to be
   updated to create a concrete property in a subclass::

      class D(C):
          @C.x.setter
          def x(self, val):
              ...


The :mod:`!abc` module also provides the following functions:

.. function:: get_cache_token()

   Returns the current abstract base class cache token.

   The token is an opaque object (that supports equality testing) identifying
   the current version of the abstract base class cache for virtual subclasses.
   The token changes with every call to :meth:`ABCMeta.register` on any ABC.

   .. versionadded:: 3.4

.. function:: update_abstractmethods(cls)

   A function to recalculate an abstract class's abstraction status. This
   function should be called if a class's abstract methods have been
   implemented or changed after it was created. Usually, this function should
   be called from within a class decorator.

   Returns *cls*, to allow usage as a class decorator.

   If *cls* is not an instance of :class:`ABCMeta`, does nothing.

   .. note::

      This function assumes that *cls*'s superclasses are already updated.
      It does not update any subclasses.

   .. versionadded:: 3.10

.. rubric:: Footnotes

.. [#] C++ programmers should note that Python's virtual base class
   concept is not the same as C++'s.


================================================
File: /Doc/library/aifc.rst
================================================
:mod:`!aifc` --- Read and write AIFF and AIFC files
===================================================

.. module:: aifc
   :synopsis: Removed in 3.13.
   :deprecated:

.. deprecated-removed:: 3.11 3.13

This module is no longer part of the Python standard library.
It was :ref:`removed in Python 3.13 <whatsnew313-pep594>` after
being deprecated in Python 3.11.  The removal was decided in :pep:`594`.

The last version of Python that provided the :mod:`!aifc` module was
`Python 3.12 <https://docs.python.org/3.12/library/aifc.html>`_.


================================================
File: /Doc/library/allos.rst
================================================
.. _allos:

*********************************
Generic Operating System Services
*********************************

The modules described in this chapter provide interfaces to operating system
features that are available on (almost) all operating systems, such as files and
a clock.  The interfaces are generally modeled after the Unix or C interfaces,
but they are available on most other systems as well.  Here's an overview:


.. toctree::

   os.rst
   io.rst
   time.rst
   logging.rst
   logging.config.rst
   logging.handlers.rst
   platform.rst
   errno.rst
   ctypes.rst


================================================
File: /Doc/library/annotationlib.rst
================================================
:mod:`!annotationlib` --- Functionality for introspecting annotations
=====================================================================

.. module:: annotationlib
   :synopsis: Functionality for introspecting annotations


**Source code:** :source:`Lib/annotationlib.py`

.. testsetup:: default

   import annotationlib
   from annotationlib import *

--------------

The :mod:`!annotationlib` module provides tools for introspecting
:term:`annotations <annotation>` on modules, classes, and functions.

Annotations are :ref:`lazily evaluated <lazy-evaluation>` and often contain
forward references to objects that are not yet defined when the annotation
is created. This module provides a set of low-level tools that can be used to retrieve annotations in a reliable way, even
in the presence of forward references and other edge cases.

This module supports retrieving annotations in three main formats
(see :class:`Format`), each of which works best for different use cases:

* :attr:`~Format.VALUE` evaluates the annotations and returns their value.
  This is most straightforward to work with, but it may raise errors,
  for example if the annotations contain references to undefined names.
* :attr:`~Format.FORWARDREF` returns :class:`ForwardRef` objects
  for annotations that cannot be resolved, allowing you to inspect the
  annotations without evaluating them. This is useful when you need to
  work with annotations that may contain unresolved forward references.
* :attr:`~Format.STRING` returns the annotations as a string, similar
  to how it would appear in the source file. This is useful for documentation
  generators that want to display annotations in a readable way.

The :func:`get_annotations` function is the main entry point for
retrieving annotations. Given a function, class, or module, it returns
an annotations dictionary in the requested format. This module also provides
functionality for working directly with the :term:`annotate function`
that is used to evaluate annotations, such as :func:`get_annotate_function`
and :func:`call_annotate_function`, as well as the
:func:`call_evaluate_function` function for working with
:term:`evaluate functions <evaluate function>`.


.. seealso::

   :pep:`649` proposed the current model for how annotations work in Python.

   :pep:`749` expanded on various aspects of :pep:`649` and introduced the
   :mod:`!annotationlib` module.

   :ref:`annotations-howto` provides best practices for working with
   annotations.

   :pypi:`typing-extensions` provides a backport of :func:`get_annotations`
   that works on earlier versions of Python.

Annotation semantics
--------------------

The way annotations are evaluated has changed over the history of Python 3,
and currently still depends on a :ref:`future import <future>`.
There have been execution models for annotations:

* *Stock semantics* (default in Python 3.0 through 3.13; see :pep:`3107`
  and :pep:`526`): Annotations are evaluated eagerly, as they are
  encountered in the source code.
* *Stringified annotations* (used with ``from __future__ import annotations``
  in Python 3.7 and newer; see :pep:`563`): Annotations are stored as
  strings only.
* *Deferred evaluation* (default in Python 3.14 and newer; see :pep:`649` and
  :pep:`749`): Annotations are evaluated lazily, only when they are accessed.

As an example, consider the following program::

   def func(a: Cls) -> None:
       print(a)

   class Cls: pass

   print(func.__annotations__)

This will behave as follows:

* Under stock semantics (Python 3.13 and earlier), it will throw a
  :exc:`NameError` at the line where ``func`` is defined,
  because ``Cls`` is an undefined name at that point.
* Under stringified annotations (if ``from __future__ import annotations``
  is used), it will print ``{'a': 'Cls', 'return': 'None'}``.
* Under deferred evaluation (Python 3.14 and later), it will print
  ``{'a': <class 'Cls'>, 'return': None}``.

Stock semantics were used when function annotations were first introduced
in Python 3.0 (by :pep:`3107`) because this was the simplest, most obvious
way to implement annotations. The same execution model was used when variable
annotations were introduced in Python 3.6 (by :pep:`526`). However,
stock semantics caused problems when using annotations as type hints,
such as a need to refer to names that are not yet defined when the
annotation is encountered. In addition, there were performance problems
with executing annotations at module import time. Therefore, in Python 3.7,
:pep:`563` introduced the ability to store annotations as strings using the
``from __future__ import annotations`` syntax. The plan at the time was to
eventually make this behavior the default, but a problem appeared:
stringified annotations are more difficult to process for those who
introspect annotations at runtime. An alternative proposal, :pep:`649`,
introduced the third execution model, deferred evaluation, and was implemented
in Python 3.14. Stringified annotations are still used if
``from __future__ import annotations`` is present, but this behavior will
eventually be removed.

Classes
-------

.. class:: Format

   An :class:`~enum.IntEnum` describing the formats in which annotations
   can be returned. Members of the enum, or their equivalent integer values,
   can be passed to :func:`get_annotations` and other functions in this
   module, as well as to :attr:`~object.__annotate__` functions.

   .. attribute:: VALUE
      :value: 1

      Values are the result of evaluating the annotation expressions.

   .. attribute:: FORWARDREF
      :value: 2

      Values are real annotation values (as per :attr:`Format.VALUE` format)
      for defined values, and :class:`ForwardRef` proxies for undefined
      values. Real objects may contain references to, :class:`ForwardRef`
      proxy objects.

   .. attribute:: STRING
      :value: 3

      Values are the text string of the annotation as it appears in the
      source code, up to modifications including, but not restricted to,
      whitespace normalizations and constant values optimizations.

      The exact values of these strings may change in future versions of Python.

   .. attribute:: VALUE_WITH_FAKE_GLOBALS
      :value: 4

      Special value used to signal that an annotate function is being
      evaluated in a special environment with fake globals. When passed this
      value, annotate functions should either return the same value as for
      the :attr:`Format.VALUE` format, or raise :exc:`NotImplementedError`
      to signal that they do not support execution in this environment.
      This format is only used internally and should not be passed to
      the functions in this module.

   .. versionadded:: 3.14

.. class:: ForwardRef

   A proxy object for forward references in annotations.

   Instances of this class are returned when the :attr:`~Format.FORWARDREF`
   format is used and annotations contain a name that cannot be resolved.
   This can happen when a forward reference is used in an annotation, such as
   when a class is referenced before it is defined.

   .. attribute:: __forward_arg__

      A string containing the code that was evaluated to produce the
      :class:`~ForwardRef`. The string may not be exactly equivalent
      to the original source.

   .. method:: evaluate(*, globals=None, locals=None, type_params=None, owner=None)

      Evaluate the forward reference, returning its value.

      This may throw an exception, such as :exc:`NameError`, if the forward
      reference refers to names that do not exist. The arguments to this
      method can be used to provide bindings for names that would otherwise
      be undefined.

      :class:`~ForwardRef` instances returned by :func:`get_annotations`
      retain references to information about the scope they originated from,
      so calling this method with no further arguments may be sufficient to
      evaluate such objects. :class:`~ForwardRef` instances created by other
      means may not have any information about their scope, so passing
      arguments to this method may be necessary to evaluate them successfully.

      *globals* and *locals* are passed to :func:`eval`, representing
      the global and local namespaces in which the name is evaluated.
      *type_params*, if given, must be a tuple of
      :ref:`type parameters <type-params>` that are in scope while the forward
      reference is being evaluated. *owner* is the object that owns the
      annotation from which the forward reference derives, usually a function,
      class, or module.

      .. important::

         Once a :class:`~ForwardRef` instance has been evaluated, it caches
         the evaluated value, and future calls to :meth:`evaluate` will return
         the cached value, regardless of the parameters passed in.

   .. versionadded:: 3.14


Functions
---------

.. function:: annotations_to_string(annotations)

   Convert an annotations dict containing runtime values to a
   dict containing only strings. If the values are not already strings,
   they are converted using :func:`value_to_string`.
   This is meant as a helper for user-provided
   annotate functions that support the :attr:`~Format.STRING` format but
   do not have access to the code creating the annotations.

   For example, this is used to implement the :attr:`~Format.STRING` for
   :class:`typing.TypedDict` classes created through the functional syntax:

   .. doctest::

       >>> from typing import TypedDict
       >>> Movie = TypedDict("movie", {"name": str, "year": int})
       >>> get_annotations(Movie, format=Format.STRING)
       {'name': 'str', 'year': 'int'}

   .. versionadded:: 3.14

.. function:: call_annotate_function(annotate, format, *, owner=None)

   Call the :term:`annotate function` *annotate* with the given *format*,
   a member of the :class:`Format` enum, and return the annotations
   dictionary produced by the function.

   This helper function is required because annotate functions generated by
   the compiler for functions, classes, and modules only support
   the :attr:`~Format.VALUE` format when called directly.
   To support other formats, this function calls the annotate function
   in a special environment that allows it to produce annotations in the
   other formats. This is a useful building block when implementing
   functionality that needs to partially evaluate annotations while a class
   is being constructed.

   *owner* is the object that owns the annotation function, usually
   a function, class, or module. If provided, it is used in the
   :attr:`~Format.FORWARDREF` format to produce a :class:`ForwardRef`
   object that carries more information.

   .. seealso::

      :PEP:`PEP 649 <649#the-stringizer-and-the-fake-globals-environment>`
      contains an explanation of the implementation technique used by this
      function.

   .. versionadded:: 3.14

.. function:: call_evaluate_function(evaluate, format, *, owner=None)

   Call the :term:`evaluate function` *evaluate* with the given *format*,
   a member of the :class:`Format` enum, and return the value produced by
   the function. This is similar to :func:`call_annotate_function`,
   but the latter always returns a dictionary mapping strings to annotations,
   while this function returns a single value.

   This is intended for use with the evaluate functions generated for lazily
   evaluated elements related to type aliases and type parameters:

   * :meth:`typing.TypeAliasType.evaluate_value`, the value of type aliases
   * :meth:`typing.TypeVar.evaluate_bound`, the bound of type variables
   * :meth:`typing.TypeVar.evaluate_constraints`, the constraints of
     type variables
   * :meth:`typing.TypeVar.evaluate_default`, the default value of
     type variables
   * :meth:`typing.ParamSpec.evaluate_default`, the default value of
     parameter specifications
   * :meth:`typing.TypeVarTuple.evaluate_default`, the default value of
     type variable tuples

   *owner* is the object that owns the evaluate function, such as the type
   alias or type variable object.

   *format* can be used to control the format in which the value is returned:

   .. doctest::

      >>> type Alias = undefined
      >>> call_evaluate_function(Alias.evaluate_value, Format.VALUE)
      Traceback (most recent call last):
      ...
      NameError: name 'undefined' is not defined
      >>> call_evaluate_function(Alias.evaluate_value, Format.FORWARDREF)
      ForwardRef('undefined')
      >>> call_evaluate_function(Alias.evaluate_value, Format.STRING)
      'undefined'

   .. versionadded:: 3.14

.. function:: get_annotate_function(obj)

   Retrieve the :term:`annotate function` for *obj*. Return :const:`!None`
   if *obj* does not have an annotate function.

   This is usually equivalent to accessing the :attr:`~object.__annotate__`
   attribute of *obj*, but direct access to the attribute may return the wrong
   object in certain situations involving metaclasses. This function should be
   used instead of accessing the attribute directly.

   .. versionadded:: 3.14

.. function:: get_annotations(obj, *, globals=None, locals=None, eval_str=False, format=Format.VALUE)

   Compute the annotations dict for an object.

   *obj* may be a callable, class, module, or other object with
   :attr:`~object.__annotate__` and :attr:`~object.__annotations__` attributes.
   Passing in an object of any other type raises :exc:`TypeError`.

   The *format* parameter controls the format in which annotations are returned,
   and must be a member of the :class:`Format` enum or its integer equivalent.

   Returns a dict. :func:`!get_annotations` returns a new dict every time
   it's called; calling it twice on the same object will return two
   different but equivalent dicts.

   This function handles several details for you:

   * If *eval_str* is true, values of type :class:`!str` will
     be un-stringized using :func:`eval`. This is intended
     for use with stringized annotations
     (``from __future__ import annotations``). It is an error
     to set *eval_str* to true with formats other than :attr:`Format.VALUE`.
   * If *obj* doesn't have an annotations dict, returns an
     empty dict. (Functions and methods always have an
     annotations dict; classes, modules, and other types of
     callables may not.)
   * Ignores inherited annotations on classes, as well as annotations
     on metaclasses. If a class
     doesn't have its own annotations dict, returns an empty dict.
   * All accesses to object members and dict values are done
     using ``getattr()`` and ``dict.get()`` for safety.

   *eval_str* controls whether or not values of type :class:`!str` are
   replaced with the result of calling :func:`eval` on those values:

   * If eval_str is true, :func:`eval` is called on values of type
     :class:`!str`. (Note that :func:`!get_annotations` doesn't catch
     exceptions; if :func:`eval` raises an exception, it will unwind
     the stack past the :func:`!get_annotations` call.)
   * If *eval_str* is false (the default), values of type :class:`!str` are
     unchanged.

   *globals* and *locals* are passed in to :func:`eval`; see the documentation
   for :func:`eval` for more information. If *globals* or *locals*
   is :const:`!None`, this function may replace that value with a
   context-specific default, contingent on ``type(obj)``:

   * If *obj* is a module, *globals* defaults to ``obj.__dict__``.
   * If *obj* is a class, *globals* defaults to
     ``sys.modules[obj.__module__].__dict__`` and *locals* defaults
     to the *obj* class namespace.
   * If *obj* is a callable, *globals* defaults to
     :attr:`obj.__globals__ <function.__globals__>`,
     although if *obj* is a wrapped function (using
     :func:`functools.update_wrapper`) or a :class:`functools.partial` object,
     it is unwrapped until a non-wrapped function is found.

   Calling :func:`!get_annotations` is best practice for accessing the
   annotations dict of any object. See :ref:`annotations-howto` for
   more information on annotations best practices.

   .. doctest::

      >>> def f(a: int, b: str) -> float:
      ...     pass
      >>> get_annotations(f)
      {'a': <class 'int'>, 'b': <class 'str'>, 'return': <class 'float'>}

   .. versionadded:: 3.14

.. function:: value_to_string(value)

   Convert an arbitrary Python value to a format suitable for use by the
   :attr:`~Format.STRING` format. This calls :func:`repr` for most
   objects, but has special handling for some objects, such as type objects.

   This is meant as a helper for user-provided
   annotate functions that support the :attr:`~Format.STRING` format but
   do not have access to the code creating the annotations. It can also
   be used to provide a user-friendly string representation for other
   objects that contain values that are commonly encountered in annotations.

   .. versionadded:: 3.14



================================================
File: /Doc/library/archiving.rst
================================================
.. _archiving:

******************************
Data Compression and Archiving
******************************

The modules described in this chapter support data compression with the zlib,
gzip, bzip2 and lzma algorithms, and the creation of ZIP- and tar-format
archives.  See also :ref:`archiving-operations` provided by the :mod:`shutil`
module.


.. toctree::

   zlib.rst
   gzip.rst
   bz2.rst
   lzma.rst
   zipfile.rst
   tarfile.rst


================================================
File: /Doc/library/array.rst
================================================
:mod:`!array` --- Efficient arrays of numeric values
====================================================

.. module:: array
   :synopsis: Space efficient arrays of uniformly typed numeric values.

.. index:: single: arrays

--------------

This module defines an object type which can compactly represent an array of
basic values: characters, integers, floating-point numbers.  Arrays are sequence
types and behave very much like lists, except that the type of objects stored in
them is constrained.  The type is specified at object creation time by using a
:dfn:`type code`, which is a single character.  The following type codes are
defined:

+-----------+--------------------+-------------------+-----------------------+-------+
| Type code | C Type             | Python Type       | Minimum size in bytes | Notes |
+===========+====================+===================+=======================+=======+
| ``'b'``   | signed char        | int               | 1                     |       |
+-----------+--------------------+-------------------+-----------------------+-------+
| ``'B'``   | unsigned char      | int               | 1                     |       |
+-----------+--------------------+-------------------+-----------------------+-------+
| ``'u'``   | wchar_t            | Unicode character | 2                     | \(1)  |
+-----------+--------------------+-------------------+-----------------------+-------+
| ``'w'``   | Py_UCS4            | Unicode character | 4                     |       |
+-----------+--------------------+-------------------+-----------------------+-------+
| ``'h'``   | signed short       | int               | 2                     |       |
+-----------+--------------------+-------------------+-----------------------+-------+
| ``'H'``   | unsigned short     | int               | 2                     |       |
+-----------+--------------------+-------------------+-----------------------+-------+
| ``'i'``   | signed int         | int               | 2                     |       |
+-----------+--------------------+-------------------+-----------------------+-------+
| ``'I'``   | unsigned int       | int               | 2                     |       |
+-----------+--------------------+-------------------+-----------------------+-------+
| ``'l'``   | signed long        | int               | 4                     |       |
+-----------+--------------------+-------------------+-----------------------+-------+
| ``'L'``   | unsigned long      | int               | 4                     |       |
+-----------+--------------------+-------------------+-----------------------+-------+
| ``'q'``   | signed long long   | int               | 8                     |       |
+-----------+--------------------+-------------------+-----------------------+-------+
| ``'Q'``   | unsigned long long | int               | 8                     |       |
+-----------+--------------------+-------------------+-----------------------+-------+
| ``'f'``   | float              | float             | 4                     |       |
+-----------+--------------------+-------------------+-----------------------+-------+
| ``'d'``   | double             | float             | 8                     |       |
+-----------+--------------------+-------------------+-----------------------+-------+

Notes:

(1)
   It can be 16 bits or 32 bits depending on the platform.

   .. versionchanged:: 3.9
      ``array('u')`` now uses :c:type:`wchar_t` as C type instead of deprecated
      ``Py_UNICODE``. This change doesn't affect its behavior because
      ``Py_UNICODE`` is alias of :c:type:`wchar_t` since Python 3.3.

   .. deprecated-removed:: 3.3 3.16
      Please migrate to ``'w'`` typecode.


The actual representation of values is determined by the machine architecture
(strictly speaking, by the C implementation).  The actual size can be accessed
through the :attr:`array.itemsize` attribute.

The module defines the following item:


.. data:: typecodes

   A string with all available type codes.


The module defines the following type:


.. class:: array(typecode[, initializer])

   A new array whose items are restricted by *typecode*, and initialized
   from the optional *initializer* value, which must be a :class:`bytes`
   or :class:`bytearray` object, a Unicode string, or iterable over elements
   of the appropriate type.

   If given a :class:`bytes` or :class:`bytearray` object, the initializer
   is passed to the new array's :meth:`frombytes` method;
   if given a Unicode string, the initializer is passed to the
   :meth:`fromunicode` method;
   otherwise, the initializer's iterator is passed to the :meth:`extend` method
   to add initial items to the array.

   Array objects support the ordinary sequence operations of indexing, slicing,
   concatenation, and multiplication.  When using slice assignment, the assigned
   value must be an array object with the same type code; in all other cases,
   :exc:`TypeError` is raised. Array objects also implement the buffer interface,
   and may be used wherever :term:`bytes-like objects <bytes-like object>` are supported.

   .. audit-event:: array.__new__ typecode,initializer array.array


   .. attribute:: typecode

      The typecode character used to create the array.


   .. attribute:: itemsize

      The length in bytes of one array item in the internal representation.


   .. method:: append(x)

      Append a new item with value *x* to the end of the array.


   .. method:: buffer_info()

      Return a tuple ``(address, length)`` giving the current memory address and the
      length in elements of the buffer used to hold array's contents.  The size of the
      memory buffer in bytes can be computed as ``array.buffer_info()[1] *
      array.itemsize``.  This is occasionally useful when working with low-level (and
      inherently unsafe) I/O interfaces that require memory addresses, such as certain
      :c:func:`!ioctl` operations.  The returned numbers are valid as long as the array
      exists and no length-changing operations are applied to it.

      .. note::

         When using array objects from code written in C or C++ (the only way to
         effectively make use of this information), it makes more sense to use the buffer
         interface supported by array objects.  This method is maintained for backward
         compatibility and should be avoided in new code.  The buffer interface is
         documented in :ref:`bufferobjects`.


   .. method:: byteswap()

      "Byteswap" all items of the array.  This is only supported for values which are
      1, 2, 4, or 8 bytes in size; for other types of values, :exc:`RuntimeError` is
      raised.  It is useful when reading data from a file written on a machine with a
      different byte order.


   .. method:: count(x)

      Return the number of occurrences of *x* in the array.


   .. method:: extend(iterable)

      Append items from *iterable* to the end of the array.  If *iterable* is another
      array, it must have *exactly* the same type code; if not, :exc:`TypeError` will
      be raised.  If *iterable* is not an array, it must be iterable and its elements
      must be the right type to be appended to the array.


   .. method:: frombytes(buffer)

      Appends items from the :term:`bytes-like object`, interpreting
      its content as an array of machine values (as if it had been read
      from a file using the :meth:`fromfile` method).

      .. versionadded:: 3.2
         :meth:`!fromstring` is renamed to :meth:`frombytes` for clarity.


   .. method:: fromfile(f, n)

      Read *n* items (as machine values) from the :term:`file object` *f* and append
      them to the end of the array.  If less than *n* items are available,
      :exc:`EOFError` is raised, but the items that were available are still
      inserted into the array.


   .. method:: fromlist(list)

      Append items from the list.  This is equivalent to ``for x in list:
      a.append(x)`` except that if there is a type error, the array is unchanged.


   .. method:: fromunicode(s)

      Extends this array with data from the given Unicode string.
      The array must have type code ``'u'`` or ``'w'``; otherwise a :exc:`ValueError` is raised.
      Use ``array.frombytes(unicodestring.encode(enc))`` to append Unicode data to an
      array of some other type.


   .. method:: index(x[, start[, stop]])

      Return the smallest *i* such that *i* is the index of the first occurrence of
      *x* in the array.  The optional arguments *start* and *stop* can be
      specified to search for *x* within a subsection of the array.  Raise
      :exc:`ValueError` if *x* is not found.

      .. versionchanged:: 3.10
         Added optional *start* and *stop* parameters.


   .. method:: insert(i, x)

      Insert a new item with value *x* in the array before position *i*. Negative
      values are treated as being relative to the end of the array.


   .. method:: pop([i])

      Removes the item with the index *i* from the array and returns it. The optional
      argument defaults to ``-1``, so that by default the last item is removed and
      returned.


   .. method:: remove(x)

      Remove the first occurrence of *x* from the array.


   .. method:: clear()

      Remove all elements from the array.

      .. versionadded:: 3.13


   .. method:: reverse()

      Reverse the order of the items in the array.


   .. method:: tobytes()

      Convert the array to an array of machine values and return the bytes
      representation (the same sequence of bytes that would be written to a file by
      the :meth:`tofile` method.)

      .. versionadded:: 3.2
         :meth:`!tostring` is renamed to :meth:`tobytes` for clarity.


   .. method:: tofile(f)

      Write all items (as machine values) to the :term:`file object` *f*.


   .. method:: tolist()

      Convert the array to an ordinary list with the same items.


   .. method:: tounicode()

      Convert the array to a Unicode string.  The array must have a type ``'u'`` or ``'w'``;
      otherwise a :exc:`ValueError` is raised. Use ``array.tobytes().decode(enc)`` to
      obtain a Unicode string from an array of some other type.


The string representation of array objects has the form
``array(typecode, initializer)``.
The *initializer* is omitted if the array is empty, otherwise it is
a Unicode string if the *typecode* is ``'u'`` or ``'w'``, otherwise it is
a list of numbers.
The string representation is guaranteed to be able to be converted back to an
array with the same type and value using :func:`eval`, so long as the
:class:`~array.array` class has been imported using ``from array import array``.
Variables ``inf`` and ``nan`` must also be defined if it contains
corresponding floating-point values.
Examples::

   array('l')
   array('w', 'hello \u2641')
   array('l', [1, 2, 3, 4, 5])
   array('d', [1.0, 2.0, 3.14, -inf, nan])


.. seealso::

   Module :mod:`struct`
      Packing and unpacking of heterogeneous binary data.

   `NumPy <https://numpy.org/>`_
      The NumPy package defines another array type.


================================================
File: /Doc/library/asynchat.rst
================================================
:mod:`!asynchat` --- Asynchronous socket command/response handler
=================================================================

.. module:: asynchat
   :synopsis: Removed in 3.12.
   :deprecated:

.. deprecated-removed:: 3.6 3.12

This module is no longer part of the Python standard library.
It was :ref:`removed in Python 3.12 <whatsnew312-removed>` after
being deprecated in Python 3.6.  The removal was decided in :pep:`594`.

Applications should use the :mod:`asyncio` module instead.

The last version of Python that provided the :mod:`!asynchat` module was
`Python 3.11 <https://docs.python.org/3.11/library/asynchat.html>`_.


================================================
File: /Doc/library/asyncio-api-index.rst
================================================
.. currentmodule:: asyncio


====================
High-level API Index
====================

This page lists all high-level async/await enabled asyncio APIs.


Tasks
=====

Utilities to run asyncio programs, create Tasks, and
await on multiple things with timeouts.

.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :func:`run`
      - Create event loop, run a coroutine, close the loop.

    * - :class:`Runner`
      - A context manager that simplifies multiple async function calls.

    * - :class:`Task`
      - Task object.

    * - :class:`TaskGroup`
      - A context manager that holds a group of tasks. Provides
        a convenient and reliable way to wait for all tasks in the group to
        finish.

    * - :func:`create_task`
      - Start an asyncio Task, then returns it.

    * - :func:`current_task`
      - Return the current Task.

    * - :func:`all_tasks`
      - Return all tasks that are not yet finished for an event loop.

    * - ``await`` :func:`sleep`
      - Sleep for a number of seconds.

    * - ``await`` :func:`gather`
      - Schedule and wait for things concurrently.

    * - ``await`` :func:`wait_for`
      - Run with a timeout.

    * - ``await`` :func:`shield`
      - Shield from cancellation.

    * - ``await`` :func:`wait`
      - Monitor for completion.

    * - :func:`timeout`
      - Run with a timeout. Useful in cases when ``wait_for`` is not suitable.

    * - :func:`to_thread`
      - Asynchronously run a function in a separate OS thread.

    * - :func:`run_coroutine_threadsafe`
      - Schedule a coroutine from another OS thread.

    * - ``for in`` :func:`as_completed`
      - Monitor for completion with a ``for`` loop.


.. rubric:: Examples

* :ref:`Using asyncio.gather() to run things in parallel
  <asyncio_example_gather>`.

* :ref:`Using asyncio.wait_for() to enforce a timeout
  <asyncio_example_waitfor>`.

* :ref:`Cancellation <asyncio_example_task_cancel>`.

* :ref:`Using asyncio.sleep() <asyncio_example_sleep>`.

* See also the main :ref:`Tasks documentation page <coroutine>`.


Queues
======

Queues should be used to distribute work amongst multiple asyncio Tasks,
implement connection pools, and pub/sub patterns.


.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :class:`Queue`
      - A FIFO queue.

    * - :class:`PriorityQueue`
      - A priority queue.

    * - :class:`LifoQueue`
      - A LIFO queue.


.. rubric:: Examples

* :ref:`Using asyncio.Queue to distribute workload between several
  Tasks <asyncio_example_queue_dist>`.

* See also the :ref:`Queues documentation page <asyncio-queues>`.


Subprocesses
============

Utilities to spawn subprocesses and run shell commands.

.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - ``await`` :func:`create_subprocess_exec`
      - Create a subprocess.

    * - ``await`` :func:`create_subprocess_shell`
      - Run a shell command.


.. rubric:: Examples

* :ref:`Executing a shell command <asyncio_example_subprocess_shell>`.

* See also the :ref:`subprocess APIs <asyncio-subprocess>`
  documentation.


Streams
=======

High-level APIs to work with network IO.

.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - ``await`` :func:`open_connection`
      -  Establish a TCP connection.

    * - ``await`` :func:`open_unix_connection`
      -  Establish a Unix socket connection.

    * - ``await`` :func:`start_server`
      - Start a TCP server.

    * - ``await`` :func:`start_unix_server`
      - Start a Unix socket server.

    * - :class:`StreamReader`
      - High-level async/await object to receive network data.

    * - :class:`StreamWriter`
      - High-level async/await object to send network data.


.. rubric:: Examples

* :ref:`Example TCP client <asyncio_example_stream>`.

* See also the :ref:`streams APIs <asyncio-streams>`
  documentation.


Synchronization
===============

Threading-like synchronization primitives that can be used in Tasks.

.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :class:`Lock`
      - A mutex lock.

    * - :class:`Event`
      - An event object.

    * - :class:`Condition`
      - A condition object.

    * - :class:`Semaphore`
      - A semaphore.

    * - :class:`BoundedSemaphore`
      - A bounded semaphore.

    * - :class:`Barrier`
      - A barrier object.


.. rubric:: Examples

* :ref:`Using asyncio.Event <asyncio_example_sync_event>`.

* :ref:`Using asyncio.Barrier <asyncio_example_barrier>`.

* See also the documentation of asyncio
  :ref:`synchronization primitives <asyncio-sync>`.


Exceptions
==========

.. list-table::
    :widths: 50 50
    :class: full-width-table


    * - :exc:`asyncio.CancelledError`
      - Raised when a Task is cancelled. See also :meth:`Task.cancel`.

    * - :exc:`asyncio.BrokenBarrierError`
      - Raised when a Barrier is broken. See also :meth:`Barrier.wait`.


.. rubric:: Examples

* :ref:`Handling CancelledError to run code on cancellation request
  <asyncio_example_task_cancel>`.

* See also the full list of
  :ref:`asyncio-specific exceptions <asyncio-exceptions>`.


================================================
File: /Doc/library/asyncio-dev.rst
================================================
.. currentmodule:: asyncio

.. _asyncio-dev:

=======================
Developing with asyncio
=======================

Asynchronous programming is different from classic "sequential"
programming.

This page lists common mistakes and traps and explains how
to avoid them.


.. _asyncio-debug-mode:

Debug Mode
==========

By default asyncio runs in production mode.  In order to ease
the development asyncio has a *debug mode*.

There are several ways to enable asyncio debug mode:

* Setting the :envvar:`PYTHONASYNCIODEBUG` environment variable to ``1``.

* Using the :ref:`Python Development Mode <devmode>`.

* Passing ``debug=True`` to :func:`asyncio.run`.

* Calling :meth:`loop.set_debug`.

In addition to enabling the debug mode, consider also:

* setting the log level of the :ref:`asyncio logger <asyncio-logger>` to
  :py:const:`logging.DEBUG`, for example the following snippet of code
  can be run at startup of the application::

    logging.basicConfig(level=logging.DEBUG)

* configuring the :mod:`warnings` module to display
  :exc:`ResourceWarning` warnings.  One way of doing that is by
  using the :option:`-W` ``default`` command line option.


When the debug mode is enabled:

* asyncio checks for :ref:`coroutines that were not awaited
  <asyncio-coroutine-not-scheduled>` and logs them; this mitigates
  the "forgotten await" pitfall.

* Many non-threadsafe asyncio APIs (such as :meth:`loop.call_soon` and
  :meth:`loop.call_at` methods) raise an exception if they are called
  from a wrong thread.

* The execution time of the I/O selector is logged if it takes too long to
  perform an I/O operation.

* Callbacks taking longer than 100 milliseconds are logged.  The
  :attr:`loop.slow_callback_duration` attribute can be used to set the
  minimum execution duration in seconds that is considered "slow".


.. _asyncio-multithreading:

Concurrency and Multithreading
==============================

An event loop runs in a thread (typically the main thread) and executes
all callbacks and Tasks in its thread.  While a Task is running in the
event loop, no other Tasks can run in the same thread.  When a Task
executes an ``await`` expression, the running Task gets suspended, and
the event loop executes the next Task.

To schedule a :term:`callback` from another OS thread, the
:meth:`loop.call_soon_threadsafe` method should be used. Example::

    loop.call_soon_threadsafe(callback, *args)

Almost all asyncio objects are not thread safe, which is typically
not a problem unless there is code that works with them from outside
of a Task or a callback.  If there's a need for such code to call a
low-level asyncio API, the :meth:`loop.call_soon_threadsafe` method
should be used, e.g.::

    loop.call_soon_threadsafe(fut.cancel)

To schedule a coroutine object from a different OS thread, the
:func:`run_coroutine_threadsafe` function should be used. It returns a
:class:`concurrent.futures.Future` to access the result::

     async def coro_func():
          return await asyncio.sleep(1, 42)

     # Later in another OS thread:

     future = asyncio.run_coroutine_threadsafe(coro_func(), loop)
     # Wait for the result:
     result = future.result()

To handle signals the event loop must be
run in the main thread.

The :meth:`loop.run_in_executor` method can be used with a
:class:`concurrent.futures.ThreadPoolExecutor` or
:class:`~concurrent.futures.InterpreterPoolExecutor` to execute
blocking code in a different OS thread without blocking the OS thread
that the event loop runs in.

There is currently no way to schedule coroutines or callbacks directly
from a different process (such as one started with
:mod:`multiprocessing`). The :ref:`asyncio-event-loop-methods`
section lists APIs that can read from pipes and watch file descriptors
without blocking the event loop. In addition, asyncio's
:ref:`Subprocess <asyncio-subprocess>` APIs provide a way to start a
process and communicate with it from the event loop. Lastly, the
aforementioned :meth:`loop.run_in_executor` method can also be used
with a :class:`concurrent.futures.ProcessPoolExecutor` to execute
code in a different process.

.. _asyncio-handle-blocking:

Running Blocking Code
=====================

Blocking (CPU-bound) code should not be called directly.  For example,
if a function performs a CPU-intensive calculation for 1 second,
all concurrent asyncio Tasks and IO operations would be delayed
by 1 second.

An executor can be used to run a task in a different thread,
including in a different interpreter, or even in
a different process to avoid blocking the OS thread with the
event loop.  See the :meth:`loop.run_in_executor` method for more
details.


.. _asyncio-logger:

Logging
=======

asyncio uses the :mod:`logging` module and all logging is performed
via the ``"asyncio"`` logger.

The default log level is :py:const:`logging.INFO`, which can be easily
adjusted::

   logging.getLogger("asyncio").setLevel(logging.WARNING)


Network logging can block the event loop. It is recommended to use
a separate thread for handling logs or use non-blocking IO. For example,
see :ref:`blocking-handlers`.


.. _asyncio-coroutine-not-scheduled:

Detect never-awaited coroutines
===============================

When a coroutine function is called, but not awaited
(e.g. ``coro()`` instead of ``await coro()``)
or the coroutine is not scheduled with :meth:`asyncio.create_task`, asyncio
will emit a :exc:`RuntimeWarning`::

    import asyncio

    async def test():
        print("never scheduled")

    async def main():
        test()

    asyncio.run(main())

Output::

  test.py:7: RuntimeWarning: coroutine 'test' was never awaited
    test()

Output in debug mode::

  test.py:7: RuntimeWarning: coroutine 'test' was never awaited
  Coroutine created at (most recent call last)
    File "../t.py", line 9, in <module>
      asyncio.run(main(), debug=True)

    < .. >

    File "../t.py", line 7, in main
      test()
    test()

The usual fix is to either await the coroutine or call the
:meth:`asyncio.create_task` function::

    async def main():
        await test()


Detect never-retrieved exceptions
=================================

If a :meth:`Future.set_exception` is called but the Future object is
never awaited on, the exception would never be propagated to the
user code.  In this case, asyncio would emit a log message when the
Future object is garbage collected.

Example of an unhandled exception::

    import asyncio

    async def bug():
        raise Exception("not consumed")

    async def main():
        asyncio.create_task(bug())

    asyncio.run(main())

Output::

    Task exception was never retrieved
    future: <Task finished coro=<bug() done, defined at test.py:3>
      exception=Exception('not consumed')>

    Traceback (most recent call last):
      File "test.py", line 4, in bug
        raise Exception("not consumed")
    Exception: not consumed

:ref:`Enable the debug mode <asyncio-debug-mode>` to get the
traceback where the task was created::

    asyncio.run(main(), debug=True)

Output in debug mode::

    Task exception was never retrieved
    future: <Task finished coro=<bug() done, defined at test.py:3>
        exception=Exception('not consumed') created at asyncio/tasks.py:321>

    source_traceback: Object created at (most recent call last):
      File "../t.py", line 9, in <module>
        asyncio.run(main(), debug=True)

    < .. >

    Traceback (most recent call last):
      File "../t.py", line 4, in bug
        raise Exception("not consumed")
    Exception: not consumed


================================================
File: /Doc/library/asyncio-exceptions.rst
================================================
.. currentmodule:: asyncio


.. _asyncio-exceptions:

==========
Exceptions
==========

**Source code:** :source:`Lib/asyncio/exceptions.py`

----------------------------------------------------

.. exception:: TimeoutError

   A deprecated alias of :exc:`TimeoutError`,
   raised when the operation has exceeded the given deadline.

   .. versionchanged:: 3.11

      This class was made an alias of :exc:`TimeoutError`.


.. exception:: CancelledError

   The operation has been cancelled.

   This exception can be caught to perform custom operations
   when asyncio Tasks are cancelled.  In almost all situations the
   exception must be re-raised.

   .. versionchanged:: 3.8

      :exc:`CancelledError` is now a subclass of :class:`BaseException` rather than :class:`Exception`.


.. exception:: InvalidStateError

   Invalid internal state of :class:`Task` or :class:`Future`.

   Can be raised in situations like setting a result value for a
   *Future* object that already has a result value set.


.. exception:: SendfileNotAvailableError

   The "sendfile" syscall is not available for the given
   socket or file type.

   A subclass of :exc:`RuntimeError`.


.. exception:: IncompleteReadError

   The requested read operation did not complete fully.

   Raised by the :ref:`asyncio stream APIs<asyncio-streams>`.

   This exception is a subclass of :exc:`EOFError`.

   .. attribute:: expected

      The total number (:class:`int`) of expected bytes.

   .. attribute:: partial

      A string of :class:`bytes` read before the end of stream was reached.


.. exception:: LimitOverrunError

   Reached the buffer size limit while looking for a separator.

   Raised by the :ref:`asyncio stream APIs <asyncio-streams>`.

   .. attribute:: consumed

      The total number of to be consumed bytes.


================================================
File: /Doc/library/asyncio-extending.rst
================================================
.. currentmodule:: asyncio


=========
Extending
=========

The main direction for :mod:`asyncio` extending is writing custom *event loop*
classes. Asyncio has helpers that could be used to simplify this task.

.. note::

   Third-parties should reuse existing asyncio code with caution,
   a new Python version is free to break backward compatibility
   in *internal* part of API.


Writing a Custom Event Loop
===========================

:class:`asyncio.AbstractEventLoop` declares very many methods.  Implementing all them
from scratch is a tedious job.

A loop can get many common methods implementation for free by inheriting from
:class:`asyncio.BaseEventLoop`.

In turn, the successor should implement a bunch of *private* methods declared but not
implemented in :class:`asyncio.BaseEventLoop`.

For example, ``loop.create_connection()`` checks arguments, resolves DNS addresses, and
calls ``loop._make_socket_transport()`` that should be implemented by inherited class.
The ``_make_socket_transport()`` method is not documented and is considered as an
*internal* API.



Future and Task private constructors
====================================

:class:`asyncio.Future` and :class:`asyncio.Task` should be never created directly,
please use corresponding :meth:`loop.create_future` and :meth:`loop.create_task`,
or :func:`asyncio.create_task` factories instead.

However, third-party *event loops* may *reuse* built-in future and task implementations
for the sake of getting a complex and highly optimized code for free.

For this purpose the following, *private* constructors are listed:

.. method:: Future.__init__(*, loop=None)

   Create a built-in future instance.

   *loop* is an optional event loop instance.

.. method:: Task.__init__(coro, *, loop=None, name=None, context=None)

   Create a built-in task instance.

   *loop* is an optional event loop instance. The rest of arguments are described in
   :meth:`loop.create_task` description.

   .. versionchanged:: 3.11

      *context* argument is added.



Task lifetime support
=====================

A third party task implementation should call the following functions to keep a task
visible by :func:`asyncio.all_tasks` and :func:`asyncio.current_task`:

.. function:: _register_task(task)

   Register a new *task* as managed by *asyncio*.

   Call the function from a task constructor.

.. function:: _unregister_task(task)

   Unregister a *task* from *asyncio* internal structures.

   The function should be called when a task is about to finish.

.. function:: _enter_task(loop, task)

   Switch the current task to the *task* argument.

   Call the function just before executing a portion of embedded *coroutine*
   (:meth:`coroutine.send` or :meth:`coroutine.throw`).

.. function:: _leave_task(loop, task)

   Switch the current task back from *task* to ``None``.

   Call the function just after :meth:`coroutine.send` or :meth:`coroutine.throw`
   execution.


================================================
File: /Doc/library/asyncio-future.rst
================================================
.. currentmodule:: asyncio


.. _asyncio-futures:

=======
Futures
=======

**Source code:** :source:`Lib/asyncio/futures.py`,
:source:`Lib/asyncio/base_futures.py`

-------------------------------------

*Future* objects are used to bridge **low-level callback-based code**
with high-level async/await code.


Future Functions
================

.. function:: isfuture(obj)

   Return ``True`` if *obj* is either of:

   * an instance of :class:`asyncio.Future`,
   * an instance of :class:`asyncio.Task`,
   * a Future-like object with a ``_asyncio_future_blocking``
     attribute.

   .. versionadded:: 3.5


.. function:: ensure_future(obj, *, loop=None)

   Return:

   * *obj* argument as is, if *obj* is a :class:`Future`,
     a :class:`Task`, or a Future-like object (:func:`isfuture`
     is used for the test.)

   * a :class:`Task` object wrapping *obj*, if *obj* is a
     coroutine (:func:`iscoroutine` is used for the test);
     in this case the coroutine will be scheduled by
     ``ensure_future()``.

   * a :class:`Task` object that would await on *obj*, if *obj* is an
     awaitable (:func:`inspect.isawaitable` is used for the test.)

   If *obj* is neither of the above a :exc:`TypeError` is raised.

   .. important::

      See also the :func:`create_task` function which is the
      preferred way for creating new Tasks.

      Save a reference to the result of this function, to avoid
      a task disappearing mid-execution.

   .. versionchanged:: 3.5.1
      The function accepts any :term:`awaitable` object.

   .. deprecated:: 3.10
      Deprecation warning is emitted if *obj* is not a Future-like object
      and *loop* is not specified and there is no running event loop.


.. function:: wrap_future(future, *, loop=None)

   Wrap a :class:`concurrent.futures.Future` object in a
   :class:`asyncio.Future` object.

   .. deprecated:: 3.10
      Deprecation warning is emitted if *future* is not a Future-like object
      and *loop* is not specified and there is no running event loop.


Future Object
=============

.. class:: Future(*, loop=None)

   A Future represents an eventual result of an asynchronous
   operation.  Not thread-safe.

   Future is an :term:`awaitable` object.  Coroutines can await on
   Future objects until they either have a result or an exception
   set, or until they are cancelled. A Future can be awaited multiple
   times and the result is same.

   Typically Futures are used to enable low-level
   callback-based code (e.g. in protocols implemented using asyncio
   :ref:`transports <asyncio-transports-protocols>`)
   to interoperate with high-level async/await code.

   The rule of thumb is to never expose Future objects in user-facing
   APIs, and the recommended way to create a Future object is to call
   :meth:`loop.create_future`.  This way alternative event loop
   implementations can inject their own optimized implementations
   of a Future object.

   .. versionchanged:: 3.7
      Added support for the :mod:`contextvars` module.

   .. deprecated:: 3.10
      Deprecation warning is emitted if *loop* is not specified
      and there is no running event loop.

   .. method:: result()

      Return the result of the Future.

      If the Future is *done* and has a result set by the
      :meth:`set_result` method, the result value is returned.

      If the Future is *done* and has an exception set by the
      :meth:`set_exception` method, this method raises the exception.

      If the Future has been *cancelled*, this method raises
      a :exc:`CancelledError` exception.

      If the Future's result isn't yet available, this method raises
      an :exc:`InvalidStateError` exception.

   .. method:: set_result(result)

      Mark the Future as *done* and set its result.

      Raises an :exc:`InvalidStateError` error if the Future is
      already *done*.

   .. method:: set_exception(exception)

      Mark the Future as *done* and set an exception.

      Raises an :exc:`InvalidStateError` error if the Future is
      already *done*.

   .. method:: done()

      Return ``True`` if the Future is *done*.

      A Future is *done* if it was *cancelled* or if it has a result
      or an exception set with :meth:`set_result` or
      :meth:`set_exception` calls.

   .. method:: cancelled()

      Return ``True`` if the Future was *cancelled*.

      The method is usually used to check if a Future is not
      *cancelled* before setting a result or an exception for it::

          if not fut.cancelled():
              fut.set_result(42)

   .. method:: add_done_callback(callback, *, context=None)

      Add a callback to be run when the Future is *done*.

      The *callback* is called with the Future object as its only
      argument.

      If the Future is already *done* when this method is called,
      the callback is scheduled with :meth:`loop.call_soon`.

      An optional keyword-only *context* argument allows specifying a
      custom :class:`contextvars.Context` for the *callback* to run in.
      The current context is used when no *context* is provided.

      :func:`functools.partial` can be used to pass parameters
      to the callback, e.g.::

          # Call 'print("Future:", fut)' when "fut" is done.
          fut.add_done_callback(
              functools.partial(print, "Future:"))

      .. versionchanged:: 3.7
         The *context* keyword-only parameter was added.
         See :pep:`567` for more details.

   .. method:: remove_done_callback(callback)

      Remove *callback* from the callbacks list.

      Returns the number of callbacks removed, which is typically 1,
      unless a callback was added more than once.

   .. method:: cancel(msg=None)

      Cancel the Future and schedule callbacks.

      If the Future is already *done* or *cancelled*, return ``False``.
      Otherwise, change the Future's state to *cancelled*,
      schedule the callbacks, and return ``True``.

      .. versionchanged:: 3.9
         Added the *msg* parameter.

   .. method:: exception()

      Return the exception that was set on this Future.

      The exception (or ``None`` if no exception was set) is
      returned only if the Future is *done*.

      If the Future has been *cancelled*, this method raises a
      :exc:`CancelledError` exception.

      If the Future isn't *done* yet, this method raises an
      :exc:`InvalidStateError` exception.

   .. method:: get_loop()

      Return the event loop the Future object is bound to.

      .. versionadded:: 3.7


.. _asyncio_example_future:

This example creates a Future object, creates and schedules an
asynchronous Task to set result for the Future, and waits until
the Future has a result::

    async def set_after(fut, delay, value):
        # Sleep for *delay* seconds.
        await asyncio.sleep(delay)

        # Set *value* as a result of *fut* Future.
        fut.set_result(value)

    async def main():
        # Get the current event loop.
        loop = asyncio.get_running_loop()

        # Create a new Future object.
        fut = loop.create_future()

        # Run "set_after()" coroutine in a parallel Task.
        # We are using the low-level "loop.create_task()" API here because
        # we already have a reference to the event loop at hand.
        # Otherwise we could have just used "asyncio.create_task()".
        loop.create_task(
            set_after(fut, 1, '... world'))

        print('hello ...')

        # Wait until *fut* has a result (1 second) and print it.
        print(await fut)

    asyncio.run(main())


.. important::

   The Future object was designed to mimic
   :class:`concurrent.futures.Future`.  Key differences include:

   - unlike asyncio Futures, :class:`concurrent.futures.Future`
     instances cannot be awaited.

   - :meth:`asyncio.Future.result` and :meth:`asyncio.Future.exception`
     do not accept the *timeout* argument.

   - :meth:`asyncio.Future.result` and :meth:`asyncio.Future.exception`
     raise an :exc:`InvalidStateError` exception when the Future is not
     *done*.

   - Callbacks registered with :meth:`asyncio.Future.add_done_callback`
     are not called immediately.  They are scheduled with
     :meth:`loop.call_soon` instead.

   - asyncio Future is not compatible with the
     :func:`concurrent.futures.wait` and
     :func:`concurrent.futures.as_completed` functions.

   - :meth:`asyncio.Future.cancel` accepts an optional ``msg`` argument,
     but :meth:`concurrent.futures.Future.cancel` does not.


================================================
File: /Doc/library/asyncio-llapi-index.rst
================================================
.. currentmodule:: asyncio


===================
Low-level API Index
===================

This page lists all low-level asyncio APIs.


Obtaining the Event Loop
========================

.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :func:`asyncio.get_running_loop`
      - The **preferred** function to get the running event loop.

    * - :func:`asyncio.get_event_loop`
      - Get an event loop instance (running or current via the current policy).

    * - :func:`asyncio.set_event_loop`
      - Set the event loop as current via the current policy.

    * - :func:`asyncio.new_event_loop`
      - Create a new event loop.


.. rubric:: Examples

* :ref:`Using asyncio.get_running_loop() <asyncio_example_future>`.


Event Loop Methods
==================

See also the main documentation section about the
:ref:`asyncio-event-loop-methods`.

.. rubric:: Lifecycle
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`loop.run_until_complete`
      - Run a Future/Task/awaitable until complete.

    * - :meth:`loop.run_forever`
      - Run the event loop forever.

    * - :meth:`loop.stop`
      - Stop the event loop.

    * - :meth:`loop.close`
      - Close the event loop.

    * - :meth:`loop.is_running`
      - Return ``True`` if the event loop is running.

    * - :meth:`loop.is_closed`
      - Return ``True`` if the event loop is closed.

    * - ``await`` :meth:`loop.shutdown_asyncgens`
      - Close asynchronous generators.


.. rubric:: Debugging
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`loop.set_debug`
      - Enable or disable the debug mode.

    * - :meth:`loop.get_debug`
      - Get the current debug mode.


.. rubric:: Scheduling Callbacks
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`loop.call_soon`
      - Invoke a callback soon.

    * - :meth:`loop.call_soon_threadsafe`
      - A thread-safe variant of :meth:`loop.call_soon`.

    * - :meth:`loop.call_later`
      - Invoke a callback *after* the given time.

    * - :meth:`loop.call_at`
      - Invoke a callback *at* the given time.


.. rubric:: Thread/Interpreter/Process Pool
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - ``await`` :meth:`loop.run_in_executor`
      - Run a CPU-bound or other blocking function in
        a :mod:`concurrent.futures` executor.

    * - :meth:`loop.set_default_executor`
      - Set the default executor for :meth:`loop.run_in_executor`.


.. rubric:: Tasks and Futures
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`loop.create_future`
      - Create a :class:`Future` object.

    * - :meth:`loop.create_task`
      - Schedule coroutine as a :class:`Task`.

    * - :meth:`loop.set_task_factory`
      - Set a factory used by :meth:`loop.create_task` to
        create :class:`Tasks <Task>`.

    * - :meth:`loop.get_task_factory`
      - Get the factory :meth:`loop.create_task` uses
        to create :class:`Tasks <Task>`.


.. rubric:: DNS
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - ``await`` :meth:`loop.getaddrinfo`
      - Asynchronous version of :meth:`socket.getaddrinfo`.

    * - ``await`` :meth:`loop.getnameinfo`
      - Asynchronous version of :meth:`socket.getnameinfo`.


.. rubric:: Networking and IPC
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - ``await`` :meth:`loop.create_connection`
      - Open a TCP connection.

    * - ``await`` :meth:`loop.create_server`
      - Create a TCP server.

    * - ``await`` :meth:`loop.create_unix_connection`
      - Open a Unix socket connection.

    * - ``await`` :meth:`loop.create_unix_server`
      - Create a Unix socket server.

    * - ``await`` :meth:`loop.connect_accepted_socket`
      - Wrap a :class:`~socket.socket` into a ``(transport, protocol)``
        pair.

    * - ``await`` :meth:`loop.create_datagram_endpoint`
      - Open a datagram (UDP) connection.

    * - ``await`` :meth:`loop.sendfile`
      - Send a file over a transport.

    * - ``await`` :meth:`loop.start_tls`
      - Upgrade an existing connection to TLS.

    * - ``await`` :meth:`loop.connect_read_pipe`
      - Wrap a read end of a pipe into a ``(transport, protocol)`` pair.

    * - ``await`` :meth:`loop.connect_write_pipe`
      - Wrap a write end of a pipe into a ``(transport, protocol)`` pair.


.. rubric:: Sockets
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - ``await`` :meth:`loop.sock_recv`
      - Receive data from the :class:`~socket.socket`.

    * - ``await`` :meth:`loop.sock_recv_into`
      - Receive data from the :class:`~socket.socket` into a buffer.

    * - ``await`` :meth:`loop.sock_recvfrom`
      - Receive a datagram from the :class:`~socket.socket`.

    * - ``await`` :meth:`loop.sock_recvfrom_into`
      - Receive a datagram from the :class:`~socket.socket` into a buffer.

    * - ``await`` :meth:`loop.sock_sendall`
      - Send data to the :class:`~socket.socket`.

    * - ``await`` :meth:`loop.sock_sendto`
      - Send a datagram via the :class:`~socket.socket` to the given address.

    * - ``await`` :meth:`loop.sock_connect`
      - Connect the :class:`~socket.socket`.

    * - ``await`` :meth:`loop.sock_accept`
      - Accept a :class:`~socket.socket` connection.

    * - ``await`` :meth:`loop.sock_sendfile`
      - Send a file over the :class:`~socket.socket`.

    * - :meth:`loop.add_reader`
      - Start watching a file descriptor for read availability.

    * - :meth:`loop.remove_reader`
      - Stop watching a file descriptor for read availability.

    * - :meth:`loop.add_writer`
      - Start watching a file descriptor for write availability.

    * - :meth:`loop.remove_writer`
      - Stop watching a file descriptor for write availability.


.. rubric:: Unix Signals
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`loop.add_signal_handler`
      - Add a handler for a :mod:`signal`.

    * - :meth:`loop.remove_signal_handler`
      - Remove a handler for a :mod:`signal`.


.. rubric:: Subprocesses
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`loop.subprocess_exec`
      - Spawn a subprocess.

    * - :meth:`loop.subprocess_shell`
      - Spawn a subprocess from a shell command.


.. rubric:: Error Handling
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`loop.call_exception_handler`
      - Call the exception handler.

    * - :meth:`loop.set_exception_handler`
      - Set a new exception handler.

    * - :meth:`loop.get_exception_handler`
      - Get the current exception handler.

    * - :meth:`loop.default_exception_handler`
      - The default exception handler implementation.


.. rubric:: Examples

* :ref:`Using asyncio.new_event_loop() and loop.run_forever()
  <asyncio_example_lowlevel_helloworld>`.

* :ref:`Using loop.call_later() <asyncio_example_call_later>`.

* Using ``loop.create_connection()`` to implement
  :ref:`an echo-client <asyncio_example_tcp_echo_client_protocol>`.

* Using ``loop.create_connection()`` to
  :ref:`connect a socket <asyncio_example_create_connection>`.

* :ref:`Using add_reader() to watch an FD for read events
  <asyncio_example_watch_fd>`.

* :ref:`Using loop.add_signal_handler() <asyncio_example_unix_signals>`.

* :ref:`Using loop.subprocess_exec() <asyncio_example_subprocess_proto>`.


Transports
==========

All transports implement the following methods:

.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`transport.close() <BaseTransport.close>`
      - Close the transport.

    * - :meth:`transport.is_closing() <BaseTransport.is_closing>`
      - Return ``True`` if the transport is closing or is closed.

    * - :meth:`transport.get_extra_info() <BaseTransport.get_extra_info>`
      - Request for information about the transport.

    * - :meth:`transport.set_protocol() <BaseTransport.set_protocol>`
      - Set a new protocol.

    * - :meth:`transport.get_protocol() <BaseTransport.get_protocol>`
      - Return the current protocol.


Transports that can receive data (TCP and Unix connections,
pipes, etc).  Returned from methods like
:meth:`loop.create_connection`, :meth:`loop.create_unix_connection`,
:meth:`loop.connect_read_pipe`, etc:

.. rubric:: Read Transports
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`transport.is_reading() <ReadTransport.is_reading>`
      - Return ``True`` if the transport is receiving.

    * - :meth:`transport.pause_reading() <ReadTransport.pause_reading>`
      - Pause receiving.

    * - :meth:`transport.resume_reading() <ReadTransport.resume_reading>`
      - Resume receiving.


Transports that can Send data (TCP and Unix connections,
pipes, etc).  Returned from methods like
:meth:`loop.create_connection`, :meth:`loop.create_unix_connection`,
:meth:`loop.connect_write_pipe`, etc:

.. rubric:: Write Transports
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`transport.write() <WriteTransport.write>`
      - Write data to the transport.

    * - :meth:`transport.writelines() <WriteTransport.writelines>`
      - Write buffers to the transport.

    * - :meth:`transport.can_write_eof() <WriteTransport.can_write_eof>`
      - Return :const:`True` if the transport supports sending EOF.

    * - :meth:`transport.write_eof() <WriteTransport.write_eof>`
      - Close and send EOF after flushing buffered data.

    * - :meth:`transport.abort() <WriteTransport.abort>`
      - Close the transport immediately.

    * - :meth:`transport.get_write_buffer_size()
        <WriteTransport.get_write_buffer_size>`
      - Return the current size of the output buffer.

    * - :meth:`transport.get_write_buffer_limits()
        <WriteTransport.get_write_buffer_limits>`
      - Return high and low water marks for write flow control.

    * - :meth:`transport.set_write_buffer_limits()
        <WriteTransport.set_write_buffer_limits>`
      - Set new high and low water marks for write flow control.


Transports returned by :meth:`loop.create_datagram_endpoint`:

.. rubric:: Datagram Transports
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`transport.sendto() <DatagramTransport.sendto>`
      - Send data to the remote peer.

    * - :meth:`transport.abort() <DatagramTransport.abort>`
      - Close the transport immediately.


Low-level transport abstraction over subprocesses.
Returned by :meth:`loop.subprocess_exec` and
:meth:`loop.subprocess_shell`:

.. rubric:: Subprocess Transports
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`transport.get_pid() <SubprocessTransport.get_pid>`
      - Return the subprocess process id.

    * - :meth:`transport.get_pipe_transport()
        <SubprocessTransport.get_pipe_transport>`
      - Return the transport for the requested communication pipe
        (*stdin*, *stdout*, or *stderr*).

    * - :meth:`transport.get_returncode() <SubprocessTransport.get_returncode>`
      - Return the subprocess return code.

    * - :meth:`transport.kill() <SubprocessTransport.kill>`
      - Kill the subprocess.

    * - :meth:`transport.send_signal() <SubprocessTransport.send_signal>`
      - Send a signal to the subprocess.

    * - :meth:`transport.terminate() <SubprocessTransport.terminate>`
      - Stop the subprocess.

    * - :meth:`transport.close() <SubprocessTransport.close>`
      - Kill the subprocess and close all pipes.


Protocols
=========

Protocol classes can implement the following **callback methods**:

.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - ``callback`` :meth:`connection_made() <BaseProtocol.connection_made>`
      - Called when a connection is made.

    * - ``callback`` :meth:`connection_lost() <BaseProtocol.connection_lost>`
      - Called when the connection is lost or closed.

    * - ``callback`` :meth:`pause_writing() <BaseProtocol.pause_writing>`
      - Called when the transport's buffer goes over the high water mark.

    * - ``callback`` :meth:`resume_writing() <BaseProtocol.resume_writing>`
      - Called when the transport's buffer drains below the low water mark.


.. rubric:: Streaming Protocols (TCP, Unix Sockets, Pipes)
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - ``callback`` :meth:`data_received() <Protocol.data_received>`
      - Called when some data is received.

    * - ``callback`` :meth:`eof_received() <Protocol.eof_received>`
      - Called when an EOF is received.


.. rubric:: Buffered Streaming Protocols
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - ``callback`` :meth:`get_buffer() <BufferedProtocol.get_buffer>`
      - Called to allocate a new receive buffer.

    * - ``callback`` :meth:`buffer_updated() <BufferedProtocol.buffer_updated>`
      - Called when the buffer was updated with the received data.

    * - ``callback`` :meth:`eof_received() <BufferedProtocol.eof_received>`
      - Called when an EOF is received.


.. rubric:: Datagram Protocols
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - ``callback`` :meth:`datagram_received()
        <DatagramProtocol.datagram_received>`
      - Called when a datagram is received.

    * - ``callback`` :meth:`error_received() <DatagramProtocol.error_received>`
      - Called when a previous send or receive operation raises an
        :class:`OSError`.


.. rubric:: Subprocess Protocols
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - ``callback`` :meth:`~SubprocessProtocol.pipe_data_received`
      - Called when the child process writes data into its
        *stdout* or *stderr* pipe.

    * - ``callback`` :meth:`~SubprocessProtocol.pipe_connection_lost`
      - Called when one of the pipes communicating with
        the child process is closed.

    * - ``callback`` :meth:`process_exited()
        <SubprocessProtocol.process_exited>`
      - Called when the child process has exited. It can be called before
        :meth:`~SubprocessProtocol.pipe_data_received` and
        :meth:`~SubprocessProtocol.pipe_connection_lost` methods.


Event Loop Policies
===================

Policies is a low-level mechanism to alter the behavior of
functions like :func:`asyncio.get_event_loop`.  See also
the main :ref:`policies section <asyncio-policies>` for more
details.


.. rubric:: Accessing Policies
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`asyncio.get_event_loop_policy`
      - Return the current process-wide policy.

    * - :meth:`asyncio.set_event_loop_policy`
      - Set a new process-wide policy.

    * - :class:`AbstractEventLoopPolicy`
      - Base class for policy objects.


================================================
File: /Doc/library/asyncio-platforms.rst
================================================
.. currentmodule:: asyncio


.. _asyncio-platform-support:


================
Platform Support
================

The :mod:`asyncio` module is designed to be portable,
but some platforms have subtle differences and limitations
due to the platforms' underlying architecture and capabilities.


All Platforms
=============

* :meth:`loop.add_reader` and :meth:`loop.add_writer`
  cannot be used to monitor file I/O.


Windows
=======

**Source code:** :source:`Lib/asyncio/proactor_events.py`,
:source:`Lib/asyncio/windows_events.py`,
:source:`Lib/asyncio/windows_utils.py`

--------------------------------------

.. versionchanged:: 3.8

   On Windows, :class:`ProactorEventLoop` is now the default event loop.

All event loops on Windows do not support the following methods:

* :meth:`loop.create_unix_connection` and
  :meth:`loop.create_unix_server` are not supported.
  The :const:`socket.AF_UNIX` socket family is specific to Unix.

* :meth:`loop.add_signal_handler` and
  :meth:`loop.remove_signal_handler` are not supported.

:class:`SelectorEventLoop` has the following limitations:

* :class:`~selectors.SelectSelector` is used to wait on socket events:
  it supports sockets and is limited to 512 sockets.

* :meth:`loop.add_reader` and :meth:`loop.add_writer` only accept
  socket handles (e.g. pipe file descriptors are not supported).

* Pipes are not supported, so the :meth:`loop.connect_read_pipe`
  and :meth:`loop.connect_write_pipe` methods are not implemented.

* :ref:`Subprocesses <asyncio-subprocess>` are not supported, i.e.
  :meth:`loop.subprocess_exec` and :meth:`loop.subprocess_shell`
  methods are not implemented.

:class:`ProactorEventLoop` has the following limitations:

* The :meth:`loop.add_reader` and :meth:`loop.add_writer`
  methods are not supported.

The resolution of the monotonic clock on Windows is usually around 15.6
milliseconds.  The best resolution is 0.5 milliseconds. The resolution depends on the
hardware (availability of `HPET
<https://en.wikipedia.org/wiki/High_Precision_Event_Timer>`_) and on the
Windows configuration.


.. _asyncio-windows-subprocess:

Subprocess Support on Windows
-----------------------------

On Windows, the default event loop :class:`ProactorEventLoop` supports
subprocesses, whereas :class:`SelectorEventLoop` does not.


macOS
=====

Modern macOS versions are fully supported.

.. rubric:: macOS <= 10.8

On macOS 10.6, 10.7 and 10.8, the default event loop
uses :class:`selectors.KqueueSelector`, which does not support
character devices on these versions.  The :class:`SelectorEventLoop`
can be manually configured to use :class:`~selectors.SelectSelector`
or :class:`~selectors.PollSelector` to support character devices on
these older versions of macOS.  Example::

    import asyncio
    import selectors

    selector = selectors.SelectSelector()
    loop = asyncio.SelectorEventLoop(selector)
    asyncio.set_event_loop(loop)


================================================
File: /Doc/library/asyncio-policy.rst
================================================
.. currentmodule:: asyncio


.. _asyncio-policies:

========
Policies
========

.. warning::

   Policies are deprecated and will be removed in Python 3.16.
   Users are encouraged to use the :func:`asyncio.run` function
   or the :class:`asyncio.Runner` with *loop_factory* to use
   the desired loop implementation.


An event loop policy is a global object
used to get and set the current :ref:`event loop <asyncio-event-loop>`,
as well as create new event loops.
The default policy can be :ref:`replaced <asyncio-policy-get-set>` with
:ref:`built-in alternatives <asyncio-policy-builtin>`
to use different event loop implementations,
or substituted by a :ref:`custom policy <asyncio-custom-policies>`
that can override these behaviors.

The :ref:`policy object <asyncio-policy-objects>`
gets and sets a separate event loop per *context*.
This is per-thread by default,
though custom policies could define *context* differently.

Custom event loop policies can control the behavior of
:func:`get_event_loop`, :func:`set_event_loop`, and :func:`new_event_loop`.

Policy objects should implement the APIs defined
in the :class:`AbstractEventLoopPolicy` abstract base class.


.. _asyncio-policy-get-set:

Getting and Setting the Policy
==============================

The following functions can be used to get and set the policy
for the current process:

.. function:: get_event_loop_policy()

   Return the current process-wide policy.

   .. deprecated:: next
      The :func:`get_event_loop_policy` function is deprecated and
      will be removed in Python 3.16.

.. function:: set_event_loop_policy(policy)

   Set the current process-wide policy to *policy*.

   If *policy* is set to ``None``, the default policy is restored.

   .. deprecated:: next
      The :func:`set_event_loop_policy` function is deprecated and
      will be removed in Python 3.16.


.. _asyncio-policy-objects:

Policy Objects
==============

The abstract event loop policy base class is defined as follows:

.. class:: AbstractEventLoopPolicy

   An abstract base class for asyncio policies.

   .. method:: get_event_loop()

      Get the event loop for the current context.

      Return an event loop object implementing the
      :class:`AbstractEventLoop` interface.

      This method should never return ``None``.

      .. versionchanged:: 3.6

   .. method:: set_event_loop(loop)

      Set the event loop for the current context to *loop*.

   .. method:: new_event_loop()

      Create and return a new event loop object.

      This method should never return ``None``.

   .. deprecated:: next
      The :class:`AbstractEventLoopPolicy` class is deprecated and
      will be removed in Python 3.16.


.. _asyncio-policy-builtin:

asyncio ships with the following built-in policies:


.. class:: DefaultEventLoopPolicy

   The default asyncio policy.  Uses :class:`SelectorEventLoop`
   on Unix and :class:`ProactorEventLoop` on Windows.

   There is no need to install the default policy manually. asyncio
   is configured to use the default policy automatically.

   .. versionchanged:: 3.8

      On Windows, :class:`ProactorEventLoop` is now used by default.

   .. versionchanged:: 3.14
      The :meth:`get_event_loop` method of the default asyncio policy now
      raises a :exc:`RuntimeError` if there is no set event loop.

   .. deprecated:: next
      The :class:`DefaultEventLoopPolicy` class is deprecated and
      will be removed in Python 3.16.


.. class:: WindowsSelectorEventLoopPolicy

   An alternative event loop policy that uses the
   :class:`SelectorEventLoop` event loop implementation.

   .. availability:: Windows.

   .. deprecated:: next
      The :class:`WindowsSelectorEventLoopPolicy` class is deprecated and
      will be removed in Python 3.16.


.. class:: WindowsProactorEventLoopPolicy

   An alternative event loop policy that uses the
   :class:`ProactorEventLoop` event loop implementation.

   .. availability:: Windows.

   .. deprecated:: next
      The :class:`WindowsProactorEventLoopPolicy` class is deprecated and
      will be removed in Python 3.16.


.. _asyncio-custom-policies:

Custom Policies
===============

To implement a new event loop policy, it is recommended to subclass
:class:`DefaultEventLoopPolicy` and override the methods for which
custom behavior is wanted, e.g.::

    class MyEventLoopPolicy(asyncio.DefaultEventLoopPolicy):

        def get_event_loop(self):
            """Get the event loop.

            This may be None or an instance of EventLoop.
            """
            loop = super().get_event_loop()
            # Do something with loop ...
            return loop

    asyncio.set_event_loop_policy(MyEventLoopPolicy())


================================================
File: /Doc/library/asyncio-protocol.rst
================================================
.. currentmodule:: asyncio


.. _asyncio-transports-protocols:


========================
Transports and Protocols
========================

.. rubric:: Preface

Transports and Protocols are used by the **low-level** event loop
APIs such as :meth:`loop.create_connection`.  They use
callback-based programming style and enable high-performance
implementations of network or IPC protocols (e.g. HTTP).

Essentially, transports and protocols should only be used in
libraries and frameworks and never in high-level asyncio
applications.

This documentation page covers both `Transports`_ and `Protocols`_.

.. rubric:: Introduction

At the highest level, the transport is concerned with *how* bytes
are transmitted, while the protocol determines *which* bytes to
transmit (and to some extent when).

A different way of saying the same thing: a transport is an
abstraction for a socket (or similar I/O endpoint) while a protocol
is an abstraction for an application, from the transport's point
of view.

Yet another view is the transport and protocol interfaces
together define an abstract interface for using network I/O and
interprocess I/O.

There is always a 1:1 relationship between transport and protocol
objects: the protocol calls transport methods to send data,
while the transport calls protocol methods to pass it data that
has been received.

Most of connection oriented event loop methods
(such as :meth:`loop.create_connection`) usually accept a
*protocol_factory* argument used to create a *Protocol* object
for an accepted connection, represented by a *Transport* object.
Such methods usually return a tuple of ``(transport, protocol)``.

.. rubric:: Contents

This documentation page contains the following sections:

* The `Transports`_ section documents asyncio :class:`BaseTransport`,
  :class:`ReadTransport`, :class:`WriteTransport`, :class:`Transport`,
  :class:`DatagramTransport`, and :class:`SubprocessTransport`
  classes.

* The `Protocols`_ section documents asyncio :class:`BaseProtocol`,
  :class:`Protocol`, :class:`BufferedProtocol`,
  :class:`DatagramProtocol`, and :class:`SubprocessProtocol` classes.

* The `Examples`_ section showcases how to work with transports,
  protocols, and low-level event loop APIs.


.. _asyncio-transport:

Transports
==========

**Source code:** :source:`Lib/asyncio/transports.py`

----------------------------------------------------

Transports are classes provided by :mod:`asyncio` in order to abstract
various kinds of communication channels.

Transport objects are always instantiated by an
:ref:`asyncio event loop <asyncio-event-loop>`.

asyncio implements transports for TCP, UDP, SSL, and subprocess pipes.
The methods available on a transport depend on the transport's kind.

The transport classes are :ref:`not thread safe <asyncio-multithreading>`.


Transports Hierarchy
--------------------

.. class:: BaseTransport

   Base class for all transports.  Contains methods that all
   asyncio transports share.

.. class:: WriteTransport(BaseTransport)

   A base transport for write-only connections.

   Instances of the *WriteTransport* class are returned from
   the :meth:`loop.connect_write_pipe` event loop method and
   are also used by subprocess-related methods like
   :meth:`loop.subprocess_exec`.

.. class:: ReadTransport(BaseTransport)

   A base transport for read-only connections.

   Instances of the *ReadTransport* class are returned from
   the :meth:`loop.connect_read_pipe` event loop method and
   are also used by subprocess-related methods like
   :meth:`loop.subprocess_exec`.

.. class:: Transport(WriteTransport, ReadTransport)

   Interface representing a bidirectional transport, such as a
   TCP connection.

   The user does not instantiate a transport directly; they call a
   utility function, passing it a protocol factory and other
   information necessary to create the transport and protocol.

   Instances of the *Transport* class are returned from or used by
   event loop methods like :meth:`loop.create_connection`,
   :meth:`loop.create_unix_connection`,
   :meth:`loop.create_server`, :meth:`loop.sendfile`, etc.


.. class:: DatagramTransport(BaseTransport)

   A transport for datagram (UDP) connections.

   Instances of the *DatagramTransport* class are returned from
   the :meth:`loop.create_datagram_endpoint` event loop method.


.. class:: SubprocessTransport(BaseTransport)

   An abstraction to represent a connection between a parent and its
   child OS process.

   Instances of the *SubprocessTransport* class are returned from
   event loop methods :meth:`loop.subprocess_shell` and
   :meth:`loop.subprocess_exec`.


Base Transport
--------------

.. method:: BaseTransport.close()

   Close the transport.

   If the transport has a buffer for outgoing
   data, buffered data will be flushed asynchronously.  No more data
   will be received.  After all buffered data is flushed, the
   protocol's :meth:`protocol.connection_lost()
   <BaseProtocol.connection_lost>` method will be called with
   :const:`None` as its argument. The transport should not be
   used once it is closed.

.. method:: BaseTransport.is_closing()

   Return ``True`` if the transport is closing or is closed.

.. method:: BaseTransport.get_extra_info(name, default=None)

   Return information about the transport or underlying resources
   it uses.

   *name* is a string representing the piece of transport-specific
   information to get.

   *default* is the value to return if the information is not
   available, or if the transport does not support querying it
   with the given third-party event loop implementation or on the
   current platform.

   For example, the following code attempts to get the underlying
   socket object of the transport::

      sock = transport.get_extra_info('socket')
      if sock is not None:
          print(sock.getsockopt(...))

   Categories of information that can be queried on some transports:

   * socket:

     - ``'peername'``: the remote address to which the socket is
       connected, result of :meth:`socket.socket.getpeername`
       (``None`` on error)

     - ``'socket'``: :class:`socket.socket` instance

     - ``'sockname'``: the socket's own address,
       result of :meth:`socket.socket.getsockname`

   * SSL socket:

     - ``'compression'``: the compression algorithm being used as a
       string, or ``None`` if the connection isn't compressed; result
       of :meth:`ssl.SSLSocket.compression`

     - ``'cipher'``: a three-value tuple containing the name of the
       cipher being used, the version of the SSL protocol that defines
       its use, and the number of secret bits being used; result of
       :meth:`ssl.SSLSocket.cipher`

     - ``'peercert'``: peer certificate; result of
       :meth:`ssl.SSLSocket.getpeercert`

     - ``'sslcontext'``: :class:`ssl.SSLContext` instance

     - ``'ssl_object'``: :class:`ssl.SSLObject` or
       :class:`ssl.SSLSocket` instance

   * pipe:

     - ``'pipe'``: pipe object

   * subprocess:

     - ``'subprocess'``: :class:`subprocess.Popen` instance

.. method:: BaseTransport.set_protocol(protocol)

   Set a new protocol.

   Switching protocol should only be done when both
   protocols are documented to support the switch.

.. method:: BaseTransport.get_protocol()

   Return the current protocol.


Read-only Transports
--------------------

.. method:: ReadTransport.is_reading()

   Return ``True`` if the transport is receiving new data.

   .. versionadded:: 3.7

.. method:: ReadTransport.pause_reading()

   Pause the receiving end of the transport.  No data will be passed to
   the protocol's :meth:`protocol.data_received() <Protocol.data_received>`
   method until :meth:`resume_reading` is called.

   .. versionchanged:: 3.7
      The method is idempotent, i.e. it can be called when the
      transport is already paused or closed.

.. method:: ReadTransport.resume_reading()

   Resume the receiving end.  The protocol's
   :meth:`protocol.data_received() <Protocol.data_received>` method
   will be called once again if some data is available for reading.

   .. versionchanged:: 3.7
      The method is idempotent, i.e. it can be called when the
      transport is already reading.


Write-only Transports
---------------------

.. method:: WriteTransport.abort()

   Close the transport immediately, without waiting for pending operations
   to complete.  Buffered data will be lost.  No more data will be received.
   The protocol's :meth:`protocol.connection_lost()
   <BaseProtocol.connection_lost>` method will eventually be
   called with :const:`None` as its argument.

.. method:: WriteTransport.can_write_eof()

   Return :const:`True` if the transport supports
   :meth:`~WriteTransport.write_eof`, :const:`False` if not.

.. method:: WriteTransport.get_write_buffer_size()

   Return the current size of the output buffer used by the transport.

.. method:: WriteTransport.get_write_buffer_limits()

   Get the *high* and *low* watermarks for write flow control. Return a
   tuple ``(low, high)`` where *low* and *high* are positive number of
   bytes.

   Use :meth:`set_write_buffer_limits` to set the limits.

   .. versionadded:: 3.4.2

.. method:: WriteTransport.set_write_buffer_limits(high=None, low=None)

   Set the *high* and *low* watermarks for write flow control.

   These two values (measured in number of
   bytes) control when the protocol's
   :meth:`protocol.pause_writing() <BaseProtocol.pause_writing>`
   and :meth:`protocol.resume_writing() <BaseProtocol.resume_writing>`
   methods are called. If specified, the low watermark must be less
   than or equal to the high watermark.  Neither *high* nor *low*
   can be negative.

   :meth:`~BaseProtocol.pause_writing` is called when the buffer size
   becomes greater than or equal to the *high* value. If writing has
   been paused, :meth:`~BaseProtocol.resume_writing` is called when
   the buffer size becomes less than or equal to the *low* value.

   The defaults are implementation-specific.  If only the
   high watermark is given, the low watermark defaults to an
   implementation-specific value less than or equal to the
   high watermark.  Setting *high* to zero forces *low* to zero as
   well, and causes :meth:`~BaseProtocol.pause_writing` to be called
   whenever the buffer becomes non-empty.  Setting *low* to zero causes
   :meth:`~BaseProtocol.resume_writing` to be called only once the
   buffer is empty. Use of zero for either limit is generally
   sub-optimal as it reduces opportunities for doing I/O and
   computation concurrently.

   Use :meth:`~WriteTransport.get_write_buffer_limits`
   to get the limits.

.. method:: WriteTransport.write(data)

   Write some *data* bytes to the transport.

   This method does not block; it buffers the data and arranges for it
   to be sent out asynchronously.

.. method:: WriteTransport.writelines(list_of_data)

   Write a list (or any iterable) of data bytes to the transport.
   This is functionally equivalent to calling :meth:`write` on each
   element yielded by the iterable, but may be implemented more
   efficiently.

.. method:: WriteTransport.write_eof()

   Close the write end of the transport after flushing all buffered data.
   Data may still be received.

   This method can raise :exc:`NotImplementedError` if the transport
   (e.g. SSL) doesn't support half-closed connections.


Datagram Transports
-------------------

.. method:: DatagramTransport.sendto(data, addr=None)

   Send the *data* bytes to the remote peer given by *addr* (a
   transport-dependent target address).  If *addr* is :const:`None`,
   the data is sent to the target address given on transport
   creation.

   This method does not block; it buffers the data and arranges
   for it to be sent out asynchronously.

   .. versionchanged:: 3.13
      This method can be called with an empty bytes object to send a
      zero-length datagram. The buffer size calculation used for flow
      control is also updated to account for the datagram header.

.. method:: DatagramTransport.abort()

   Close the transport immediately, without waiting for pending
   operations to complete.  Buffered data will be lost.
   No more data will be received.  The protocol's
   :meth:`protocol.connection_lost() <BaseProtocol.connection_lost>`
   method will eventually be called with :const:`None` as its argument.


.. _asyncio-subprocess-transports:

Subprocess Transports
---------------------

.. method:: SubprocessTransport.get_pid()

   Return the subprocess process id as an integer.

.. method:: SubprocessTransport.get_pipe_transport(fd)

   Return the transport for the communication pipe corresponding to the
   integer file descriptor *fd*:

   * ``0``: readable streaming transport of the standard input (*stdin*),
     or :const:`None` if the subprocess was not created with ``stdin=PIPE``
   * ``1``: writable streaming transport of the standard output (*stdout*),
     or :const:`None` if the subprocess was not created with ``stdout=PIPE``
   * ``2``: writable streaming transport of the standard error (*stderr*),
     or :const:`None` if the subprocess was not created with ``stderr=PIPE``
   * other *fd*: :const:`None`

.. method:: SubprocessTransport.get_returncode()

   Return the subprocess return code as an integer or :const:`None`
   if it hasn't returned, which is similar to the
   :attr:`subprocess.Popen.returncode` attribute.

.. method:: SubprocessTransport.kill()

   Kill the subprocess.

   On POSIX systems, the function sends SIGKILL to the subprocess.
   On Windows, this method is an alias for :meth:`terminate`.

   See also :meth:`subprocess.Popen.kill`.

.. method:: SubprocessTransport.send_signal(signal)

   Send the *signal* number to the subprocess, as in
   :meth:`subprocess.Popen.send_signal`.

.. method:: SubprocessTransport.terminate()

   Stop the subprocess.

   On POSIX systems, this method sends :py:const:`~signal.SIGTERM` to the subprocess.
   On Windows, the Windows API function :c:func:`!TerminateProcess` is called to
   stop the subprocess.

   See also :meth:`subprocess.Popen.terminate`.

.. method:: SubprocessTransport.close()

   Kill the subprocess by calling the :meth:`kill` method.

   If the subprocess hasn't returned yet, and close transports of
   *stdin*, *stdout*, and *stderr* pipes.


.. _asyncio-protocol:

Protocols
=========

**Source code:** :source:`Lib/asyncio/protocols.py`

---------------------------------------------------

asyncio provides a set of abstract base classes that should be used
to implement network protocols.  Those classes are meant to be used
together with :ref:`transports <asyncio-transport>`.

Subclasses of abstract base protocol classes may implement some or
all methods.  All these methods are callbacks: they are called by
transports on certain events, for example when some data is received.
A base protocol method should be called by the corresponding transport.


Base Protocols
--------------

.. class:: BaseProtocol

   Base protocol with methods that all protocols share.

.. class:: Protocol(BaseProtocol)

   The base class for implementing streaming protocols
   (TCP, Unix sockets, etc).

.. class:: BufferedProtocol(BaseProtocol)

   A base class for implementing streaming protocols with manual
   control of the receive buffer.

.. class:: DatagramProtocol(BaseProtocol)

   The base class for implementing datagram (UDP) protocols.

.. class:: SubprocessProtocol(BaseProtocol)

   The base class for implementing protocols communicating with child
   processes (unidirectional pipes).


Base Protocol
-------------

All asyncio protocols can implement Base Protocol callbacks.

.. rubric:: Connection Callbacks

Connection callbacks are called on all protocols, exactly once per
a successful connection.  All other protocol callbacks can only be
called between those two methods.

.. method:: BaseProtocol.connection_made(transport)

   Called when a connection is made.

   The *transport* argument is the transport representing the
   connection.  The protocol is responsible for storing the reference
   to its transport.

.. method:: BaseProtocol.connection_lost(exc)

   Called when the connection is lost or closed.

   The argument is either an exception object or :const:`None`.
   The latter means a regular EOF is received, or the connection was
   aborted or closed by this side of the connection.


.. rubric:: Flow Control Callbacks

Flow control callbacks can be called by transports to pause or
resume writing performed by the protocol.

See the documentation of the :meth:`~WriteTransport.set_write_buffer_limits`
method for more details.

.. method:: BaseProtocol.pause_writing()

   Called when the transport's buffer goes over the high watermark.

.. method:: BaseProtocol.resume_writing()

   Called when the transport's buffer drains below the low watermark.

If the buffer size equals the high watermark,
:meth:`~BaseProtocol.pause_writing` is not called: the buffer size must
go strictly over.

Conversely, :meth:`~BaseProtocol.resume_writing` is called when the
buffer size is equal or lower than the low watermark.  These end
conditions are important to ensure that things go as expected when
either mark is zero.


Streaming Protocols
-------------------

Event methods, such as :meth:`loop.create_server`,
:meth:`loop.create_unix_server`, :meth:`loop.create_connection`,
:meth:`loop.create_unix_connection`, :meth:`loop.connect_accepted_socket`,
:meth:`loop.connect_read_pipe`, and :meth:`loop.connect_write_pipe`
accept factories that return streaming protocols.

.. method:: Protocol.data_received(data)

   Called when some data is received.  *data* is a non-empty bytes
   object containing the incoming data.

   Whether the data is buffered, chunked or reassembled depends on
   the transport.  In general, you shouldn't rely on specific semantics
   and instead make your parsing generic and flexible. However,
   data is always received in the correct order.

   The method can be called an arbitrary number of times while
   a connection is open.

   However, :meth:`protocol.eof_received() <Protocol.eof_received>`
   is called at most once.  Once ``eof_received()`` is called,
   ``data_received()`` is not called anymore.

.. method:: Protocol.eof_received()

   Called when the other end signals it won't send any more data
   (for example by calling :meth:`transport.write_eof()
   <WriteTransport.write_eof>`, if the other end also uses
   asyncio).

   This method may return a false value (including ``None``), in which case
   the transport will close itself.  Conversely, if this method returns a
   true value, the protocol used determines whether to close the transport.
   Since the default implementation returns ``None``, it implicitly closes the
   connection.

   Some transports, including SSL, don't support half-closed connections,
   in which case returning true from this method will result in the connection
   being closed.


State machine:

.. code-block:: none

    start -> connection_made
        [-> data_received]*
        [-> eof_received]?
    -> connection_lost -> end


Buffered Streaming Protocols
----------------------------

.. versionadded:: 3.7

Buffered Protocols can be used with any event loop method
that supports `Streaming Protocols`_.

``BufferedProtocol`` implementations allow explicit manual allocation
and control of the receive buffer.  Event loops can then use the buffer
provided by the protocol to avoid unnecessary data copies.  This
can result in noticeable performance improvement for protocols that
receive big amounts of data.  Sophisticated protocol implementations
can significantly reduce the number of buffer allocations.

The following callbacks are called on :class:`BufferedProtocol`
instances:

.. method:: BufferedProtocol.get_buffer(sizehint)

   Called to allocate a new receive buffer.

   *sizehint* is the recommended minimum size for the returned
   buffer.  It is acceptable to return smaller or larger buffers
   than what *sizehint* suggests.  When set to -1, the buffer size
   can be arbitrary. It is an error to return a buffer with a zero size.

   ``get_buffer()`` must return an object implementing the
   :ref:`buffer protocol <bufferobjects>`.

.. method:: BufferedProtocol.buffer_updated(nbytes)

   Called when the buffer was updated with the received data.

   *nbytes* is the total number of bytes that were written to the buffer.

.. method:: BufferedProtocol.eof_received()

   See the documentation of the :meth:`protocol.eof_received()
   <Protocol.eof_received>` method.


:meth:`~BufferedProtocol.get_buffer` can be called an arbitrary number
of times during a connection.  However, :meth:`protocol.eof_received()
<Protocol.eof_received>` is called at most once
and, if called, :meth:`~BufferedProtocol.get_buffer` and
:meth:`~BufferedProtocol.buffer_updated` won't be called after it.

State machine:

.. code-block:: none

    start -> connection_made
        [-> get_buffer
            [-> buffer_updated]?
        ]*
        [-> eof_received]?
    -> connection_lost -> end


Datagram Protocols
------------------

Datagram Protocol instances should be constructed by protocol
factories passed to the :meth:`loop.create_datagram_endpoint` method.

.. method:: DatagramProtocol.datagram_received(data, addr)

   Called when a datagram is received.  *data* is a bytes object containing
   the incoming data.  *addr* is the address of the peer sending the data;
   the exact format depends on the transport.

.. method:: DatagramProtocol.error_received(exc)

   Called when a previous send or receive operation raises an
   :class:`OSError`.  *exc* is the :class:`OSError` instance.

   This method is called in rare conditions, when the transport (e.g. UDP)
   detects that a datagram could not be delivered to its recipient.
   In many conditions though, undeliverable datagrams will be silently
   dropped.

.. note::

   On BSD systems (macOS, FreeBSD, etc.) flow control is not supported
   for datagram protocols, because there is no reliable way to detect send
   failures caused by writing too many packets.

   The socket always appears 'ready' and excess packets are dropped. An
   :class:`OSError` with ``errno`` set to :const:`errno.ENOBUFS` may
   or may not be raised; if it is raised, it will be reported to
   :meth:`DatagramProtocol.error_received` but otherwise ignored.


.. _asyncio-subprocess-protocols:

Subprocess Protocols
--------------------

Subprocess Protocol instances should be constructed by protocol
factories passed to the :meth:`loop.subprocess_exec` and
:meth:`loop.subprocess_shell` methods.

.. method:: SubprocessProtocol.pipe_data_received(fd, data)

   Called when the child process writes data into its stdout or stderr
   pipe.

   *fd* is the integer file descriptor of the pipe.

   *data* is a non-empty bytes object containing the received data.

.. method:: SubprocessProtocol.pipe_connection_lost(fd, exc)

   Called when one of the pipes communicating with the child process
   is closed.

   *fd* is the integer file descriptor that was closed.

.. method:: SubprocessProtocol.process_exited()

   Called when the child process has exited.

   It can be called before :meth:`~SubprocessProtocol.pipe_data_received` and
   :meth:`~SubprocessProtocol.pipe_connection_lost` methods.


Examples
========

.. _asyncio_example_tcp_echo_server_protocol:

TCP Echo Server
---------------

Create a TCP echo server using the :meth:`loop.create_server` method, send back
received data, and close the connection::

    import asyncio


    class EchoServerProtocol(asyncio.Protocol):
        def connection_made(self, transport):
            peername = transport.get_extra_info('peername')
            print('Connection from {}'.format(peername))
            self.transport = transport

        def data_received(self, data):
            message = data.decode()
            print('Data received: {!r}'.format(message))

            print('Send: {!r}'.format(message))
            self.transport.write(data)

            print('Close the client socket')
            self.transport.close()


    async def main():
        # Get a reference to the event loop as we plan to use
        # low-level APIs.
        loop = asyncio.get_running_loop()

        server = await loop.create_server(
            EchoServerProtocol,
            '127.0.0.1', 8888)

        async with server:
            await server.serve_forever()


    asyncio.run(main())


.. seealso::

   The :ref:`TCP echo server using streams <asyncio-tcp-echo-server-streams>`
   example uses the high-level :func:`asyncio.start_server` function.

.. _asyncio_example_tcp_echo_client_protocol:

TCP Echo Client
---------------

A TCP echo client using the :meth:`loop.create_connection` method, sends
data, and waits until the connection is closed::

    import asyncio


    class EchoClientProtocol(asyncio.Protocol):
        def __init__(self, message, on_con_lost):
            self.message = message
            self.on_con_lost = on_con_lost

        def connection_made(self, transport):
            transport.write(self.message.encode())
            print('Data sent: {!r}'.format(self.message))

        def data_received(self, data):
            print('Data received: {!r}'.format(data.decode()))

        def connection_lost(self, exc):
            print('The server closed the connection')
            self.on_con_lost.set_result(True)


    async def main():
        # Get a reference to the event loop as we plan to use
        # low-level APIs.
        loop = asyncio.get_running_loop()

        on_con_lost = loop.create_future()
        message = 'Hello World!'

        transport, protocol = await loop.create_connection(
            lambda: EchoClientProtocol(message, on_con_lost),
            '127.0.0.1', 8888)

        # Wait until the protocol signals that the connection
        # is lost and close the transport.
        try:
            await on_con_lost
        finally:
            transport.close()


    asyncio.run(main())


.. seealso::

   The :ref:`TCP echo client using streams <asyncio-tcp-echo-client-streams>`
   example uses the high-level :func:`asyncio.open_connection` function.


.. _asyncio-udp-echo-server-protocol:

UDP Echo Server
---------------

A UDP echo server, using the :meth:`loop.create_datagram_endpoint`
method, sends back received data::

    import asyncio


    class EchoServerProtocol:
        def connection_made(self, transport):
            self.transport = transport

        def datagram_received(self, data, addr):
            message = data.decode()
            print('Received %r from %s' % (message, addr))
            print('Send %r to %s' % (message, addr))
            self.transport.sendto(data, addr)


    async def main():
        print("Starting UDP server")

        # Get a reference to the event loop as we plan to use
        # low-level APIs.
        loop = asyncio.get_running_loop()

        # One protocol instance will be created to serve all
        # client requests.
        transport, protocol = await loop.create_datagram_endpoint(
            EchoServerProtocol,
            local_addr=('127.0.0.1', 9999))

        try:
            await asyncio.sleep(3600)  # Serve for 1 hour.
        finally:
            transport.close()


    asyncio.run(main())


.. _asyncio-udp-echo-client-protocol:

UDP Echo Client
---------------

A UDP echo client, using the :meth:`loop.create_datagram_endpoint`
method, sends data and closes the transport when it receives the answer::

    import asyncio


    class EchoClientProtocol:
        def __init__(self, message, on_con_lost):
            self.message = message
            self.on_con_lost = on_con_lost
            self.transport = None

        def connection_made(self, transport):
            self.transport = transport
            print('Send:', self.message)
            self.transport.sendto(self.message.encode())

        def datagram_received(self, data, addr):
            print("Received:", data.decode())

            print("Close the socket")
            self.transport.close()

        def error_received(self, exc):
            print('Error received:', exc)

        def connection_lost(self, exc):
            print("Connection closed")
            self.on_con_lost.set_result(True)


    async def main():
        # Get a reference to the event loop as we plan to use
        # low-level APIs.
        loop = asyncio.get_running_loop()

        on_con_lost = loop.create_future()
        message = "Hello World!"

        transport, protocol = await loop.create_datagram_endpoint(
            lambda: EchoClientProtocol(message, on_con_lost),
            remote_addr=('127.0.0.1', 9999))

        try:
            await on_con_lost
        finally:
            transport.close()


    asyncio.run(main())


.. _asyncio_example_create_connection:

Connecting Existing Sockets
---------------------------

Wait until a socket receives data using the
:meth:`loop.create_connection` method with a protocol::

    import asyncio
    import socket


    class MyProtocol(asyncio.Protocol):

        def __init__(self, on_con_lost):
            self.transport = None
            self.on_con_lost = on_con_lost

        def connection_made(self, transport):
            self.transport = transport

        def data_received(self, data):
            print("Received:", data.decode())

            # We are done: close the transport;
            # connection_lost() will be called automatically.
            self.transport.close()

        def connection_lost(self, exc):
            # The socket has been closed
            self.on_con_lost.set_result(True)


    async def main():
        # Get a reference to the event loop as we plan to use
        # low-level APIs.
        loop = asyncio.get_running_loop()
        on_con_lost = loop.create_future()

        # Create a pair of connected sockets
        rsock, wsock = socket.socketpair()

        # Register the socket to wait for data.
        transport, protocol = await loop.create_connection(
            lambda: MyProtocol(on_con_lost), sock=rsock)

        # Simulate the reception of data from the network.
        loop.call_soon(wsock.send, 'abc'.encode())

        try:
            await protocol.on_con_lost
        finally:
            transport.close()
            wsock.close()

    asyncio.run(main())

.. seealso::

   The :ref:`watch a file descriptor for read events
   <asyncio_example_watch_fd>` example uses the low-level
   :meth:`loop.add_reader` method to register an FD.

   The :ref:`register an open socket to wait for data using streams
   <asyncio_example_create_connection-streams>` example uses high-level streams
   created by the :func:`open_connection` function in a coroutine.

.. _asyncio_example_subprocess_proto:

loop.subprocess_exec() and SubprocessProtocol
---------------------------------------------

An example of a subprocess protocol used to get the output of a
subprocess and to wait for the subprocess exit.

The subprocess is created by the :meth:`loop.subprocess_exec` method::

    import asyncio
    import sys

    class DateProtocol(asyncio.SubprocessProtocol):
        def __init__(self, exit_future):
            self.exit_future = exit_future
            self.output = bytearray()
            self.pipe_closed = False
            self.exited = False

        def pipe_connection_lost(self, fd, exc):
            self.pipe_closed = True
            self.check_for_exit()

        def pipe_data_received(self, fd, data):
            self.output.extend(data)

        def process_exited(self):
            self.exited = True
            # process_exited() method can be called before
            # pipe_connection_lost() method: wait until both methods are
            # called.
            self.check_for_exit()

        def check_for_exit(self):
            if self.pipe_closed and self.exited:
                self.exit_future.set_result(True)

    async def get_date():
        # Get a reference to the event loop as we plan to use
        # low-level APIs.
        loop = asyncio.get_running_loop()

        code = 'import datetime; print(datetime.datetime.now())'
        exit_future = asyncio.Future(loop=loop)

        # Create the subprocess controlled by DateProtocol;
        # redirect the standard output into a pipe.
        transport, protocol = await loop.subprocess_exec(
            lambda: DateProtocol(exit_future),
            sys.executable, '-c', code,
            stdin=None, stderr=None)

        # Wait for the subprocess exit using the process_exited()
        # method of the protocol.
        await exit_future

        # Close the stdout pipe.
        transport.close()

        # Read the output which was collected by the
        # pipe_data_received() method of the protocol.
        data = bytes(protocol.output)
        return data.decode('ascii').rstrip()

    date = asyncio.run(get_date())
    print(f"Current date: {date}")

See also the :ref:`same example <asyncio_example_create_subprocess_exec>`
written using high-level APIs.


================================================
File: /Doc/library/asyncio-queue.rst
================================================
.. currentmodule:: asyncio

.. _asyncio-queues:

======
Queues
======

**Source code:** :source:`Lib/asyncio/queues.py`

------------------------------------------------

asyncio queues are designed to be similar to classes of the
:mod:`queue` module.  Although asyncio queues are not thread-safe,
they are designed to be used specifically in async/await code.

Note that methods of asyncio queues don't have a *timeout* parameter;
use :func:`asyncio.wait_for` function to do queue operations with a
timeout.

See also the `Examples`_ section below.

Queue
=====

.. class:: Queue(maxsize=0)

   A first in, first out (FIFO) queue.

   If *maxsize* is less than or equal to zero, the queue size is
   infinite.  If it is an integer greater than ``0``, then
   ``await put()`` blocks when the queue reaches *maxsize*
   until an item is removed by :meth:`get`.

   Unlike the standard library threading :mod:`queue`, the size of
   the queue is always known and can be returned by calling the
   :meth:`qsize` method.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.


   This class is :ref:`not thread safe <asyncio-multithreading>`.

   .. attribute:: maxsize

      Number of items allowed in the queue.

   .. method:: empty()

      Return ``True`` if the queue is empty, ``False`` otherwise.

   .. method:: full()

      Return ``True`` if there are :attr:`maxsize` items in the queue.

      If the queue was initialized with ``maxsize=0`` (the default),
      then :meth:`full` never returns ``True``.

   .. coroutinemethod:: get()

      Remove and return an item from the queue. If queue is empty,
      wait until an item is available.

      Raises :exc:`QueueShutDown` if the queue has been shut down and
      is empty, or if the queue has been shut down immediately.

   .. method:: get_nowait()

      Return an item if one is immediately available, else raise
      :exc:`QueueEmpty`.

   .. coroutinemethod:: join()

      Block until all items in the queue have been received and processed.

      The count of unfinished tasks goes up whenever an item is added
      to the queue. The count goes down whenever a consumer coroutine calls
      :meth:`task_done` to indicate that the item was retrieved and all
      work on it is complete.  When the count of unfinished tasks drops
      to zero, :meth:`join` unblocks.

   .. coroutinemethod:: put(item)

      Put an item into the queue. If the queue is full, wait until a
      free slot is available before adding the item.

      Raises :exc:`QueueShutDown` if the queue has been shut down.

   .. method:: put_nowait(item)

      Put an item into the queue without blocking.

      If no free slot is immediately available, raise :exc:`QueueFull`.

   .. method:: qsize()

      Return the number of items in the queue.

   .. method:: shutdown(immediate=False)

      Shut down the queue, making :meth:`~Queue.get` and :meth:`~Queue.put`
      raise :exc:`QueueShutDown`.

      By default, :meth:`~Queue.get` on a shut down queue will only
      raise once the queue is empty. Set *immediate* to true to make
      :meth:`~Queue.get` raise immediately instead.

      All blocked callers of :meth:`~Queue.put` and :meth:`~Queue.get`
      will be unblocked. If *immediate* is true, a task will be marked
      as done for each remaining item in the queue, which may unblock
      callers of :meth:`~Queue.join`.

      .. versionadded:: 3.13

   .. method:: task_done()

      Indicate that a formerly enqueued work item is complete.

      Used by queue consumers. For each :meth:`~Queue.get` used to
      fetch a work item, a subsequent call to :meth:`task_done` tells the
      queue that the processing on the work item is complete.

      If a :meth:`join` is currently blocking, it will resume when all
      items have been processed (meaning that a :meth:`task_done`
      call was received for every item that had been :meth:`~Queue.put`
      into the queue).

      ``shutdown(immediate=True)`` calls :meth:`task_done` for each
      remaining item in the queue.

      Raises :exc:`ValueError` if called more times than there were
      items placed in the queue.


Priority Queue
==============

.. class:: PriorityQueue

   A variant of :class:`Queue`; retrieves entries in priority order
   (lowest first).

   Entries are typically tuples of the form
   ``(priority_number, data)``.


LIFO Queue
==========

.. class:: LifoQueue

   A variant of :class:`Queue` that retrieves most recently added
   entries first (last in, first out).


Exceptions
==========

.. exception:: QueueEmpty

   This exception is raised when the :meth:`~Queue.get_nowait` method
   is called on an empty queue.


.. exception:: QueueFull

   Exception raised when the :meth:`~Queue.put_nowait` method is called
   on a queue that has reached its *maxsize*.


.. exception:: QueueShutDown

   Exception raised when :meth:`~Queue.put` or :meth:`~Queue.get` is
   called on a queue which has been shut down.

   .. versionadded:: 3.13


Examples
========

.. _asyncio_example_queue_dist:

Queues can be used to distribute workload between several
concurrent tasks::

   import asyncio
   import random
   import time


   async def worker(name, queue):
       while True:
           # Get a "work item" out of the queue.
           sleep_for = await queue.get()

           # Sleep for the "sleep_for" seconds.
           await asyncio.sleep(sleep_for)

           # Notify the queue that the "work item" has been processed.
           queue.task_done()

           print(f'{name} has slept for {sleep_for:.2f} seconds')


   async def main():
       # Create a queue that we will use to store our "workload".
       queue = asyncio.Queue()

       # Generate random timings and put them into the queue.
       total_sleep_time = 0
       for _ in range(20):
           sleep_for = random.uniform(0.05, 1.0)
           total_sleep_time += sleep_for
           queue.put_nowait(sleep_for)

       # Create three worker tasks to process the queue concurrently.
       tasks = []
       for i in range(3):
           task = asyncio.create_task(worker(f'worker-{i}', queue))
           tasks.append(task)

       # Wait until the queue is fully processed.
       started_at = time.monotonic()
       await queue.join()
       total_slept_for = time.monotonic() - started_at

       # Cancel our worker tasks.
       for task in tasks:
           task.cancel()
       # Wait until all worker tasks are cancelled.
       await asyncio.gather(*tasks, return_exceptions=True)

       print('====')
       print(f'3 workers slept in parallel for {total_slept_for:.2f} seconds')
       print(f'total expected sleep time: {total_sleep_time:.2f} seconds')


   asyncio.run(main())


================================================
File: /Doc/library/asyncio-runner.rst
================================================
.. currentmodule:: asyncio


=======
Runners
=======

**Source code:** :source:`Lib/asyncio/runners.py`


This section outlines high-level asyncio primitives to run asyncio code.

They are built on top of an :ref:`event loop <asyncio-event-loop>` with the aim
to simplify async code usage for common wide-spread scenarios.

.. contents::
   :depth: 1
   :local:



Running an asyncio Program
==========================

.. function:: run(coro, *, debug=None, loop_factory=None)

   Execute *coro* in an asyncio event loop and return the result.

   The argument can be any awaitable object.

   This function runs the awaitable, taking care of managing the
   asyncio event loop, *finalizing asynchronous generators*, and
   closing the executor.

   This function cannot be called when another asyncio event loop is
   running in the same thread.

   If *debug* is ``True``, the event loop will be run in debug mode. ``False`` disables
   debug mode explicitly. ``None`` is used to respect the global
   :ref:`asyncio-debug-mode` settings.

   If *loop_factory* is not ``None``, it is used to create a new event loop;
   otherwise :func:`asyncio.new_event_loop` is used. The loop is closed at the end.
   This function should be used as a main entry point for asyncio programs,
   and should ideally only be called once. It is recommended to use
   *loop_factory* to configure the event loop instead of policies.
   Passing :class:`asyncio.EventLoop` allows running asyncio without the
   policy system.

   The executor is given a timeout duration of 5 minutes to shutdown.
   If the executor hasn't finished within that duration, a warning is
   emitted and the executor is closed.

   Example::

       async def main():
           await asyncio.sleep(1)
           print('hello')

       asyncio.run(main())

   .. versionadded:: 3.7

   .. versionchanged:: 3.9
      Updated to use :meth:`loop.shutdown_default_executor`.

   .. versionchanged:: 3.10

      *debug* is ``None`` by default to respect the global debug mode settings.

   .. versionchanged:: 3.12

      Added *loop_factory* parameter.

   .. versionchanged:: 3.14

      *coro* can be any awaitable object.

   .. note::

      The :mod:`!asyncio` policy system is deprecated and will be removed
      in Python 3.16; from there on, an explicit *loop_factory* is needed
      to configure the event loop.


Runner context manager
======================

.. class:: Runner(*, debug=None, loop_factory=None)

   A context manager that simplifies *multiple* async function calls in the same
   context.

   Sometimes several top-level async functions should be called in the same :ref:`event
   loop <asyncio-event-loop>` and :class:`contextvars.Context`.

   If *debug* is ``True``, the event loop will be run in debug mode. ``False`` disables
   debug mode explicitly. ``None`` is used to respect the global
   :ref:`asyncio-debug-mode` settings.

   *loop_factory* could be used for overriding the loop creation.
   It is the responsibility of the *loop_factory* to set the created loop as the
   current one. By default :func:`asyncio.new_event_loop` is used and set as
   current event loop with :func:`asyncio.set_event_loop` if *loop_factory* is ``None``.

   Basically, :func:`asyncio.run` example can be rewritten with the runner usage::

        async def main():
            await asyncio.sleep(1)
            print('hello')

        with asyncio.Runner() as runner:
            runner.run(main())

   .. versionadded:: 3.11

   .. method:: run(coro, *, context=None)

      Execute *coro* in the embedded event loop.

      The argument can be any awaitable object.

      If the argument is a coroutine, it is wrapped in a Task.

      An optional keyword-only *context* argument allows specifying a
      custom :class:`contextvars.Context` for the code to run in.
      The runner's default context is used if context is ``None``.

      Returns the awaitable's result or raises an exception.

      This function cannot be called when another asyncio event loop is
      running in the same thread.

      .. versionchanged:: 3.14

         *coro* can be any awaitable object.

   .. method:: close()

      Close the runner.

      Finalize asynchronous generators, shutdown default executor, close the event loop
      and release embedded :class:`contextvars.Context`.

   .. method:: get_loop()

      Return the event loop associated with the runner instance.

   .. note::

      :class:`Runner` uses the lazy initialization strategy, its constructor doesn't
      initialize underlying low-level structures.

      Embedded *loop* and *context* are created at the :keyword:`with` body entering
      or the first call of :meth:`run` or :meth:`get_loop`.


Handling Keyboard Interruption
==============================

.. versionadded:: 3.11

When :const:`signal.SIGINT` is raised by :kbd:`Ctrl-C`, :exc:`KeyboardInterrupt`
exception is raised in the main thread by default. However this doesn't work with
:mod:`asyncio` because it can interrupt asyncio internals and can hang the program from
exiting.

To mitigate this issue, :mod:`asyncio` handles :const:`signal.SIGINT` as follows:

1. :meth:`asyncio.Runner.run` installs a custom :const:`signal.SIGINT` handler before
   any user code is executed and removes it when exiting from the function.
2. The :class:`~asyncio.Runner` creates the main task for the passed coroutine for its
   execution.
3. When :const:`signal.SIGINT` is raised by :kbd:`Ctrl-C`, the custom signal handler
   cancels the main task by calling :meth:`asyncio.Task.cancel` which raises
   :exc:`asyncio.CancelledError` inside the main task.  This causes the Python stack
   to unwind, ``try/except`` and ``try/finally`` blocks can be used for resource
   cleanup.  After the main task is cancelled, :meth:`asyncio.Runner.run` raises
   :exc:`KeyboardInterrupt`.
4. A user could write a tight loop which cannot be interrupted by
   :meth:`asyncio.Task.cancel`, in which case the second following :kbd:`Ctrl-C`
   immediately raises the :exc:`KeyboardInterrupt` without cancelling the main task.


================================================
File: /Doc/library/asyncio-stream.rst
================================================
.. currentmodule:: asyncio

.. _asyncio-streams:

=======
Streams
=======

**Source code:** :source:`Lib/asyncio/streams.py`

-------------------------------------------------

Streams are high-level async/await-ready primitives to work with
network connections.  Streams allow sending and receiving data without
using callbacks or low-level protocols and transports.

.. _asyncio_example_stream:

Here is an example of a TCP echo client written using asyncio
streams::

    import asyncio

    async def tcp_echo_client(message):
        reader, writer = await asyncio.open_connection(
            '127.0.0.1', 8888)

        print(f'Send: {message!r}')
        writer.write(message.encode())
        await writer.drain()

        data = await reader.read(100)
        print(f'Received: {data.decode()!r}')

        print('Close the connection')
        writer.close()
        await writer.wait_closed()

    asyncio.run(tcp_echo_client('Hello World!'))


See also the `Examples`_ section below.


.. rubric:: Stream Functions

The following top-level asyncio functions can be used to create
and work with streams:


.. coroutinefunction:: open_connection(host=None, port=None, *, \
                          limit=None, ssl=None, family=0, proto=0, \
                          flags=0, sock=None, local_addr=None, \
                          server_hostname=None, ssl_handshake_timeout=None, \
                          ssl_shutdown_timeout=None, \
                          happy_eyeballs_delay=None, interleave=None)

   Establish a network connection and return a pair of
   ``(reader, writer)`` objects.

   The returned *reader* and *writer* objects are instances of
   :class:`StreamReader` and :class:`StreamWriter` classes.

   *limit* determines the buffer size limit used by the
   returned :class:`StreamReader` instance.  By default the *limit*
   is set to 64 KiB.

   The rest of the arguments are passed directly to
   :meth:`loop.create_connection`.

   .. note::

      The *sock* argument transfers ownership of the socket to the
      :class:`StreamWriter` created. To close the socket, call its
      :meth:`~asyncio.StreamWriter.close` method.

   .. versionchanged:: 3.7
      Added the *ssl_handshake_timeout* parameter.

   .. versionchanged:: 3.8
      Added the *happy_eyeballs_delay* and *interleave* parameters.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   .. versionchanged:: 3.11
      Added the *ssl_shutdown_timeout* parameter.


.. coroutinefunction:: start_server(client_connected_cb, host=None, \
                          port=None, *, limit=None, \
                          family=socket.AF_UNSPEC, \
                          flags=socket.AI_PASSIVE, sock=None, \
                          backlog=100, ssl=None, reuse_address=None, \
                          reuse_port=None, keep_alive=None, \
                          ssl_handshake_timeout=None, \
                          ssl_shutdown_timeout=None, start_serving=True)

   Start a socket server.

   The *client_connected_cb* callback is called whenever a new client
   connection is established.  It receives a ``(reader, writer)`` pair
   as two arguments, instances of the :class:`StreamReader` and
   :class:`StreamWriter` classes.

   *client_connected_cb* can be a plain callable or a
   :ref:`coroutine function <coroutine>`; if it is a coroutine function,
   it will be automatically scheduled as a :class:`Task`.

   *limit* determines the buffer size limit used by the
   returned :class:`StreamReader` instance.  By default the *limit*
   is set to 64 KiB.

   The rest of the arguments are passed directly to
   :meth:`loop.create_server`.

   .. note::

      The *sock* argument transfers ownership of the socket to the
      server created. To close the socket, call the server's
      :meth:`~asyncio.Server.close` method.

   .. versionchanged:: 3.7
      Added the *ssl_handshake_timeout* and *start_serving* parameters.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   .. versionchanged:: 3.11
      Added the *ssl_shutdown_timeout* parameter.

   .. versionchanged:: 3.13
      Added the *keep_alive* parameter.


.. rubric:: Unix Sockets

.. coroutinefunction:: open_unix_connection(path=None, *, limit=None, \
                        ssl=None, sock=None, server_hostname=None, \
                        ssl_handshake_timeout=None, ssl_shutdown_timeout=None)

   Establish a Unix socket connection and return a pair of
   ``(reader, writer)``.

   Similar to :func:`open_connection` but operates on Unix sockets.

   See also the documentation of :meth:`loop.create_unix_connection`.

   .. note::

      The *sock* argument transfers ownership of the socket to the
      :class:`StreamWriter` created. To close the socket, call its
      :meth:`~asyncio.StreamWriter.close` method.

   .. availability:: Unix.

   .. versionchanged:: 3.7
      Added the *ssl_handshake_timeout* parameter.
      The *path* parameter can now be a :term:`path-like object`

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   .. versionchanged:: 3.11
      Added the *ssl_shutdown_timeout* parameter.


.. coroutinefunction:: start_unix_server(client_connected_cb, path=None, \
                          *, limit=None, sock=None, backlog=100, ssl=None, \
                          ssl_handshake_timeout=None, \
                          ssl_shutdown_timeout=None, start_serving=True)

   Start a Unix socket server.

   Similar to :func:`start_server` but works with Unix sockets.

   See also the documentation of :meth:`loop.create_unix_server`.

   .. note::

      The *sock* argument transfers ownership of the socket to the
      server created. To close the socket, call the server's
      :meth:`~asyncio.Server.close` method.

   .. availability:: Unix.

   .. versionchanged:: 3.7
      Added the *ssl_handshake_timeout* and *start_serving* parameters.
      The *path* parameter can now be a :term:`path-like object`.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   .. versionchanged:: 3.11
      Added the *ssl_shutdown_timeout* parameter.


StreamReader
============

.. class:: StreamReader

   Represents a reader object that provides APIs to read data
   from the IO stream. As an :term:`asynchronous iterable`, the
   object supports the :keyword:`async for` statement.

   It is not recommended to instantiate *StreamReader* objects
   directly; use :func:`open_connection` and :func:`start_server`
   instead.

   .. method:: feed_eof()

      Acknowledge the EOF.

   .. coroutinemethod:: read(n=-1)

      Read up to *n* bytes from the stream.

      If *n* is not provided or set to ``-1``,
      read until EOF, then return all read :class:`bytes`.
      If EOF was received and the internal buffer is empty,
      return an empty ``bytes`` object.

      If *n* is ``0``, return an empty ``bytes`` object immediately.

      If *n* is positive, return at most *n* available ``bytes``
      as soon as at least 1 byte is available in the internal buffer.
      If EOF is received before any byte is read, return an empty
      ``bytes`` object.

   .. coroutinemethod:: readline()

      Read one line, where "line" is a sequence of bytes
      ending with ``\n``.

      If EOF is received and ``\n`` was not found, the method
      returns partially read data.

      If EOF is received and the internal buffer is empty,
      return an empty ``bytes`` object.

   .. coroutinemethod:: readexactly(n)

      Read exactly *n* bytes.

      Raise an :exc:`IncompleteReadError` if EOF is reached before *n*
      can be read.  Use the :attr:`IncompleteReadError.partial`
      attribute to get the partially read data.

   .. coroutinemethod:: readuntil(separator=b'\n')

      Read data from the stream until *separator* is found.

      On success, the data and separator will be removed from the
      internal buffer (consumed). Returned data will include the
      separator at the end.

      If the amount of data read exceeds the configured stream limit, a
      :exc:`LimitOverrunError` exception is raised, and the data
      is left in the internal buffer and can be read again.

      If EOF is reached before the complete separator is found,
      an :exc:`IncompleteReadError` exception is raised, and the internal
      buffer is reset.  The :attr:`IncompleteReadError.partial` attribute
      may contain a portion of the separator.

      The *separator* may also be a tuple of separators. In this
      case the return value will be the shortest possible that has any
      separator as the suffix. For the purposes of :exc:`LimitOverrunError`,
      the shortest possible separator is considered to be the one that
      matched.

      .. versionadded:: 3.5.2

      .. versionchanged:: 3.13

         The *separator* parameter may now be a :class:`tuple` of
         separators.

   .. method:: at_eof()

      Return ``True`` if the buffer is empty and :meth:`feed_eof`
      was called.


StreamWriter
============

.. class:: StreamWriter

   Represents a writer object that provides APIs to write data
   to the IO stream.

   It is not recommended to instantiate *StreamWriter* objects
   directly; use :func:`open_connection` and :func:`start_server`
   instead.

   .. method:: write(data)

      The method attempts to write the *data* to the underlying socket immediately.
      If that fails, the data is queued in an internal write buffer until it can be
      sent.

      The method should be used along with the ``drain()`` method::

         stream.write(data)
         await stream.drain()

   .. method:: writelines(data)

      The method writes a list (or any iterable) of bytes to the underlying socket
      immediately.
      If that fails, the data is queued in an internal write buffer until it can be
      sent.

      The method should be used along with the ``drain()`` method::

         stream.writelines(lines)
         await stream.drain()

   .. method:: close()

      The method closes the stream and the underlying socket.

      The method should be used, though not mandatory,
      along with the ``wait_closed()`` method::

         stream.close()
         await stream.wait_closed()

   .. method:: can_write_eof()

      Return ``True`` if the underlying transport supports
      the :meth:`write_eof` method, ``False`` otherwise.

   .. method:: write_eof()

      Close the write end of the stream after the buffered write
      data is flushed.

   .. attribute:: transport

      Return the underlying asyncio transport.

   .. method:: get_extra_info(name, default=None)

      Access optional transport information; see
      :meth:`BaseTransport.get_extra_info` for details.

   .. coroutinemethod:: drain()

      Wait until it is appropriate to resume writing to the stream.
      Example::

          writer.write(data)
          await writer.drain()

      This is a flow control method that interacts with the underlying
      IO write buffer.  When the size of the buffer reaches
      the high watermark, *drain()* blocks until the size of the
      buffer is drained down to the low watermark and writing can
      be resumed.  When there is nothing to wait for, the :meth:`drain`
      returns immediately.

   .. coroutinemethod:: start_tls(sslcontext, *, server_hostname=None, \
                          ssl_handshake_timeout=None, ssl_shutdown_timeout=None)

      Upgrade an existing stream-based connection to TLS.

      Parameters:

      * *sslcontext*: a configured instance of :class:`~ssl.SSLContext`.

      * *server_hostname*: sets or overrides the host name that the target
        server's certificate will be matched against.

      * *ssl_handshake_timeout* is the time in seconds to wait for the TLS
        handshake to complete before aborting the connection.  ``60.0`` seconds
        if ``None`` (default).

      * *ssl_shutdown_timeout* is the time in seconds to wait for the SSL shutdown
        to complete before aborting the connection. ``30.0`` seconds if ``None``
        (default).

      .. versionadded:: 3.11

      .. versionchanged:: 3.12
         Added the *ssl_shutdown_timeout* parameter.


   .. method:: is_closing()

      Return ``True`` if the stream is closed or in the process of
      being closed.

      .. versionadded:: 3.7

   .. coroutinemethod:: wait_closed()

      Wait until the stream is closed.

      Should be called after :meth:`close` to wait until the underlying
      connection is closed, ensuring that all data has been flushed
      before e.g. exiting the program.

      .. versionadded:: 3.7


Examples
========

.. _asyncio-tcp-echo-client-streams:

TCP echo client using streams
-----------------------------

TCP echo client using the :func:`asyncio.open_connection` function::

    import asyncio

    async def tcp_echo_client(message):
        reader, writer = await asyncio.open_connection(
            '127.0.0.1', 8888)

        print(f'Send: {message!r}')
        writer.write(message.encode())
        await writer.drain()

        data = await reader.read(100)
        print(f'Received: {data.decode()!r}')

        print('Close the connection')
        writer.close()
        await writer.wait_closed()

    asyncio.run(tcp_echo_client('Hello World!'))


.. seealso::

   The :ref:`TCP echo client protocol <asyncio_example_tcp_echo_client_protocol>`
   example uses the low-level :meth:`loop.create_connection` method.


.. _asyncio-tcp-echo-server-streams:

TCP echo server using streams
-----------------------------

TCP echo server using the :func:`asyncio.start_server` function::

    import asyncio

    async def handle_echo(reader, writer):
        data = await reader.read(100)
        message = data.decode()
        addr = writer.get_extra_info('peername')

        print(f"Received {message!r} from {addr!r}")

        print(f"Send: {message!r}")
        writer.write(data)
        await writer.drain()

        print("Close the connection")
        writer.close()
        await writer.wait_closed()

    async def main():
        server = await asyncio.start_server(
            handle_echo, '127.0.0.1', 8888)

        addrs = ', '.join(str(sock.getsockname()) for sock in server.sockets)
        print(f'Serving on {addrs}')

        async with server:
            await server.serve_forever()

    asyncio.run(main())


.. seealso::

   The :ref:`TCP echo server protocol <asyncio_example_tcp_echo_server_protocol>`
   example uses the :meth:`loop.create_server` method.


Get HTTP headers
----------------

Simple example querying HTTP headers of the URL passed on the command line::

    import asyncio
    import urllib.parse
    import sys

    async def print_http_headers(url):
        url = urllib.parse.urlsplit(url)
        if url.scheme == 'https':
            reader, writer = await asyncio.open_connection(
                url.hostname, 443, ssl=True)
        else:
            reader, writer = await asyncio.open_connection(
                url.hostname, 80)

        query = (
            f"HEAD {url.path or '/'} HTTP/1.0\r\n"
            f"Host: {url.hostname}\r\n"
            f"\r\n"
        )

        writer.write(query.encode('latin-1'))
        while True:
            line = await reader.readline()
            if not line:
                break

            line = line.decode('latin1').rstrip()
            if line:
                print(f'HTTP header> {line}')

        # Ignore the body, close the socket
        writer.close()
        await writer.wait_closed()

    url = sys.argv[1]
    asyncio.run(print_http_headers(url))


Usage::

    python example.py http://example.com/path/page.html

or with HTTPS::

    python example.py https://example.com/path/page.html


.. _asyncio_example_create_connection-streams:

Register an open socket to wait for data using streams
------------------------------------------------------

Coroutine waiting until a socket receives data using the
:func:`open_connection` function::

    import asyncio
    import socket

    async def wait_for_data():
        # Get a reference to the current event loop because
        # we want to access low-level APIs.
        loop = asyncio.get_running_loop()

        # Create a pair of connected sockets.
        rsock, wsock = socket.socketpair()

        # Register the open socket to wait for data.
        reader, writer = await asyncio.open_connection(sock=rsock)

        # Simulate the reception of data from the network
        loop.call_soon(wsock.send, 'abc'.encode())

        # Wait for data
        data = await reader.read(100)

        # Got data, we are done: close the socket
        print("Received:", data.decode())
        writer.close()
        await writer.wait_closed()

        # Close the second socket
        wsock.close()

    asyncio.run(wait_for_data())

.. seealso::

   The :ref:`register an open socket to wait for data using a protocol
   <asyncio_example_create_connection>` example uses a low-level protocol and
   the :meth:`loop.create_connection` method.

   The :ref:`watch a file descriptor for read events
   <asyncio_example_watch_fd>` example uses the low-level
   :meth:`loop.add_reader` method to watch a file descriptor.


================================================
File: /Doc/library/asyncio-subprocess.rst
================================================
.. currentmodule:: asyncio

.. _asyncio-subprocess:

============
Subprocesses
============

**Source code:** :source:`Lib/asyncio/subprocess.py`,
:source:`Lib/asyncio/base_subprocess.py`

----------------------------------------

This section describes high-level async/await asyncio APIs to
create and manage subprocesses.

.. _asyncio_example_subprocess_shell:

Here's an example of how asyncio can run a shell command and
obtain its result::

    import asyncio

    async def run(cmd):
        proc = await asyncio.create_subprocess_shell(
            cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE)

        stdout, stderr = await proc.communicate()

        print(f'[{cmd!r} exited with {proc.returncode}]')
        if stdout:
            print(f'[stdout]\n{stdout.decode()}')
        if stderr:
            print(f'[stderr]\n{stderr.decode()}')

    asyncio.run(run('ls /zzz'))

will print::

    ['ls /zzz' exited with 1]
    [stderr]
    ls: /zzz: No such file or directory

Because all asyncio subprocess functions are asynchronous and asyncio
provides many tools to work with such functions, it is easy to execute
and monitor multiple subprocesses in parallel.  It is indeed trivial
to modify the above example to run several commands simultaneously::

    async def main():
        await asyncio.gather(
            run('ls /zzz'),
            run('sleep 1; echo "hello"'))

    asyncio.run(main())

See also the `Examples`_ subsection.


Creating Subprocesses
=====================

.. coroutinefunction:: create_subprocess_exec(program, *args, stdin=None, \
                          stdout=None, stderr=None, limit=None, **kwds)

   Create a subprocess.

   The *limit* argument sets the buffer limit for :class:`StreamReader`
   wrappers for :attr:`Process.stdout` and :attr:`Process.stderr`
   (if :const:`subprocess.PIPE` is passed to *stdout* and *stderr* arguments).

   Return a :class:`~asyncio.subprocess.Process` instance.

   See the documentation of :meth:`loop.subprocess_exec` for other
   parameters.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.


.. coroutinefunction:: create_subprocess_shell(cmd, stdin=None, \
                          stdout=None, stderr=None, limit=None, **kwds)

   Run the *cmd* shell command.

   The *limit* argument sets the buffer limit for :class:`StreamReader`
   wrappers for :attr:`Process.stdout` and :attr:`Process.stderr`
   (if :const:`subprocess.PIPE` is passed to *stdout* and *stderr* arguments).

   Return a :class:`~asyncio.subprocess.Process` instance.

   See the documentation of :meth:`loop.subprocess_shell` for other
   parameters.

   .. important::

      It is the application's responsibility to ensure that all whitespace and
      special characters are quoted appropriately to avoid `shell injection
      <https://en.wikipedia.org/wiki/Shell_injection#Shell_injection>`_
      vulnerabilities. The :func:`shlex.quote` function can be used to properly
      escape whitespace and special shell characters in strings that are going
      to be used to construct shell commands.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

.. note::

   Subprocesses are available for Windows if a :class:`ProactorEventLoop` is
   used. See :ref:`Subprocess Support on Windows <asyncio-windows-subprocess>`
   for details.

.. seealso::

   asyncio also has the following *low-level* APIs to work with subprocesses:
   :meth:`loop.subprocess_exec`, :meth:`loop.subprocess_shell`,
   :meth:`loop.connect_read_pipe`, :meth:`loop.connect_write_pipe`,
   as well as the :ref:`Subprocess Transports <asyncio-subprocess-transports>`
   and :ref:`Subprocess Protocols <asyncio-subprocess-protocols>`.


Constants
=========

.. data:: asyncio.subprocess.PIPE
   :module:

   Can be passed to the *stdin*, *stdout* or *stderr* parameters.

   If *PIPE* is passed to *stdin* argument, the
   :attr:`Process.stdin <asyncio.subprocess.Process.stdin>` attribute
   will point to a :class:`StreamWriter` instance.

   If *PIPE* is passed to *stdout* or *stderr* arguments, the
   :attr:`Process.stdout <asyncio.subprocess.Process.stdout>` and
   :attr:`Process.stderr <asyncio.subprocess.Process.stderr>`
   attributes will point to :class:`StreamReader` instances.

.. data:: asyncio.subprocess.STDOUT
   :module:

   Special value that can be used as the *stderr* argument and indicates
   that standard error should be redirected into standard output.

.. data:: asyncio.subprocess.DEVNULL
   :module:

   Special value that can be used as the *stdin*, *stdout* or *stderr* argument
   to process creation functions.  It indicates that the special file
   :data:`os.devnull` will be used for the corresponding subprocess stream.


Interacting with Subprocesses
=============================

Both :func:`create_subprocess_exec` and :func:`create_subprocess_shell`
functions return instances of the *Process* class.  *Process* is a high-level
wrapper that allows communicating with subprocesses and watching for
their completion.

.. class:: asyncio.subprocess.Process
   :module:

   An object that wraps OS processes created by the
   :func:`create_subprocess_exec` and :func:`create_subprocess_shell`
   functions.

   This class is designed to have a similar API to the
   :class:`subprocess.Popen` class, but there are some
   notable differences:

   * unlike Popen, Process instances do not have an equivalent to
     the :meth:`~subprocess.Popen.poll` method;

   * the :meth:`~asyncio.subprocess.Process.communicate` and
     :meth:`~asyncio.subprocess.Process.wait` methods don't have a
     *timeout* parameter: use the :func:`~asyncio.wait_for` function;

   * the :meth:`Process.wait() <asyncio.subprocess.Process.wait>` method
     is asynchronous, whereas :meth:`subprocess.Popen.wait` method
     is implemented as a blocking busy loop;

   * the *universal_newlines* parameter is not supported.

   This class is :ref:`not thread safe <asyncio-multithreading>`.

   See also the :ref:`Subprocess and Threads <asyncio-subprocess-threads>`
   section.

   .. coroutinemethod:: wait()

      Wait for the child process to terminate.

      Set and return the :attr:`returncode` attribute.

      .. note::

         This method can deadlock when using ``stdout=PIPE`` or
         ``stderr=PIPE`` and the child process generates so much output
         that it blocks waiting for the OS pipe buffer to accept
         more data. Use the :meth:`communicate` method when using pipes
         to avoid this condition.

   .. coroutinemethod:: communicate(input=None)

      Interact with process:

      1. send data to *stdin* (if *input* is not ``None``);
      2. closes *stdin*;
      3. read data from *stdout* and *stderr*, until EOF is reached;
      4. wait for process to terminate.

      The optional *input* argument is the data (:class:`bytes` object)
      that will be sent to the child process.

      Return a tuple ``(stdout_data, stderr_data)``.

      If either :exc:`BrokenPipeError` or :exc:`ConnectionResetError`
      exception is raised when writing *input* into *stdin*, the
      exception is ignored.  This condition occurs when the process
      exits before all data are written into *stdin*.

      If it is desired to send data to the process' *stdin*,
      the process needs to be created with ``stdin=PIPE``.  Similarly,
      to get anything other than ``None`` in the result tuple, the
      process has to be created with ``stdout=PIPE`` and/or
      ``stderr=PIPE`` arguments.

      Note, that the data read is buffered in memory, so do not use
      this method if the data size is large or unlimited.

      .. versionchanged:: 3.12

         *stdin* gets closed when `input=None` too.

   .. method:: send_signal(signal)

      Sends the signal *signal* to the child process.

      .. note::

         On Windows, :py:const:`~signal.SIGTERM` is an alias for :meth:`terminate`.
         ``CTRL_C_EVENT`` and ``CTRL_BREAK_EVENT`` can be sent to processes
         started with a *creationflags* parameter which includes
         ``CREATE_NEW_PROCESS_GROUP``.

   .. method:: terminate()

      Stop the child process.

      On POSIX systems this method sends :py:const:`~signal.SIGTERM` to the
      child process.

      On Windows the Win32 API function :c:func:`!TerminateProcess` is
      called to stop the child process.

   .. method:: kill()

      Kill the child process.

      On POSIX systems this method sends :py:data:`SIGKILL` to the child
      process.

      On Windows this method is an alias for :meth:`terminate`.

   .. attribute:: stdin

      Standard input stream (:class:`StreamWriter`) or ``None``
      if the process was created with ``stdin=None``.

   .. attribute:: stdout

      Standard output stream (:class:`StreamReader`) or ``None``
      if the process was created with ``stdout=None``.

   .. attribute:: stderr

      Standard error stream (:class:`StreamReader`) or ``None``
      if the process was created with ``stderr=None``.

   .. warning::

      Use the :meth:`communicate` method rather than
      :attr:`process.stdin.write() <stdin>`,
      :attr:`await process.stdout.read() <stdout>` or
      :attr:`await process.stderr.read() <stderr>`.
      This avoids deadlocks due to streams pausing reading or writing
      and blocking the child process.

   .. attribute:: pid

      Process identification number (PID).

      Note that for processes created by the :func:`create_subprocess_shell`
      function, this attribute is the PID of the spawned shell.

   .. attribute:: returncode

      Return code of the process when it exits.

      A ``None`` value indicates that the process has not terminated yet.

      A negative value ``-N`` indicates that the child was terminated
      by signal ``N`` (POSIX only).


.. _asyncio-subprocess-threads:

Subprocess and Threads
----------------------

Standard asyncio event loop supports running subprocesses from different threads by
default.

On Windows subprocesses are provided by :class:`ProactorEventLoop` only (default),
:class:`SelectorEventLoop` has no subprocess support.

Note that alternative event loop implementations might have own limitations;
please refer to their documentation.

.. seealso::

   The :ref:`Concurrency and multithreading in asyncio
   <asyncio-multithreading>` section.


Examples
--------

An example using the :class:`~asyncio.subprocess.Process` class to
control a subprocess and the :class:`StreamReader` class to read from
its standard output.

.. _asyncio_example_create_subprocess_exec:

The subprocess is created by the :func:`create_subprocess_exec`
function::

    import asyncio
    import sys

    async def get_date():
        code = 'import datetime; print(datetime.datetime.now())'

        # Create the subprocess; redirect the standard output
        # into a pipe.
        proc = await asyncio.create_subprocess_exec(
            sys.executable, '-c', code,
            stdout=asyncio.subprocess.PIPE)

        # Read one line of output.
        data = await proc.stdout.readline()
        line = data.decode('ascii').rstrip()

        # Wait for the subprocess exit.
        await proc.wait()
        return line

    date = asyncio.run(get_date())
    print(f"Current date: {date}")


See also the :ref:`same example <asyncio_example_subprocess_proto>`
written using low-level APIs.


================================================
File: /Doc/library/asyncio-sync.rst
================================================
.. currentmodule:: asyncio

.. _asyncio-sync:

==========================
Synchronization Primitives
==========================

**Source code:** :source:`Lib/asyncio/locks.py`

-----------------------------------------------

asyncio synchronization primitives are designed to be similar to
those of the :mod:`threading` module with two important caveats:

* asyncio primitives are not thread-safe, therefore they should not
  be used for OS thread synchronization (use :mod:`threading` for
  that);

* methods of these synchronization primitives do not accept the *timeout*
  argument; use the :func:`asyncio.wait_for` function to perform
  operations with timeouts.

asyncio has the following basic synchronization primitives:

* :class:`Lock`
* :class:`Event`
* :class:`Condition`
* :class:`Semaphore`
* :class:`BoundedSemaphore`
* :class:`Barrier`


---------


Lock
====

.. class:: Lock()

   Implements a mutex lock for asyncio tasks.  Not thread-safe.

   An asyncio lock can be used to guarantee exclusive access to a
   shared resource.

   The preferred way to use a Lock is an :keyword:`async with`
   statement::

       lock = asyncio.Lock()

       # ... later
       async with lock:
           # access shared state

   which is equivalent to::

       lock = asyncio.Lock()

       # ... later
       await lock.acquire()
       try:
           # access shared state
       finally:
           lock.release()

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   .. coroutinemethod:: acquire()

      Acquire the lock.

      This method waits until the lock is *unlocked*, sets it to
      *locked* and returns ``True``.

      When more than one coroutine is blocked in :meth:`acquire`
      waiting for the lock to be unlocked, only one coroutine
      eventually proceeds.

      Acquiring a lock is *fair*: the coroutine that proceeds will be
      the first coroutine that started waiting on the lock.

   .. method:: release()

      Release the lock.

      When the lock is *locked*, reset it to *unlocked* and return.

      If the lock is *unlocked*, a :exc:`RuntimeError` is raised.

   .. method:: locked()

      Return ``True`` if the lock is *locked*.


Event
=====

.. class:: Event()

   An event object.  Not thread-safe.

   An asyncio event can be used to notify multiple asyncio tasks
   that some event has happened.

   An Event object manages an internal flag that can be set to *true*
   with the :meth:`~Event.set` method and reset to *false* with the
   :meth:`clear` method.  The :meth:`~Event.wait` method blocks until the
   flag is set to *true*.  The flag is set to *false* initially.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   .. _asyncio_example_sync_event:

   Example::

      async def waiter(event):
          print('waiting for it ...')
          await event.wait()
          print('... got it!')

      async def main():
          # Create an Event object.
          event = asyncio.Event()

          # Spawn a Task to wait until 'event' is set.
          waiter_task = asyncio.create_task(waiter(event))

          # Sleep for 1 second and set the event.
          await asyncio.sleep(1)
          event.set()

          # Wait until the waiter task is finished.
          await waiter_task

      asyncio.run(main())

   .. coroutinemethod:: wait()

      Wait until the event is set.

      If the event is set, return ``True`` immediately.
      Otherwise block until another task calls :meth:`~Event.set`.

   .. method:: set()

      Set the event.

      All tasks waiting for event to be set will be immediately
      awakened.

   .. method:: clear()

      Clear (unset) the event.

      Tasks awaiting on :meth:`~Event.wait` will now block until the
      :meth:`~Event.set` method is called again.

   .. method:: is_set()

      Return ``True`` if the event is set.


Condition
=========

.. class:: Condition(lock=None)

   A Condition object.  Not thread-safe.

   An asyncio condition primitive can be used by a task to wait for
   some event to happen and then get exclusive access to a shared
   resource.

   In essence, a Condition object combines the functionality
   of an :class:`Event` and a :class:`Lock`.  It is possible to have
   multiple Condition objects share one Lock, which allows coordinating
   exclusive access to a shared resource between different tasks
   interested in particular states of that shared resource.

   The optional *lock* argument must be a :class:`Lock` object or
   ``None``.  In the latter case a new Lock object is created
   automatically.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   The preferred way to use a Condition is an :keyword:`async with`
   statement::

       cond = asyncio.Condition()

       # ... later
       async with cond:
           await cond.wait()

   which is equivalent to::

       cond = asyncio.Condition()

       # ... later
       await cond.acquire()
       try:
           await cond.wait()
       finally:
           cond.release()

   .. coroutinemethod:: acquire()

      Acquire the underlying lock.

      This method waits until the underlying lock is *unlocked*,
      sets it to *locked* and returns ``True``.

   .. method:: notify(n=1)

      Wake up *n* tasks (1 by default) waiting on this
      condition.  If fewer than *n* tasks are waiting they are all awakened.

      The lock must be acquired before this method is called and
      released shortly after.  If called with an *unlocked* lock
      a :exc:`RuntimeError` error is raised.

   .. method:: locked()

      Return ``True`` if the underlying lock is acquired.

   .. method:: notify_all()

      Wake up all tasks waiting on this condition.

      This method acts like :meth:`notify`, but wakes up all waiting
      tasks.

      The lock must be acquired before this method is called and
      released shortly after.  If called with an *unlocked* lock
      a :exc:`RuntimeError` error is raised.

   .. method:: release()

      Release the underlying lock.

      When invoked on an unlocked lock, a :exc:`RuntimeError` is
      raised.

   .. coroutinemethod:: wait()

      Wait until notified.

      If the calling task has not acquired the lock when this method is
      called, a :exc:`RuntimeError` is raised.

      This method releases the underlying lock, and then blocks until
      it is awakened by a :meth:`notify` or :meth:`notify_all` call.
      Once awakened, the Condition re-acquires its lock and this method
      returns ``True``.

      Note that a task *may* return from this call spuriously,
      which is why the caller should always re-check the state
      and be prepared to :meth:`~Condition.wait` again. For this reason, you may
      prefer to use :meth:`~Condition.wait_for` instead.

   .. coroutinemethod:: wait_for(predicate)

      Wait until a predicate becomes *true*.

      The predicate must be a callable which result will be
      interpreted as a boolean value.  The method will repeatedly
      :meth:`~Condition.wait` until the predicate evaluates to *true*. The final value is the
      return value.


Semaphore
=========

.. class:: Semaphore(value=1)

   A Semaphore object.  Not thread-safe.

   A semaphore manages an internal counter which is decremented by each
   :meth:`acquire` call and incremented by each :meth:`release` call.
   The counter can never go below zero; when :meth:`acquire` finds
   that it is zero, it blocks, waiting until some task calls
   :meth:`release`.

   The optional *value* argument gives the initial value for the
   internal counter (``1`` by default). If the given value is
   less than ``0`` a :exc:`ValueError` is raised.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   The preferred way to use a Semaphore is an :keyword:`async with`
   statement::

       sem = asyncio.Semaphore(10)

       # ... later
       async with sem:
           # work with shared resource

   which is equivalent to::

       sem = asyncio.Semaphore(10)

       # ... later
       await sem.acquire()
       try:
           # work with shared resource
       finally:
           sem.release()

   .. coroutinemethod:: acquire()

      Acquire a semaphore.

      If the internal counter is greater than zero, decrement
      it by one and return ``True`` immediately.  If it is zero, wait
      until a :meth:`release` is called and return ``True``.

   .. method:: locked()

      Returns ``True`` if semaphore can not be acquired immediately.

   .. method:: release()

      Release a semaphore, incrementing the internal counter by one.
      Can wake up a task waiting to acquire the semaphore.

      Unlike :class:`BoundedSemaphore`, :class:`Semaphore` allows
      making more ``release()`` calls than ``acquire()`` calls.


BoundedSemaphore
================

.. class:: BoundedSemaphore(value=1)

   A bounded semaphore object.  Not thread-safe.

   Bounded Semaphore is a version of :class:`Semaphore` that raises
   a :exc:`ValueError` in :meth:`~Semaphore.release` if it
   increases the internal counter above the initial *value*.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.


Barrier
=======

.. class:: Barrier(parties)

   A barrier object.  Not thread-safe.

   A barrier is a simple synchronization primitive that allows to block until
   *parties* number of tasks are waiting on it.
   Tasks can wait on the :meth:`~Barrier.wait` method and would be blocked until
   the specified number of tasks end up waiting on :meth:`~Barrier.wait`.
   At that point all of the waiting tasks would unblock simultaneously.

   :keyword:`async with` can be used as an alternative to awaiting on
   :meth:`~Barrier.wait`.

   The barrier can be reused any number of times.

   .. _asyncio_example_barrier:

   Example::

      async def example_barrier():
         # barrier with 3 parties
         b = asyncio.Barrier(3)

         # create 2 new waiting tasks
         asyncio.create_task(b.wait())
         asyncio.create_task(b.wait())

         await asyncio.sleep(0)
         print(b)

         # The third .wait() call passes the barrier
         await b.wait()
         print(b)
         print("barrier passed")

         await asyncio.sleep(0)
         print(b)

      asyncio.run(example_barrier())

   Result of this example is::

      <asyncio.locks.Barrier object at 0x... [filling, waiters:2/3]>
      <asyncio.locks.Barrier object at 0x... [draining, waiters:0/3]>
      barrier passed
      <asyncio.locks.Barrier object at 0x... [filling, waiters:0/3]>

   .. versionadded:: 3.11

   .. coroutinemethod:: wait()

      Pass the barrier. When all the tasks party to the barrier have called
      this function, they are all unblocked simultaneously.

      When a waiting or blocked task in the barrier is cancelled,
      this task exits the barrier which stays in the same state.
      If the state of the barrier is "filling", the number of waiting task
      decreases by 1.

      The return value is an integer in the range of 0 to ``parties-1``, different
      for each task. This can be used to select a task to do some special
      housekeeping, e.g.::

         ...
         async with barrier as position:
            if position == 0:
               # Only one task prints this
               print('End of *draining phase*')

      This method may raise a :class:`BrokenBarrierError` exception if the
      barrier is broken or reset while a task is waiting.
      It could raise a :exc:`CancelledError` if a task is cancelled.

   .. coroutinemethod:: reset()

      Return the barrier to the default, empty state.  Any tasks waiting on it
      will receive the :class:`BrokenBarrierError` exception.

      If a barrier is broken it may be better to just leave it and create a new one.

   .. coroutinemethod:: abort()

      Put the barrier into a broken state.  This causes any active or future
      calls to :meth:`~Barrier.wait` to fail with the :class:`BrokenBarrierError`.
      Use this for example if one of the tasks needs to abort, to avoid infinite
      waiting tasks.

   .. attribute:: parties

      The number of tasks required to pass the barrier.

   .. attribute:: n_waiting

      The number of tasks currently waiting in the barrier while filling.

   .. attribute:: broken

      A boolean that is ``True`` if the barrier is in the broken state.


.. exception:: BrokenBarrierError

   This exception, a subclass of :exc:`RuntimeError`, is raised when the
   :class:`Barrier` object is reset or broken.

---------


.. versionchanged:: 3.9

   Acquiring a lock using ``await lock`` or ``yield from lock`` and/or
   :keyword:`with` statement (``with await lock``, ``with (yield from
   lock)``) was removed.  Use ``async with lock`` instead.


================================================
File: /Doc/library/asyncio-task.rst
================================================
.. currentmodule:: asyncio


====================
Coroutines and Tasks
====================

This section outlines high-level asyncio APIs to work with coroutines
and Tasks.

.. contents::
   :depth: 1
   :local:


.. _coroutine:

Coroutines
==========

**Source code:** :source:`Lib/asyncio/coroutines.py`

----------------------------------------------------

:term:`Coroutines <coroutine>` declared with the async/await syntax is the
preferred way of writing asyncio applications.  For example, the following
snippet of code prints "hello", waits 1 second,
and then prints "world"::

    >>> import asyncio

    >>> async def main():
    ...     print('hello')
    ...     await asyncio.sleep(1)
    ...     print('world')

    >>> asyncio.run(main())
    hello
    world

Note that simply calling a coroutine will not schedule it to
be executed::

    >>> main()
    <coroutine object main at 0x1053bb7c8>

To actually run a coroutine, asyncio provides the following mechanisms:

* The :func:`asyncio.run` function to run the top-level
  entry point "main()" function (see the above example.)

* Awaiting on a coroutine.  The following snippet of code will
  print "hello" after waiting for 1 second, and then print "world"
  after waiting for *another* 2 seconds::

      import asyncio
      import time

      async def say_after(delay, what):
          await asyncio.sleep(delay)
          print(what)

      async def main():
          print(f"started at {time.strftime('%X')}")

          await say_after(1, 'hello')
          await say_after(2, 'world')

          print(f"finished at {time.strftime('%X')}")

      asyncio.run(main())

  Expected output::

      started at 17:13:52
      hello
      world
      finished at 17:13:55

* The :func:`asyncio.create_task` function to run coroutines
  concurrently as asyncio :class:`Tasks <Task>`.

  Let's modify the above example and run two ``say_after`` coroutines
  *concurrently*::

      async def main():
          task1 = asyncio.create_task(
              say_after(1, 'hello'))

          task2 = asyncio.create_task(
              say_after(2, 'world'))

          print(f"started at {time.strftime('%X')}")

          # Wait until both tasks are completed (should take
          # around 2 seconds.)
          await task1
          await task2

          print(f"finished at {time.strftime('%X')}")

  Note that expected output now shows that the snippet runs
  1 second faster than before::

      started at 17:14:32
      hello
      world
      finished at 17:14:34

* The :class:`asyncio.TaskGroup` class provides a more modern
  alternative to :func:`create_task`.
  Using this API, the last example becomes::

      async def main():
          async with asyncio.TaskGroup() as tg:
              task1 = tg.create_task(
                  say_after(1, 'hello'))

              task2 = tg.create_task(
                  say_after(2, 'world'))

              print(f"started at {time.strftime('%X')}")

          # The await is implicit when the context manager exits.

          print(f"finished at {time.strftime('%X')}")

  The timing and output should be the same as for the previous version.

  .. versionadded:: 3.11
     :class:`asyncio.TaskGroup`.


.. _asyncio-awaitables:

Awaitables
==========

We say that an object is an **awaitable** object if it can be used
in an :keyword:`await` expression.  Many asyncio APIs are designed to
accept awaitables.

There are three main types of *awaitable* objects:
**coroutines**, **Tasks**, and **Futures**.


.. rubric:: Coroutines

Python coroutines are *awaitables* and therefore can be awaited from
other coroutines::

    import asyncio

    async def nested():
        return 42

    async def main():
        # Nothing happens if we just call "nested()".
        # A coroutine object is created but not awaited,
        # so it *won't run at all*.
        nested()  # will raise a "RuntimeWarning".

        # Let's do it differently now and await it:
        print(await nested())  # will print "42".

    asyncio.run(main())

.. important::

   In this documentation the term "coroutine" can be used for
   two closely related concepts:

   * a *coroutine function*: an :keyword:`async def` function;

   * a *coroutine object*: an object returned by calling a
     *coroutine function*.


.. rubric:: Tasks

*Tasks* are used to schedule coroutines *concurrently*.

When a coroutine is wrapped into a *Task* with functions like
:func:`asyncio.create_task` the coroutine is automatically
scheduled to run soon::

    import asyncio

    async def nested():
        return 42

    async def main():
        # Schedule nested() to run soon concurrently
        # with "main()".
        task = asyncio.create_task(nested())

        # "task" can now be used to cancel "nested()", or
        # can simply be awaited to wait until it is complete:
        await task

    asyncio.run(main())


.. rubric:: Futures

A :class:`Future` is a special **low-level** awaitable object that
represents an **eventual result** of an asynchronous operation.

When a Future object is *awaited* it means that the coroutine will
wait until the Future is resolved in some other place.

Future objects in asyncio are needed to allow callback-based code
to be used with async/await.

Normally **there is no need** to create Future objects at the
application level code.

Future objects, sometimes exposed by libraries and some asyncio
APIs, can be awaited::

    async def main():
        await function_that_returns_a_future_object()

        # this is also valid:
        await asyncio.gather(
            function_that_returns_a_future_object(),
            some_python_coroutine()
        )

A good example of a low-level function that returns a Future object
is :meth:`loop.run_in_executor`.


Creating Tasks
==============

**Source code:** :source:`Lib/asyncio/tasks.py`

-----------------------------------------------

.. function:: create_task(coro, *, name=None, context=None)

   Wrap the *coro* :ref:`coroutine <coroutine>` into a :class:`Task`
   and schedule its execution.  Return the Task object.

   If *name* is not ``None``, it is set as the name of the task using
   :meth:`Task.set_name`.

   An optional keyword-only *context* argument allows specifying a
   custom :class:`contextvars.Context` for the *coro* to run in.
   The current context copy is created when no *context* is provided.

   The task is executed in the loop returned by :func:`get_running_loop`,
   :exc:`RuntimeError` is raised if there is no running loop in
   current thread.

   .. note::

      :meth:`asyncio.TaskGroup.create_task` is a new alternative
      leveraging structural concurrency; it allows for waiting
      for a group of related tasks with strong safety guarantees.

   .. important::

      Save a reference to the result of this function, to avoid
      a task disappearing mid-execution. The event loop only keeps
      weak references to tasks. A task that isn't referenced elsewhere
      may get garbage collected at any time, even before it's done.
      For reliable "fire-and-forget" background tasks, gather them in
      a collection::

          background_tasks = set()

          for i in range(10):
              task = asyncio.create_task(some_coro(param=i))

              # Add task to the set. This creates a strong reference.
              background_tasks.add(task)

              # To prevent keeping references to finished tasks forever,
              # make each task remove its own reference from the set after
              # completion:
              task.add_done_callback(background_tasks.discard)

   .. versionadded:: 3.7

   .. versionchanged:: 3.8
      Added the *name* parameter.

   .. versionchanged:: 3.11
      Added the *context* parameter.


Task Cancellation
=================

Tasks can easily and safely be cancelled.
When a task is cancelled, :exc:`asyncio.CancelledError` will be raised
in the task at the next opportunity.

It is recommended that coroutines use ``try/finally`` blocks to robustly
perform clean-up logic. In case :exc:`asyncio.CancelledError`
is explicitly caught, it should generally be propagated when
clean-up is complete. :exc:`asyncio.CancelledError` directly subclasses
:exc:`BaseException` so most code will not need to be aware of it.

The asyncio components that enable structured concurrency, like
:class:`asyncio.TaskGroup` and :func:`asyncio.timeout`,
are implemented using cancellation internally and might misbehave if
a coroutine swallows :exc:`asyncio.CancelledError`. Similarly, user code
should not generally call :meth:`uncancel <asyncio.Task.uncancel>`.
However, in cases when suppressing :exc:`asyncio.CancelledError` is
truly desired, it is necessary to also call ``uncancel()`` to completely
remove the cancellation state.

.. _taskgroups:

Task Groups
===========

Task groups combine a task creation API with a convenient
and reliable way to wait for all tasks in the group to finish.

.. class:: TaskGroup()

   An :ref:`asynchronous context manager <async-context-managers>`
   holding a group of tasks.
   Tasks can be added to the group using :meth:`create_task`.
   All tasks are awaited when the context manager exits.

   .. versionadded:: 3.11

   .. method:: create_task(coro, *, name=None, context=None)

      Create a task in this task group.
      The signature matches that of :func:`asyncio.create_task`.
      If the task group is inactive (e.g. not yet entered,
      already finished, or in the process of shutting down),
      we will close the given ``coro``.

      .. versionchanged:: 3.13

         Close the given coroutine if the task group is not active.

Example::

    async def main():
        async with asyncio.TaskGroup() as tg:
            task1 = tg.create_task(some_coro(...))
            task2 = tg.create_task(another_coro(...))
        print(f"Both tasks have completed now: {task1.result()}, {task2.result()}")

The ``async with`` statement will wait for all tasks in the group to finish.
While waiting, new tasks may still be added to the group
(for example, by passing ``tg`` into one of the coroutines
and calling ``tg.create_task()`` in that coroutine).
Once the last task has finished and the ``async with`` block is exited,
no new tasks may be added to the group.

The first time any of the tasks belonging to the group fails
with an exception other than :exc:`asyncio.CancelledError`,
the remaining tasks in the group are cancelled.
No further tasks can then be added to the group.
At this point, if the body of the ``async with`` statement is still active
(i.e., :meth:`~object.__aexit__` hasn't been called yet),
the task directly containing the ``async with`` statement is also cancelled.
The resulting :exc:`asyncio.CancelledError` will interrupt an ``await``,
but it will not bubble out of the containing ``async with`` statement.

Once all tasks have finished, if any tasks have failed
with an exception other than :exc:`asyncio.CancelledError`,
those exceptions are combined in an
:exc:`ExceptionGroup` or :exc:`BaseExceptionGroup`
(as appropriate; see their documentation)
which is then raised.

Two base exceptions are treated specially:
If any task fails with :exc:`KeyboardInterrupt` or :exc:`SystemExit`,
the task group still cancels the remaining tasks and waits for them,
but then the initial :exc:`KeyboardInterrupt` or :exc:`SystemExit`
is re-raised instead of :exc:`ExceptionGroup` or :exc:`BaseExceptionGroup`.

If the body of the ``async with`` statement exits with an exception
(so :meth:`~object.__aexit__` is called with an exception set),
this is treated the same as if one of the tasks failed:
the remaining tasks are cancelled and then waited for,
and non-cancellation exceptions are grouped into an
exception group and raised.
The exception passed into :meth:`~object.__aexit__`,
unless it is :exc:`asyncio.CancelledError`,
is also included in the exception group.
The same special case is made for
:exc:`KeyboardInterrupt` and :exc:`SystemExit` as in the previous paragraph.

Task groups are careful not to mix up the internal cancellation used to
"wake up" their :meth:`~object.__aexit__` with cancellation requests
for the task in which they are running made by other parties.
In particular, when one task group is syntactically nested in another,
and both experience an exception in one of their child tasks simultaneously,
the inner task group will process its exceptions, and then the outer task group
will receive another cancellation and process its own exceptions.

In the case where a task group is cancelled externally and also must
raise an :exc:`ExceptionGroup`, it will call the parent task's
:meth:`~asyncio.Task.cancel` method. This ensures that a
:exc:`asyncio.CancelledError` will be raised at the next
:keyword:`await`, so the cancellation is not lost.

Task groups preserve the cancellation count
reported by :meth:`asyncio.Task.cancelling`.

.. versionchanged:: 3.13

   Improved handling of simultaneous internal and external cancellations
   and correct preservation of cancellation counts.

Terminating a Task Group
------------------------

While terminating a task group is not natively supported by the standard
library, termination can be achieved by adding an exception-raising task
to the task group and ignoring the raised exception:

.. code-block:: python

   import asyncio
   from asyncio import TaskGroup

   class TerminateTaskGroup(Exception):
       """Exception raised to terminate a task group."""

   async def force_terminate_task_group():
       """Used to force termination of a task group."""
       raise TerminateTaskGroup()

   async def job(task_id, sleep_time):
       print(f'Task {task_id}: start')
       await asyncio.sleep(sleep_time)
       print(f'Task {task_id}: done')

   async def main():
       try:
           async with TaskGroup() as group:
               # spawn some tasks
               group.create_task(job(1, 0.5))
               group.create_task(job(2, 1.5))
               # sleep for 1 second
               await asyncio.sleep(1)
               # add an exception-raising task to force the group to terminate
               group.create_task(force_terminate_task_group())
       except* TerminateTaskGroup:
           pass

   asyncio.run(main())

Expected output:

.. code-block:: text

   Task 1: start
   Task 2: start
   Task 1: done

Sleeping
========

.. coroutinefunction:: sleep(delay, result=None)

   Block for *delay* seconds.

   If *result* is provided, it is returned to the caller
   when the coroutine completes.

   ``sleep()`` always suspends the current task, allowing other tasks
   to run.

   Setting the delay to 0 provides an optimized path to allow other
   tasks to run. This can be used by long-running functions to avoid
   blocking the event loop for the full duration of the function call.

   .. _asyncio_example_sleep:

   Example of coroutine displaying the current date every second
   for 5 seconds::

    import asyncio
    import datetime

    async def display_date():
        loop = asyncio.get_running_loop()
        end_time = loop.time() + 5.0
        while True:
            print(datetime.datetime.now())
            if (loop.time() + 1.0) >= end_time:
                break
            await asyncio.sleep(1)

    asyncio.run(display_date())


   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   .. versionchanged:: 3.13
      Raises :exc:`ValueError` if *delay* is :data:`~math.nan`.


Running Tasks Concurrently
==========================

.. awaitablefunction:: gather(*aws, return_exceptions=False)

   Run :ref:`awaitable objects <asyncio-awaitables>` in the *aws*
   sequence *concurrently*.

   If any awaitable in *aws* is a coroutine, it is automatically
   scheduled as a Task.

   If all awaitables are completed successfully, the result is an
   aggregate list of returned values.  The order of result values
   corresponds to the order of awaitables in *aws*.

   If *return_exceptions* is ``False`` (default), the first
   raised exception is immediately propagated to the task that
   awaits on ``gather()``.  Other awaitables in the *aws* sequence
   **won't be cancelled** and will continue to run.

   If *return_exceptions* is ``True``, exceptions are treated the
   same as successful results, and aggregated in the result list.

   If ``gather()`` is *cancelled*, all submitted awaitables
   (that have not completed yet) are also *cancelled*.

   If any Task or Future from the *aws* sequence is *cancelled*, it is
   treated as if it raised :exc:`CancelledError` -- the ``gather()``
   call is **not** cancelled in this case.  This is to prevent the
   cancellation of one submitted Task/Future to cause other
   Tasks/Futures to be cancelled.

   .. note::
      A new alternative to create and run tasks concurrently and
      wait for their completion is :class:`asyncio.TaskGroup`. *TaskGroup*
      provides stronger safety guarantees than *gather* for scheduling a nesting of subtasks:
      if a task (or a subtask, a task scheduled by a task)
      raises an exception, *TaskGroup* will, while *gather* will not,
      cancel the remaining scheduled tasks).

   .. _asyncio_example_gather:

   Example::

      import asyncio

      async def factorial(name, number):
          f = 1
          for i in range(2, number + 1):
              print(f"Task {name}: Compute factorial({number}), currently i={i}...")
              await asyncio.sleep(1)
              f *= i
          print(f"Task {name}: factorial({number}) = {f}")
          return f

      async def main():
          # Schedule three calls *concurrently*:
          L = await asyncio.gather(
              factorial("A", 2),
              factorial("B", 3),
              factorial("C", 4),
          )
          print(L)

      asyncio.run(main())

      # Expected output:
      #
      #     Task A: Compute factorial(2), currently i=2...
      #     Task B: Compute factorial(3), currently i=2...
      #     Task C: Compute factorial(4), currently i=2...
      #     Task A: factorial(2) = 2
      #     Task B: Compute factorial(3), currently i=3...
      #     Task C: Compute factorial(4), currently i=3...
      #     Task B: factorial(3) = 6
      #     Task C: Compute factorial(4), currently i=4...
      #     Task C: factorial(4) = 24
      #     [2, 6, 24]

   .. note::
      If *return_exceptions* is false, cancelling gather() after it
      has been marked done won't cancel any submitted awaitables.
      For instance, gather can be marked done after propagating an
      exception to the caller, therefore, calling ``gather.cancel()``
      after catching an exception (raised by one of the awaitables) from
      gather won't cancel any other awaitables.

   .. versionchanged:: 3.7
      If the *gather* itself is cancelled, the cancellation is
      propagated regardless of *return_exceptions*.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   .. deprecated:: 3.10
      Deprecation warning is emitted if no positional arguments are provided
      or not all positional arguments are Future-like objects
      and there is no running event loop.


.. _eager-task-factory:

Eager Task Factory
==================

.. function:: eager_task_factory(loop, coro, *, name=None, context=None)

    A task factory for eager task execution.

    When using this factory (via :meth:`loop.set_task_factory(asyncio.eager_task_factory) <loop.set_task_factory>`),
    coroutines begin execution synchronously during :class:`Task` construction.
    Tasks are only scheduled on the event loop if they block.
    This can be a performance improvement as the overhead of loop scheduling
    is avoided for coroutines that complete synchronously.

    A common example where this is beneficial is coroutines which employ
    caching or memoization to avoid actual I/O when possible.

    .. note::

        Immediate execution of the coroutine is a semantic change.
        If the coroutine returns or raises, the task is never scheduled
        to the event loop. If the coroutine execution blocks, the task is
        scheduled to the event loop. This change may introduce behavior
        changes to existing applications. For example,
        the application's task execution order is likely to change.

    .. versionadded:: 3.12

.. function:: create_eager_task_factory(custom_task_constructor)

    Create an eager task factory, similar to :func:`eager_task_factory`,
    using the provided *custom_task_constructor* when creating a new task instead
    of the default :class:`Task`.

    *custom_task_constructor* must be a *callable* with the signature matching
    the signature of :class:`Task.__init__ <Task>`.
    The callable must return a :class:`asyncio.Task`-compatible object.

    This function returns a *callable* intended to be used as a task factory of an
    event loop via :meth:`loop.set_task_factory(factory) <loop.set_task_factory>`).

    .. versionadded:: 3.12


Shielding From Cancellation
===========================

.. awaitablefunction:: shield(aw)

   Protect an :ref:`awaitable object <asyncio-awaitables>`
   from being :meth:`cancelled <Task.cancel>`.

   If *aw* is a coroutine it is automatically scheduled as a Task.

   The statement::

       task = asyncio.create_task(something())
       res = await shield(task)

   is equivalent to::

       res = await something()

   *except* that if the coroutine containing it is cancelled, the
   Task running in ``something()`` is not cancelled.  From the point
   of view of ``something()``, the cancellation did not happen.
   Although its caller is still cancelled, so the "await" expression
   still raises a :exc:`CancelledError`.

   If ``something()`` is cancelled by other means (i.e. from within
   itself) that would also cancel ``shield()``.

   If it is desired to completely ignore cancellation (not recommended)
   the ``shield()`` function should be combined with a try/except
   clause, as follows::

       task = asyncio.create_task(something())
       try:
           res = await shield(task)
       except CancelledError:
           res = None

   .. important::

      Save a reference to tasks passed to this function, to avoid
      a task disappearing mid-execution. The event loop only keeps
      weak references to tasks. A task that isn't referenced elsewhere
      may get garbage collected at any time, even before it's done.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   .. deprecated:: 3.10
      Deprecation warning is emitted if *aw* is not Future-like object
      and there is no running event loop.


Timeouts
========

.. function:: timeout(delay)

    Return an :ref:`asynchronous context manager <async-context-managers>`
    that can be used to limit the amount of time spent waiting on
    something.

    *delay* can either be ``None``, or a float/int number of
    seconds to wait. If *delay* is ``None``, no time limit will
    be applied; this can be useful if the delay is unknown when
    the context manager is created.

    In either case, the context manager can be rescheduled after
    creation using :meth:`Timeout.reschedule`.

    Example::

        async def main():
            async with asyncio.timeout(10):
                await long_running_task()

    If ``long_running_task`` takes more than 10 seconds to complete,
    the context manager will cancel the current task and handle
    the resulting :exc:`asyncio.CancelledError` internally, transforming it
    into a :exc:`TimeoutError` which can be caught and handled.

    .. note::

      The :func:`asyncio.timeout` context manager is what transforms
      the :exc:`asyncio.CancelledError` into a :exc:`TimeoutError`,
      which means the :exc:`TimeoutError` can only be caught
      *outside* of the context manager.

    Example of catching :exc:`TimeoutError`::

        async def main():
            try:
                async with asyncio.timeout(10):
                    await long_running_task()
            except TimeoutError:
                print("The long operation timed out, but we've handled it.")

            print("This statement will run regardless.")

    The context manager produced by :func:`asyncio.timeout` can be
    rescheduled to a different deadline and inspected.

    .. class:: Timeout(when)

       An :ref:`asynchronous context manager <async-context-managers>`
       for cancelling overdue coroutines.

       ``when`` should be an absolute time at which the context should time out,
       as measured by the event loop's clock:

       - If ``when`` is ``None``, the timeout will never trigger.
       - If ``when < loop.time()``, the timeout will trigger on the next
         iteration of the event loop.

        .. method:: when() -> float | None

           Return the current deadline, or ``None`` if the current
           deadline is not set.

        .. method:: reschedule(when: float | None)

            Reschedule the timeout.

        .. method:: expired() -> bool

           Return whether the context manager has exceeded its deadline
           (expired).

    Example::

        async def main():
            try:
                # We do not know the timeout when starting, so we pass ``None``.
                async with asyncio.timeout(None) as cm:
                    # We know the timeout now, so we reschedule it.
                    new_deadline = get_running_loop().time() + 10
                    cm.reschedule(new_deadline)

                    await long_running_task()
            except TimeoutError:
                pass

            if cm.expired():
                print("Looks like we haven't finished on time.")

    Timeout context managers can be safely nested.

    .. versionadded:: 3.11

.. function:: timeout_at(when)

   Similar to :func:`asyncio.timeout`, except *when* is the absolute time
   to stop waiting, or ``None``.

   Example::

      async def main():
          loop = get_running_loop()
          deadline = loop.time() + 20
          try:
              async with asyncio.timeout_at(deadline):
                  await long_running_task()
          except TimeoutError:
              print("The long operation timed out, but we've handled it.")

          print("This statement will run regardless.")

   .. versionadded:: 3.11

.. coroutinefunction:: wait_for(aw, timeout)

   Wait for the *aw* :ref:`awaitable <asyncio-awaitables>`
   to complete with a timeout.

   If *aw* is a coroutine it is automatically scheduled as a Task.

   *timeout* can either be ``None`` or a float or int number of seconds
   to wait for.  If *timeout* is ``None``, block until the future
   completes.

   If a timeout occurs, it cancels the task and raises
   :exc:`TimeoutError`.

   To avoid the task :meth:`cancellation <Task.cancel>`,
   wrap it in :func:`shield`.

   The function will wait until the future is actually cancelled,
   so the total wait time may exceed the *timeout*. If an exception
   happens during cancellation, it is propagated.

   If the wait is cancelled, the future *aw* is also cancelled.

   .. _asyncio_example_waitfor:

   Example::

       async def eternity():
           # Sleep for one hour
           await asyncio.sleep(3600)
           print('yay!')

       async def main():
           # Wait for at most 1 second
           try:
               await asyncio.wait_for(eternity(), timeout=1.0)
           except TimeoutError:
               print('timeout!')

       asyncio.run(main())

       # Expected output:
       #
       #     timeout!

   .. versionchanged:: 3.7
      When *aw* is cancelled due to a timeout, ``wait_for`` waits
      for *aw* to be cancelled.  Previously, it raised
      :exc:`TimeoutError` immediately.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   .. versionchanged:: 3.11
      Raises :exc:`TimeoutError` instead of :exc:`asyncio.TimeoutError`.


Waiting Primitives
==================

.. coroutinefunction:: wait(aws, *, timeout=None, return_when=ALL_COMPLETED)

   Run :class:`~asyncio.Future` and :class:`~asyncio.Task` instances in the *aws*
   iterable concurrently and block until the condition specified
   by *return_when*.

   The *aws* iterable must not be empty.

   Returns two sets of Tasks/Futures: ``(done, pending)``.

   Usage::

        done, pending = await asyncio.wait(aws)

   *timeout* (a float or int), if specified, can be used to control
   the maximum number of seconds to wait before returning.

   Note that this function does not raise :exc:`TimeoutError`.
   Futures or Tasks that aren't done when the timeout occurs are simply
   returned in the second set.

   *return_when* indicates when this function should return.  It must
   be one of the following constants:

   .. list-table::
      :header-rows: 1

      * - Constant
        - Description

      * - .. data:: FIRST_COMPLETED
        - The function will return when any future finishes or is cancelled.

      * - .. data:: FIRST_EXCEPTION
        - The function will return when any future finishes by raising an
          exception. If no future raises an exception
          then it is equivalent to :const:`ALL_COMPLETED`.

      * - .. data:: ALL_COMPLETED
        - The function will return when all futures finish or are cancelled.

   Unlike :func:`~asyncio.wait_for`, ``wait()`` does not cancel the
   futures when a timeout occurs.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   .. versionchanged:: 3.11
      Passing coroutine objects to ``wait()`` directly is forbidden.

   .. versionchanged:: 3.12
      Added support for generators yielding tasks.


.. function:: as_completed(aws, *, timeout=None)

   Run :ref:`awaitable objects <asyncio-awaitables>` in the *aws* iterable
   concurrently. The returned object can be iterated to obtain the results
   of the awaitables as they finish.

   The object returned by ``as_completed()`` can be iterated as an
   :term:`asynchronous iterator` or a plain :term:`iterator`. When asynchronous
   iteration is used, the originally-supplied awaitables are yielded if they
   are tasks or futures. This makes it easy to correlate previously-scheduled
   tasks with their results. Example::

       ipv4_connect = create_task(open_connection("127.0.0.1", 80))
       ipv6_connect = create_task(open_connection("::1", 80))
       tasks = [ipv4_connect, ipv6_connect]

       async for earliest_connect in as_completed(tasks):
           # earliest_connect is done. The result can be obtained by
           # awaiting it or calling earliest_connect.result()
           reader, writer = await earliest_connect

           if earliest_connect is ipv6_connect:
               print("IPv6 connection established.")
           else:
               print("IPv4 connection established.")

   During asynchronous iteration, implicitly-created tasks will be yielded for
   supplied awaitables that aren't tasks or futures.

   When used as a plain iterator, each iteration yields a new coroutine that
   returns the result or raises the exception of the next completed awaitable.
   This pattern is compatible with Python versions older than 3.13::

       ipv4_connect = create_task(open_connection("127.0.0.1", 80))
       ipv6_connect = create_task(open_connection("::1", 80))
       tasks = [ipv4_connect, ipv6_connect]

       for next_connect in as_completed(tasks):
           # next_connect is not one of the original task objects. It must be
           # awaited to obtain the result value or raise the exception of the
           # awaitable that finishes next.
           reader, writer = await next_connect

   A :exc:`TimeoutError` is raised if the timeout occurs before all awaitables
   are done. This is raised by the ``async for`` loop during asynchronous
   iteration or by the coroutines yielded during plain iteration.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   .. deprecated:: 3.10
      Deprecation warning is emitted if not all awaitable objects in the *aws*
      iterable are Future-like objects and there is no running event loop.

   .. versionchanged:: 3.12
      Added support for generators yielding tasks.

   .. versionchanged:: 3.13
      The result can now be used as either an :term:`asynchronous iterator`
      or as a plain :term:`iterator` (previously it was only a plain iterator).


Running in Threads
==================

.. coroutinefunction:: to_thread(func, /, *args, **kwargs)

   Asynchronously run function *func* in a separate thread.

   Any \*args and \*\*kwargs supplied for this function are directly passed
   to *func*. Also, the current :class:`contextvars.Context` is propagated,
   allowing context variables from the event loop thread to be accessed in the
   separate thread.

   Return a coroutine that can be awaited to get the eventual result of *func*.

   This coroutine function is primarily intended to be used for executing
   IO-bound functions/methods that would otherwise block the event loop if
   they were run in the main thread. For example::

       def blocking_io():
           print(f"start blocking_io at {time.strftime('%X')}")
           # Note that time.sleep() can be replaced with any blocking
           # IO-bound operation, such as file operations.
           time.sleep(1)
           print(f"blocking_io complete at {time.strftime('%X')}")

       async def main():
           print(f"started main at {time.strftime('%X')}")

           await asyncio.gather(
               asyncio.to_thread(blocking_io),
               asyncio.sleep(1))

           print(f"finished main at {time.strftime('%X')}")


       asyncio.run(main())

       # Expected output:
       #
       # started main at 19:50:53
       # start blocking_io at 19:50:53
       # blocking_io complete at 19:50:54
       # finished main at 19:50:54

   Directly calling ``blocking_io()`` in any coroutine would block the event loop
   for its duration, resulting in an additional 1 second of run time. Instead,
   by using ``asyncio.to_thread()``, we can run it in a separate thread without
   blocking the event loop.

   .. note::

      Due to the :term:`GIL`, ``asyncio.to_thread()`` can typically only be used
      to make IO-bound functions non-blocking. However, for extension modules
      that release the GIL or alternative Python implementations that don't
      have one, ``asyncio.to_thread()`` can also be used for CPU-bound functions.

   .. versionadded:: 3.9


Scheduling From Other Threads
=============================

.. function:: run_coroutine_threadsafe(coro, loop)

   Submit a coroutine to the given event loop.  Thread-safe.

   Return a :class:`concurrent.futures.Future` to wait for the result
   from another OS thread.

   This function is meant to be called from a different OS thread
   than the one where the event loop is running.  Example::

     def in_thread(loop: asyncio.AbstractEventLoop) -> None:
         # Run some blocking IO
         pathlib.Path("example.txt").write_text("hello world", encoding="utf8")

         # Create a coroutine
         coro = asyncio.sleep(1, result=3)

         # Submit the coroutine to a given loop
         future = asyncio.run_coroutine_threadsafe(coro, loop)

         # Wait for the result with an optional timeout argument
         assert future.result(timeout=2) == 3

     async def amain() -> None:
         # Get the running loop
         loop = asyncio.get_running_loop()

         # Run something in a thread
         await asyncio.to_thread(in_thread, loop)

   It's also possible to run the other way around.  Example::

     @contextlib.contextmanager
     def loop_in_thread() -> Generator[asyncio.AbstractEventLoop]:
         loop_fut = concurrent.futures.Future[asyncio.AbstractEventLoop]()
         stop_event = asyncio.Event()

         async def main() -> None:
             loop_fut.set_result(asyncio.get_running_loop())
             await stop_event.wait()

         with concurrent.futures.ThreadPoolExecutor(1) as tpe:
             complete_fut = tpe.submit(asyncio.run, main())
             for fut in concurrent.futures.as_completed((loop_fut, complete_fut)):
                 if fut is loop_fut:
                     loop = loop_fut.result()
                     try:
                         yield loop
                     finally:
                         loop.call_soon_threadsafe(stop_event.set)
                 else:
                     fut.result()

     # Create a loop in another thread
     with loop_in_thread() as loop:
         # Create a coroutine
         coro = asyncio.sleep(1, result=3)

         # Submit the coroutine to a given loop
         future = asyncio.run_coroutine_threadsafe(coro, loop)

         # Wait for the result with an optional timeout argument
         assert future.result(timeout=2) == 3

   If an exception is raised in the coroutine, the returned Future
   will be notified.  It can also be used to cancel the task in
   the event loop::

     try:
         result = future.result(timeout)
     except TimeoutError:
         print('The coroutine took too long, cancelling the task...')
         future.cancel()
     except Exception as exc:
         print(f'The coroutine raised an exception: {exc!r}')
     else:
         print(f'The coroutine returned: {result!r}')

   See the :ref:`concurrency and multithreading <asyncio-multithreading>`
   section of the documentation.

   Unlike other asyncio functions this function requires the *loop*
   argument to be passed explicitly.

   .. versionadded:: 3.5.1


Introspection
=============


.. function:: current_task(loop=None)

   Return the currently running :class:`Task` instance, or ``None`` if
   no task is running.

   If *loop* is ``None`` :func:`get_running_loop` is used to get
   the current loop.

   .. versionadded:: 3.7


.. function:: all_tasks(loop=None)

   Return a set of not yet finished :class:`Task` objects run by
   the loop.

   If *loop* is ``None``, :func:`get_running_loop` is used for getting
   current loop.

   .. versionadded:: 3.7


.. function:: iscoroutine(obj)

   Return ``True`` if *obj* is a coroutine object.

   .. versionadded:: 3.4


Task Object
===========

.. class:: Task(coro, *, loop=None, name=None, context=None, eager_start=False)

   A :class:`Future-like <Future>` object that runs a Python
   :ref:`coroutine <coroutine>`.  Not thread-safe.

   Tasks are used to run coroutines in event loops.
   If a coroutine awaits on a Future, the Task suspends
   the execution of the coroutine and waits for the completion
   of the Future.  When the Future is *done*, the execution of
   the wrapped coroutine resumes.

   Event loops use cooperative scheduling: an event loop runs
   one Task at a time.  While a Task awaits for the completion of a
   Future, the event loop runs other Tasks, callbacks, or performs
   IO operations.

   Use the high-level :func:`asyncio.create_task` function to create
   Tasks, or the low-level :meth:`loop.create_task` or
   :func:`ensure_future` functions.  Manual instantiation of Tasks
   is discouraged.

