    async def test():
        print("never scheduled")

    async def main():
        test()

    asyncio.run(main())

Output::

  test.py:7: RuntimeWarning: coroutine 'test' was never awaited
    test()

Output in debug mode::

  test.py:7: RuntimeWarning: coroutine 'test' was never awaited
  Coroutine created at (most recent call last)
    File "../t.py", line 9, in <module>
      asyncio.run(main(), debug=True)

    < .. >

    File "../t.py", line 7, in main
      test()
    test()

The usual fix is to either await the coroutine or call the
:meth:`asyncio.create_task` function::

    async def main():
        await test()


Detect never-retrieved exceptions
=================================

If a :meth:`Future.set_exception` is called but the Future object is
never awaited on, the exception would never be propagated to the
user code.  In this case, asyncio would emit a log message when the
Future object is garbage collected.

Example of an unhandled exception::

    import asyncio

    async def bug():
        raise Exception("not consumed")

    async def main():
        asyncio.create_task(bug())

    asyncio.run(main())

Output::

    Task exception was never retrieved
    future: <Task finished coro=<bug() done, defined at test.py:3>
      exception=Exception('not consumed')>

    Traceback (most recent call last):
      File "test.py", line 4, in bug
        raise Exception("not consumed")
    Exception: not consumed

:ref:`Enable the debug mode <asyncio-debug-mode>` to get the
traceback where the task was created::

    asyncio.run(main(), debug=True)

Output in debug mode::

    Task exception was never retrieved
    future: <Task finished coro=<bug() done, defined at test.py:3>
        exception=Exception('not consumed') created at asyncio/tasks.py:321>

    source_traceback: Object created at (most recent call last):
      File "../t.py", line 9, in <module>
        asyncio.run(main(), debug=True)

    < .. >

    Traceback (most recent call last):
      File "../t.py", line 4, in bug
        raise Exception("not consumed")
    Exception: not consumed


================================================
File: /Doc/library/asyncio-exceptions.rst
================================================
.. currentmodule:: asyncio


.. _asyncio-exceptions:

==========
Exceptions
==========

**Source code:** :source:`Lib/asyncio/exceptions.py`

----------------------------------------------------

.. exception:: TimeoutError

   A deprecated alias of :exc:`TimeoutError`,
   raised when the operation has exceeded the given deadline.

   .. versionchanged:: 3.11

      This class was made an alias of :exc:`TimeoutError`.


.. exception:: CancelledError

   The operation has been cancelled.

   This exception can be caught to perform custom operations
   when asyncio Tasks are cancelled.  In almost all situations the
   exception must be re-raised.

   .. versionchanged:: 3.8

      :exc:`CancelledError` is now a subclass of :class:`BaseException` rather than :class:`Exception`.


.. exception:: InvalidStateError

   Invalid internal state of :class:`Task` or :class:`Future`.

   Can be raised in situations like setting a result value for a
   *Future* object that already has a result value set.


.. exception:: SendfileNotAvailableError

   The "sendfile" syscall is not available for the given
   socket or file type.

   A subclass of :exc:`RuntimeError`.


.. exception:: IncompleteReadError

   The requested read operation did not complete fully.

   Raised by the :ref:`asyncio stream APIs<asyncio-streams>`.

   This exception is a subclass of :exc:`EOFError`.

   .. attribute:: expected

      The total number (:class:`int`) of expected bytes.

   .. attribute:: partial

      A string of :class:`bytes` read before the end of stream was reached.


.. exception:: LimitOverrunError

   Reached the buffer size limit while looking for a separator.

   Raised by the :ref:`asyncio stream APIs <asyncio-streams>`.

   .. attribute:: consumed

      The total number of to be consumed bytes.


================================================
File: /Doc/library/asyncio-extending.rst
================================================
.. currentmodule:: asyncio


=========
Extending
=========

The main direction for :mod:`asyncio` extending is writing custom *event loop*
classes. Asyncio has helpers that could be used to simplify this task.

.. note::

   Third-parties should reuse existing asyncio code with caution,
   a new Python version is free to break backward compatibility
   in *internal* part of API.


Writing a Custom Event Loop
===========================

:class:`asyncio.AbstractEventLoop` declares very many methods.  Implementing all them
from scratch is a tedious job.

A loop can get many common methods implementation for free by inheriting from
:class:`asyncio.BaseEventLoop`.

In turn, the successor should implement a bunch of *private* methods declared but not
implemented in :class:`asyncio.BaseEventLoop`.

For example, ``loop.create_connection()`` checks arguments, resolves DNS addresses, and
calls ``loop._make_socket_transport()`` that should be implemented by inherited class.
The ``_make_socket_transport()`` method is not documented and is considered as an
*internal* API.



Future and Task private constructors
====================================

:class:`asyncio.Future` and :class:`asyncio.Task` should be never created directly,
please use corresponding :meth:`loop.create_future` and :meth:`loop.create_task`,
or :func:`asyncio.create_task` factories instead.

However, third-party *event loops* may *reuse* built-in future and task implementations
for the sake of getting a complex and highly optimized code for free.

For this purpose the following, *private* constructors are listed:

.. method:: Future.__init__(*, loop=None)

   Create a built-in future instance.

   *loop* is an optional event loop instance.

.. method:: Task.__init__(coro, *, loop=None, name=None, context=None)

   Create a built-in task instance.

   *loop* is an optional event loop instance. The rest of arguments are described in
   :meth:`loop.create_task` description.

   .. versionchanged:: 3.11

      *context* argument is added.



Task lifetime support
=====================

A third party task implementation should call the following functions to keep a task
visible by :func:`asyncio.all_tasks` and :func:`asyncio.current_task`:

.. function:: _register_task(task)

   Register a new *task* as managed by *asyncio*.

   Call the function from a task constructor.

.. function:: _unregister_task(task)

   Unregister a *task* from *asyncio* internal structures.

   The function should be called when a task is about to finish.

.. function:: _enter_task(loop, task)

   Switch the current task to the *task* argument.

   Call the function just before executing a portion of embedded *coroutine*
   (:meth:`coroutine.send` or :meth:`coroutine.throw`).

.. function:: _leave_task(loop, task)

   Switch the current task back from *task* to ``None``.

   Call the function just after :meth:`coroutine.send` or :meth:`coroutine.throw`
   execution.


================================================
File: /Doc/library/asyncio-future.rst
================================================
.. currentmodule:: asyncio


.. _asyncio-futures:

=======
Futures
=======

**Source code:** :source:`Lib/asyncio/futures.py`,
:source:`Lib/asyncio/base_futures.py`

-------------------------------------

*Future* objects are used to bridge **low-level callback-based code**
with high-level async/await code.


Future Functions
================

.. function:: isfuture(obj)

   Return ``True`` if *obj* is either of:

   * an instance of :class:`asyncio.Future`,
   * an instance of :class:`asyncio.Task`,
   * a Future-like object with a ``_asyncio_future_blocking``
     attribute.

   .. versionadded:: 3.5


.. function:: ensure_future(obj, *, loop=None)

   Return:

   * *obj* argument as is, if *obj* is a :class:`Future`,
     a :class:`Task`, or a Future-like object (:func:`isfuture`
     is used for the test.)

   * a :class:`Task` object wrapping *obj*, if *obj* is a
     coroutine (:func:`iscoroutine` is used for the test);
     in this case the coroutine will be scheduled by
     ``ensure_future()``.

   * a :class:`Task` object that would await on *obj*, if *obj* is an
     awaitable (:func:`inspect.isawaitable` is used for the test.)

   If *obj* is neither of the above a :exc:`TypeError` is raised.

   .. important::

      See also the :func:`create_task` function which is the
      preferred way for creating new Tasks.

      Save a reference to the result of this function, to avoid
      a task disappearing mid-execution.

   .. versionchanged:: 3.5.1
      The function accepts any :term:`awaitable` object.

   .. deprecated:: 3.10
      Deprecation warning is emitted if *obj* is not a Future-like object
      and *loop* is not specified and there is no running event loop.


.. function:: wrap_future(future, *, loop=None)

   Wrap a :class:`concurrent.futures.Future` object in a
   :class:`asyncio.Future` object.

   .. deprecated:: 3.10
      Deprecation warning is emitted if *future* is not a Future-like object
      and *loop* is not specified and there is no running event loop.


Future Object
=============

.. class:: Future(*, loop=None)

   A Future represents an eventual result of an asynchronous
   operation.  Not thread-safe.

   Future is an :term:`awaitable` object.  Coroutines can await on
   Future objects until they either have a result or an exception
   set, or until they are cancelled. A Future can be awaited multiple
   times and the result is same.

   Typically Futures are used to enable low-level
   callback-based code (e.g. in protocols implemented using asyncio
   :ref:`transports <asyncio-transports-protocols>`)
   to interoperate with high-level async/await code.

   The rule of thumb is to never expose Future objects in user-facing
   APIs, and the recommended way to create a Future object is to call
   :meth:`loop.create_future`.  This way alternative event loop
   implementations can inject their own optimized implementations
   of a Future object.

   .. versionchanged:: 3.7
      Added support for the :mod:`contextvars` module.

   .. deprecated:: 3.10
      Deprecation warning is emitted if *loop* is not specified
      and there is no running event loop.

   .. method:: result()

      Return the result of the Future.

      If the Future is *done* and has a result set by the
      :meth:`set_result` method, the result value is returned.

      If the Future is *done* and has an exception set by the
      :meth:`set_exception` method, this method raises the exception.

      If the Future has been *cancelled*, this method raises
      a :exc:`CancelledError` exception.

      If the Future's result isn't yet available, this method raises
      an :exc:`InvalidStateError` exception.

   .. method:: set_result(result)

      Mark the Future as *done* and set its result.

      Raises an :exc:`InvalidStateError` error if the Future is
      already *done*.

   .. method:: set_exception(exception)

      Mark the Future as *done* and set an exception.

      Raises an :exc:`InvalidStateError` error if the Future is
      already *done*.

   .. method:: done()

      Return ``True`` if the Future is *done*.

      A Future is *done* if it was *cancelled* or if it has a result
      or an exception set with :meth:`set_result` or
      :meth:`set_exception` calls.

   .. method:: cancelled()

      Return ``True`` if the Future was *cancelled*.

      The method is usually used to check if a Future is not
      *cancelled* before setting a result or an exception for it::

          if not fut.cancelled():
              fut.set_result(42)

   .. method:: add_done_callback(callback, *, context=None)

      Add a callback to be run when the Future is *done*.

      The *callback* is called with the Future object as its only
      argument.

      If the Future is already *done* when this method is called,
      the callback is scheduled with :meth:`loop.call_soon`.

      An optional keyword-only *context* argument allows specifying a
      custom :class:`contextvars.Context` for the *callback* to run in.
      The current context is used when no *context* is provided.

      :func:`functools.partial` can be used to pass parameters
      to the callback, e.g.::

          # Call 'print("Future:", fut)' when "fut" is done.
          fut.add_done_callback(
              functools.partial(print, "Future:"))

      .. versionchanged:: 3.7
         The *context* keyword-only parameter was added.
         See :pep:`567` for more details.

   .. method:: remove_done_callback(callback)

      Remove *callback* from the callbacks list.

      Returns the number of callbacks removed, which is typically 1,
      unless a callback was added more than once.

   .. method:: cancel(msg=None)

      Cancel the Future and schedule callbacks.

      If the Future is already *done* or *cancelled*, return ``False``.
      Otherwise, change the Future's state to *cancelled*,
      schedule the callbacks, and return ``True``.

      .. versionchanged:: 3.9
         Added the *msg* parameter.

   .. method:: exception()

      Return the exception that was set on this Future.

      The exception (or ``None`` if no exception was set) is
      returned only if the Future is *done*.

      If the Future has been *cancelled*, this method raises a
      :exc:`CancelledError` exception.

      If the Future isn't *done* yet, this method raises an
      :exc:`InvalidStateError` exception.

   .. method:: get_loop()

      Return the event loop the Future object is bound to.

      .. versionadded:: 3.7


.. _asyncio_example_future:

This example creates a Future object, creates and schedules an
asynchronous Task to set result for the Future, and waits until
the Future has a result::

    async def set_after(fut, delay, value):
        # Sleep for *delay* seconds.
        await asyncio.sleep(delay)

        # Set *value* as a result of *fut* Future.
        fut.set_result(value)

    async def main():
        # Get the current event loop.
        loop = asyncio.get_running_loop()

        # Create a new Future object.
        fut = loop.create_future()

        # Run "set_after()" coroutine in a parallel Task.
        # We are using the low-level "loop.create_task()" API here because
        # we already have a reference to the event loop at hand.
        # Otherwise we could have just used "asyncio.create_task()".
        loop.create_task(
            set_after(fut, 1, '... world'))

        print('hello ...')

        # Wait until *fut* has a result (1 second) and print it.
        print(await fut)

    asyncio.run(main())


.. important::

   The Future object was designed to mimic
   :class:`concurrent.futures.Future`.  Key differences include:

   - unlike asyncio Futures, :class:`concurrent.futures.Future`
     instances cannot be awaited.

   - :meth:`asyncio.Future.result` and :meth:`asyncio.Future.exception`
     do not accept the *timeout* argument.

   - :meth:`asyncio.Future.result` and :meth:`asyncio.Future.exception`
     raise an :exc:`InvalidStateError` exception when the Future is not
     *done*.

   - Callbacks registered with :meth:`asyncio.Future.add_done_callback`
     are not called immediately.  They are scheduled with
     :meth:`loop.call_soon` instead.

   - asyncio Future is not compatible with the
     :func:`concurrent.futures.wait` and
     :func:`concurrent.futures.as_completed` functions.

   - :meth:`asyncio.Future.cancel` accepts an optional ``msg`` argument,
     but :meth:`concurrent.futures.Future.cancel` does not.


================================================
File: /Doc/library/asyncio-llapi-index.rst
================================================
.. currentmodule:: asyncio


===================
Low-level API Index
===================

This page lists all low-level asyncio APIs.


Obtaining the Event Loop
========================

.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :func:`asyncio.get_running_loop`
      - The **preferred** function to get the running event loop.

    * - :func:`asyncio.get_event_loop`
      - Get an event loop instance (running or current via the current policy).

    * - :func:`asyncio.set_event_loop`
      - Set the event loop as current via the current policy.

    * - :func:`asyncio.new_event_loop`
      - Create a new event loop.


.. rubric:: Examples

* :ref:`Using asyncio.get_running_loop() <asyncio_example_future>`.


Event Loop Methods
==================

See also the main documentation section about the
:ref:`asyncio-event-loop-methods`.

.. rubric:: Lifecycle
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`loop.run_until_complete`
      - Run a Future/Task/awaitable until complete.

    * - :meth:`loop.run_forever`
      - Run the event loop forever.

    * - :meth:`loop.stop`
      - Stop the event loop.

    * - :meth:`loop.close`
      - Close the event loop.

    * - :meth:`loop.is_running`
      - Return ``True`` if the event loop is running.

    * - :meth:`loop.is_closed`
      - Return ``True`` if the event loop is closed.

    * - ``await`` :meth:`loop.shutdown_asyncgens`
      - Close asynchronous generators.


.. rubric:: Debugging
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`loop.set_debug`
      - Enable or disable the debug mode.

    * - :meth:`loop.get_debug`
      - Get the current debug mode.


.. rubric:: Scheduling Callbacks
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`loop.call_soon`
      - Invoke a callback soon.

    * - :meth:`loop.call_soon_threadsafe`
      - A thread-safe variant of :meth:`loop.call_soon`.

    * - :meth:`loop.call_later`
      - Invoke a callback *after* the given time.

    * - :meth:`loop.call_at`
      - Invoke a callback *at* the given time.


.. rubric:: Thread/Interpreter/Process Pool
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - ``await`` :meth:`loop.run_in_executor`
      - Run a CPU-bound or other blocking function in
        a :mod:`concurrent.futures` executor.

    * - :meth:`loop.set_default_executor`
      - Set the default executor for :meth:`loop.run_in_executor`.


.. rubric:: Tasks and Futures
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`loop.create_future`
      - Create a :class:`Future` object.

    * - :meth:`loop.create_task`
      - Schedule coroutine as a :class:`Task`.

    * - :meth:`loop.set_task_factory`
      - Set a factory used by :meth:`loop.create_task` to
        create :class:`Tasks <Task>`.

    * - :meth:`loop.get_task_factory`
      - Get the factory :meth:`loop.create_task` uses
        to create :class:`Tasks <Task>`.


.. rubric:: DNS
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - ``await`` :meth:`loop.getaddrinfo`
      - Asynchronous version of :meth:`socket.getaddrinfo`.

    * - ``await`` :meth:`loop.getnameinfo`
      - Asynchronous version of :meth:`socket.getnameinfo`.


.. rubric:: Networking and IPC
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - ``await`` :meth:`loop.create_connection`
      - Open a TCP connection.

    * - ``await`` :meth:`loop.create_server`
      - Create a TCP server.

    * - ``await`` :meth:`loop.create_unix_connection`
      - Open a Unix socket connection.

    * - ``await`` :meth:`loop.create_unix_server`
      - Create a Unix socket server.

    * - ``await`` :meth:`loop.connect_accepted_socket`
      - Wrap a :class:`~socket.socket` into a ``(transport, protocol)``
        pair.

    * - ``await`` :meth:`loop.create_datagram_endpoint`
      - Open a datagram (UDP) connection.

    * - ``await`` :meth:`loop.sendfile`
      - Send a file over a transport.

    * - ``await`` :meth:`loop.start_tls`
      - Upgrade an existing connection to TLS.

    * - ``await`` :meth:`loop.connect_read_pipe`
      - Wrap a read end of a pipe into a ``(transport, protocol)`` pair.

    * - ``await`` :meth:`loop.connect_write_pipe`
      - Wrap a write end of a pipe into a ``(transport, protocol)`` pair.


.. rubric:: Sockets
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - ``await`` :meth:`loop.sock_recv`
      - Receive data from the :class:`~socket.socket`.

    * - ``await`` :meth:`loop.sock_recv_into`
      - Receive data from the :class:`~socket.socket` into a buffer.

    * - ``await`` :meth:`loop.sock_recvfrom`
      - Receive a datagram from the :class:`~socket.socket`.

    * - ``await`` :meth:`loop.sock_recvfrom_into`
      - Receive a datagram from the :class:`~socket.socket` into a buffer.

    * - ``await`` :meth:`loop.sock_sendall`
      - Send data to the :class:`~socket.socket`.

    * - ``await`` :meth:`loop.sock_sendto`
      - Send a datagram via the :class:`~socket.socket` to the given address.

    * - ``await`` :meth:`loop.sock_connect`
      - Connect the :class:`~socket.socket`.

    * - ``await`` :meth:`loop.sock_accept`
      - Accept a :class:`~socket.socket` connection.

    * - ``await`` :meth:`loop.sock_sendfile`
      - Send a file over the :class:`~socket.socket`.

    * - :meth:`loop.add_reader`
      - Start watching a file descriptor for read availability.

    * - :meth:`loop.remove_reader`
      - Stop watching a file descriptor for read availability.

    * - :meth:`loop.add_writer`
      - Start watching a file descriptor for write availability.

    * - :meth:`loop.remove_writer`
      - Stop watching a file descriptor for write availability.


.. rubric:: Unix Signals
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`loop.add_signal_handler`
      - Add a handler for a :mod:`signal`.

    * - :meth:`loop.remove_signal_handler`
      - Remove a handler for a :mod:`signal`.


.. rubric:: Subprocesses
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`loop.subprocess_exec`
      - Spawn a subprocess.

    * - :meth:`loop.subprocess_shell`
      - Spawn a subprocess from a shell command.


.. rubric:: Error Handling
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`loop.call_exception_handler`
      - Call the exception handler.

    * - :meth:`loop.set_exception_handler`
      - Set a new exception handler.

    * - :meth:`loop.get_exception_handler`
      - Get the current exception handler.

    * - :meth:`loop.default_exception_handler`
      - The default exception handler implementation.


.. rubric:: Examples

* :ref:`Using asyncio.new_event_loop() and loop.run_forever()
  <asyncio_example_lowlevel_helloworld>`.

* :ref:`Using loop.call_later() <asyncio_example_call_later>`.

* Using ``loop.create_connection()`` to implement
  :ref:`an echo-client <asyncio_example_tcp_echo_client_protocol>`.

* Using ``loop.create_connection()`` to
  :ref:`connect a socket <asyncio_example_create_connection>`.

* :ref:`Using add_reader() to watch an FD for read events
  <asyncio_example_watch_fd>`.

* :ref:`Using loop.add_signal_handler() <asyncio_example_unix_signals>`.

* :ref:`Using loop.subprocess_exec() <asyncio_example_subprocess_proto>`.


Transports
==========

All transports implement the following methods:

.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`transport.close() <BaseTransport.close>`
      - Close the transport.

    * - :meth:`transport.is_closing() <BaseTransport.is_closing>`
      - Return ``True`` if the transport is closing or is closed.

    * - :meth:`transport.get_extra_info() <BaseTransport.get_extra_info>`
      - Request for information about the transport.

    * - :meth:`transport.set_protocol() <BaseTransport.set_protocol>`
      - Set a new protocol.

    * - :meth:`transport.get_protocol() <BaseTransport.get_protocol>`
      - Return the current protocol.


Transports that can receive data (TCP and Unix connections,
pipes, etc).  Returned from methods like
:meth:`loop.create_connection`, :meth:`loop.create_unix_connection`,
:meth:`loop.connect_read_pipe`, etc:

.. rubric:: Read Transports
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`transport.is_reading() <ReadTransport.is_reading>`
      - Return ``True`` if the transport is receiving.

    * - :meth:`transport.pause_reading() <ReadTransport.pause_reading>`
      - Pause receiving.

    * - :meth:`transport.resume_reading() <ReadTransport.resume_reading>`
      - Resume receiving.


Transports that can Send data (TCP and Unix connections,
pipes, etc).  Returned from methods like
:meth:`loop.create_connection`, :meth:`loop.create_unix_connection`,
:meth:`loop.connect_write_pipe`, etc:

.. rubric:: Write Transports
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`transport.write() <WriteTransport.write>`
      - Write data to the transport.

    * - :meth:`transport.writelines() <WriteTransport.writelines>`
      - Write buffers to the transport.

    * - :meth:`transport.can_write_eof() <WriteTransport.can_write_eof>`
      - Return :const:`True` if the transport supports sending EOF.

    * - :meth:`transport.write_eof() <WriteTransport.write_eof>`
      - Close and send EOF after flushing buffered data.

    * - :meth:`transport.abort() <WriteTransport.abort>`
      - Close the transport immediately.

    * - :meth:`transport.get_write_buffer_size()
        <WriteTransport.get_write_buffer_size>`
      - Return the current size of the output buffer.

    * - :meth:`transport.get_write_buffer_limits()
        <WriteTransport.get_write_buffer_limits>`
      - Return high and low water marks for write flow control.

    * - :meth:`transport.set_write_buffer_limits()
        <WriteTransport.set_write_buffer_limits>`
      - Set new high and low water marks for write flow control.


Transports returned by :meth:`loop.create_datagram_endpoint`:

.. rubric:: Datagram Transports
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`transport.sendto() <DatagramTransport.sendto>`
      - Send data to the remote peer.

    * - :meth:`transport.abort() <DatagramTransport.abort>`
      - Close the transport immediately.


Low-level transport abstraction over subprocesses.
Returned by :meth:`loop.subprocess_exec` and
:meth:`loop.subprocess_shell`:

.. rubric:: Subprocess Transports
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`transport.get_pid() <SubprocessTransport.get_pid>`
      - Return the subprocess process id.

    * - :meth:`transport.get_pipe_transport()
        <SubprocessTransport.get_pipe_transport>`
      - Return the transport for the requested communication pipe
        (*stdin*, *stdout*, or *stderr*).

    * - :meth:`transport.get_returncode() <SubprocessTransport.get_returncode>`
      - Return the subprocess return code.

    * - :meth:`transport.kill() <SubprocessTransport.kill>`
      - Kill the subprocess.

    * - :meth:`transport.send_signal() <SubprocessTransport.send_signal>`
      - Send a signal to the subprocess.

    * - :meth:`transport.terminate() <SubprocessTransport.terminate>`
      - Stop the subprocess.

    * - :meth:`transport.close() <SubprocessTransport.close>`
      - Kill the subprocess and close all pipes.


Protocols
=========

Protocol classes can implement the following **callback methods**:

.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - ``callback`` :meth:`connection_made() <BaseProtocol.connection_made>`
      - Called when a connection is made.

    * - ``callback`` :meth:`connection_lost() <BaseProtocol.connection_lost>`
      - Called when the connection is lost or closed.

    * - ``callback`` :meth:`pause_writing() <BaseProtocol.pause_writing>`
      - Called when the transport's buffer goes over the high water mark.

    * - ``callback`` :meth:`resume_writing() <BaseProtocol.resume_writing>`
      - Called when the transport's buffer drains below the low water mark.


.. rubric:: Streaming Protocols (TCP, Unix Sockets, Pipes)
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - ``callback`` :meth:`data_received() <Protocol.data_received>`
      - Called when some data is received.

    * - ``callback`` :meth:`eof_received() <Protocol.eof_received>`
      - Called when an EOF is received.


.. rubric:: Buffered Streaming Protocols
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - ``callback`` :meth:`get_buffer() <BufferedProtocol.get_buffer>`
      - Called to allocate a new receive buffer.

    * - ``callback`` :meth:`buffer_updated() <BufferedProtocol.buffer_updated>`
      - Called when the buffer was updated with the received data.

    * - ``callback`` :meth:`eof_received() <BufferedProtocol.eof_received>`
      - Called when an EOF is received.


.. rubric:: Datagram Protocols
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - ``callback`` :meth:`datagram_received()
        <DatagramProtocol.datagram_received>`
      - Called when a datagram is received.

    * - ``callback`` :meth:`error_received() <DatagramProtocol.error_received>`
      - Called when a previous send or receive operation raises an
        :class:`OSError`.


.. rubric:: Subprocess Protocols
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - ``callback`` :meth:`~SubprocessProtocol.pipe_data_received`
      - Called when the child process writes data into its
        *stdout* or *stderr* pipe.

    * - ``callback`` :meth:`~SubprocessProtocol.pipe_connection_lost`
      - Called when one of the pipes communicating with
        the child process is closed.

    * - ``callback`` :meth:`process_exited()
        <SubprocessProtocol.process_exited>`
      - Called when the child process has exited. It can be called before
        :meth:`~SubprocessProtocol.pipe_data_received` and
        :meth:`~SubprocessProtocol.pipe_connection_lost` methods.


Event Loop Policies
===================

Policies is a low-level mechanism to alter the behavior of
functions like :func:`asyncio.get_event_loop`.  See also
the main :ref:`policies section <asyncio-policies>` for more
details.


.. rubric:: Accessing Policies
.. list-table::
    :widths: 50 50
    :class: full-width-table

    * - :meth:`asyncio.get_event_loop_policy`
      - Return the current process-wide policy.

    * - :meth:`asyncio.set_event_loop_policy`
      - Set a new process-wide policy.

    * - :class:`AbstractEventLoopPolicy`
      - Base class for policy objects.


================================================
File: /Doc/library/asyncio-platforms.rst
================================================
.. currentmodule:: asyncio


.. _asyncio-platform-support:


================
Platform Support
================

The :mod:`asyncio` module is designed to be portable,
but some platforms have subtle differences and limitations
due to the platforms' underlying architecture and capabilities.


All Platforms
=============

* :meth:`loop.add_reader` and :meth:`loop.add_writer`
  cannot be used to monitor file I/O.


Windows
=======

**Source code:** :source:`Lib/asyncio/proactor_events.py`,
:source:`Lib/asyncio/windows_events.py`,
:source:`Lib/asyncio/windows_utils.py`

--------------------------------------

.. versionchanged:: 3.8

   On Windows, :class:`ProactorEventLoop` is now the default event loop.

All event loops on Windows do not support the following methods:

* :meth:`loop.create_unix_connection` and
  :meth:`loop.create_unix_server` are not supported.
  The :const:`socket.AF_UNIX` socket family is specific to Unix.

* :meth:`loop.add_signal_handler` and
  :meth:`loop.remove_signal_handler` are not supported.

:class:`SelectorEventLoop` has the following limitations:

* :class:`~selectors.SelectSelector` is used to wait on socket events:
  it supports sockets and is limited to 512 sockets.

* :meth:`loop.add_reader` and :meth:`loop.add_writer` only accept
  socket handles (e.g. pipe file descriptors are not supported).

* Pipes are not supported, so the :meth:`loop.connect_read_pipe`
  and :meth:`loop.connect_write_pipe` methods are not implemented.

* :ref:`Subprocesses <asyncio-subprocess>` are not supported, i.e.
  :meth:`loop.subprocess_exec` and :meth:`loop.subprocess_shell`
  methods are not implemented.

:class:`ProactorEventLoop` has the following limitations:

* The :meth:`loop.add_reader` and :meth:`loop.add_writer`
  methods are not supported.

The resolution of the monotonic clock on Windows is usually around 15.6
milliseconds.  The best resolution is 0.5 milliseconds. The resolution depends on the
hardware (availability of `HPET
<https://en.wikipedia.org/wiki/High_Precision_Event_Timer>`_) and on the
Windows configuration.


.. _asyncio-windows-subprocess:

Subprocess Support on Windows
-----------------------------

On Windows, the default event loop :class:`ProactorEventLoop` supports
subprocesses, whereas :class:`SelectorEventLoop` does not.


macOS
=====

Modern macOS versions are fully supported.

.. rubric:: macOS <= 10.8

On macOS 10.6, 10.7 and 10.8, the default event loop
uses :class:`selectors.KqueueSelector`, which does not support
character devices on these versions.  The :class:`SelectorEventLoop`
can be manually configured to use :class:`~selectors.SelectSelector`
or :class:`~selectors.PollSelector` to support character devices on
these older versions of macOS.  Example::

    import asyncio
    import selectors

    selector = selectors.SelectSelector()
    loop = asyncio.SelectorEventLoop(selector)
    asyncio.set_event_loop(loop)


================================================
File: /Doc/library/asyncio-policy.rst
================================================
.. currentmodule:: asyncio


.. _asyncio-policies:

========
Policies
========

.. warning::

   Policies are deprecated and will be removed in Python 3.16.
   Users are encouraged to use the :func:`asyncio.run` function
   or the :class:`asyncio.Runner` with *loop_factory* to use
   the desired loop implementation.


An event loop policy is a global object
used to get and set the current :ref:`event loop <asyncio-event-loop>`,
as well as create new event loops.
The default policy can be :ref:`replaced <asyncio-policy-get-set>` with
:ref:`built-in alternatives <asyncio-policy-builtin>`
to use different event loop implementations,
or substituted by a :ref:`custom policy <asyncio-custom-policies>`
that can override these behaviors.

The :ref:`policy object <asyncio-policy-objects>`
gets and sets a separate event loop per *context*.
This is per-thread by default,
though custom policies could define *context* differently.

Custom event loop policies can control the behavior of
:func:`get_event_loop`, :func:`set_event_loop`, and :func:`new_event_loop`.

Policy objects should implement the APIs defined
in the :class:`AbstractEventLoopPolicy` abstract base class.


.. _asyncio-policy-get-set:

Getting and Setting the Policy
==============================

The following functions can be used to get and set the policy
for the current process:

.. function:: get_event_loop_policy()

   Return the current process-wide policy.

   .. deprecated:: next
      The :func:`get_event_loop_policy` function is deprecated and
      will be removed in Python 3.16.

.. function:: set_event_loop_policy(policy)

   Set the current process-wide policy to *policy*.

   If *policy* is set to ``None``, the default policy is restored.

   .. deprecated:: next
      The :func:`set_event_loop_policy` function is deprecated and
      will be removed in Python 3.16.


.. _asyncio-policy-objects:

Policy Objects
==============

The abstract event loop policy base class is defined as follows:

.. class:: AbstractEventLoopPolicy

   An abstract base class for asyncio policies.

   .. method:: get_event_loop()

      Get the event loop for the current context.

      Return an event loop object implementing the
      :class:`AbstractEventLoop` interface.

      This method should never return ``None``.

      .. versionchanged:: 3.6

   .. method:: set_event_loop(loop)

      Set the event loop for the current context to *loop*.

   .. method:: new_event_loop()

      Create and return a new event loop object.

      This method should never return ``None``.

   .. deprecated:: next
      The :class:`AbstractEventLoopPolicy` class is deprecated and
      will be removed in Python 3.16.


.. _asyncio-policy-builtin:

asyncio ships with the following built-in policies:


.. class:: DefaultEventLoopPolicy

   The default asyncio policy.  Uses :class:`SelectorEventLoop`
   on Unix and :class:`ProactorEventLoop` on Windows.

   There is no need to install the default policy manually. asyncio
   is configured to use the default policy automatically.

   .. versionchanged:: 3.8

      On Windows, :class:`ProactorEventLoop` is now used by default.

   .. versionchanged:: 3.14
      The :meth:`get_event_loop` method of the default asyncio policy now
      raises a :exc:`RuntimeError` if there is no set event loop.

   .. deprecated:: next
      The :class:`DefaultEventLoopPolicy` class is deprecated and
      will be removed in Python 3.16.


.. class:: WindowsSelectorEventLoopPolicy

   An alternative event loop policy that uses the
   :class:`SelectorEventLoop` event loop implementation.

   .. availability:: Windows.

   .. deprecated:: next
      The :class:`WindowsSelectorEventLoopPolicy` class is deprecated and
      will be removed in Python 3.16.


.. class:: WindowsProactorEventLoopPolicy

   An alternative event loop policy that uses the
   :class:`ProactorEventLoop` event loop implementation.

   .. availability:: Windows.

   .. deprecated:: next
      The :class:`WindowsProactorEventLoopPolicy` class is deprecated and
      will be removed in Python 3.16.


.. _asyncio-custom-policies:

Custom Policies
===============

To implement a new event loop policy, it is recommended to subclass
:class:`DefaultEventLoopPolicy` and override the methods for which
custom behavior is wanted, e.g.::

    class MyEventLoopPolicy(asyncio.DefaultEventLoopPolicy):

        def get_event_loop(self):
            """Get the event loop.

            This may be None or an instance of EventLoop.
            """
            loop = super().get_event_loop()
            # Do something with loop ...
            return loop

    asyncio.set_event_loop_policy(MyEventLoopPolicy())


================================================
File: /Doc/library/asyncio-protocol.rst
================================================
.. currentmodule:: asyncio


.. _asyncio-transports-protocols:


========================
Transports and Protocols
========================

.. rubric:: Preface

Transports and Protocols are used by the **low-level** event loop
APIs such as :meth:`loop.create_connection`.  They use
callback-based programming style and enable high-performance
implementations of network or IPC protocols (e.g. HTTP).

Essentially, transports and protocols should only be used in
libraries and frameworks and never in high-level asyncio
applications.

This documentation page covers both `Transports`_ and `Protocols`_.

.. rubric:: Introduction

At the highest level, the transport is concerned with *how* bytes
are transmitted, while the protocol determines *which* bytes to
transmit (and to some extent when).

A different way of saying the same thing: a transport is an
abstraction for a socket (or similar I/O endpoint) while a protocol
is an abstraction for an application, from the transport's point
of view.

Yet another view is the transport and protocol interfaces
together define an abstract interface for using network I/O and
interprocess I/O.

There is always a 1:1 relationship between transport and protocol
objects: the protocol calls transport methods to send data,
while the transport calls protocol methods to pass it data that
has been received.

Most of connection oriented event loop methods
(such as :meth:`loop.create_connection`) usually accept a
*protocol_factory* argument used to create a *Protocol* object
for an accepted connection, represented by a *Transport* object.
Such methods usually return a tuple of ``(transport, protocol)``.

.. rubric:: Contents

This documentation page contains the following sections:

* The `Transports`_ section documents asyncio :class:`BaseTransport`,
  :class:`ReadTransport`, :class:`WriteTransport`, :class:`Transport`,
  :class:`DatagramTransport`, and :class:`SubprocessTransport`
  classes.

* The `Protocols`_ section documents asyncio :class:`BaseProtocol`,
  :class:`Protocol`, :class:`BufferedProtocol`,
  :class:`DatagramProtocol`, and :class:`SubprocessProtocol` classes.

* The `Examples`_ section showcases how to work with transports,
  protocols, and low-level event loop APIs.


.. _asyncio-transport:

Transports
==========

**Source code:** :source:`Lib/asyncio/transports.py`

----------------------------------------------------

Transports are classes provided by :mod:`asyncio` in order to abstract
various kinds of communication channels.

Transport objects are always instantiated by an
:ref:`asyncio event loop <asyncio-event-loop>`.

asyncio implements transports for TCP, UDP, SSL, and subprocess pipes.
The methods available on a transport depend on the transport's kind.

The transport classes are :ref:`not thread safe <asyncio-multithreading>`.


Transports Hierarchy
--------------------

.. class:: BaseTransport

   Base class for all transports.  Contains methods that all
   asyncio transports share.

.. class:: WriteTransport(BaseTransport)

   A base transport for write-only connections.

   Instances of the *WriteTransport* class are returned from
   the :meth:`loop.connect_write_pipe` event loop method and
   are also used by subprocess-related methods like
   :meth:`loop.subprocess_exec`.

.. class:: ReadTransport(BaseTransport)

   A base transport for read-only connections.

   Instances of the *ReadTransport* class are returned from
   the :meth:`loop.connect_read_pipe` event loop method and
   are also used by subprocess-related methods like
   :meth:`loop.subprocess_exec`.

.. class:: Transport(WriteTransport, ReadTransport)

   Interface representing a bidirectional transport, such as a
   TCP connection.

   The user does not instantiate a transport directly; they call a
   utility function, passing it a protocol factory and other
   information necessary to create the transport and protocol.

   Instances of the *Transport* class are returned from or used by
   event loop methods like :meth:`loop.create_connection`,
   :meth:`loop.create_unix_connection`,
   :meth:`loop.create_server`, :meth:`loop.sendfile`, etc.


.. class:: DatagramTransport(BaseTransport)

   A transport for datagram (UDP) connections.

   Instances of the *DatagramTransport* class are returned from
   the :meth:`loop.create_datagram_endpoint` event loop method.


.. class:: SubprocessTransport(BaseTransport)

   An abstraction to represent a connection between a parent and its
   child OS process.

   Instances of the *SubprocessTransport* class are returned from
   event loop methods :meth:`loop.subprocess_shell` and
   :meth:`loop.subprocess_exec`.


Base Transport
--------------

.. method:: BaseTransport.close()

   Close the transport.

   If the transport has a buffer for outgoing
   data, buffered data will be flushed asynchronously.  No more data
   will be received.  After all buffered data is flushed, the
   protocol's :meth:`protocol.connection_lost()
   <BaseProtocol.connection_lost>` method will be called with
   :const:`None` as its argument. The transport should not be
   used once it is closed.

.. method:: BaseTransport.is_closing()

   Return ``True`` if the transport is closing or is closed.

.. method:: BaseTransport.get_extra_info(name, default=None)

   Return information about the transport or underlying resources
   it uses.

   *name* is a string representing the piece of transport-specific
   information to get.

   *default* is the value to return if the information is not
   available, or if the transport does not support querying it
   with the given third-party event loop implementation or on the
   current platform.

   For example, the following code attempts to get the underlying
   socket object of the transport::

      sock = transport.get_extra_info('socket')
      if sock is not None:
          print(sock.getsockopt(...))

   Categories of information that can be queried on some transports:

   * socket:

     - ``'peername'``: the remote address to which the socket is
       connected, result of :meth:`socket.socket.getpeername`
       (``None`` on error)

     - ``'socket'``: :class:`socket.socket` instance

     - ``'sockname'``: the socket's own address,
       result of :meth:`socket.socket.getsockname`

   * SSL socket:

     - ``'compression'``: the compression algorithm being used as a
       string, or ``None`` if the connection isn't compressed; result
       of :meth:`ssl.SSLSocket.compression`

     - ``'cipher'``: a three-value tuple containing the name of the
       cipher being used, the version of the SSL protocol that defines
       its use, and the number of secret bits being used; result of
       :meth:`ssl.SSLSocket.cipher`

     - ``'peercert'``: peer certificate; result of
       :meth:`ssl.SSLSocket.getpeercert`

     - ``'sslcontext'``: :class:`ssl.SSLContext` instance

     - ``'ssl_object'``: :class:`ssl.SSLObject` or
       :class:`ssl.SSLSocket` instance

   * pipe:

     - ``'pipe'``: pipe object

   * subprocess:

     - ``'subprocess'``: :class:`subprocess.Popen` instance

.. method:: BaseTransport.set_protocol(protocol)

   Set a new protocol.

   Switching protocol should only be done when both
   protocols are documented to support the switch.

.. method:: BaseTransport.get_protocol()

   Return the current protocol.


Read-only Transports
--------------------

.. method:: ReadTransport.is_reading()

   Return ``True`` if the transport is receiving new data.

   .. versionadded:: 3.7

.. method:: ReadTransport.pause_reading()

   Pause the receiving end of the transport.  No data will be passed to
   the protocol's :meth:`protocol.data_received() <Protocol.data_received>`
   method until :meth:`resume_reading` is called.

   .. versionchanged:: 3.7
      The method is idempotent, i.e. it can be called when the
      transport is already paused or closed.

.. method:: ReadTransport.resume_reading()

   Resume the receiving end.  The protocol's
   :meth:`protocol.data_received() <Protocol.data_received>` method
   will be called once again if some data is available for reading.

   .. versionchanged:: 3.7
      The method is idempotent, i.e. it can be called when the
      transport is already reading.


Write-only Transports
---------------------

.. method:: WriteTransport.abort()

   Close the transport immediately, without waiting for pending operations
   to complete.  Buffered data will be lost.  No more data will be received.
   The protocol's :meth:`protocol.connection_lost()
   <BaseProtocol.connection_lost>` method will eventually be
   called with :const:`None` as its argument.

.. method:: WriteTransport.can_write_eof()

   Return :const:`True` if the transport supports
   :meth:`~WriteTransport.write_eof`, :const:`False` if not.

.. method:: WriteTransport.get_write_buffer_size()

   Return the current size of the output buffer used by the transport.

.. method:: WriteTransport.get_write_buffer_limits()

   Get the *high* and *low* watermarks for write flow control. Return a
   tuple ``(low, high)`` where *low* and *high* are positive number of
   bytes.

   Use :meth:`set_write_buffer_limits` to set the limits.

   .. versionadded:: 3.4.2

.. method:: WriteTransport.set_write_buffer_limits(high=None, low=None)

   Set the *high* and *low* watermarks for write flow control.

   These two values (measured in number of
   bytes) control when the protocol's
   :meth:`protocol.pause_writing() <BaseProtocol.pause_writing>`
   and :meth:`protocol.resume_writing() <BaseProtocol.resume_writing>`
   methods are called. If specified, the low watermark must be less
   than or equal to the high watermark.  Neither *high* nor *low*
   can be negative.

   :meth:`~BaseProtocol.pause_writing` is called when the buffer size
   becomes greater than or equal to the *high* value. If writing has
   been paused, :meth:`~BaseProtocol.resume_writing` is called when
   the buffer size becomes less than or equal to the *low* value.

   The defaults are implementation-specific.  If only the
   high watermark is given, the low watermark defaults to an
   implementation-specific value less than or equal to the
   high watermark.  Setting *high* to zero forces *low* to zero as
   well, and causes :meth:`~BaseProtocol.pause_writing` to be called
   whenever the buffer becomes non-empty.  Setting *low* to zero causes
   :meth:`~BaseProtocol.resume_writing` to be called only once the
   buffer is empty. Use of zero for either limit is generally
   sub-optimal as it reduces opportunities for doing I/O and
   computation concurrently.

   Use :meth:`~WriteTransport.get_write_buffer_limits`
   to get the limits.

.. method:: WriteTransport.write(data)

   Write some *data* bytes to the transport.

   This method does not block; it buffers the data and arranges for it
   to be sent out asynchronously.

.. method:: WriteTransport.writelines(list_of_data)

   Write a list (or any iterable) of data bytes to the transport.
   This is functionally equivalent to calling :meth:`write` on each
   element yielded by the iterable, but may be implemented more
   efficiently.

.. method:: WriteTransport.write_eof()

   Close the write end of the transport after flushing all buffered data.
   Data may still be received.

   This method can raise :exc:`NotImplementedError` if the transport
   (e.g. SSL) doesn't support half-closed connections.


Datagram Transports
-------------------

.. method:: DatagramTransport.sendto(data, addr=None)

   Send the *data* bytes to the remote peer given by *addr* (a
   transport-dependent target address).  If *addr* is :const:`None`,
   the data is sent to the target address given on transport
   creation.

   This method does not block; it buffers the data and arranges
   for it to be sent out asynchronously.

   .. versionchanged:: 3.13
      This method can be called with an empty bytes object to send a
      zero-length datagram. The buffer size calculation used for flow
      control is also updated to account for the datagram header.

.. method:: DatagramTransport.abort()

   Close the transport immediately, without waiting for pending
   operations to complete.  Buffered data will be lost.
   No more data will be received.  The protocol's
   :meth:`protocol.connection_lost() <BaseProtocol.connection_lost>`
   method will eventually be called with :const:`None` as its argument.


.. _asyncio-subprocess-transports:

Subprocess Transports
---------------------

.. method:: SubprocessTransport.get_pid()

   Return the subprocess process id as an integer.

.. method:: SubprocessTransport.get_pipe_transport(fd)

   Return the transport for the communication pipe corresponding to the
   integer file descriptor *fd*:

   * ``0``: readable streaming transport of the standard input (*stdin*),
     or :const:`None` if the subprocess was not created with ``stdin=PIPE``
   * ``1``: writable streaming transport of the standard output (*stdout*),
     or :const:`None` if the subprocess was not created with ``stdout=PIPE``
   * ``2``: writable streaming transport of the standard error (*stderr*),
     or :const:`None` if the subprocess was not created with ``stderr=PIPE``
   * other *fd*: :const:`None`

.. method:: SubprocessTransport.get_returncode()

   Return the subprocess return code as an integer or :const:`None`
   if it hasn't returned, which is similar to the
   :attr:`subprocess.Popen.returncode` attribute.

.. method:: SubprocessTransport.kill()

   Kill the subprocess.

   On POSIX systems, the function sends SIGKILL to the subprocess.
   On Windows, this method is an alias for :meth:`terminate`.

   See also :meth:`subprocess.Popen.kill`.

.. method:: SubprocessTransport.send_signal(signal)

   Send the *signal* number to the subprocess, as in
   :meth:`subprocess.Popen.send_signal`.

.. method:: SubprocessTransport.terminate()

   Stop the subprocess.

   On POSIX systems, this method sends :py:const:`~signal.SIGTERM` to the subprocess.
   On Windows, the Windows API function :c:func:`!TerminateProcess` is called to
   stop the subprocess.

   See also :meth:`subprocess.Popen.terminate`.

.. method:: SubprocessTransport.close()

   Kill the subprocess by calling the :meth:`kill` method.

   If the subprocess hasn't returned yet, and close transports of
   *stdin*, *stdout*, and *stderr* pipes.


.. _asyncio-protocol:

Protocols
=========

**Source code:** :source:`Lib/asyncio/protocols.py`

---------------------------------------------------

asyncio provides a set of abstract base classes that should be used
to implement network protocols.  Those classes are meant to be used
together with :ref:`transports <asyncio-transport>`.

Subclasses of abstract base protocol classes may implement some or
all methods.  All these methods are callbacks: they are called by
transports on certain events, for example when some data is received.
A base protocol method should be called by the corresponding transport.


Base Protocols
--------------

.. class:: BaseProtocol

   Base protocol with methods that all protocols share.

.. class:: Protocol(BaseProtocol)

   The base class for implementing streaming protocols
   (TCP, Unix sockets, etc).

.. class:: BufferedProtocol(BaseProtocol)

   A base class for implementing streaming protocols with manual
   control of the receive buffer.

.. class:: DatagramProtocol(BaseProtocol)

   The base class for implementing datagram (UDP) protocols.

.. class:: SubprocessProtocol(BaseProtocol)

   The base class for implementing protocols communicating with child
   processes (unidirectional pipes).


Base Protocol
-------------

All asyncio protocols can implement Base Protocol callbacks.

.. rubric:: Connection Callbacks

Connection callbacks are called on all protocols, exactly once per
a successful connection.  All other protocol callbacks can only be
called between those two methods.

.. method:: BaseProtocol.connection_made(transport)

   Called when a connection is made.

   The *transport* argument is the transport representing the
   connection.  The protocol is responsible for storing the reference
   to its transport.

.. method:: BaseProtocol.connection_lost(exc)

   Called when the connection is lost or closed.

   The argument is either an exception object or :const:`None`.
   The latter means a regular EOF is received, or the connection was
   aborted or closed by this side of the connection.


.. rubric:: Flow Control Callbacks

Flow control callbacks can be called by transports to pause or
resume writing performed by the protocol.

See the documentation of the :meth:`~WriteTransport.set_write_buffer_limits`
method for more details.

.. method:: BaseProtocol.pause_writing()

   Called when the transport's buffer goes over the high watermark.

.. method:: BaseProtocol.resume_writing()

   Called when the transport's buffer drains below the low watermark.

If the buffer size equals the high watermark,
:meth:`~BaseProtocol.pause_writing` is not called: the buffer size must
go strictly over.

Conversely, :meth:`~BaseProtocol.resume_writing` is called when the
buffer size is equal or lower than the low watermark.  These end
conditions are important to ensure that things go as expected when
either mark is zero.


Streaming Protocols
-------------------

Event methods, such as :meth:`loop.create_server`,
:meth:`loop.create_unix_server`, :meth:`loop.create_connection`,
:meth:`loop.create_unix_connection`, :meth:`loop.connect_accepted_socket`,
:meth:`loop.connect_read_pipe`, and :meth:`loop.connect_write_pipe`
accept factories that return streaming protocols.

.. method:: Protocol.data_received(data)

   Called when some data is received.  *data* is a non-empty bytes
   object containing the incoming data.

   Whether the data is buffered, chunked or reassembled depends on
   the transport.  In general, you shouldn't rely on specific semantics
   and instead make your parsing generic and flexible. However,
   data is always received in the correct order.

   The method can be called an arbitrary number of times while
   a connection is open.

   However, :meth:`protocol.eof_received() <Protocol.eof_received>`
   is called at most once.  Once ``eof_received()`` is called,
   ``data_received()`` is not called anymore.

.. method:: Protocol.eof_received()

   Called when the other end signals it won't send any more data
   (for example by calling :meth:`transport.write_eof()
   <WriteTransport.write_eof>`, if the other end also uses
   asyncio).

   This method may return a false value (including ``None``), in which case
   the transport will close itself.  Conversely, if this method returns a
   true value, the protocol used determines whether to close the transport.
   Since the default implementation returns ``None``, it implicitly closes the
   connection.

   Some transports, including SSL, don't support half-closed connections,
   in which case returning true from this method will result in the connection
   being closed.


State machine:

.. code-block:: none

    start -> connection_made
        [-> data_received]*
        [-> eof_received]?
    -> connection_lost -> end


Buffered Streaming Protocols
----------------------------

.. versionadded:: 3.7

Buffered Protocols can be used with any event loop method
that supports `Streaming Protocols`_.

``BufferedProtocol`` implementations allow explicit manual allocation
and control of the receive buffer.  Event loops can then use the buffer
provided by the protocol to avoid unnecessary data copies.  This
can result in noticeable performance improvement for protocols that
receive big amounts of data.  Sophisticated protocol implementations
can significantly reduce the number of buffer allocations.

The following callbacks are called on :class:`BufferedProtocol`
instances:

.. method:: BufferedProtocol.get_buffer(sizehint)

   Called to allocate a new receive buffer.

   *sizehint* is the recommended minimum size for the returned
   buffer.  It is acceptable to return smaller or larger buffers
   than what *sizehint* suggests.  When set to -1, the buffer size
   can be arbitrary. It is an error to return a buffer with a zero size.

   ``get_buffer()`` must return an object implementing the
   :ref:`buffer protocol <bufferobjects>`.

.. method:: BufferedProtocol.buffer_updated(nbytes)

   Called when the buffer was updated with the received data.

   *nbytes* is the total number of bytes that were written to the buffer.

.. method:: BufferedProtocol.eof_received()

   See the documentation of the :meth:`protocol.eof_received()
   <Protocol.eof_received>` method.


:meth:`~BufferedProtocol.get_buffer` can be called an arbitrary number
of times during a connection.  However, :meth:`protocol.eof_received()
<Protocol.eof_received>` is called at most once
and, if called, :meth:`~BufferedProtocol.get_buffer` and
:meth:`~BufferedProtocol.buffer_updated` won't be called after it.

State machine:

.. code-block:: none

    start -> connection_made
        [-> get_buffer
            [-> buffer_updated]?
        ]*
        [-> eof_received]?
    -> connection_lost -> end


Datagram Protocols
------------------

Datagram Protocol instances should be constructed by protocol
factories passed to the :meth:`loop.create_datagram_endpoint` method.

.. method:: DatagramProtocol.datagram_received(data, addr)

   Called when a datagram is received.  *data* is a bytes object containing
   the incoming data.  *addr* is the address of the peer sending the data;
   the exact format depends on the transport.

.. method:: DatagramProtocol.error_received(exc)

   Called when a previous send or receive operation raises an
   :class:`OSError`.  *exc* is the :class:`OSError` instance.

   This method is called in rare conditions, when the transport (e.g. UDP)
   detects that a datagram could not be delivered to its recipient.
   In many conditions though, undeliverable datagrams will be silently
   dropped.

.. note::

   On BSD systems (macOS, FreeBSD, etc.) flow control is not supported
   for datagram protocols, because there is no reliable way to detect send
   failures caused by writing too many packets.

   The socket always appears 'ready' and excess packets are dropped. An
   :class:`OSError` with ``errno`` set to :const:`errno.ENOBUFS` may
   or may not be raised; if it is raised, it will be reported to
   :meth:`DatagramProtocol.error_received` but otherwise ignored.


.. _asyncio-subprocess-protocols:

Subprocess Protocols
--------------------

Subprocess Protocol instances should be constructed by protocol
factories passed to the :meth:`loop.subprocess_exec` and
:meth:`loop.subprocess_shell` methods.

.. method:: SubprocessProtocol.pipe_data_received(fd, data)

   Called when the child process writes data into its stdout or stderr
   pipe.

   *fd* is the integer file descriptor of the pipe.

   *data* is a non-empty bytes object containing the received data.

.. method:: SubprocessProtocol.pipe_connection_lost(fd, exc)

   Called when one of the pipes communicating with the child process
   is closed.

   *fd* is the integer file descriptor that was closed.

.. method:: SubprocessProtocol.process_exited()

   Called when the child process has exited.

   It can be called before :meth:`~SubprocessProtocol.pipe_data_received` and
   :meth:`~SubprocessProtocol.pipe_connection_lost` methods.


Examples
========

.. _asyncio_example_tcp_echo_server_protocol:

TCP Echo Server
---------------

Create a TCP echo server using the :meth:`loop.create_server` method, send back
received data, and close the connection::

    import asyncio


    class EchoServerProtocol(asyncio.Protocol):
        def connection_made(self, transport):
            peername = transport.get_extra_info('peername')
            print('Connection from {}'.format(peername))
            self.transport = transport

        def data_received(self, data):
            message = data.decode()
            print('Data received: {!r}'.format(message))

            print('Send: {!r}'.format(message))
            self.transport.write(data)

            print('Close the client socket')
            self.transport.close()


    async def main():
        # Get a reference to the event loop as we plan to use
        # low-level APIs.
        loop = asyncio.get_running_loop()

        server = await loop.create_server(
            EchoServerProtocol,
            '127.0.0.1', 8888)

        async with server:
            await server.serve_forever()


    asyncio.run(main())


.. seealso::

   The :ref:`TCP echo server using streams <asyncio-tcp-echo-server-streams>`
   example uses the high-level :func:`asyncio.start_server` function.

.. _asyncio_example_tcp_echo_client_protocol:

TCP Echo Client
---------------

A TCP echo client using the :meth:`loop.create_connection` method, sends
data, and waits until the connection is closed::

    import asyncio


    class EchoClientProtocol(asyncio.Protocol):
        def __init__(self, message, on_con_lost):
            self.message = message
            self.on_con_lost = on_con_lost

        def connection_made(self, transport):
            transport.write(self.message.encode())
            print('Data sent: {!r}'.format(self.message))

        def data_received(self, data):
            print('Data received: {!r}'.format(data.decode()))

        def connection_lost(self, exc):
            print('The server closed the connection')
            self.on_con_lost.set_result(True)


    async def main():
        # Get a reference to the event loop as we plan to use
        # low-level APIs.
        loop = asyncio.get_running_loop()

        on_con_lost = loop.create_future()
        message = 'Hello World!'

        transport, protocol = await loop.create_connection(
            lambda: EchoClientProtocol(message, on_con_lost),
            '127.0.0.1', 8888)

        # Wait until the protocol signals that the connection
        # is lost and close the transport.
        try:
            await on_con_lost
        finally:
            transport.close()


    asyncio.run(main())


.. seealso::

   The :ref:`TCP echo client using streams <asyncio-tcp-echo-client-streams>`
   example uses the high-level :func:`asyncio.open_connection` function.


.. _asyncio-udp-echo-server-protocol:

UDP Echo Server
---------------

A UDP echo server, using the :meth:`loop.create_datagram_endpoint`
method, sends back received data::

    import asyncio


    class EchoServerProtocol:
        def connection_made(self, transport):
            self.transport = transport

        def datagram_received(self, data, addr):
            message = data.decode()
            print('Received %r from %s' % (message, addr))
            print('Send %r to %s' % (message, addr))
            self.transport.sendto(data, addr)


    async def main():
        print("Starting UDP server")

        # Get a reference to the event loop as we plan to use
        # low-level APIs.
        loop = asyncio.get_running_loop()

        # One protocol instance will be created to serve all
        # client requests.
        transport, protocol = await loop.create_datagram_endpoint(
            EchoServerProtocol,
            local_addr=('127.0.0.1', 9999))

        try:
            await asyncio.sleep(3600)  # Serve for 1 hour.
        finally:
            transport.close()


    asyncio.run(main())


.. _asyncio-udp-echo-client-protocol:

UDP Echo Client
---------------

A UDP echo client, using the :meth:`loop.create_datagram_endpoint`
method, sends data and closes the transport when it receives the answer::

    import asyncio


    class EchoClientProtocol:
        def __init__(self, message, on_con_lost):
            self.message = message
            self.on_con_lost = on_con_lost
            self.transport = None

        def connection_made(self, transport):
            self.transport = transport
            print('Send:', self.message)
            self.transport.sendto(self.message.encode())

        def datagram_received(self, data, addr):
            print("Received:", data.decode())

            print("Close the socket")
            self.transport.close()

        def error_received(self, exc):
            print('Error received:', exc)

        def connection_lost(self, exc):
            print("Connection closed")
            self.on_con_lost.set_result(True)


    async def main():
        # Get a reference to the event loop as we plan to use
        # low-level APIs.
        loop = asyncio.get_running_loop()

        on_con_lost = loop.create_future()
        message = "Hello World!"

        transport, protocol = await loop.create_datagram_endpoint(
            lambda: EchoClientProtocol(message, on_con_lost),
            remote_addr=('127.0.0.1', 9999))

        try:
            await on_con_lost
        finally:
            transport.close()


    asyncio.run(main())


.. _asyncio_example_create_connection:

Connecting Existing Sockets
---------------------------

Wait until a socket receives data using the
:meth:`loop.create_connection` method with a protocol::

    import asyncio
    import socket


    class MyProtocol(asyncio.Protocol):

        def __init__(self, on_con_lost):
            self.transport = None
            self.on_con_lost = on_con_lost

        def connection_made(self, transport):
            self.transport = transport

        def data_received(self, data):
            print("Received:", data.decode())

            # We are done: close the transport;
            # connection_lost() will be called automatically.
            self.transport.close()

        def connection_lost(self, exc):
            # The socket has been closed
            self.on_con_lost.set_result(True)


    async def main():
        # Get a reference to the event loop as we plan to use
        # low-level APIs.
        loop = asyncio.get_running_loop()
        on_con_lost = loop.create_future()

        # Create a pair of connected sockets
        rsock, wsock = socket.socketpair()

        # Register the socket to wait for data.
        transport, protocol = await loop.create_connection(
            lambda: MyProtocol(on_con_lost), sock=rsock)

        # Simulate the reception of data from the network.
        loop.call_soon(wsock.send, 'abc'.encode())

        try:
            await protocol.on_con_lost
        finally:
            transport.close()
            wsock.close()

    asyncio.run(main())

.. seealso::

   The :ref:`watch a file descriptor for read events
   <asyncio_example_watch_fd>` example uses the low-level
   :meth:`loop.add_reader` method to register an FD.

   The :ref:`register an open socket to wait for data using streams
   <asyncio_example_create_connection-streams>` example uses high-level streams
   created by the :func:`open_connection` function in a coroutine.

.. _asyncio_example_subprocess_proto:

loop.subprocess_exec() and SubprocessProtocol
---------------------------------------------

An example of a subprocess protocol used to get the output of a
subprocess and to wait for the subprocess exit.

The subprocess is created by the :meth:`loop.subprocess_exec` method::

    import asyncio
    import sys

    class DateProtocol(asyncio.SubprocessProtocol):
        def __init__(self, exit_future):
            self.exit_future = exit_future
            self.output = bytearray()
            self.pipe_closed = False
            self.exited = False

        def pipe_connection_lost(self, fd, exc):
            self.pipe_closed = True
            self.check_for_exit()

        def pipe_data_received(self, fd, data):
            self.output.extend(data)

        def process_exited(self):
            self.exited = True
            # process_exited() method can be called before
            # pipe_connection_lost() method: wait until both methods are
            # called.
            self.check_for_exit()

        def check_for_exit(self):
            if self.pipe_closed and self.exited:
                self.exit_future.set_result(True)

    async def get_date():
        # Get a reference to the event loop as we plan to use
        # low-level APIs.
        loop = asyncio.get_running_loop()

        code = 'import datetime; print(datetime.datetime.now())'
        exit_future = asyncio.Future(loop=loop)

        # Create the subprocess controlled by DateProtocol;
        # redirect the standard output into a pipe.
        transport, protocol = await loop.subprocess_exec(
            lambda: DateProtocol(exit_future),
            sys.executable, '-c', code,
            stdin=None, stderr=None)

        # Wait for the subprocess exit using the process_exited()
        # method of the protocol.
        await exit_future

        # Close the stdout pipe.
        transport.close()

        # Read the output which was collected by the
        # pipe_data_received() method of the protocol.
        data = bytes(protocol.output)
        return data.decode('ascii').rstrip()

    date = asyncio.run(get_date())
    print(f"Current date: {date}")

See also the :ref:`same example <asyncio_example_create_subprocess_exec>`
written using high-level APIs.


================================================
File: /Doc/library/asyncio-queue.rst
================================================
.. currentmodule:: asyncio

.. _asyncio-queues:

======
Queues
======

**Source code:** :source:`Lib/asyncio/queues.py`

------------------------------------------------

asyncio queues are designed to be similar to classes of the
:mod:`queue` module.  Although asyncio queues are not thread-safe,
they are designed to be used specifically in async/await code.

Note that methods of asyncio queues don't have a *timeout* parameter;
use :func:`asyncio.wait_for` function to do queue operations with a
timeout.

See also the `Examples`_ section below.

Queue
=====

.. class:: Queue(maxsize=0)

   A first in, first out (FIFO) queue.

   If *maxsize* is less than or equal to zero, the queue size is
   infinite.  If it is an integer greater than ``0``, then
   ``await put()`` blocks when the queue reaches *maxsize*
   until an item is removed by :meth:`get`.

   Unlike the standard library threading :mod:`queue`, the size of
   the queue is always known and can be returned by calling the
   :meth:`qsize` method.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.


   This class is :ref:`not thread safe <asyncio-multithreading>`.

   .. attribute:: maxsize

      Number of items allowed in the queue.

   .. method:: empty()

      Return ``True`` if the queue is empty, ``False`` otherwise.

   .. method:: full()

      Return ``True`` if there are :attr:`maxsize` items in the queue.

      If the queue was initialized with ``maxsize=0`` (the default),
      then :meth:`full` never returns ``True``.

   .. coroutinemethod:: get()

      Remove and return an item from the queue. If queue is empty,
      wait until an item is available.

      Raises :exc:`QueueShutDown` if the queue has been shut down and
      is empty, or if the queue has been shut down immediately.

   .. method:: get_nowait()

      Return an item if one is immediately available, else raise
      :exc:`QueueEmpty`.

   .. coroutinemethod:: join()

      Block until all items in the queue have been received and processed.

      The count of unfinished tasks goes up whenever an item is added
      to the queue. The count goes down whenever a consumer coroutine calls
      :meth:`task_done` to indicate that the item was retrieved and all
      work on it is complete.  When the count of unfinished tasks drops
      to zero, :meth:`join` unblocks.

   .. coroutinemethod:: put(item)

      Put an item into the queue. If the queue is full, wait until a
      free slot is available before adding the item.

      Raises :exc:`QueueShutDown` if the queue has been shut down.

   .. method:: put_nowait(item)

      Put an item into the queue without blocking.

      If no free slot is immediately available, raise :exc:`QueueFull`.

   .. method:: qsize()

      Return the number of items in the queue.

   .. method:: shutdown(immediate=False)

      Shut down the queue, making :meth:`~Queue.get` and :meth:`~Queue.put`
      raise :exc:`QueueShutDown`.

      By default, :meth:`~Queue.get` on a shut down queue will only
      raise once the queue is empty. Set *immediate* to true to make
      :meth:`~Queue.get` raise immediately instead.

      All blocked callers of :meth:`~Queue.put` and :meth:`~Queue.get`
      will be unblocked. If *immediate* is true, a task will be marked
      as done for each remaining item in the queue, which may unblock
      callers of :meth:`~Queue.join`.

      .. versionadded:: 3.13

   .. method:: task_done()

      Indicate that a formerly enqueued work item is complete.

      Used by queue consumers. For each :meth:`~Queue.get` used to
      fetch a work item, a subsequent call to :meth:`task_done` tells the
      queue that the processing on the work item is complete.

      If a :meth:`join` is currently blocking, it will resume when all
      items have been processed (meaning that a :meth:`task_done`
      call was received for every item that had been :meth:`~Queue.put`
      into the queue).

      ``shutdown(immediate=True)`` calls :meth:`task_done` for each
      remaining item in the queue.

      Raises :exc:`ValueError` if called more times than there were
      items placed in the queue.


Priority Queue
==============

.. class:: PriorityQueue

   A variant of :class:`Queue`; retrieves entries in priority order
   (lowest first).

   Entries are typically tuples of the form
   ``(priority_number, data)``.


LIFO Queue
==========

.. class:: LifoQueue

   A variant of :class:`Queue` that retrieves most recently added
   entries first (last in, first out).


Exceptions
==========

.. exception:: QueueEmpty

   This exception is raised when the :meth:`~Queue.get_nowait` method
   is called on an empty queue.


.. exception:: QueueFull

   Exception raised when the :meth:`~Queue.put_nowait` method is called
   on a queue that has reached its *maxsize*.


.. exception:: QueueShutDown

   Exception raised when :meth:`~Queue.put` or :meth:`~Queue.get` is
   called on a queue which has been shut down.

   .. versionadded:: 3.13


Examples
========

.. _asyncio_example_queue_dist:

Queues can be used to distribute workload between several
concurrent tasks::

   import asyncio
   import random
   import time


   async def worker(name, queue):
       while True:
           # Get a "work item" out of the queue.
           sleep_for = await queue.get()

           # Sleep for the "sleep_for" seconds.
           await asyncio.sleep(sleep_for)

           # Notify the queue that the "work item" has been processed.
           queue.task_done()

           print(f'{name} has slept for {sleep_for:.2f} seconds')


   async def main():
       # Create a queue that we will use to store our "workload".
       queue = asyncio.Queue()

       # Generate random timings and put them into the queue.
       total_sleep_time = 0
       for _ in range(20):
           sleep_for = random.uniform(0.05, 1.0)
           total_sleep_time += sleep_for
           queue.put_nowait(sleep_for)

       # Create three worker tasks to process the queue concurrently.
       tasks = []
       for i in range(3):
           task = asyncio.create_task(worker(f'worker-{i}', queue))
           tasks.append(task)

       # Wait until the queue is fully processed.
       started_at = time.monotonic()
       await queue.join()
       total_slept_for = time.monotonic() - started_at

       # Cancel our worker tasks.
       for task in tasks:
           task.cancel()
       # Wait until all worker tasks are cancelled.
       await asyncio.gather(*tasks, return_exceptions=True)

       print('====')
       print(f'3 workers slept in parallel for {total_slept_for:.2f} seconds')
       print(f'total expected sleep time: {total_sleep_time:.2f} seconds')


   asyncio.run(main())


================================================
File: /Doc/library/asyncio-runner.rst
================================================
.. currentmodule:: asyncio


=======
Runners
=======

**Source code:** :source:`Lib/asyncio/runners.py`


This section outlines high-level asyncio primitives to run asyncio code.

They are built on top of an :ref:`event loop <asyncio-event-loop>` with the aim
to simplify async code usage for common wide-spread scenarios.

.. contents::
   :depth: 1
   :local:



Running an asyncio Program
==========================

.. function:: run(coro, *, debug=None, loop_factory=None)

   Execute *coro* in an asyncio event loop and return the result.

   The argument can be any awaitable object.

   This function runs the awaitable, taking care of managing the
   asyncio event loop, *finalizing asynchronous generators*, and
   closing the executor.

   This function cannot be called when another asyncio event loop is
   running in the same thread.

   If *debug* is ``True``, the event loop will be run in debug mode. ``False`` disables
   debug mode explicitly. ``None`` is used to respect the global
   :ref:`asyncio-debug-mode` settings.

   If *loop_factory* is not ``None``, it is used to create a new event loop;
   otherwise :func:`asyncio.new_event_loop` is used. The loop is closed at the end.
   This function should be used as a main entry point for asyncio programs,
   and should ideally only be called once. It is recommended to use
   *loop_factory* to configure the event loop instead of policies.
   Passing :class:`asyncio.EventLoop` allows running asyncio without the
   policy system.

   The executor is given a timeout duration of 5 minutes to shutdown.
   If the executor hasn't finished within that duration, a warning is
   emitted and the executor is closed.

   Example::

       async def main():
           await asyncio.sleep(1)
           print('hello')

       asyncio.run(main())

   .. versionadded:: 3.7

   .. versionchanged:: 3.9
      Updated to use :meth:`loop.shutdown_default_executor`.

   .. versionchanged:: 3.10

      *debug* is ``None`` by default to respect the global debug mode settings.

   .. versionchanged:: 3.12

      Added *loop_factory* parameter.

   .. versionchanged:: 3.14

      *coro* can be any awaitable object.

   .. note::

      The :mod:`!asyncio` policy system is deprecated and will be removed
      in Python 3.16; from there on, an explicit *loop_factory* is needed
      to configure the event loop.


Runner context manager
======================

.. class:: Runner(*, debug=None, loop_factory=None)

   A context manager that simplifies *multiple* async function calls in the same
   context.

   Sometimes several top-level async functions should be called in the same :ref:`event
   loop <asyncio-event-loop>` and :class:`contextvars.Context`.

   If *debug* is ``True``, the event loop will be run in debug mode. ``False`` disables
   debug mode explicitly. ``None`` is used to respect the global
   :ref:`asyncio-debug-mode` settings.

   *loop_factory* could be used for overriding the loop creation.
   It is the responsibility of the *loop_factory* to set the created loop as the
   current one. By default :func:`asyncio.new_event_loop` is used and set as
   current event loop with :func:`asyncio.set_event_loop` if *loop_factory* is ``None``.

   Basically, :func:`asyncio.run` example can be rewritten with the runner usage::

        async def main():
            await asyncio.sleep(1)
            print('hello')

        with asyncio.Runner() as runner:
            runner.run(main())

   .. versionadded:: 3.11

   .. method:: run(coro, *, context=None)

      Execute *coro* in the embedded event loop.

      The argument can be any awaitable object.

      If the argument is a coroutine, it is wrapped in a Task.

      An optional keyword-only *context* argument allows specifying a
      custom :class:`contextvars.Context` for the code to run in.
      The runner's default context is used if context is ``None``.

      Returns the awaitable's result or raises an exception.

      This function cannot be called when another asyncio event loop is
      running in the same thread.

      .. versionchanged:: 3.14

         *coro* can be any awaitable object.

   .. method:: close()

      Close the runner.

      Finalize asynchronous generators, shutdown default executor, close the event loop
      and release embedded :class:`contextvars.Context`.

   .. method:: get_loop()

      Return the event loop associated with the runner instance.

   .. note::

      :class:`Runner` uses the lazy initialization strategy, its constructor doesn't
      initialize underlying low-level structures.

      Embedded *loop* and *context* are created at the :keyword:`with` body entering
      or the first call of :meth:`run` or :meth:`get_loop`.


Handling Keyboard Interruption
==============================

.. versionadded:: 3.11

When :const:`signal.SIGINT` is raised by :kbd:`Ctrl-C`, :exc:`KeyboardInterrupt`
exception is raised in the main thread by default. However this doesn't work with
:mod:`asyncio` because it can interrupt asyncio internals and can hang the program from
exiting.

To mitigate this issue, :mod:`asyncio` handles :const:`signal.SIGINT` as follows:

1. :meth:`asyncio.Runner.run` installs a custom :const:`signal.SIGINT` handler before
   any user code is executed and removes it when exiting from the function.
2. The :class:`~asyncio.Runner` creates the main task for the passed coroutine for its
   execution.
3. When :const:`signal.SIGINT` is raised by :kbd:`Ctrl-C`, the custom signal handler
   cancels the main task by calling :meth:`asyncio.Task.cancel` which raises
   :exc:`asyncio.CancelledError` inside the main task.  This causes the Python stack
   to unwind, ``try/except`` and ``try/finally`` blocks can be used for resource
   cleanup.  After the main task is cancelled, :meth:`asyncio.Runner.run` raises
   :exc:`KeyboardInterrupt`.
4. A user could write a tight loop which cannot be interrupted by
   :meth:`asyncio.Task.cancel`, in which case the second following :kbd:`Ctrl-C`
   immediately raises the :exc:`KeyboardInterrupt` without cancelling the main task.


================================================
File: /Doc/library/asyncio-stream.rst
================================================
.. currentmodule:: asyncio

.. _asyncio-streams:

=======
Streams
=======

**Source code:** :source:`Lib/asyncio/streams.py`

-------------------------------------------------

Streams are high-level async/await-ready primitives to work with
network connections.  Streams allow sending and receiving data without
using callbacks or low-level protocols and transports.

.. _asyncio_example_stream:

Here is an example of a TCP echo client written using asyncio
streams::

    import asyncio

    async def tcp_echo_client(message):
        reader, writer = await asyncio.open_connection(
            '127.0.0.1', 8888)

        print(f'Send: {message!r}')
        writer.write(message.encode())
        await writer.drain()

        data = await reader.read(100)
        print(f'Received: {data.decode()!r}')

        print('Close the connection')
        writer.close()
        await writer.wait_closed()

    asyncio.run(tcp_echo_client('Hello World!'))


See also the `Examples`_ section below.


.. rubric:: Stream Functions

The following top-level asyncio functions can be used to create
and work with streams:


.. coroutinefunction:: open_connection(host=None, port=None, *, \
                          limit=None, ssl=None, family=0, proto=0, \
                          flags=0, sock=None, local_addr=None, \
                          server_hostname=None, ssl_handshake_timeout=None, \
                          ssl_shutdown_timeout=None, \
                          happy_eyeballs_delay=None, interleave=None)

   Establish a network connection and return a pair of
   ``(reader, writer)`` objects.

   The returned *reader* and *writer* objects are instances of
   :class:`StreamReader` and :class:`StreamWriter` classes.

   *limit* determines the buffer size limit used by the
   returned :class:`StreamReader` instance.  By default the *limit*
   is set to 64 KiB.

   The rest of the arguments are passed directly to
   :meth:`loop.create_connection`.

   .. note::

      The *sock* argument transfers ownership of the socket to the
      :class:`StreamWriter` created. To close the socket, call its
      :meth:`~asyncio.StreamWriter.close` method.

   .. versionchanged:: 3.7
      Added the *ssl_handshake_timeout* parameter.

   .. versionchanged:: 3.8
      Added the *happy_eyeballs_delay* and *interleave* parameters.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   .. versionchanged:: 3.11
      Added the *ssl_shutdown_timeout* parameter.


.. coroutinefunction:: start_server(client_connected_cb, host=None, \
                          port=None, *, limit=None, \
                          family=socket.AF_UNSPEC, \
                          flags=socket.AI_PASSIVE, sock=None, \
                          backlog=100, ssl=None, reuse_address=None, \
                          reuse_port=None, keep_alive=None, \
                          ssl_handshake_timeout=None, \
                          ssl_shutdown_timeout=None, start_serving=True)

   Start a socket server.

   The *client_connected_cb* callback is called whenever a new client
   connection is established.  It receives a ``(reader, writer)`` pair
   as two arguments, instances of the :class:`StreamReader` and
   :class:`StreamWriter` classes.

   *client_connected_cb* can be a plain callable or a
   :ref:`coroutine function <coroutine>`; if it is a coroutine function,
   it will be automatically scheduled as a :class:`Task`.

   *limit* determines the buffer size limit used by the
   returned :class:`StreamReader` instance.  By default the *limit*
   is set to 64 KiB.

   The rest of the arguments are passed directly to
   :meth:`loop.create_server`.

   .. note::

      The *sock* argument transfers ownership of the socket to the
      server created. To close the socket, call the server's
      :meth:`~asyncio.Server.close` method.

   .. versionchanged:: 3.7
      Added the *ssl_handshake_timeout* and *start_serving* parameters.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   .. versionchanged:: 3.11
      Added the *ssl_shutdown_timeout* parameter.

   .. versionchanged:: 3.13
      Added the *keep_alive* parameter.


.. rubric:: Unix Sockets

.. coroutinefunction:: open_unix_connection(path=None, *, limit=None, \
                        ssl=None, sock=None, server_hostname=None, \
                        ssl_handshake_timeout=None, ssl_shutdown_timeout=None)

   Establish a Unix socket connection and return a pair of
   ``(reader, writer)``.

   Similar to :func:`open_connection` but operates on Unix sockets.

   See also the documentation of :meth:`loop.create_unix_connection`.

   .. note::

      The *sock* argument transfers ownership of the socket to the
      :class:`StreamWriter` created. To close the socket, call its
      :meth:`~asyncio.StreamWriter.close` method.

   .. availability:: Unix.

   .. versionchanged:: 3.7
      Added the *ssl_handshake_timeout* parameter.
      The *path* parameter can now be a :term:`path-like object`

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   .. versionchanged:: 3.11
      Added the *ssl_shutdown_timeout* parameter.


.. coroutinefunction:: start_unix_server(client_connected_cb, path=None, \
                          *, limit=None, sock=None, backlog=100, ssl=None, \
                          ssl_handshake_timeout=None, \
                          ssl_shutdown_timeout=None, start_serving=True)

   Start a Unix socket server.

   Similar to :func:`start_server` but works with Unix sockets.

   See also the documentation of :meth:`loop.create_unix_server`.

   .. note::

      The *sock* argument transfers ownership of the socket to the
      server created. To close the socket, call the server's
      :meth:`~asyncio.Server.close` method.

   .. availability:: Unix.

   .. versionchanged:: 3.7
      Added the *ssl_handshake_timeout* and *start_serving* parameters.
      The *path* parameter can now be a :term:`path-like object`.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   .. versionchanged:: 3.11
      Added the *ssl_shutdown_timeout* parameter.


StreamReader
============

.. class:: StreamReader

   Represents a reader object that provides APIs to read data
   from the IO stream. As an :term:`asynchronous iterable`, the
   object supports the :keyword:`async for` statement.

   It is not recommended to instantiate *StreamReader* objects
   directly; use :func:`open_connection` and :func:`start_server`
   instead.

   .. method:: feed_eof()

      Acknowledge the EOF.

   .. coroutinemethod:: read(n=-1)

      Read up to *n* bytes from the stream.

      If *n* is not provided or set to ``-1``,
      read until EOF, then return all read :class:`bytes`.
      If EOF was received and the internal buffer is empty,
      return an empty ``bytes`` object.

      If *n* is ``0``, return an empty ``bytes`` object immediately.

      If *n* is positive, return at most *n* available ``bytes``
      as soon as at least 1 byte is available in the internal buffer.
      If EOF is received before any byte is read, return an empty
      ``bytes`` object.

   .. coroutinemethod:: readline()

      Read one line, where "line" is a sequence of bytes
      ending with ``\n``.

      If EOF is received and ``\n`` was not found, the method
      returns partially read data.

      If EOF is received and the internal buffer is empty,
      return an empty ``bytes`` object.

   .. coroutinemethod:: readexactly(n)

      Read exactly *n* bytes.

      Raise an :exc:`IncompleteReadError` if EOF is reached before *n*
      can be read.  Use the :attr:`IncompleteReadError.partial`
      attribute to get the partially read data.

   .. coroutinemethod:: readuntil(separator=b'\n')

      Read data from the stream until *separator* is found.

      On success, the data and separator will be removed from the
      internal buffer (consumed). Returned data will include the
      separator at the end.

      If the amount of data read exceeds the configured stream limit, a
      :exc:`LimitOverrunError` exception is raised, and the data
      is left in the internal buffer and can be read again.

      If EOF is reached before the complete separator is found,
      an :exc:`IncompleteReadError` exception is raised, and the internal
      buffer is reset.  The :attr:`IncompleteReadError.partial` attribute
      may contain a portion of the separator.

      The *separator* may also be a tuple of separators. In this
      case the return value will be the shortest possible that has any
      separator as the suffix. For the purposes of :exc:`LimitOverrunError`,
      the shortest possible separator is considered to be the one that
      matched.

      .. versionadded:: 3.5.2

      .. versionchanged:: 3.13

         The *separator* parameter may now be a :class:`tuple` of
         separators.

   .. method:: at_eof()

      Return ``True`` if the buffer is empty and :meth:`feed_eof`
      was called.


StreamWriter
============

.. class:: StreamWriter

   Represents a writer object that provides APIs to write data
   to the IO stream.

   It is not recommended to instantiate *StreamWriter* objects
   directly; use :func:`open_connection` and :func:`start_server`
   instead.

   .. method:: write(data)

      The method attempts to write the *data* to the underlying socket immediately.
      If that fails, the data is queued in an internal write buffer until it can be
      sent.

      The method should be used along with the ``drain()`` method::

         stream.write(data)
         await stream.drain()

   .. method:: writelines(data)

      The method writes a list (or any iterable) of bytes to the underlying socket
      immediately.
      If that fails, the data is queued in an internal write buffer until it can be
      sent.

      The method should be used along with the ``drain()`` method::

         stream.writelines(lines)
         await stream.drain()

   .. method:: close()

      The method closes the stream and the underlying socket.

      The method should be used, though not mandatory,
      along with the ``wait_closed()`` method::

         stream.close()
         await stream.wait_closed()

   .. method:: can_write_eof()

      Return ``True`` if the underlying transport supports
      the :meth:`write_eof` method, ``False`` otherwise.

   .. method:: write_eof()

      Close the write end of the stream after the buffered write
      data is flushed.

   .. attribute:: transport

      Return the underlying asyncio transport.

   .. method:: get_extra_info(name, default=None)

      Access optional transport information; see
      :meth:`BaseTransport.get_extra_info` for details.

   .. coroutinemethod:: drain()

      Wait until it is appropriate to resume writing to the stream.
      Example::

          writer.write(data)
          await writer.drain()

      This is a flow control method that interacts with the underlying
      IO write buffer.  When the size of the buffer reaches
      the high watermark, *drain()* blocks until the size of the
      buffer is drained down to the low watermark and writing can
      be resumed.  When there is nothing to wait for, the :meth:`drain`
      returns immediately.

   .. coroutinemethod:: start_tls(sslcontext, *, server_hostname=None, \
                          ssl_handshake_timeout=None, ssl_shutdown_timeout=None)

      Upgrade an existing stream-based connection to TLS.

      Parameters:

      * *sslcontext*: a configured instance of :class:`~ssl.SSLContext`.

      * *server_hostname*: sets or overrides the host name that the target
        server's certificate will be matched against.

      * *ssl_handshake_timeout* is the time in seconds to wait for the TLS
        handshake to complete before aborting the connection.  ``60.0`` seconds
        if ``None`` (default).

      * *ssl_shutdown_timeout* is the time in seconds to wait for the SSL shutdown
        to complete before aborting the connection. ``30.0`` seconds if ``None``
        (default).

      .. versionadded:: 3.11

      .. versionchanged:: 3.12
         Added the *ssl_shutdown_timeout* parameter.


   .. method:: is_closing()

      Return ``True`` if the stream is closed or in the process of
      being closed.

      .. versionadded:: 3.7

   .. coroutinemethod:: wait_closed()

      Wait until the stream is closed.

      Should be called after :meth:`close` to wait until the underlying
      connection is closed, ensuring that all data has been flushed
      before e.g. exiting the program.

      .. versionadded:: 3.7


Examples
========

.. _asyncio-tcp-echo-client-streams:

TCP echo client using streams
-----------------------------

TCP echo client using the :func:`asyncio.open_connection` function::

    import asyncio

    async def tcp_echo_client(message):
        reader, writer = await asyncio.open_connection(
            '127.0.0.1', 8888)

        print(f'Send: {message!r}')
        writer.write(message.encode())
        await writer.drain()

        data = await reader.read(100)
        print(f'Received: {data.decode()!r}')

        print('Close the connection')
        writer.close()
        await writer.wait_closed()

    asyncio.run(tcp_echo_client('Hello World!'))


.. seealso::

   The :ref:`TCP echo client protocol <asyncio_example_tcp_echo_client_protocol>`
   example uses the low-level :meth:`loop.create_connection` method.


.. _asyncio-tcp-echo-server-streams:

TCP echo server using streams
-----------------------------

TCP echo server using the :func:`asyncio.start_server` function::

    import asyncio

    async def handle_echo(reader, writer):
        data = await reader.read(100)
        message = data.decode()
        addr = writer.get_extra_info('peername')

        print(f"Received {message!r} from {addr!r}")

        print(f"Send: {message!r}")
        writer.write(data)
        await writer.drain()

        print("Close the connection")
        writer.close()
        await writer.wait_closed()

    async def main():
        server = await asyncio.start_server(
            handle_echo, '127.0.0.1', 8888)

        addrs = ', '.join(str(sock.getsockname()) for sock in server.sockets)
        print(f'Serving on {addrs}')

        async with server:
            await server.serve_forever()

    asyncio.run(main())


.. seealso::

   The :ref:`TCP echo server protocol <asyncio_example_tcp_echo_server_protocol>`
   example uses the :meth:`loop.create_server` method.


Get HTTP headers
----------------

Simple example querying HTTP headers of the URL passed on the command line::

    import asyncio
    import urllib.parse
    import sys

    async def print_http_headers(url):
        url = urllib.parse.urlsplit(url)
        if url.scheme == 'https':
            reader, writer = await asyncio.open_connection(
                url.hostname, 443, ssl=True)
        else:
            reader, writer = await asyncio.open_connection(
                url.hostname, 80)

        query = (
            f"HEAD {url.path or '/'} HTTP/1.0\r\n"
            f"Host: {url.hostname}\r\n"
            f"\r\n"
        )

        writer.write(query.encode('latin-1'))
        while True:
            line = await reader.readline()
            if not line:
                break

            line = line.decode('latin1').rstrip()
            if line:
                print(f'HTTP header> {line}')

        # Ignore the body, close the socket
        writer.close()
        await writer.wait_closed()

    url = sys.argv[1]
    asyncio.run(print_http_headers(url))


Usage::

    python example.py http://example.com/path/page.html

or with HTTPS::

    python example.py https://example.com/path/page.html


.. _asyncio_example_create_connection-streams:

Register an open socket to wait for data using streams
------------------------------------------------------

Coroutine waiting until a socket receives data using the
:func:`open_connection` function::

    import asyncio
    import socket

    async def wait_for_data():
        # Get a reference to the current event loop because
        # we want to access low-level APIs.
        loop = asyncio.get_running_loop()

        # Create a pair of connected sockets.
        rsock, wsock = socket.socketpair()

        # Register the open socket to wait for data.
        reader, writer = await asyncio.open_connection(sock=rsock)

        # Simulate the reception of data from the network
        loop.call_soon(wsock.send, 'abc'.encode())

        # Wait for data
        data = await reader.read(100)

        # Got data, we are done: close the socket
        print("Received:", data.decode())
        writer.close()
        await writer.wait_closed()

        # Close the second socket
        wsock.close()

    asyncio.run(wait_for_data())

.. seealso::

   The :ref:`register an open socket to wait for data using a protocol
   <asyncio_example_create_connection>` example uses a low-level protocol and
   the :meth:`loop.create_connection` method.

   The :ref:`watch a file descriptor for read events
   <asyncio_example_watch_fd>` example uses the low-level
   :meth:`loop.add_reader` method to watch a file descriptor.


================================================
File: /Doc/library/asyncio-subprocess.rst
================================================
.. currentmodule:: asyncio

.. _asyncio-subprocess:

============
Subprocesses
============

**Source code:** :source:`Lib/asyncio/subprocess.py`,
:source:`Lib/asyncio/base_subprocess.py`

----------------------------------------

This section describes high-level async/await asyncio APIs to
create and manage subprocesses.

.. _asyncio_example_subprocess_shell:

Here's an example of how asyncio can run a shell command and
obtain its result::

    import asyncio

    async def run(cmd):
        proc = await asyncio.create_subprocess_shell(
            cmd,
            stdout=asyncio.subprocess.PIPE,
            stderr=asyncio.subprocess.PIPE)

        stdout, stderr = await proc.communicate()

        print(f'[{cmd!r} exited with {proc.returncode}]')
        if stdout:
            print(f'[stdout]\n{stdout.decode()}')
        if stderr:
            print(f'[stderr]\n{stderr.decode()}')

    asyncio.run(run('ls /zzz'))

will print::

    ['ls /zzz' exited with 1]
    [stderr]
    ls: /zzz: No such file or directory

Because all asyncio subprocess functions are asynchronous and asyncio
provides many tools to work with such functions, it is easy to execute
and monitor multiple subprocesses in parallel.  It is indeed trivial
to modify the above example to run several commands simultaneously::

    async def main():
        await asyncio.gather(
            run('ls /zzz'),
            run('sleep 1; echo "hello"'))

    asyncio.run(main())

See also the `Examples`_ subsection.


Creating Subprocesses
=====================

.. coroutinefunction:: create_subprocess_exec(program, *args, stdin=None, \
                          stdout=None, stderr=None, limit=None, **kwds)

   Create a subprocess.

   The *limit* argument sets the buffer limit for :class:`StreamReader`
   wrappers for :attr:`Process.stdout` and :attr:`Process.stderr`
   (if :const:`subprocess.PIPE` is passed to *stdout* and *stderr* arguments).

   Return a :class:`~asyncio.subprocess.Process` instance.

   See the documentation of :meth:`loop.subprocess_exec` for other
   parameters.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.


.. coroutinefunction:: create_subprocess_shell(cmd, stdin=None, \
                          stdout=None, stderr=None, limit=None, **kwds)

   Run the *cmd* shell command.

   The *limit* argument sets the buffer limit for :class:`StreamReader`
   wrappers for :attr:`Process.stdout` and :attr:`Process.stderr`
   (if :const:`subprocess.PIPE` is passed to *stdout* and *stderr* arguments).

   Return a :class:`~asyncio.subprocess.Process` instance.

   See the documentation of :meth:`loop.subprocess_shell` for other
   parameters.

   .. important::

      It is the application's responsibility to ensure that all whitespace and
      special characters are quoted appropriately to avoid `shell injection
      <https://en.wikipedia.org/wiki/Shell_injection#Shell_injection>`_
      vulnerabilities. The :func:`shlex.quote` function can be used to properly
      escape whitespace and special shell characters in strings that are going
      to be used to construct shell commands.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

.. note::

   Subprocesses are available for Windows if a :class:`ProactorEventLoop` is
   used. See :ref:`Subprocess Support on Windows <asyncio-windows-subprocess>`
   for details.

.. seealso::

   asyncio also has the following *low-level* APIs to work with subprocesses:
   :meth:`loop.subprocess_exec`, :meth:`loop.subprocess_shell`,
   :meth:`loop.connect_read_pipe`, :meth:`loop.connect_write_pipe`,
   as well as the :ref:`Subprocess Transports <asyncio-subprocess-transports>`
   and :ref:`Subprocess Protocols <asyncio-subprocess-protocols>`.


Constants
=========

.. data:: asyncio.subprocess.PIPE
   :module:

   Can be passed to the *stdin*, *stdout* or *stderr* parameters.

   If *PIPE* is passed to *stdin* argument, the
   :attr:`Process.stdin <asyncio.subprocess.Process.stdin>` attribute
   will point to a :class:`StreamWriter` instance.

   If *PIPE* is passed to *stdout* or *stderr* arguments, the
   :attr:`Process.stdout <asyncio.subprocess.Process.stdout>` and
   :attr:`Process.stderr <asyncio.subprocess.Process.stderr>`
   attributes will point to :class:`StreamReader` instances.

.. data:: asyncio.subprocess.STDOUT
   :module:

   Special value that can be used as the *stderr* argument and indicates
   that standard error should be redirected into standard output.

.. data:: asyncio.subprocess.DEVNULL
   :module:

   Special value that can be used as the *stdin*, *stdout* or *stderr* argument
   to process creation functions.  It indicates that the special file
   :data:`os.devnull` will be used for the corresponding subprocess stream.


Interacting with Subprocesses
=============================

Both :func:`create_subprocess_exec` and :func:`create_subprocess_shell`
functions return instances of the *Process* class.  *Process* is a high-level
wrapper that allows communicating with subprocesses and watching for
their completion.

.. class:: asyncio.subprocess.Process
   :module:

   An object that wraps OS processes created by the
   :func:`create_subprocess_exec` and :func:`create_subprocess_shell`
   functions.

   This class is designed to have a similar API to the
   :class:`subprocess.Popen` class, but there are some
   notable differences:

   * unlike Popen, Process instances do not have an equivalent to
     the :meth:`~subprocess.Popen.poll` method;

   * the :meth:`~asyncio.subprocess.Process.communicate` and
     :meth:`~asyncio.subprocess.Process.wait` methods don't have a
     *timeout* parameter: use the :func:`~asyncio.wait_for` function;

   * the :meth:`Process.wait() <asyncio.subprocess.Process.wait>` method
     is asynchronous, whereas :meth:`subprocess.Popen.wait` method
     is implemented as a blocking busy loop;

   * the *universal_newlines* parameter is not supported.

   This class is :ref:`not thread safe <asyncio-multithreading>`.

   See also the :ref:`Subprocess and Threads <asyncio-subprocess-threads>`
   section.

   .. coroutinemethod:: wait()

      Wait for the child process to terminate.

      Set and return the :attr:`returncode` attribute.

      .. note::

         This method can deadlock when using ``stdout=PIPE`` or
         ``stderr=PIPE`` and the child process generates so much output
         that it blocks waiting for the OS pipe buffer to accept
         more data. Use the :meth:`communicate` method when using pipes
         to avoid this condition.

   .. coroutinemethod:: communicate(input=None)

      Interact with process:

      1. send data to *stdin* (if *input* is not ``None``);
      2. closes *stdin*;
      3. read data from *stdout* and *stderr*, until EOF is reached;
      4. wait for process to terminate.

      The optional *input* argument is the data (:class:`bytes` object)
      that will be sent to the child process.

      Return a tuple ``(stdout_data, stderr_data)``.

      If either :exc:`BrokenPipeError` or :exc:`ConnectionResetError`
      exception is raised when writing *input* into *stdin*, the
      exception is ignored.  This condition occurs when the process
      exits before all data are written into *stdin*.

      If it is desired to send data to the process' *stdin*,
      the process needs to be created with ``stdin=PIPE``.  Similarly,
      to get anything other than ``None`` in the result tuple, the
      process has to be created with ``stdout=PIPE`` and/or
      ``stderr=PIPE`` arguments.

      Note, that the data read is buffered in memory, so do not use
      this method if the data size is large or unlimited.

      .. versionchanged:: 3.12

         *stdin* gets closed when `input=None` too.

   .. method:: send_signal(signal)

      Sends the signal *signal* to the child process.

      .. note::

         On Windows, :py:const:`~signal.SIGTERM` is an alias for :meth:`terminate`.
         ``CTRL_C_EVENT`` and ``CTRL_BREAK_EVENT`` can be sent to processes
         started with a *creationflags* parameter which includes
         ``CREATE_NEW_PROCESS_GROUP``.

   .. method:: terminate()

      Stop the child process.

      On POSIX systems this method sends :py:const:`~signal.SIGTERM` to the
      child process.

      On Windows the Win32 API function :c:func:`!TerminateProcess` is
      called to stop the child process.

   .. method:: kill()

      Kill the child process.

      On POSIX systems this method sends :py:data:`SIGKILL` to the child
      process.

      On Windows this method is an alias for :meth:`terminate`.

   .. attribute:: stdin

      Standard input stream (:class:`StreamWriter`) or ``None``
      if the process was created with ``stdin=None``.

   .. attribute:: stdout

      Standard output stream (:class:`StreamReader`) or ``None``
      if the process was created with ``stdout=None``.

   .. attribute:: stderr

      Standard error stream (:class:`StreamReader`) or ``None``
      if the process was created with ``stderr=None``.

   .. warning::

      Use the :meth:`communicate` method rather than
      :attr:`process.stdin.write() <stdin>`,
      :attr:`await process.stdout.read() <stdout>` or
      :attr:`await process.stderr.read() <stderr>`.
      This avoids deadlocks due to streams pausing reading or writing
      and blocking the child process.

   .. attribute:: pid

      Process identification number (PID).

      Note that for processes created by the :func:`create_subprocess_shell`
      function, this attribute is the PID of the spawned shell.

   .. attribute:: returncode

      Return code of the process when it exits.

      A ``None`` value indicates that the process has not terminated yet.

      A negative value ``-N`` indicates that the child was terminated
      by signal ``N`` (POSIX only).


.. _asyncio-subprocess-threads:

Subprocess and Threads
----------------------

Standard asyncio event loop supports running subprocesses from different threads by
default.

On Windows subprocesses are provided by :class:`ProactorEventLoop` only (default),
:class:`SelectorEventLoop` has no subprocess support.

Note that alternative event loop implementations might have own limitations;
please refer to their documentation.

.. seealso::

   The :ref:`Concurrency and multithreading in asyncio
   <asyncio-multithreading>` section.


Examples
--------

An example using the :class:`~asyncio.subprocess.Process` class to
control a subprocess and the :class:`StreamReader` class to read from
its standard output.

.. _asyncio_example_create_subprocess_exec:

The subprocess is created by the :func:`create_subprocess_exec`
function::

    import asyncio
    import sys

    async def get_date():
        code = 'import datetime; print(datetime.datetime.now())'

        # Create the subprocess; redirect the standard output
        # into a pipe.
        proc = await asyncio.create_subprocess_exec(
            sys.executable, '-c', code,
            stdout=asyncio.subprocess.PIPE)

        # Read one line of output.
        data = await proc.stdout.readline()
        line = data.decode('ascii').rstrip()

        # Wait for the subprocess exit.
        await proc.wait()
        return line

    date = asyncio.run(get_date())
    print(f"Current date: {date}")


See also the :ref:`same example <asyncio_example_subprocess_proto>`
written using low-level APIs.


================================================
File: /Doc/library/asyncio-sync.rst
================================================
.. currentmodule:: asyncio

.. _asyncio-sync:

==========================
Synchronization Primitives
==========================

**Source code:** :source:`Lib/asyncio/locks.py`

-----------------------------------------------

asyncio synchronization primitives are designed to be similar to
those of the :mod:`threading` module with two important caveats:

* asyncio primitives are not thread-safe, therefore they should not
  be used for OS thread synchronization (use :mod:`threading` for
  that);

* methods of these synchronization primitives do not accept the *timeout*
  argument; use the :func:`asyncio.wait_for` function to perform
  operations with timeouts.

asyncio has the following basic synchronization primitives:

* :class:`Lock`
* :class:`Event`
* :class:`Condition`
* :class:`Semaphore`
* :class:`BoundedSemaphore`
* :class:`Barrier`


---------


Lock
====

.. class:: Lock()

   Implements a mutex lock for asyncio tasks.  Not thread-safe.

   An asyncio lock can be used to guarantee exclusive access to a
   shared resource.

   The preferred way to use a Lock is an :keyword:`async with`
   statement::

       lock = asyncio.Lock()

       # ... later
       async with lock:
           # access shared state

   which is equivalent to::

       lock = asyncio.Lock()

       # ... later
       await lock.acquire()
       try:
           # access shared state
       finally:
           lock.release()

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   .. coroutinemethod:: acquire()

      Acquire the lock.

      This method waits until the lock is *unlocked*, sets it to
      *locked* and returns ``True``.

      When more than one coroutine is blocked in :meth:`acquire`
      waiting for the lock to be unlocked, only one coroutine
      eventually proceeds.

      Acquiring a lock is *fair*: the coroutine that proceeds will be
      the first coroutine that started waiting on the lock.

   .. method:: release()

      Release the lock.

      When the lock is *locked*, reset it to *unlocked* and return.

      If the lock is *unlocked*, a :exc:`RuntimeError` is raised.

   .. method:: locked()

      Return ``True`` if the lock is *locked*.


Event
=====

.. class:: Event()

   An event object.  Not thread-safe.

   An asyncio event can be used to notify multiple asyncio tasks
   that some event has happened.

   An Event object manages an internal flag that can be set to *true*
   with the :meth:`~Event.set` method and reset to *false* with the
   :meth:`clear` method.  The :meth:`~Event.wait` method blocks until the
   flag is set to *true*.  The flag is set to *false* initially.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   .. _asyncio_example_sync_event:

   Example::

      async def waiter(event):
          print('waiting for it ...')
          await event.wait()
          print('... got it!')

      async def main():
          # Create an Event object.
          event = asyncio.Event()

          # Spawn a Task to wait until 'event' is set.
          waiter_task = asyncio.create_task(waiter(event))

          # Sleep for 1 second and set the event.
          await asyncio.sleep(1)
          event.set()

          # Wait until the waiter task is finished.
          await waiter_task

      asyncio.run(main())

   .. coroutinemethod:: wait()

      Wait until the event is set.

      If the event is set, return ``True`` immediately.
      Otherwise block until another task calls :meth:`~Event.set`.

   .. method:: set()

      Set the event.

      All tasks waiting for event to be set will be immediately
      awakened.

   .. method:: clear()

      Clear (unset) the event.

      Tasks awaiting on :meth:`~Event.wait` will now block until the
      :meth:`~Event.set` method is called again.

   .. method:: is_set()

      Return ``True`` if the event is set.


Condition
=========

.. class:: Condition(lock=None)

   A Condition object.  Not thread-safe.

   An asyncio condition primitive can be used by a task to wait for
   some event to happen and then get exclusive access to a shared
   resource.

   In essence, a Condition object combines the functionality
   of an :class:`Event` and a :class:`Lock`.  It is possible to have
   multiple Condition objects share one Lock, which allows coordinating
   exclusive access to a shared resource between different tasks
   interested in particular states of that shared resource.

   The optional *lock* argument must be a :class:`Lock` object or
   ``None``.  In the latter case a new Lock object is created
   automatically.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   The preferred way to use a Condition is an :keyword:`async with`
   statement::

       cond = asyncio.Condition()

       # ... later
       async with cond:
           await cond.wait()

   which is equivalent to::

       cond = asyncio.Condition()

       # ... later
       await cond.acquire()
       try:
           await cond.wait()
       finally:
           cond.release()

   .. coroutinemethod:: acquire()

      Acquire the underlying lock.

      This method waits until the underlying lock is *unlocked*,
      sets it to *locked* and returns ``True``.

   .. method:: notify(n=1)

      Wake up *n* tasks (1 by default) waiting on this
      condition.  If fewer than *n* tasks are waiting they are all awakened.

      The lock must be acquired before this method is called and
      released shortly after.  If called with an *unlocked* lock
      a :exc:`RuntimeError` error is raised.

   .. method:: locked()

      Return ``True`` if the underlying lock is acquired.

   .. method:: notify_all()

      Wake up all tasks waiting on this condition.

      This method acts like :meth:`notify`, but wakes up all waiting
      tasks.

      The lock must be acquired before this method is called and
      released shortly after.  If called with an *unlocked* lock
      a :exc:`RuntimeError` error is raised.

   .. method:: release()

      Release the underlying lock.

      When invoked on an unlocked lock, a :exc:`RuntimeError` is
      raised.

   .. coroutinemethod:: wait()

      Wait until notified.

      If the calling task has not acquired the lock when this method is
      called, a :exc:`RuntimeError` is raised.

      This method releases the underlying lock, and then blocks until
      it is awakened by a :meth:`notify` or :meth:`notify_all` call.
      Once awakened, the Condition re-acquires its lock and this method
      returns ``True``.

      Note that a task *may* return from this call spuriously,
      which is why the caller should always re-check the state
      and be prepared to :meth:`~Condition.wait` again. For this reason, you may
      prefer to use :meth:`~Condition.wait_for` instead.

   .. coroutinemethod:: wait_for(predicate)

      Wait until a predicate becomes *true*.

      The predicate must be a callable which result will be
      interpreted as a boolean value.  The method will repeatedly
      :meth:`~Condition.wait` until the predicate evaluates to *true*. The final value is the
      return value.


Semaphore
=========

.. class:: Semaphore(value=1)

   A Semaphore object.  Not thread-safe.

   A semaphore manages an internal counter which is decremented by each
   :meth:`acquire` call and incremented by each :meth:`release` call.
   The counter can never go below zero; when :meth:`acquire` finds
   that it is zero, it blocks, waiting until some task calls
   :meth:`release`.

   The optional *value* argument gives the initial value for the
   internal counter (``1`` by default). If the given value is
   less than ``0`` a :exc:`ValueError` is raised.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   The preferred way to use a Semaphore is an :keyword:`async with`
   statement::

       sem = asyncio.Semaphore(10)

       # ... later
       async with sem:
           # work with shared resource

   which is equivalent to::

       sem = asyncio.Semaphore(10)

       # ... later
       await sem.acquire()
       try:
           # work with shared resource
       finally:
           sem.release()

   .. coroutinemethod:: acquire()

      Acquire a semaphore.

      If the internal counter is greater than zero, decrement
      it by one and return ``True`` immediately.  If it is zero, wait
      until a :meth:`release` is called and return ``True``.

   .. method:: locked()

      Returns ``True`` if semaphore can not be acquired immediately.

   .. method:: release()

      Release a semaphore, incrementing the internal counter by one.
      Can wake up a task waiting to acquire the semaphore.

      Unlike :class:`BoundedSemaphore`, :class:`Semaphore` allows
      making more ``release()`` calls than ``acquire()`` calls.


BoundedSemaphore
================

.. class:: BoundedSemaphore(value=1)

   A bounded semaphore object.  Not thread-safe.

   Bounded Semaphore is a version of :class:`Semaphore` that raises
   a :exc:`ValueError` in :meth:`~Semaphore.release` if it
   increases the internal counter above the initial *value*.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.


Barrier
=======

.. class:: Barrier(parties)

   A barrier object.  Not thread-safe.

   A barrier is a simple synchronization primitive that allows to block until
   *parties* number of tasks are waiting on it.
   Tasks can wait on the :meth:`~Barrier.wait` method and would be blocked until
   the specified number of tasks end up waiting on :meth:`~Barrier.wait`.
   At that point all of the waiting tasks would unblock simultaneously.

   :keyword:`async with` can be used as an alternative to awaiting on
   :meth:`~Barrier.wait`.

   The barrier can be reused any number of times.

   .. _asyncio_example_barrier:

   Example::

      async def example_barrier():
         # barrier with 3 parties
         b = asyncio.Barrier(3)

         # create 2 new waiting tasks
         asyncio.create_task(b.wait())
         asyncio.create_task(b.wait())

         await asyncio.sleep(0)
         print(b)

         # The third .wait() call passes the barrier
         await b.wait()
         print(b)
         print("barrier passed")

         await asyncio.sleep(0)
         print(b)

      asyncio.run(example_barrier())

   Result of this example is::

      <asyncio.locks.Barrier object at 0x... [filling, waiters:2/3]>
      <asyncio.locks.Barrier object at 0x... [draining, waiters:0/3]>
      barrier passed
      <asyncio.locks.Barrier object at 0x... [filling, waiters:0/3]>

   .. versionadded:: 3.11

   .. coroutinemethod:: wait()

      Pass the barrier. When all the tasks party to the barrier have called
      this function, they are all unblocked simultaneously.

      When a waiting or blocked task in the barrier is cancelled,
      this task exits the barrier which stays in the same state.
      If the state of the barrier is "filling", the number of waiting task
      decreases by 1.

      The return value is an integer in the range of 0 to ``parties-1``, different
      for each task. This can be used to select a task to do some special
      housekeeping, e.g.::

         ...
         async with barrier as position:
            if position == 0:
               # Only one task prints this
               print('End of *draining phase*')

      This method may raise a :class:`BrokenBarrierError` exception if the
      barrier is broken or reset while a task is waiting.
      It could raise a :exc:`CancelledError` if a task is cancelled.

   .. coroutinemethod:: reset()

      Return the barrier to the default, empty state.  Any tasks waiting on it
      will receive the :class:`BrokenBarrierError` exception.

      If a barrier is broken it may be better to just leave it and create a new one.

   .. coroutinemethod:: abort()

      Put the barrier into a broken state.  This causes any active or future
      calls to :meth:`~Barrier.wait` to fail with the :class:`BrokenBarrierError`.
      Use this for example if one of the tasks needs to abort, to avoid infinite
      waiting tasks.

   .. attribute:: parties

      The number of tasks required to pass the barrier.

   .. attribute:: n_waiting

      The number of tasks currently waiting in the barrier while filling.

   .. attribute:: broken

      A boolean that is ``True`` if the barrier is in the broken state.


.. exception:: BrokenBarrierError

   This exception, a subclass of :exc:`RuntimeError`, is raised when the
   :class:`Barrier` object is reset or broken.

---------


.. versionchanged:: 3.9

   Acquiring a lock using ``await lock`` or ``yield from lock`` and/or
   :keyword:`with` statement (``with await lock``, ``with (yield from
   lock)``) was removed.  Use ``async with lock`` instead.


================================================
File: /Doc/library/asyncio-task.rst
================================================
.. currentmodule:: asyncio


====================
Coroutines and Tasks
====================

This section outlines high-level asyncio APIs to work with coroutines
and Tasks.

.. contents::
   :depth: 1
   :local:


.. _coroutine:

Coroutines
==========

**Source code:** :source:`Lib/asyncio/coroutines.py`

----------------------------------------------------

:term:`Coroutines <coroutine>` declared with the async/await syntax is the
preferred way of writing asyncio applications.  For example, the following
snippet of code prints "hello", waits 1 second,
and then prints "world"::

    >>> import asyncio

    >>> async def main():
    ...     print('hello')
    ...     await asyncio.sleep(1)
    ...     print('world')

    >>> asyncio.run(main())
    hello
    world

Note that simply calling a coroutine will not schedule it to
be executed::

    >>> main()
    <coroutine object main at 0x1053bb7c8>

To actually run a coroutine, asyncio provides the following mechanisms:

* The :func:`asyncio.run` function to run the top-level
  entry point "main()" function (see the above example.)

* Awaiting on a coroutine.  The following snippet of code will
  print "hello" after waiting for 1 second, and then print "world"
  after waiting for *another* 2 seconds::

      import asyncio
      import time

      async def say_after(delay, what):
          await asyncio.sleep(delay)
          print(what)

      async def main():
          print(f"started at {time.strftime('%X')}")

          await say_after(1, 'hello')
          await say_after(2, 'world')

          print(f"finished at {time.strftime('%X')}")

      asyncio.run(main())

  Expected output::

      started at 17:13:52
      hello
      world
      finished at 17:13:55

* The :func:`asyncio.create_task` function to run coroutines
  concurrently as asyncio :class:`Tasks <Task>`.

  Let's modify the above example and run two ``say_after`` coroutines
  *concurrently*::

      async def main():
          task1 = asyncio.create_task(
              say_after(1, 'hello'))

          task2 = asyncio.create_task(
              say_after(2, 'world'))

          print(f"started at {time.strftime('%X')}")

          # Wait until both tasks are completed (should take
          # around 2 seconds.)
          await task1
          await task2

          print(f"finished at {time.strftime('%X')}")

  Note that expected output now shows that the snippet runs
  1 second faster than before::

      started at 17:14:32
      hello
      world
      finished at 17:14:34

* The :class:`asyncio.TaskGroup` class provides a more modern
  alternative to :func:`create_task`.
  Using this API, the last example becomes::

      async def main():
          async with asyncio.TaskGroup() as tg:
              task1 = tg.create_task(
                  say_after(1, 'hello'))

              task2 = tg.create_task(
                  say_after(2, 'world'))

              print(f"started at {time.strftime('%X')}")

          # The await is implicit when the context manager exits.

          print(f"finished at {time.strftime('%X')}")

  The timing and output should be the same as for the previous version.

  .. versionadded:: 3.11
     :class:`asyncio.TaskGroup`.


.. _asyncio-awaitables:

Awaitables
==========

We say that an object is an **awaitable** object if it can be used
in an :keyword:`await` expression.  Many asyncio APIs are designed to
accept awaitables.

There are three main types of *awaitable* objects:
**coroutines**, **Tasks**, and **Futures**.


.. rubric:: Coroutines

Python coroutines are *awaitables* and therefore can be awaited from
other coroutines::

    import asyncio

    async def nested():
        return 42

    async def main():
        # Nothing happens if we just call "nested()".
        # A coroutine object is created but not awaited,
        # so it *won't run at all*.
        nested()  # will raise a "RuntimeWarning".

        # Let's do it differently now and await it:
        print(await nested())  # will print "42".

    asyncio.run(main())

.. important::

   In this documentation the term "coroutine" can be used for
   two closely related concepts:

   * a *coroutine function*: an :keyword:`async def` function;

   * a *coroutine object*: an object returned by calling a
     *coroutine function*.


.. rubric:: Tasks

*Tasks* are used to schedule coroutines *concurrently*.

When a coroutine is wrapped into a *Task* with functions like
:func:`asyncio.create_task` the coroutine is automatically
scheduled to run soon::

    import asyncio

    async def nested():
        return 42

    async def main():
        # Schedule nested() to run soon concurrently
        # with "main()".
        task = asyncio.create_task(nested())

        # "task" can now be used to cancel "nested()", or
        # can simply be awaited to wait until it is complete:
        await task

    asyncio.run(main())


.. rubric:: Futures

A :class:`Future` is a special **low-level** awaitable object that
represents an **eventual result** of an asynchronous operation.

When a Future object is *awaited* it means that the coroutine will
wait until the Future is resolved in some other place.

Future objects in asyncio are needed to allow callback-based code
to be used with async/await.

Normally **there is no need** to create Future objects at the
application level code.

Future objects, sometimes exposed by libraries and some asyncio
APIs, can be awaited::

    async def main():
        await function_that_returns_a_future_object()

        # this is also valid:
        await asyncio.gather(
            function_that_returns_a_future_object(),
            some_python_coroutine()
        )

A good example of a low-level function that returns a Future object
is :meth:`loop.run_in_executor`.


Creating Tasks
==============

**Source code:** :source:`Lib/asyncio/tasks.py`

-----------------------------------------------

.. function:: create_task(coro, *, name=None, context=None)

   Wrap the *coro* :ref:`coroutine <coroutine>` into a :class:`Task`
   and schedule its execution.  Return the Task object.

   If *name* is not ``None``, it is set as the name of the task using
   :meth:`Task.set_name`.

   An optional keyword-only *context* argument allows specifying a
   custom :class:`contextvars.Context` for the *coro* to run in.
   The current context copy is created when no *context* is provided.

   The task is executed in the loop returned by :func:`get_running_loop`,
   :exc:`RuntimeError` is raised if there is no running loop in
   current thread.

   .. note::

      :meth:`asyncio.TaskGroup.create_task` is a new alternative
      leveraging structural concurrency; it allows for waiting
      for a group of related tasks with strong safety guarantees.

   .. important::

      Save a reference to the result of this function, to avoid
      a task disappearing mid-execution. The event loop only keeps
      weak references to tasks. A task that isn't referenced elsewhere
      may get garbage collected at any time, even before it's done.
      For reliable "fire-and-forget" background tasks, gather them in
      a collection::

          background_tasks = set()

          for i in range(10):
              task = asyncio.create_task(some_coro(param=i))

              # Add task to the set. This creates a strong reference.
              background_tasks.add(task)

              # To prevent keeping references to finished tasks forever,
              # make each task remove its own reference from the set after
              # completion:
              task.add_done_callback(background_tasks.discard)

   .. versionadded:: 3.7

   .. versionchanged:: 3.8
      Added the *name* parameter.

   .. versionchanged:: 3.11
      Added the *context* parameter.


Task Cancellation
=================

Tasks can easily and safely be cancelled.
When a task is cancelled, :exc:`asyncio.CancelledError` will be raised
in the task at the next opportunity.

It is recommended that coroutines use ``try/finally`` blocks to robustly
perform clean-up logic. In case :exc:`asyncio.CancelledError`
is explicitly caught, it should generally be propagated when
clean-up is complete. :exc:`asyncio.CancelledError` directly subclasses
:exc:`BaseException` so most code will not need to be aware of it.

The asyncio components that enable structured concurrency, like
:class:`asyncio.TaskGroup` and :func:`asyncio.timeout`,
are implemented using cancellation internally and might misbehave if
a coroutine swallows :exc:`asyncio.CancelledError`. Similarly, user code
should not generally call :meth:`uncancel <asyncio.Task.uncancel>`.
However, in cases when suppressing :exc:`asyncio.CancelledError` is
truly desired, it is necessary to also call ``uncancel()`` to completely
remove the cancellation state.

.. _taskgroups:

Task Groups
===========

Task groups combine a task creation API with a convenient
and reliable way to wait for all tasks in the group to finish.

.. class:: TaskGroup()

   An :ref:`asynchronous context manager <async-context-managers>`
   holding a group of tasks.
   Tasks can be added to the group using :meth:`create_task`.
   All tasks are awaited when the context manager exits.

   .. versionadded:: 3.11

   .. method:: create_task(coro, *, name=None, context=None)

      Create a task in this task group.
      The signature matches that of :func:`asyncio.create_task`.
      If the task group is inactive (e.g. not yet entered,
      already finished, or in the process of shutting down),
      we will close the given ``coro``.

      .. versionchanged:: 3.13

         Close the given coroutine if the task group is not active.

Example::

    async def main():
        async with asyncio.TaskGroup() as tg:
            task1 = tg.create_task(some_coro(...))
            task2 = tg.create_task(another_coro(...))
        print(f"Both tasks have completed now: {task1.result()}, {task2.result()}")

The ``async with`` statement will wait for all tasks in the group to finish.
While waiting, new tasks may still be added to the group
(for example, by passing ``tg`` into one of the coroutines
and calling ``tg.create_task()`` in that coroutine).
Once the last task has finished and the ``async with`` block is exited,
no new tasks may be added to the group.

The first time any of the tasks belonging to the group fails
with an exception other than :exc:`asyncio.CancelledError`,
the remaining tasks in the group are cancelled.
No further tasks can then be added to the group.
At this point, if the body of the ``async with`` statement is still active
(i.e., :meth:`~object.__aexit__` hasn't been called yet),
the task directly containing the ``async with`` statement is also cancelled.
The resulting :exc:`asyncio.CancelledError` will interrupt an ``await``,
but it will not bubble out of the containing ``async with`` statement.

Once all tasks have finished, if any tasks have failed
with an exception other than :exc:`asyncio.CancelledError`,
those exceptions are combined in an
:exc:`ExceptionGroup` or :exc:`BaseExceptionGroup`
(as appropriate; see their documentation)
which is then raised.

Two base exceptions are treated specially:
If any task fails with :exc:`KeyboardInterrupt` or :exc:`SystemExit`,
the task group still cancels the remaining tasks and waits for them,
but then the initial :exc:`KeyboardInterrupt` or :exc:`SystemExit`
is re-raised instead of :exc:`ExceptionGroup` or :exc:`BaseExceptionGroup`.

If the body of the ``async with`` statement exits with an exception
(so :meth:`~object.__aexit__` is called with an exception set),
this is treated the same as if one of the tasks failed:
the remaining tasks are cancelled and then waited for,
and non-cancellation exceptions are grouped into an
exception group and raised.
The exception passed into :meth:`~object.__aexit__`,
unless it is :exc:`asyncio.CancelledError`,
is also included in the exception group.
The same special case is made for
:exc:`KeyboardInterrupt` and :exc:`SystemExit` as in the previous paragraph.

Task groups are careful not to mix up the internal cancellation used to
"wake up" their :meth:`~object.__aexit__` with cancellation requests
for the task in which they are running made by other parties.
In particular, when one task group is syntactically nested in another,
and both experience an exception in one of their child tasks simultaneously,
the inner task group will process its exceptions, and then the outer task group
will receive another cancellation and process its own exceptions.

In the case where a task group is cancelled externally and also must
raise an :exc:`ExceptionGroup`, it will call the parent task's
:meth:`~asyncio.Task.cancel` method. This ensures that a
:exc:`asyncio.CancelledError` will be raised at the next
:keyword:`await`, so the cancellation is not lost.

Task groups preserve the cancellation count
reported by :meth:`asyncio.Task.cancelling`.

.. versionchanged:: 3.13

   Improved handling of simultaneous internal and external cancellations
   and correct preservation of cancellation counts.

Terminating a Task Group
------------------------

While terminating a task group is not natively supported by the standard
library, termination can be achieved by adding an exception-raising task
to the task group and ignoring the raised exception:

.. code-block:: python

   import asyncio
   from asyncio import TaskGroup

   class TerminateTaskGroup(Exception):
       """Exception raised to terminate a task group."""

   async def force_terminate_task_group():
       """Used to force termination of a task group."""
       raise TerminateTaskGroup()

   async def job(task_id, sleep_time):
       print(f'Task {task_id}: start')
       await asyncio.sleep(sleep_time)
       print(f'Task {task_id}: done')

   async def main():
       try:
           async with TaskGroup() as group:
               # spawn some tasks
               group.create_task(job(1, 0.5))
               group.create_task(job(2, 1.5))
               # sleep for 1 second
               await asyncio.sleep(1)
               # add an exception-raising task to force the group to terminate
               group.create_task(force_terminate_task_group())
       except* TerminateTaskGroup:
           pass

   asyncio.run(main())

Expected output:

.. code-block:: text

   Task 1: start
   Task 2: start
   Task 1: done

Sleeping
========

.. coroutinefunction:: sleep(delay, result=None)

   Block for *delay* seconds.

   If *result* is provided, it is returned to the caller
   when the coroutine completes.

   ``sleep()`` always suspends the current task, allowing other tasks
   to run.

   Setting the delay to 0 provides an optimized path to allow other
   tasks to run. This can be used by long-running functions to avoid
   blocking the event loop for the full duration of the function call.

   .. _asyncio_example_sleep:

   Example of coroutine displaying the current date every second
   for 5 seconds::

    import asyncio
    import datetime

    async def display_date():
        loop = asyncio.get_running_loop()
        end_time = loop.time() + 5.0
        while True:
            print(datetime.datetime.now())
            if (loop.time() + 1.0) >= end_time:
                break
            await asyncio.sleep(1)

    asyncio.run(display_date())


   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   .. versionchanged:: 3.13
      Raises :exc:`ValueError` if *delay* is :data:`~math.nan`.


Running Tasks Concurrently
==========================

.. awaitablefunction:: gather(*aws, return_exceptions=False)

   Run :ref:`awaitable objects <asyncio-awaitables>` in the *aws*
   sequence *concurrently*.

   If any awaitable in *aws* is a coroutine, it is automatically
   scheduled as a Task.

   If all awaitables are completed successfully, the result is an
   aggregate list of returned values.  The order of result values
   corresponds to the order of awaitables in *aws*.

   If *return_exceptions* is ``False`` (default), the first
   raised exception is immediately propagated to the task that
   awaits on ``gather()``.  Other awaitables in the *aws* sequence
   **won't be cancelled** and will continue to run.

   If *return_exceptions* is ``True``, exceptions are treated the
   same as successful results, and aggregated in the result list.

   If ``gather()`` is *cancelled*, all submitted awaitables
   (that have not completed yet) are also *cancelled*.

   If any Task or Future from the *aws* sequence is *cancelled*, it is
   treated as if it raised :exc:`CancelledError` -- the ``gather()``
   call is **not** cancelled in this case.  This is to prevent the
   cancellation of one submitted Task/Future to cause other
   Tasks/Futures to be cancelled.

   .. note::
      A new alternative to create and run tasks concurrently and
      wait for their completion is :class:`asyncio.TaskGroup`. *TaskGroup*
      provides stronger safety guarantees than *gather* for scheduling a nesting of subtasks:
      if a task (or a subtask, a task scheduled by a task)
      raises an exception, *TaskGroup* will, while *gather* will not,
      cancel the remaining scheduled tasks).

   .. _asyncio_example_gather:

   Example::

      import asyncio

      async def factorial(name, number):
          f = 1
          for i in range(2, number + 1):
              print(f"Task {name}: Compute factorial({number}), currently i={i}...")
              await asyncio.sleep(1)
              f *= i
          print(f"Task {name}: factorial({number}) = {f}")
          return f

      async def main():
          # Schedule three calls *concurrently*:
          L = await asyncio.gather(
              factorial("A", 2),
              factorial("B", 3),
              factorial("C", 4),
          )
          print(L)

      asyncio.run(main())

      # Expected output:
      #
      #     Task A: Compute factorial(2), currently i=2...
      #     Task B: Compute factorial(3), currently i=2...
      #     Task C: Compute factorial(4), currently i=2...
      #     Task A: factorial(2) = 2
      #     Task B: Compute factorial(3), currently i=3...
      #     Task C: Compute factorial(4), currently i=3...
      #     Task B: factorial(3) = 6
      #     Task C: Compute factorial(4), currently i=4...
      #     Task C: factorial(4) = 24
      #     [2, 6, 24]

   .. note::
      If *return_exceptions* is false, cancelling gather() after it
      has been marked done won't cancel any submitted awaitables.
      For instance, gather can be marked done after propagating an
      exception to the caller, therefore, calling ``gather.cancel()``
      after catching an exception (raised by one of the awaitables) from
      gather won't cancel any other awaitables.

   .. versionchanged:: 3.7
      If the *gather* itself is cancelled, the cancellation is
      propagated regardless of *return_exceptions*.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   .. deprecated:: 3.10
      Deprecation warning is emitted if no positional arguments are provided
      or not all positional arguments are Future-like objects
      and there is no running event loop.


.. _eager-task-factory:

Eager Task Factory
==================

.. function:: eager_task_factory(loop, coro, *, name=None, context=None)

    A task factory for eager task execution.

    When using this factory (via :meth:`loop.set_task_factory(asyncio.eager_task_factory) <loop.set_task_factory>`),
    coroutines begin execution synchronously during :class:`Task` construction.
    Tasks are only scheduled on the event loop if they block.
    This can be a performance improvement as the overhead of loop scheduling
    is avoided for coroutines that complete synchronously.

    A common example where this is beneficial is coroutines which employ
    caching or memoization to avoid actual I/O when possible.

    .. note::

        Immediate execution of the coroutine is a semantic change.
        If the coroutine returns or raises, the task is never scheduled
        to the event loop. If the coroutine execution blocks, the task is
        scheduled to the event loop. This change may introduce behavior
        changes to existing applications. For example,
        the application's task execution order is likely to change.

    .. versionadded:: 3.12

.. function:: create_eager_task_factory(custom_task_constructor)

    Create an eager task factory, similar to :func:`eager_task_factory`,
    using the provided *custom_task_constructor* when creating a new task instead
    of the default :class:`Task`.

    *custom_task_constructor* must be a *callable* with the signature matching
    the signature of :class:`Task.__init__ <Task>`.
    The callable must return a :class:`asyncio.Task`-compatible object.

    This function returns a *callable* intended to be used as a task factory of an
    event loop via :meth:`loop.set_task_factory(factory) <loop.set_task_factory>`).

    .. versionadded:: 3.12


Shielding From Cancellation
===========================

.. awaitablefunction:: shield(aw)

   Protect an :ref:`awaitable object <asyncio-awaitables>`
   from being :meth:`cancelled <Task.cancel>`.

   If *aw* is a coroutine it is automatically scheduled as a Task.

   The statement::

       task = asyncio.create_task(something())
       res = await shield(task)

   is equivalent to::

       res = await something()

   *except* that if the coroutine containing it is cancelled, the
   Task running in ``something()`` is not cancelled.  From the point
   of view of ``something()``, the cancellation did not happen.
   Although its caller is still cancelled, so the "await" expression
   still raises a :exc:`CancelledError`.

   If ``something()`` is cancelled by other means (i.e. from within
   itself) that would also cancel ``shield()``.

   If it is desired to completely ignore cancellation (not recommended)
   the ``shield()`` function should be combined with a try/except
   clause, as follows::

       task = asyncio.create_task(something())
       try:
           res = await shield(task)
       except CancelledError:
           res = None

   .. important::

      Save a reference to tasks passed to this function, to avoid
      a task disappearing mid-execution. The event loop only keeps
      weak references to tasks. A task that isn't referenced elsewhere
      may get garbage collected at any time, even before it's done.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   .. deprecated:: 3.10
      Deprecation warning is emitted if *aw* is not Future-like object
      and there is no running event loop.


Timeouts
========

.. function:: timeout(delay)

    Return an :ref:`asynchronous context manager <async-context-managers>`
    that can be used to limit the amount of time spent waiting on
    something.

    *delay* can either be ``None``, or a float/int number of
    seconds to wait. If *delay* is ``None``, no time limit will
    be applied; this can be useful if the delay is unknown when
    the context manager is created.

    In either case, the context manager can be rescheduled after
    creation using :meth:`Timeout.reschedule`.

    Example::

        async def main():
            async with asyncio.timeout(10):
                await long_running_task()

    If ``long_running_task`` takes more than 10 seconds to complete,
    the context manager will cancel the current task and handle
    the resulting :exc:`asyncio.CancelledError` internally, transforming it
    into a :exc:`TimeoutError` which can be caught and handled.

    .. note::

      The :func:`asyncio.timeout` context manager is what transforms
      the :exc:`asyncio.CancelledError` into a :exc:`TimeoutError`,
      which means the :exc:`TimeoutError` can only be caught
      *outside* of the context manager.

    Example of catching :exc:`TimeoutError`::

        async def main():
            try:
                async with asyncio.timeout(10):
                    await long_running_task()
            except TimeoutError:
                print("The long operation timed out, but we've handled it.")

            print("This statement will run regardless.")

    The context manager produced by :func:`asyncio.timeout` can be
    rescheduled to a different deadline and inspected.

    .. class:: Timeout(when)

       An :ref:`asynchronous context manager <async-context-managers>`
       for cancelling overdue coroutines.

       ``when`` should be an absolute time at which the context should time out,
       as measured by the event loop's clock:

       - If ``when`` is ``None``, the timeout will never trigger.
       - If ``when < loop.time()``, the timeout will trigger on the next
         iteration of the event loop.

        .. method:: when() -> float | None

           Return the current deadline, or ``None`` if the current
           deadline is not set.

        .. method:: reschedule(when: float | None)

            Reschedule the timeout.

        .. method:: expired() -> bool

           Return whether the context manager has exceeded its deadline
           (expired).

    Example::

        async def main():
            try:
                # We do not know the timeout when starting, so we pass ``None``.
                async with asyncio.timeout(None) as cm:
                    # We know the timeout now, so we reschedule it.
                    new_deadline = get_running_loop().time() + 10
                    cm.reschedule(new_deadline)

                    await long_running_task()
            except TimeoutError:
                pass

            if cm.expired():
                print("Looks like we haven't finished on time.")

    Timeout context managers can be safely nested.

    .. versionadded:: 3.11

.. function:: timeout_at(when)

   Similar to :func:`asyncio.timeout`, except *when* is the absolute time
   to stop waiting, or ``None``.

   Example::

      async def main():
          loop = get_running_loop()
          deadline = loop.time() + 20
          try:
              async with asyncio.timeout_at(deadline):
                  await long_running_task()
          except TimeoutError:
              print("The long operation timed out, but we've handled it.")

          print("This statement will run regardless.")

   .. versionadded:: 3.11

.. coroutinefunction:: wait_for(aw, timeout)

   Wait for the *aw* :ref:`awaitable <asyncio-awaitables>`
   to complete with a timeout.

   If *aw* is a coroutine it is automatically scheduled as a Task.

   *timeout* can either be ``None`` or a float or int number of seconds
   to wait for.  If *timeout* is ``None``, block until the future
   completes.

   If a timeout occurs, it cancels the task and raises
   :exc:`TimeoutError`.

   To avoid the task :meth:`cancellation <Task.cancel>`,
   wrap it in :func:`shield`.

   The function will wait until the future is actually cancelled,
   so the total wait time may exceed the *timeout*. If an exception
   happens during cancellation, it is propagated.

   If the wait is cancelled, the future *aw* is also cancelled.

   .. _asyncio_example_waitfor:

   Example::

       async def eternity():
           # Sleep for one hour
           await asyncio.sleep(3600)
           print('yay!')

       async def main():
           # Wait for at most 1 second
           try:
               await asyncio.wait_for(eternity(), timeout=1.0)
           except TimeoutError:
               print('timeout!')

       asyncio.run(main())

       # Expected output:
       #
       #     timeout!

   .. versionchanged:: 3.7
      When *aw* is cancelled due to a timeout, ``wait_for`` waits
      for *aw* to be cancelled.  Previously, it raised
      :exc:`TimeoutError` immediately.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   .. versionchanged:: 3.11
      Raises :exc:`TimeoutError` instead of :exc:`asyncio.TimeoutError`.


Waiting Primitives
==================

.. coroutinefunction:: wait(aws, *, timeout=None, return_when=ALL_COMPLETED)

   Run :class:`~asyncio.Future` and :class:`~asyncio.Task` instances in the *aws*
   iterable concurrently and block until the condition specified
   by *return_when*.

   The *aws* iterable must not be empty.

   Returns two sets of Tasks/Futures: ``(done, pending)``.

   Usage::

        done, pending = await asyncio.wait(aws)

   *timeout* (a float or int), if specified, can be used to control
   the maximum number of seconds to wait before returning.

   Note that this function does not raise :exc:`TimeoutError`.
   Futures or Tasks that aren't done when the timeout occurs are simply
   returned in the second set.

   *return_when* indicates when this function should return.  It must
   be one of the following constants:

   .. list-table::
      :header-rows: 1

      * - Constant
        - Description

      * - .. data:: FIRST_COMPLETED
        - The function will return when any future finishes or is cancelled.

      * - .. data:: FIRST_EXCEPTION
        - The function will return when any future finishes by raising an
          exception. If no future raises an exception
          then it is equivalent to :const:`ALL_COMPLETED`.

      * - .. data:: ALL_COMPLETED
        - The function will return when all futures finish or are cancelled.

   Unlike :func:`~asyncio.wait_for`, ``wait()`` does not cancel the
   futures when a timeout occurs.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   .. versionchanged:: 3.11
      Passing coroutine objects to ``wait()`` directly is forbidden.

   .. versionchanged:: 3.12
      Added support for generators yielding tasks.


.. function:: as_completed(aws, *, timeout=None)

   Run :ref:`awaitable objects <asyncio-awaitables>` in the *aws* iterable
   concurrently. The returned object can be iterated to obtain the results
   of the awaitables as they finish.

   The object returned by ``as_completed()`` can be iterated as an
   :term:`asynchronous iterator` or a plain :term:`iterator`. When asynchronous
   iteration is used, the originally-supplied awaitables are yielded if they
   are tasks or futures. This makes it easy to correlate previously-scheduled
   tasks with their results. Example::

       ipv4_connect = create_task(open_connection("127.0.0.1", 80))
       ipv6_connect = create_task(open_connection("::1", 80))
       tasks = [ipv4_connect, ipv6_connect]

       async for earliest_connect in as_completed(tasks):
           # earliest_connect is done. The result can be obtained by
           # awaiting it or calling earliest_connect.result()
           reader, writer = await earliest_connect

           if earliest_connect is ipv6_connect:
               print("IPv6 connection established.")
           else:
               print("IPv4 connection established.")

   During asynchronous iteration, implicitly-created tasks will be yielded for
   supplied awaitables that aren't tasks or futures.

   When used as a plain iterator, each iteration yields a new coroutine that
   returns the result or raises the exception of the next completed awaitable.
   This pattern is compatible with Python versions older than 3.13::

       ipv4_connect = create_task(open_connection("127.0.0.1", 80))
       ipv6_connect = create_task(open_connection("::1", 80))
       tasks = [ipv4_connect, ipv6_connect]

       for next_connect in as_completed(tasks):
           # next_connect is not one of the original task objects. It must be
           # awaited to obtain the result value or raise the exception of the
           # awaitable that finishes next.
           reader, writer = await next_connect

   A :exc:`TimeoutError` is raised if the timeout occurs before all awaitables
   are done. This is raised by the ``async for`` loop during asynchronous
   iteration or by the coroutines yielded during plain iteration.

   .. versionchanged:: 3.10
      Removed the *loop* parameter.

   .. deprecated:: 3.10
      Deprecation warning is emitted if not all awaitable objects in the *aws*
      iterable are Future-like objects and there is no running event loop.

   .. versionchanged:: 3.12
      Added support for generators yielding tasks.

   .. versionchanged:: 3.13
      The result can now be used as either an :term:`asynchronous iterator`
      or as a plain :term:`iterator` (previously it was only a plain iterator).


Running in Threads
==================

.. coroutinefunction:: to_thread(func, /, *args, **kwargs)

   Asynchronously run function *func* in a separate thread.

   Any \*args and \*\*kwargs supplied for this function are directly passed
   to *func*. Also, the current :class:`contextvars.Context` is propagated,
   allowing context variables from the event loop thread to be accessed in the
   separate thread.

   Return a coroutine that can be awaited to get the eventual result of *func*.

   This coroutine function is primarily intended to be used for executing
   IO-bound functions/methods that would otherwise block the event loop if
   they were run in the main thread. For example::

       def blocking_io():
           print(f"start blocking_io at {time.strftime('%X')}")
           # Note that time.sleep() can be replaced with any blocking
           # IO-bound operation, such as file operations.
           time.sleep(1)
           print(f"blocking_io complete at {time.strftime('%X')}")

       async def main():
           print(f"started main at {time.strftime('%X')}")

           await asyncio.gather(
               asyncio.to_thread(blocking_io),
               asyncio.sleep(1))

           print(f"finished main at {time.strftime('%X')}")


       asyncio.run(main())

       # Expected output:
       #
       # started main at 19:50:53
       # start blocking_io at 19:50:53
       # blocking_io complete at 19:50:54
       # finished main at 19:50:54

   Directly calling ``blocking_io()`` in any coroutine would block the event loop
   for its duration, resulting in an additional 1 second of run time. Instead,
   by using ``asyncio.to_thread()``, we can run it in a separate thread without
   blocking the event loop.

   .. note::

      Due to the :term:`GIL`, ``asyncio.to_thread()`` can typically only be used
      to make IO-bound functions non-blocking. However, for extension modules
      that release the GIL or alternative Python implementations that don't
      have one, ``asyncio.to_thread()`` can also be used for CPU-bound functions.

   .. versionadded:: 3.9


Scheduling From Other Threads
=============================

.. function:: run_coroutine_threadsafe(coro, loop)

   Submit a coroutine to the given event loop.  Thread-safe.

   Return a :class:`concurrent.futures.Future` to wait for the result
   from another OS thread.

   This function is meant to be called from a different OS thread
   than the one where the event loop is running.  Example::

     def in_thread(loop: asyncio.AbstractEventLoop) -> None:
         # Run some blocking IO
         pathlib.Path("example.txt").write_text("hello world", encoding="utf8")

         # Create a coroutine
         coro = asyncio.sleep(1, result=3)

         # Submit the coroutine to a given loop
         future = asyncio.run_coroutine_threadsafe(coro, loop)

         # Wait for the result with an optional timeout argument
         assert future.result(timeout=2) == 3

     async def amain() -> None:
         # Get the running loop
         loop = asyncio.get_running_loop()

         # Run something in a thread
         await asyncio.to_thread(in_thread, loop)

   It's also possible to run the other way around.  Example::

     @contextlib.contextmanager
     def loop_in_thread() -> Generator[asyncio.AbstractEventLoop]:
         loop_fut = concurrent.futures.Future[asyncio.AbstractEventLoop]()
         stop_event = asyncio.Event()

         async def main() -> None:
             loop_fut.set_result(asyncio.get_running_loop())
             await stop_event.wait()

         with concurrent.futures.ThreadPoolExecutor(1) as tpe:
             complete_fut = tpe.submit(asyncio.run, main())
             for fut in concurrent.futures.as_completed((loop_fut, complete_fut)):
                 if fut is loop_fut:
                     loop = loop_fut.result()
                     try:
                         yield loop
                     finally:
                         loop.call_soon_threadsafe(stop_event.set)
                 else:
                     fut.result()

     # Create a loop in another thread
     with loop_in_thread() as loop:
         # Create a coroutine
         coro = asyncio.sleep(1, result=3)

         # Submit the coroutine to a given loop
         future = asyncio.run_coroutine_threadsafe(coro, loop)

         # Wait for the result with an optional timeout argument
         assert future.result(timeout=2) == 3

   If an exception is raised in the coroutine, the returned Future
   will be notified.  It can also be used to cancel the task in
   the event loop::

     try:
         result = future.result(timeout)
     except TimeoutError:
         print('The coroutine took too long, cancelling the task...')
         future.cancel()
     except Exception as exc:
         print(f'The coroutine raised an exception: {exc!r}')
     else:
         print(f'The coroutine returned: {result!r}')

   See the :ref:`concurrency and multithreading <asyncio-multithreading>`
   section of the documentation.

   Unlike other asyncio functions this function requires the *loop*
   argument to be passed explicitly.

   .. versionadded:: 3.5.1


Introspection
=============


.. function:: current_task(loop=None)

   Return the currently running :class:`Task` instance, or ``None`` if
   no task is running.

   If *loop* is ``None`` :func:`get_running_loop` is used to get
   the current loop.

   .. versionadded:: 3.7


.. function:: all_tasks(loop=None)

   Return a set of not yet finished :class:`Task` objects run by
   the loop.

   If *loop* is ``None``, :func:`get_running_loop` is used for getting
   current loop.

   .. versionadded:: 3.7


.. function:: iscoroutine(obj)

   Return ``True`` if *obj* is a coroutine object.

   .. versionadded:: 3.4


Task Object
===========

.. class:: Task(coro, *, loop=None, name=None, context=None, eager_start=False)

   A :class:`Future-like <Future>` object that runs a Python
   :ref:`coroutine <coroutine>`.  Not thread-safe.

   Tasks are used to run coroutines in event loops.
   If a coroutine awaits on a Future, the Task suspends
   the execution of the coroutine and waits for the completion
   of the Future.  When the Future is *done*, the execution of
   the wrapped coroutine resumes.

   Event loops use cooperative scheduling: an event loop runs
   one Task at a time.  While a Task awaits for the completion of a
   Future, the event loop runs other Tasks, callbacks, or performs
   IO operations.

   Use the high-level :func:`asyncio.create_task` function to create
   Tasks, or the low-level :meth:`loop.create_task` or
   :func:`ensure_future` functions.  Manual instantiation of Tasks
   is discouraged.

   To cancel a running Task use the :meth:`cancel` method.  Calling it
   will cause the Task to throw a :exc:`CancelledError` exception into
   the wrapped coroutine.  If a coroutine is awaiting on a Future
   object during cancellation, the Future object will be cancelled.

   :meth:`cancelled` can be used to check if the Task was cancelled.
   The method returns ``True`` if the wrapped coroutine did not
   suppress the :exc:`CancelledError` exception and was actually
   cancelled.

   :class:`asyncio.Task` inherits from :class:`Future` all of its
   APIs except :meth:`Future.set_result` and
   :meth:`Future.set_exception`.

   An optional keyword-only *context* argument allows specifying a
   custom :class:`contextvars.Context` for the *coro* to run in.
   If no *context* is provided, the Task copies the current context
   and later runs its coroutine in the copied context.

   An optional keyword-only *eager_start* argument allows eagerly starting
   the execution of the :class:`asyncio.Task` at task creation time.
   If set to ``True`` and the event loop is running, the task will start
   executing the coroutine immediately, until the first time the coroutine
   blocks. If the coroutine returns or raises without blocking, the task
   will be finished eagerly and will skip scheduling to the event loop.

   .. versionchanged:: 3.7
      Added support for the :mod:`contextvars` module.

   .. versionchanged:: 3.8
      Added the *name* parameter.

   .. deprecated:: 3.10
      Deprecation warning is emitted if *loop* is not specified
      and there is no running event loop.

   .. versionchanged:: 3.11
      Added the *context* parameter.

   .. versionchanged:: 3.12
      Added the *eager_start* parameter.

   .. method:: done()

      Return ``True`` if the Task is *done*.

      A Task is *done* when the wrapped coroutine either returned
      a value, raised an exception, or the Task was cancelled.

   .. method:: result()

      Return the result of the Task.

      If the Task is *done*, the result of the wrapped coroutine
      is returned (or if the coroutine raised an exception, that
      exception is re-raised.)

      If the Task has been *cancelled*, this method raises
      a :exc:`CancelledError` exception.

      If the Task's result isn't yet available, this method raises
      an :exc:`InvalidStateError` exception.

   .. method:: exception()

      Return the exception of the Task.

      If the wrapped coroutine raised an exception that exception
      is returned.  If the wrapped coroutine returned normally
      this method returns ``None``.

      If the Task has been *cancelled*, this method raises a
      :exc:`CancelledError` exception.

      If the Task isn't *done* yet, this method raises an
      :exc:`InvalidStateError` exception.

   .. method:: add_done_callback(callback, *, context=None)

      Add a callback to be run when the Task is *done*.

      This method should only be used in low-level callback-based code.

      See the documentation of :meth:`Future.add_done_callback`
      for more details.

   .. method:: remove_done_callback(callback)

      Remove *callback* from the callbacks list.

      This method should only be used in low-level callback-based code.

      See the documentation of :meth:`Future.remove_done_callback`
      for more details.

   .. method:: get_stack(*, limit=None)

      Return the list of stack frames for this Task.

      If the wrapped coroutine is not done, this returns the stack
      where it is suspended.  If the coroutine has completed
      successfully or was cancelled, this returns an empty list.
      If the coroutine was terminated by an exception, this returns
      the list of traceback frames.

      The frames are always ordered from oldest to newest.

      Only one stack frame is returned for a suspended coroutine.

      The optional *limit* argument sets the maximum number of frames
      to return; by default all available frames are returned.
      The ordering of the returned list differs depending on whether
      a stack or a traceback is returned: the newest frames of a
      stack are returned, but the oldest frames of a traceback are
      returned.  (This matches the behavior of the traceback module.)

   .. method:: print_stack(*, limit=None, file=None)

      Print the stack or traceback for this Task.

      This produces output similar to that of the traceback module
      for the frames retrieved by :meth:`get_stack`.

      The *limit* argument is passed to :meth:`get_stack` directly.

      The *file* argument is an I/O stream to which the output
      is written; by default output is written to :data:`sys.stdout`.

   .. method:: get_coro()

      Return the coroutine object wrapped by the :class:`Task`.

      .. note::

         This will return ``None`` for Tasks which have already
         completed eagerly. See the :ref:`Eager Task Factory <eager-task-factory>`.

      .. versionadded:: 3.8

      .. versionchanged:: 3.12

         Newly added eager task execution means result may be ``None``.

   .. method:: get_context()

      Return the :class:`contextvars.Context` object
      associated with the task.

      .. versionadded:: 3.12

   .. method:: get_name()

      Return the name of the Task.

      If no name has been explicitly assigned to the Task, the default
      asyncio Task implementation generates a default name during
      instantiation.

      .. versionadded:: 3.8

   .. method:: set_name(value)

      Set the name of the Task.

      The *value* argument can be any object, which is then
      converted to a string.

      In the default Task implementation, the name will be visible
      in the :func:`repr` output of a task object.

      .. versionadded:: 3.8

   .. method:: cancel(msg=None)

      Request the Task to be cancelled.

      This arranges for a :exc:`CancelledError` exception to be thrown
      into the wrapped coroutine on the next cycle of the event loop.

      The coroutine then has a chance to clean up or even deny the
      request by suppressing the exception with a :keyword:`try` ...
      ... ``except CancelledError`` ... :keyword:`finally` block.
      Therefore, unlike :meth:`Future.cancel`, :meth:`Task.cancel` does
      not guarantee that the Task will be cancelled, although
      suppressing cancellation completely is not common and is actively
      discouraged.  Should the coroutine nevertheless decide to suppress
      the cancellation, it needs to call :meth:`Task.uncancel` in addition
      to catching the exception.

      .. versionchanged:: 3.9
         Added the *msg* parameter.

      .. versionchanged:: 3.11
         The ``msg`` parameter is propagated from cancelled task to its awaiter.

      .. _asyncio_example_task_cancel:

      The following example illustrates how coroutines can intercept
      the cancellation request::

          async def cancel_me():
              print('cancel_me(): before sleep')

              try:
                  # Wait for 1 hour
                  await asyncio.sleep(3600)
              except asyncio.CancelledError:
                  print('cancel_me(): cancel sleep')
                  raise
              finally:
                  print('cancel_me(): after sleep')

          async def main():
              # Create a "cancel_me" Task
              task = asyncio.create_task(cancel_me())

              # Wait for 1 second
              await asyncio.sleep(1)

              task.cancel()
              try:
                  await task
              except asyncio.CancelledError:
                  print("main(): cancel_me is cancelled now")

          asyncio.run(main())

          # Expected output:
          #
          #     cancel_me(): before sleep
          #     cancel_me(): cancel sleep
          #     cancel_me(): after sleep
          #     main(): cancel_me is cancelled now

   .. method:: cancelled()

      Return ``True`` if the Task is *cancelled*.

      The Task is *cancelled* when the cancellation was requested with
      :meth:`cancel` and the wrapped coroutine propagated the
      :exc:`CancelledError` exception thrown into it.

   .. method:: uncancel()

      Decrement the count of cancellation requests to this Task.

      Returns the remaining number of cancellation requests.

      Note that once execution of a cancelled task completed, further
      calls to :meth:`uncancel` are ineffective.

      .. versionadded:: 3.11

      This method is used by asyncio's internals and isn't expected to be
      used by end-user code.  In particular, if a Task gets successfully
      uncancelled, this allows for elements of structured concurrency like
      :ref:`taskgroups` and :func:`asyncio.timeout` to continue running,
      isolating cancellation to the respective structured block.
      For example::

        async def make_request_with_timeout():
            try:
                async with asyncio.timeout(1):
                    # Structured block affected by the timeout:
                    await make_request()
                    await make_another_request()
            except TimeoutError:
                log("There was a timeout")
            # Outer code not affected by the timeout:
            await unrelated_code()

      While the block with ``make_request()`` and ``make_another_request()``
      might get cancelled due to the timeout, ``unrelated_code()`` should
      continue running even in case of the timeout.  This is implemented
      with :meth:`uncancel`.  :class:`TaskGroup` context managers use
      :func:`uncancel` in a similar fashion.

      If end-user code is, for some reason, suppressing cancellation by
      catching :exc:`CancelledError`, it needs to call this method to remove
      the cancellation state.

      When this method decrements the cancellation count to zero,
      the method checks if a previous :meth:`cancel` call had arranged
      for :exc:`CancelledError` to be thrown into the task.
      If it hasn't been thrown yet, that arrangement will be
      rescinded (by resetting the internal ``_must_cancel`` flag).

   .. versionchanged:: 3.13
      Changed to rescind pending cancellation requests upon reaching zero.

   .. method:: cancelling()

      Return the number of pending cancellation requests to this Task, i.e.,
      the number of calls to :meth:`cancel` less the number of
      :meth:`uncancel` calls.

      Note that if this number is greater than zero but the Task is
      still executing, :meth:`cancelled` will still return ``False``.
      This is because this number can be lowered by calling :meth:`uncancel`,
      which can lead to the task not being cancelled after all if the
      cancellation requests go down to zero.

      This method is used by asyncio's internals and isn't expected to be
      used by end-user code.  See :meth:`uncancel` for more details.

      .. versionadded:: 3.11


================================================
File: /Doc/library/asyncio.rst
================================================
:mod:`!asyncio` --- Asynchronous I/O
====================================

.. module:: asyncio
   :synopsis: Asynchronous I/O.

-------------------------------

.. sidebar:: Hello World!

   ::

       import asyncio

       async def main():
           print('Hello ...')
           await asyncio.sleep(1)
           print('... World!')

       asyncio.run(main())

asyncio is a library to write **concurrent** code using
the **async/await** syntax.

asyncio is used as a foundation for multiple Python asynchronous
frameworks that provide high-performance network and web-servers,
database connection libraries, distributed task queues, etc.

asyncio is often a perfect fit for IO-bound and high-level
**structured** network code.

asyncio provides a set of **high-level** APIs to:

* :ref:`run Python coroutines <coroutine>` concurrently and
  have full control over their execution;

* perform :ref:`network IO and IPC <asyncio-streams>`;

* control :ref:`subprocesses <asyncio-subprocess>`;

* distribute tasks via :ref:`queues <asyncio-queues>`;

* :ref:`synchronize <asyncio-sync>` concurrent code;

Additionally, there are **low-level** APIs for
*library and framework developers* to:

* create and manage :ref:`event loops <asyncio-event-loop>`, which
  provide asynchronous APIs for :ref:`networking <loop_create_server>`,
  running :ref:`subprocesses <loop_subprocess_exec>`,
  handling :ref:`OS signals <loop_add_signal_handler>`, etc;

* implement efficient protocols using
  :ref:`transports <asyncio-transports-protocols>`;

* :ref:`bridge <asyncio-futures>` callback-based libraries and code
  with async/await syntax.

.. include:: ../includes/wasm-notavail.rst

.. _asyncio-cli:

.. rubric:: asyncio REPL

You can experiment with an ``asyncio`` concurrent context in the :term:`REPL`:

.. code-block:: pycon

   $ python -m asyncio
   asyncio REPL ...
   Use "await" directly instead of "asyncio.run()".
   Type "help", "copyright", "credits" or "license" for more information.
   >>> import asyncio
   >>> await asyncio.sleep(10, result='hello')
   'hello'

.. audit-event:: cpython.run_stdin "" ""

.. versionchanged:: 3.12.5 (also 3.11.10, 3.10.15, 3.9.20, and 3.8.20)
   Emits audit events.

.. versionchanged:: 3.13
   Uses PyREPL if possible, in which case :envvar:`PYTHONSTARTUP` is
   also executed. Emits audit events.

.. We use the "rubric" directive here to avoid creating
   the "Reference" subsection in the TOC.

.. rubric:: Reference

.. toctree::
   :caption: High-level APIs
   :maxdepth: 1

   asyncio-runner.rst
   asyncio-task.rst
   asyncio-stream.rst
   asyncio-sync.rst
   asyncio-subprocess.rst
   asyncio-queue.rst
   asyncio-exceptions.rst

.. toctree::
   :caption: Low-level APIs
   :maxdepth: 1

   asyncio-eventloop.rst
   asyncio-future.rst
   asyncio-protocol.rst
   asyncio-policy.rst
   asyncio-platforms.rst
   asyncio-extending.rst

.. toctree::
   :caption: Guides and Tutorials
   :maxdepth: 1

   asyncio-api-index.rst
   asyncio-llapi-index.rst
   asyncio-dev.rst

.. note::
   The source code for asyncio can be found in :source:`Lib/asyncio/`.


================================================
File: /Doc/library/asyncore.rst
================================================
:mod:`!asyncore` --- Asynchronous socket handler
================================================

.. module:: asyncore
   :synopsis: Removed in 3.12.
   :deprecated:

.. deprecated-removed:: 3.6 3.12

This module is no longer part of the Python standard library.
It was :ref:`removed in Python 3.12 <whatsnew312-removed>` after
being deprecated in Python 3.6.  The removal was decided in :pep:`594`.

Applications should use the :mod:`asyncio` module instead.

The last version of Python that provided the :mod:`!asyncore` module was
`Python 3.11 <https://docs.python.org/3.11/library/asyncore.html>`_.


================================================
File: /Doc/library/atexit.rst
================================================
:mod:`!atexit` --- Exit handlers
================================

.. module:: atexit
   :synopsis: Register and execute cleanup functions.

.. moduleauthor:: Skip Montanaro <skip.montanaro@gmail.com>
.. sectionauthor:: Skip Montanaro <skip.montanaro@gmail.com>

--------------

The :mod:`atexit` module defines functions to register and unregister cleanup
functions.  Functions thus registered are automatically executed upon normal
interpreter termination.  :mod:`atexit` runs these functions in the *reverse*
order in which they were registered; if you register ``A``, ``B``, and ``C``,
at interpreter termination time they will be run in the order ``C``, ``B``,
``A``.

**Note:** The functions registered via this module are not called when the
program is killed by a signal not handled by Python, when a Python fatal
internal error is detected, or when :func:`os._exit` is called.

**Note:** The effect of registering or unregistering functions from within
a cleanup function is undefined.

.. versionchanged:: 3.7
    When used with C-API subinterpreters, registered functions
    are local to the interpreter they were registered in.

.. function:: register(func, *args, **kwargs)

   Register *func* as a function to be executed at termination.  Any optional
   arguments that are to be passed to *func* must be passed as arguments to
   :func:`register`.  It is possible to register the same function and arguments
   more than once.

   At normal program termination (for instance, if :func:`sys.exit` is called or
   the main module's execution completes), all functions registered are called in
   last in, first out order.  The assumption is that lower level modules will
   normally be imported before higher level modules and thus must be cleaned up
   later.

   If an exception is raised during execution of the exit handlers, a traceback is
   printed (unless :exc:`SystemExit` is raised) and the exception information is
   saved.  After all exit handlers have had a chance to run, the last exception to
   be raised is re-raised.

   This function returns *func*, which makes it possible to use it as a
   decorator.

   .. warning::
       Starting new threads or calling :func:`os.fork` from a registered
       function can lead to race condition between the main Python
       runtime thread freeing thread states while internal :mod:`threading`
       routines or the new process try to use that state. This can lead to
       crashes rather than clean shutdown.

   .. versionchanged:: 3.12
       Attempts to start a new thread or :func:`os.fork` a new process
       in a registered function now leads to :exc:`RuntimeError`.

.. function:: unregister(func)

   Remove *func* from the list of functions to be run at interpreter shutdown.
   :func:`unregister` silently does nothing if *func* was not previously
   registered.  If *func* has been registered more than once, every occurrence
   of that function in the :mod:`atexit` call stack will be removed.  Equality
   comparisons (``==``) are used internally during unregistration, so function
   references do not need to have matching identities.


.. seealso::

   Module :mod:`readline`
      Useful example of :mod:`atexit` to read and write :mod:`readline` history
      files.


.. _atexit-example:

:mod:`atexit` Example
---------------------

The following simple example demonstrates how a module can initialize a counter
from a file when it is imported and save the counter's updated value
automatically when the program terminates without relying on the application
making an explicit call into this module at termination. ::

   try:
       with open('counterfile') as infile:
           _count = int(infile.read())
   except FileNotFoundError:
       _count = 0

   def incrcounter(n):
       global _count
       _count = _count + n

   def savecounter():
       with open('counterfile', 'w') as outfile:
           outfile.write('%d' % _count)

   import atexit

   atexit.register(savecounter)

Positional and keyword arguments may also be passed to :func:`register` to be
passed along to the registered function when it is called::

   def goodbye(name, adjective):
       print('Goodbye %s, it was %s to meet you.' % (name, adjective))

   import atexit

   atexit.register(goodbye, 'Donny', 'nice')
   # or:
   atexit.register(goodbye, adjective='nice', name='Donny')

Usage as a :term:`decorator`::

   import atexit

   @atexit.register
   def goodbye():
       print('You are now leaving the Python sector.')

This only works with functions that can be called without arguments.


================================================
File: /Doc/library/audioop.rst
================================================
:mod:`!audioop` --- Manipulate raw audio data
=============================================

.. module:: audioop
   :synopsis: Removed in 3.13.
   :deprecated:

.. deprecated-removed:: 3.11 3.13

This module is no longer part of the Python standard library.
It was :ref:`removed in Python 3.13 <whatsnew313-pep594>` after
being deprecated in Python 3.11.  The removal was decided in :pep:`594`.

The last version of Python that provided the :mod:`!audioop` module was
`Python 3.12 <https://docs.python.org/3.12/library/audioop.html>`_.


================================================
File: /Doc/library/audit_events.rst
================================================
.. _audit-events:

.. index:: single: audit events

Audit events table
==================

This table contains all events raised by :func:`sys.audit` or
:c:func:`PySys_Audit` calls throughout the CPython runtime and the
standard library.  These calls were added in 3.8 or later (see :pep:`578`).

See :func:`sys.addaudithook` and :c:func:`PySys_AddAuditHook` for
information on handling these events.

.. impl-detail::

   This table is generated from the CPython documentation, and may not
   represent events raised by other implementations. See your runtime
   specific documentation for actual events raised.

.. audit-event-table::

The following events are raised internally and do not correspond to any
public API of CPython:

+--------------------------+-------------------------------------------+
| Audit event              | Arguments                                 |
+==========================+===========================================+
| _winapi.CreateFile       | ``file_name``, ``desired_access``,        |
|                          | ``share_mode``, ``creation_disposition``, |
|                          | ``flags_and_attributes``                  |
+--------------------------+-------------------------------------------+
| _winapi.CreateJunction   | ``src_path``, ``dst_path``                |
+--------------------------+-------------------------------------------+
| _winapi.CreateNamedPipe  | ``name``, ``open_mode``, ``pipe_mode``    |
+--------------------------+-------------------------------------------+
| _winapi.CreatePipe       |                                           |
+--------------------------+-------------------------------------------+
| _winapi.CreateProcess    | ``application_name``, ``command_line``,   |
|                          | ``current_directory``                     |
+--------------------------+-------------------------------------------+
| _winapi.OpenProcess      | ``process_id``, ``desired_access``        |
+--------------------------+-------------------------------------------+
| _winapi.TerminateProcess | ``handle``, ``exit_code``                 |
+--------------------------+-------------------------------------------+
| ctypes.PyObj_FromPtr     | ``obj``                                   |
+--------------------------+-------------------------------------------+


================================================
File: /Doc/library/base64.rst
================================================
:mod:`!base64` --- Base16, Base32, Base64, Base85 Data Encodings
================================================================

.. module:: base64
   :synopsis: RFC 4648: Base16, Base32, Base64 Data Encodings;
              Base85 and Ascii85

**Source code:** :source:`Lib/base64.py`

.. index::
   pair: base64; encoding
   single: MIME; base64 encoding

--------------

This module provides functions for encoding binary data to printable
ASCII characters and decoding such encodings back to binary data.
It provides encoding and decoding functions for the encodings specified in
:rfc:`4648`, which defines the Base16, Base32, and Base64 algorithms,
and for the de-facto standard Ascii85 and Base85 encodings.

The :rfc:`4648` encodings are suitable for encoding binary data so that it can be
safely sent by email, used as parts of URLs, or included as part of an HTTP
POST request.  The encoding algorithm is not the same as the
:program:`uuencode` program.

There are two interfaces provided by this module.  The modern interface
supports encoding :term:`bytes-like objects <bytes-like object>` to ASCII
:class:`bytes`, and decoding :term:`bytes-like objects <bytes-like object>` or
strings containing ASCII to :class:`bytes`.  Both base-64 alphabets
defined in :rfc:`4648` (normal, and URL- and filesystem-safe) are supported.

The legacy interface does not support decoding from strings, but it does
provide functions for encoding and decoding to and from :term:`file objects
<file object>`.  It only supports the Base64 standard alphabet, and it adds
newlines every 76 characters as per :rfc:`2045`.  Note that if you are looking
for :rfc:`2045` support you probably want to be looking at the :mod:`email`
package instead.


.. versionchanged:: 3.3
   ASCII-only Unicode strings are now accepted by the decoding functions of
   the modern interface.

.. versionchanged:: 3.4
   Any :term:`bytes-like objects <bytes-like object>` are now accepted by all
   encoding and decoding functions in this module.  Ascii85/Base85 support added.

The modern interface provides:

.. function:: b64encode(s, altchars=None)

   Encode the :term:`bytes-like object` *s* using Base64 and return the encoded
   :class:`bytes`.

   Optional *altchars* must be a :term:`bytes-like object` of length 2 which
   specifies an alternative alphabet for the ``+`` and ``/`` characters.
   This allows an application to e.g. generate URL or filesystem safe Base64
   strings.  The default is ``None``, for which the standard Base64 alphabet is used.

   May assert or raise a :exc:`ValueError` if the length of *altchars* is not 2.  Raises a
   :exc:`TypeError` if *altchars* is not a :term:`bytes-like object`.


.. function:: b64decode(s, altchars=None, validate=False)

   Decode the Base64 encoded :term:`bytes-like object` or ASCII string
   *s* and return the decoded :class:`bytes`.

   Optional *altchars* must be a :term:`bytes-like object` or ASCII string
   of length 2 which specifies the alternative alphabet used instead of the
   ``+`` and ``/`` characters.

   A :exc:`binascii.Error` exception is raised
   if *s* is incorrectly padded.

   If *validate* is ``False`` (the default), characters that are neither
   in the normal base-64 alphabet nor the alternative alphabet are
   discarded prior to the padding check.  If *validate* is ``True``,
   these non-alphabet characters in the input result in a
   :exc:`binascii.Error`.

   For more information about the strict base64 check, see :func:`binascii.a2b_base64`

   May assert or raise a :exc:`ValueError` if the length of *altchars* is not 2.

.. function:: standard_b64encode(s)

   Encode :term:`bytes-like object` *s* using the standard Base64 alphabet
   and return the encoded :class:`bytes`.


.. function:: standard_b64decode(s)

   Decode :term:`bytes-like object` or ASCII string *s* using the standard
   Base64 alphabet and return the decoded :class:`bytes`.


.. function:: urlsafe_b64encode(s)

   Encode :term:`bytes-like object` *s* using the
   URL- and filesystem-safe alphabet, which
   substitutes ``-`` instead of ``+`` and ``_`` instead of ``/`` in the
   standard Base64 alphabet, and return the encoded :class:`bytes`.  The result
   can still contain ``=``.


.. function:: urlsafe_b64decode(s)

   Decode :term:`bytes-like object` or ASCII string *s*
   using the URL- and filesystem-safe
   alphabet, which substitutes ``-`` instead of ``+`` and ``_`` instead of
   ``/`` in the standard Base64 alphabet, and return the decoded
   :class:`bytes`.


.. function:: b32encode(s)

   Encode the :term:`bytes-like object` *s* using Base32 and return the
   encoded :class:`bytes`.


.. function:: b32decode(s, casefold=False, map01=None)

   Decode the Base32 encoded :term:`bytes-like object` or ASCII string *s* and
   return the decoded :class:`bytes`.

   Optional *casefold* is a flag specifying
   whether a lowercase alphabet is acceptable as input.  For security purposes,
   the default is ``False``.

   :rfc:`4648` allows for optional mapping of the digit 0 (zero) to the letter O
   (oh), and for optional mapping of the digit 1 (one) to either the letter I (eye)
   or letter L (el).  The optional argument *map01* when not ``None``, specifies
   which letter the digit 1 should be mapped to (when *map01* is not ``None``, the
   digit 0 is always mapped to the letter O).  For security purposes the default is
   ``None``, so that 0 and 1 are not allowed in the input.

   A :exc:`binascii.Error` is raised if *s* is
   incorrectly padded or if there are non-alphabet characters present in the
   input.


.. function:: b32hexencode(s)

   Similar to :func:`b32encode` but uses the Extended Hex Alphabet, as defined in
   :rfc:`4648`.

   .. versionadded:: 3.10


.. function:: b32hexdecode(s, casefold=False)

   Similar to :func:`b32decode` but uses the Extended Hex Alphabet, as defined in
   :rfc:`4648`.

   This version does not allow the digit 0 (zero) to the letter O (oh) and digit
   1 (one) to either the letter I (eye) or letter L (el) mappings, all these
   characters are included in the Extended Hex Alphabet and are not
   interchangeable.

   .. versionadded:: 3.10


.. function:: b16encode(s)

   Encode the :term:`bytes-like object` *s* using Base16 and return the
   encoded :class:`bytes`.


.. function:: b16decode(s, casefold=False)

   Decode the Base16 encoded :term:`bytes-like object` or ASCII string *s* and
   return the decoded :class:`bytes`.

   Optional *casefold* is a flag specifying whether a
   lowercase alphabet is acceptable as input.  For security purposes, the default
   is ``False``.

   A :exc:`binascii.Error` is raised if *s* is
   incorrectly padded or if there are non-alphabet characters present in the
   input.


.. function:: a85encode(b, *, foldspaces=False, wrapcol=0, pad=False, adobe=False)

   Encode the :term:`bytes-like object` *b* using Ascii85 and return the
   encoded :class:`bytes`.

   *foldspaces* is an optional flag that uses the special short sequence 'y'
   instead of 4 consecutive spaces (ASCII 0x20) as supported by 'btoa'. This
   feature is not supported by the "standard" Ascii85 encoding.

   *wrapcol* controls whether the output should have newline (``b'\n'``)
   characters added to it. If this is non-zero, each output line will be
   at most this many characters long, excluding the trailing newline.

   *pad* controls whether the input is padded to a multiple of 4
   before encoding. Note that the ``btoa`` implementation always pads.

   *adobe* controls whether the encoded byte sequence is framed with ``<~``
   and ``~>``, which is used by the Adobe implementation.

   .. versionadded:: 3.4


.. function:: a85decode(b, *, foldspaces=False, adobe=False, ignorechars=b' \t\n\r\v')

   Decode the Ascii85 encoded :term:`bytes-like object` or ASCII string *b* and
   return the decoded :class:`bytes`.

   *foldspaces* is a flag that specifies whether the 'y' short sequence
   should be accepted as shorthand for 4 consecutive spaces (ASCII 0x20).
   This feature is not supported by the "standard" Ascii85 encoding.

   *adobe* controls whether the input sequence is in Adobe Ascii85 format
   (i.e. is framed with <~ and ~>).

   *ignorechars* should be a :term:`bytes-like object` or ASCII string
   containing characters to ignore
   from the input. This should only contain whitespace characters, and by
   default contains all whitespace characters in ASCII.

   .. versionadded:: 3.4


.. function:: b85encode(b, pad=False)

   Encode the :term:`bytes-like object` *b* using base85 (as used in e.g.
   git-style binary diffs) and return the encoded :class:`bytes`.

   If *pad* is true, the input is padded with ``b'\0'`` so its length is a
   multiple of 4 bytes before encoding.

   .. versionadded:: 3.4


.. function:: b85decode(b)

   Decode the base85-encoded :term:`bytes-like object` or ASCII string *b* and
   return the decoded :class:`bytes`.  Padding is implicitly removed, if
   necessary.

   .. versionadded:: 3.4


.. function:: z85encode(s)

   Encode the :term:`bytes-like object` *s* using Z85 (as used in ZeroMQ)
   and return the encoded :class:`bytes`.  See `Z85  specification
   <https://rfc.zeromq.org/spec/32/>`_ for more information.

   .. versionadded:: 3.13


.. function:: z85decode(s)

   Decode the Z85-encoded :term:`bytes-like object` or ASCII string *s* and
   return the decoded :class:`bytes`.  See `Z85  specification
   <https://rfc.zeromq.org/spec/32/>`_ for more information.

   .. versionadded:: 3.13


The legacy interface:

.. function:: decode(input, output)

   Decode the contents of the binary *input* file and write the resulting binary
   data to the *output* file. *input* and *output* must be :term:`file objects
   <file object>`. *input* will be read until ``input.readline()`` returns an
   empty bytes object.


.. function:: decodebytes(s)

   Decode the :term:`bytes-like object` *s*, which must contain one or more
   lines of base64 encoded data, and return the decoded :class:`bytes`.

   .. versionadded:: 3.1


.. function:: encode(input, output)

   Encode the contents of the binary *input* file and write the resulting base64
   encoded data to the *output* file. *input* and *output* must be :term:`file
   objects <file object>`. *input* will be read until ``input.read()`` returns
   an empty bytes object. :func:`encode` inserts a newline character (``b'\n'``)
   after every 76 bytes of the output, as well as ensuring that the output
   always ends with a newline, as per :rfc:`2045` (MIME).


.. function:: encodebytes(s)

   Encode the :term:`bytes-like object` *s*, which can contain arbitrary binary
   data, and return :class:`bytes` containing the base64-encoded data, with newlines
   (``b'\n'``) inserted after every 76 bytes of output, and ensuring that
   there is a trailing newline, as per :rfc:`2045` (MIME).

   .. versionadded:: 3.1


An example usage of the module:

   >>> import base64
   >>> encoded = base64.b64encode(b'data to be encoded')
   >>> encoded
   b'ZGF0YSB0byBiZSBlbmNvZGVk'
   >>> data = base64.b64decode(encoded)
   >>> data
   b'data to be encoded'

.. _base64-security:

Security Considerations
-----------------------

A new security considerations section was added to :rfc:`4648` (section 12); it's
recommended to review the security section for any code deployed to production.

.. seealso::

   Module :mod:`binascii`
      Support module containing ASCII-to-binary and binary-to-ASCII conversions.

   :rfc:`1521` - MIME (Multipurpose Internet Mail Extensions) Part One: Mechanisms for Specifying and Describing the Format of Internet Message Bodies
      Section 5.2, "Base64 Content-Transfer-Encoding," provides the definition of the
      base64 encoding.



================================================
File: /Doc/library/bdb.rst
================================================
:mod:`!bdb` --- Debugger framework
==================================

.. module:: bdb
   :synopsis: Debugger framework.

**Source code:** :source:`Lib/bdb.py`

--------------

The :mod:`bdb` module handles basic debugger functions, like setting breakpoints
or managing execution via the debugger.

The following exception is defined:

.. exception:: BdbQuit

   Exception raised by the :class:`Bdb` class for quitting the debugger.


The :mod:`bdb` module also defines two classes:

.. class:: Breakpoint(self, file, line, temporary=False, cond=None, funcname=None)

   This class implements temporary breakpoints, ignore counts, disabling and
   (re-)enabling, and conditionals.

   Breakpoints are indexed by number through a list called :attr:`bpbynumber`
   and by ``(file, line)`` pairs through :attr:`bplist`.  The former points to
   a single instance of class :class:`Breakpoint`.  The latter points to a list
   of such instances since there may be more than one breakpoint per line.

   When creating a breakpoint, its associated :attr:`file name <file>` should
   be in canonical form.  If a :attr:`funcname` is defined, a breakpoint
   :attr:`hit <hits>` will be counted when the first line of that function is
   executed.  A :attr:`conditional <cond>` breakpoint always counts a
   :attr:`hit <hits>`.

   :class:`Breakpoint` instances have the following methods:

   .. method:: deleteMe()

      Delete the breakpoint from the list associated to a file/line.  If it is
      the last breakpoint in that position, it also deletes the entry for the
      file/line.


   .. method:: enable()

      Mark the breakpoint as enabled.


   .. method:: disable()

      Mark the breakpoint as disabled.


   .. method:: bpformat()

      Return a string with all the information about the breakpoint, nicely
      formatted:

      * Breakpoint number.
      * Temporary status (del or keep).
      * File/line position.
      * Break condition.
      * Number of times to ignore.
      * Number of times hit.

      .. versionadded:: 3.2

   .. method:: bpprint(out=None)

      Print the output of :meth:`bpformat` to the file *out*, or if it is
      ``None``, to standard output.

   :class:`Breakpoint` instances have the following attributes:

   .. attribute:: file

      File name of the :class:`Breakpoint`.

   .. attribute:: line

      Line number of the :class:`Breakpoint` within :attr:`file`.

   .. attribute:: temporary

      ``True`` if a :class:`Breakpoint` at (file, line) is temporary.

   .. attribute:: cond

      Condition for evaluating a :class:`Breakpoint` at (file, line).

   .. attribute:: funcname

      Function name that defines whether a :class:`Breakpoint` is hit upon
      entering the function.

   .. attribute:: enabled

      ``True`` if :class:`Breakpoint` is enabled.

   .. attribute:: bpbynumber

      Numeric index for a single instance of a :class:`Breakpoint`.

   .. attribute:: bplist

      Dictionary of :class:`Breakpoint` instances indexed by
      (:attr:`file`, :attr:`line`) tuples.

   .. attribute:: ignore

      Number of times to ignore a :class:`Breakpoint`.

   .. attribute:: hits

      Count of the number of times a :class:`Breakpoint` has been hit.

.. class:: Bdb(skip=None)

   The :class:`Bdb` class acts as a generic Python debugger base class.

   This class takes care of the details of the trace facility; a derived class
   should implement user interaction.  The standard debugger class
   (:class:`pdb.Pdb`) is an example.

   The *skip* argument, if given, must be an iterable of glob-style
   module name patterns.  The debugger will not step into frames that
   originate in a module that matches one of these patterns. Whether a
   frame is considered to originate in a certain module is determined
   by the ``__name__`` in the frame globals.

   .. versionchanged:: 3.1
      Added the *skip* parameter.

   The following methods of :class:`Bdb` normally don't need to be overridden.

   .. method:: canonic(filename)

      Return canonical form of *filename*.

      For real file names, the canonical form is an operating-system-dependent,
      :func:`case-normalized <os.path.normcase>` :func:`absolute path
      <os.path.abspath>`. A *filename* with angle brackets, such as ``"<stdin>"``
      generated in interactive mode, is returned unchanged.

   .. method:: reset()

      Set the :attr:`!botframe`, :attr:`!stopframe`, :attr:`!returnframe` and
      :attr:`quitting <Bdb.set_quit>` attributes with values ready to start debugging.

   .. method:: trace_dispatch(frame, event, arg)

      This function is installed as the trace function of debugged frames.  Its
      return value is the new trace function (in most cases, that is, itself).

      The default implementation decides how to dispatch a frame, depending on
      the type of event (passed as a string) that is about to be executed.
      *event* can be one of the following:

      * ``"line"``: A new line of code is going to be executed.
      * ``"call"``: A function is about to be called, or another code block
        entered.
      * ``"return"``: A function or other code block is about to return.
      * ``"exception"``: An exception has occurred.
      * ``"c_call"``: A C function is about to be called.
      * ``"c_return"``: A C function has returned.
      * ``"c_exception"``: A C function has raised an exception.

      For the Python events, specialized functions (see below) are called.  For
      the C events, no action is taken.

      The *arg* parameter depends on the previous event.

      See the documentation for :func:`sys.settrace` for more information on the
      trace function.  For more information on code and frame objects, refer to
      :ref:`types`.

   .. method:: dispatch_line(frame)

      If the debugger should stop on the current line, invoke the
      :meth:`user_line` method (which should be overridden in subclasses).
      Raise a :exc:`BdbQuit` exception if the :attr:`quitting  <Bdb.set_quit>` flag is set
      (which can be set from :meth:`user_line`).  Return a reference to the
      :meth:`trace_dispatch` method for further tracing in that scope.

   .. method:: dispatch_call(frame, arg)

      If the debugger should stop on this function call, invoke the
      :meth:`user_call` method (which should be overridden in subclasses).
      Raise a :exc:`BdbQuit` exception if the :attr:`quitting  <Bdb.set_quit>` flag is set
      (which can be set from :meth:`user_call`).  Return a reference to the
      :meth:`trace_dispatch` method for further tracing in that scope.

   .. method:: dispatch_return(frame, arg)

      If the debugger should stop on this function return, invoke the
      :meth:`user_return` method (which should be overridden in subclasses).
      Raise a :exc:`BdbQuit` exception if the :attr:`quitting  <Bdb.set_quit>` flag is set
      (which can be set from :meth:`user_return`).  Return a reference to the
      :meth:`trace_dispatch` method for further tracing in that scope.

   .. method:: dispatch_exception(frame, arg)

      If the debugger should stop at this exception, invokes the
      :meth:`user_exception` method (which should be overridden in subclasses).
      Raise a :exc:`BdbQuit` exception if the :attr:`quitting  <Bdb.set_quit>` flag is set
      (which can be set from :meth:`user_exception`).  Return a reference to the
      :meth:`trace_dispatch` method for further tracing in that scope.

   Normally derived classes don't override the following methods, but they may
   if they want to redefine the definition of stopping and breakpoints.

   .. method:: is_skipped_line(module_name)

      Return ``True`` if *module_name* matches any skip pattern.

   .. method:: stop_here(frame)

      Return ``True`` if *frame* is below the starting frame in the stack.

   .. method:: break_here(frame)

      Return ``True`` if there is an effective breakpoint for this line.

      Check whether a line or function breakpoint exists and is in effect.  Delete temporary
      breakpoints based on information from :func:`effective`.

   .. method:: break_anywhere(frame)

      Return ``True`` if any breakpoint exists for *frame*'s filename.

   Derived classes should override these methods to gain control over debugger
   operation.

   .. method:: user_call(frame, argument_list)

      Called from :meth:`dispatch_call` if a break might stop inside the
      called function.

      *argument_list* is not used anymore and will always be ``None``.
      The argument is kept for backwards compatibility.

   .. method:: user_line(frame)

      Called from :meth:`dispatch_line` when either :meth:`stop_here` or
      :meth:`break_here` returns ``True``.

   .. method:: user_return(frame, return_value)

      Called from :meth:`dispatch_return` when :meth:`stop_here` returns ``True``.

   .. method:: user_exception(frame, exc_info)

      Called from :meth:`dispatch_exception` when :meth:`stop_here`
      returns ``True``.

   .. method:: do_clear(arg)

      Handle how a breakpoint must be removed when it is a temporary one.

      This method must be implemented by derived classes.


   Derived classes and clients can call the following methods to affect the
   stepping state.

   .. method:: set_step()

      Stop after one line of code.

   .. method:: set_next(frame)

      Stop on the next line in or below the given frame.

   .. method:: set_return(frame)

      Stop when returning from the given frame.

   .. method:: set_until(frame, lineno=None)

      Stop when the line with the *lineno* greater than the current one is
      reached or when returning from current frame.

   .. method:: set_trace([frame])

      Start debugging from *frame*.  If *frame* is not specified, debugging
      starts from caller's frame.

      .. versionchanged:: 3.13
         :func:`set_trace` will enter the debugger immediately, rather than
         on the next line of code to be executed.

   .. method:: set_continue()

      Stop only at breakpoints or when finished.  If there are no breakpoints,
      set the system trace function to ``None``.

   .. method:: set_quit()

      .. index:: single: quitting (bdb.Bdb attribute)

      Set the :attr:`!quitting` attribute to ``True``.  This raises :exc:`BdbQuit` in
      the next call to one of the :meth:`!dispatch_\*` methods.


   Derived classes and clients can call the following methods to manipulate
   breakpoints.  These methods return a string containing an error message if
   something went wrong, or ``None`` if all is well.

   .. method:: set_break(filename, lineno, temporary=False, cond=None, funcname=None)

      Set a new breakpoint.  If the *lineno* line doesn't exist for the
      *filename* passed as argument, return an error message.  The *filename*
      should be in canonical form, as described in the :meth:`canonic` method.

   .. method:: clear_break(filename, lineno)

      Delete the breakpoints in *filename* and *lineno*.  If none were set,
      return an error message.

   .. method:: clear_bpbynumber(arg)

      Delete the breakpoint which has the index *arg* in the
      :attr:`Breakpoint.bpbynumber`.  If *arg* is not numeric or out of range,
      return an error message.

   .. method:: clear_all_file_breaks(filename)

      Delete all breakpoints in *filename*.  If none were set, return an error
      message.

   .. method:: clear_all_breaks()

      Delete all existing breakpoints.  If none were set, return an error
      message.

   .. method:: get_bpbynumber(arg)

      Return a breakpoint specified by the given number.  If *arg* is a string,
      it will be converted to a number.  If *arg* is a non-numeric string, if
      the given breakpoint never existed or has been deleted, a
      :exc:`ValueError` is raised.

      .. versionadded:: 3.2

   .. method:: get_break(filename, lineno)

      Return ``True`` if there is a breakpoint for *lineno* in *filename*.

   .. method:: get_breaks(filename, lineno)

      Return all breakpoints for *lineno* in *filename*, or an empty list if
      none are set.

   .. method:: get_file_breaks(filename)

      Return all breakpoints in *filename*, or an empty list if none are set.

   .. method:: get_all_breaks()

      Return all breakpoints that are set.


   Derived classes and clients can call the following methods to get a data
   structure representing a stack trace.

   .. method:: get_stack(f, t)

      Return a list of (frame, lineno) tuples in a stack trace, and a size.

      The most recently called frame is last in the list. The size is the number
      of frames below the frame where the debugger was invoked.

   .. method:: format_stack_entry(frame_lineno, lprefix=': ')

      Return a string with information about a stack entry, which is a
      ``(frame, lineno)`` tuple.  The return string contains:

      * The canonical filename which contains the frame.
      * The function name or ``"<lambda>"``.
      * The input arguments.
      * The return value.
      * The line of code (if it exists).


   The following two methods can be called by clients to use a debugger to debug
   a :term:`statement`, given as a string.

   .. method:: run(cmd, globals=None, locals=None)

      Debug a statement executed via the :func:`exec` function.  *globals*
      defaults to :attr:`!__main__.__dict__`, *locals* defaults to *globals*.

   .. method:: runeval(expr, globals=None, locals=None)

      Debug an expression executed via the :func:`eval` function.  *globals* and
      *locals* have the same meaning as in :meth:`run`.

   .. method:: runctx(cmd, globals, locals)

      For backwards compatibility.  Calls the :meth:`run` method.

   .. method:: runcall(func, /, *args, **kwds)

      Debug a single function call, and return its result.


Finally, the module defines the following functions:

.. function:: checkfuncname(b, frame)

   Return ``True`` if we should break here, depending on the way the
   :class:`Breakpoint` *b* was set.

   If it was set via line number, it checks if
   :attr:`b.line <bdb.Breakpoint.line>` is the same as the one in *frame*.
   If the breakpoint was set via
   :attr:`function name <bdb.Breakpoint.funcname>`, we have to check we are in
   the right *frame* (the right function) and if we are on its first executable
   line.

.. function:: effective(file, line, frame)

   Return ``(active breakpoint, delete temporary flag)`` or ``(None, None)`` as the
   breakpoint to act upon.

   The *active breakpoint* is the first entry in
   :attr:`bplist <bdb.Breakpoint.bplist>` for the
   (:attr:`file <bdb.Breakpoint.file>`, :attr:`line <bdb.Breakpoint.line>`)
   (which must exist) that is :attr:`enabled <bdb.Breakpoint.enabled>`, for
   which :func:`checkfuncname` is true, and that has neither a false
   :attr:`condition <bdb.Breakpoint.cond>` nor positive
   :attr:`ignore <bdb.Breakpoint.ignore>` count.  The *flag*, meaning that a
   temporary breakpoint should be deleted, is ``False`` only when the
   :attr:`cond <bdb.Breakpoint.cond>` cannot be evaluated (in which case,
   :attr:`ignore <bdb.Breakpoint.ignore>` count is ignored).

   If no such entry exists, then ``(None, None)`` is returned.


.. function:: set_trace()

   Start debugging with a :class:`Bdb` instance from caller's frame.


================================================
File: /Doc/library/binary.rst
================================================
.. _binaryservices:

********************
Binary Data Services
********************

The modules described in this chapter provide some basic services operations
for manipulation of binary data. Other operations on binary data, specifically
in relation to file formats and network protocols, are described in the
relevant sections.

Some libraries described under :ref:`textservices` also work with either
ASCII-compatible binary formats (for example, :mod:`re`) or all binary data
(for example, :mod:`difflib`).

In addition, see the documentation for Python's built-in binary data types in
:ref:`binaryseq`.

.. toctree::

   struct.rst
   codecs.rst



================================================
File: /Doc/library/binascii.rst
================================================
:mod:`!binascii` --- Convert between binary and ASCII
=====================================================

.. module:: binascii
   :synopsis: Tools for converting between binary and various ASCII-encoded binary
              representations.

.. index::
   pair: module; base64

--------------

The :mod:`binascii` module contains a number of methods to convert between
binary and various ASCII-encoded binary representations. Normally, you will not
use these functions directly but use wrapper modules like
:mod:`base64` instead. The :mod:`binascii` module contains
low-level functions written in C for greater speed that are used by the
higher-level modules.

.. note::

   ``a2b_*`` functions accept Unicode strings containing only ASCII characters.
   Other functions only accept :term:`bytes-like objects <bytes-like object>` (such as
   :class:`bytes`, :class:`bytearray` and other objects that support the buffer
   protocol).

   .. versionchanged:: 3.3
      ASCII-only unicode strings are now accepted by the ``a2b_*`` functions.


The :mod:`binascii` module defines the following functions:


.. function:: a2b_uu(string)

   Convert a single line of uuencoded data back to binary and return the binary
   data. Lines normally contain 45 (binary) bytes, except for the last line. Line
   data may be followed by whitespace.


.. function:: b2a_uu(data, *, backtick=False)

   Convert binary data to a line of ASCII characters, the return value is the
   converted line, including a newline char. The length of *data* should be at most
   45. If *backtick* is true, zeros are represented by ``'`'`` instead of spaces.

   .. versionchanged:: 3.7
      Added the *backtick* parameter.


.. function:: a2b_base64(string, /, *, strict_mode=False)

   Convert a block of base64 data back to binary and return the binary data. More
   than one line may be passed at a time.

   If *strict_mode* is true, only valid base64 data will be converted. Invalid base64
   data will raise :exc:`binascii.Error`.

   Valid base64:

   * Conforms to :rfc:`3548`.
   * Contains only characters from the base64 alphabet.
   * Contains no excess data after padding (including excess padding, newlines, etc.).
   * Does not start with a padding.

   .. versionchanged:: 3.11
      Added the *strict_mode* parameter.


.. function:: b2a_base64(data, *, newline=True)

   Convert binary data to a line of ASCII characters in base64 coding. The return
   value is the converted line, including a newline char if *newline* is
   true.  The output of this function conforms to :rfc:`3548`.

   .. versionchanged:: 3.6
      Added the *newline* parameter.


.. function:: a2b_qp(data, header=False)

   Convert a block of quoted-printable data back to binary and return the binary
   data. More than one line may be passed at a time. If the optional argument
   *header* is present and true, underscores will be decoded as spaces.


.. function:: b2a_qp(data, quotetabs=False, istext=True, header=False)

   Convert binary data to a line(s) of ASCII characters in quoted-printable
   encoding.  The return value is the converted line(s). If the optional argument
   *quotetabs* is present and true, all tabs and spaces will be encoded.   If the
   optional argument *istext* is present and true, newlines are not encoded but
   trailing whitespace will be encoded. If the optional argument *header* is
   present and true, spaces will be encoded as underscores per :rfc:`1522`. If the
   optional argument *header* is present and false, newline characters will be
   encoded as well; otherwise linefeed conversion might corrupt the binary data
   stream.


.. function:: crc_hqx(data, value)

   Compute a 16-bit CRC value of *data*, starting with *value* as the
   initial CRC, and return the result.  This uses the CRC-CCITT polynomial
   *x*:sup:`16` + *x*:sup:`12` + *x*:sup:`5` + 1, often represented as
   0x1021.  This CRC is used in the binhex4 format.


.. function:: crc32(data[, value])

   Compute CRC-32, the unsigned 32-bit checksum of *data*, starting with an
   initial CRC of *value*.  The default initial CRC is zero.  The algorithm
   is consistent with the ZIP file checksum.  Since the algorithm is designed for
   use as a checksum algorithm, it is not suitable for use as a general hash
   algorithm.  Use as follows::

      print(binascii.crc32(b"hello world"))
      # Or, in two pieces:
      crc = binascii.crc32(b"hello")
      crc = binascii.crc32(b" world", crc)
      print('crc32 = {:#010x}'.format(crc))

   .. versionchanged:: 3.0
      The result is always unsigned.

.. function:: b2a_hex(data[, sep[, bytes_per_sep=1]])
              hexlify(data[, sep[, bytes_per_sep=1]])

   Return the hexadecimal representation of the binary *data*.  Every byte of
   *data* is converted into the corresponding 2-digit hex representation.  The
   returned bytes object is therefore twice as long as the length of *data*.

   Similar functionality (but returning a text string) is also conveniently
   accessible using the :meth:`bytes.hex` method.

   If *sep* is specified, it must be a single character str or bytes object.
   It will be inserted in the output after every *bytes_per_sep* input bytes.
   Separator placement is counted from the right end of the output by default,
   if you wish to count from the left, supply a negative *bytes_per_sep* value.

      >>> import binascii
      >>> binascii.b2a_hex(b'\xb9\x01\xef')
      b'b901ef'
      >>> binascii.hexlify(b'\xb9\x01\xef', '-')
      b'b9-01-ef'
      >>> binascii.b2a_hex(b'\xb9\x01\xef', b'_', 2)
      b'b9_01ef'
      >>> binascii.b2a_hex(b'\xb9\x01\xef', b' ', -2)
      b'b901 ef'

   .. versionchanged:: 3.8
      The *sep* and *bytes_per_sep* parameters were added.

.. function:: a2b_hex(hexstr)
              unhexlify(hexstr)

   Return the binary data represented by the hexadecimal string *hexstr*.  This
   function is the inverse of :func:`b2a_hex`. *hexstr* must contain an even number
   of hexadecimal digits (which can be upper or lower case), otherwise an
   :exc:`Error` exception is raised.

   Similar functionality (accepting only text string arguments, but more
   liberal towards whitespace) is also accessible using the
   :meth:`bytes.fromhex` class method.

.. exception:: Error

   Exception raised on errors. These are usually programming errors.


.. exception:: Incomplete

   Exception raised on incomplete data. These are usually not programming errors,
   but may be handled by reading a little more data and trying again.


.. seealso::

   Module :mod:`base64`
      Support for RFC compliant base64-style encoding in base 16, 32, 64,
      and 85.

   Module :mod:`quopri`
      Support for quoted-printable encoding used in MIME email messages.


================================================
File: /Doc/library/bisect.rst
================================================
:mod:`!bisect` --- Array bisection algorithm
============================================

.. module:: bisect
   :synopsis: Array bisection algorithms for binary searching.
.. sectionauthor:: Fred L. Drake, Jr. <fdrake@acm.org>
.. sectionauthor:: Raymond Hettinger <python at rcn.com>
.. example based on the PyModules FAQ entry by Aaron Watters <arw@pythonpros.com>

**Source code:** :source:`Lib/bisect.py`

--------------

This module provides support for maintaining a list in sorted order without
having to sort the list after each insertion.  For long lists of items with
expensive comparison operations, this can be an improvement over
linear searches or frequent resorting.

The module is called :mod:`bisect` because it uses a basic bisection
algorithm to do its work.  Unlike other bisection tools that search for a
specific value, the functions in this module are designed to locate an
insertion point. Accordingly, the functions never call an :meth:`~object.__eq__`
method to determine whether a value has been found.  Instead, the
functions only call the :meth:`~object.__lt__` method and will return an insertion
point between values in an array.

.. _bisect functions:

The following functions are provided:


.. function:: bisect_left(a, x, lo=0, hi=len(a), *, key=None)

   Locate the insertion point for *x* in *a* to maintain sorted order.
   The parameters *lo* and *hi* may be used to specify a subset of the list
   which should be considered; by default the entire list is used.  If *x* is
   already present in *a*, the insertion point will be before (to the left of)
   any existing entries.  The return value is suitable for use as the first
   parameter to ``list.insert()`` assuming that *a* is already sorted.

   The returned insertion point *ip* partitions the array *a* into two
   slices such that ``all(elem < x for elem in a[lo : ip])`` is true for the
   left slice and ``all(elem >= x for elem in a[ip : hi])`` is true for the
   right slice.

   *key* specifies a :term:`key function` of one argument that is used to
   extract a comparison key from each element in the array.  To support
   searching complex records, the key function is not applied to the *x* value.

   If *key* is ``None``, the elements are compared directly and
   no key function is called.

   .. versionchanged:: 3.10
      Added the *key* parameter.


.. function:: bisect_right(a, x, lo=0, hi=len(a), *, key=None)
              bisect(a, x, lo=0, hi=len(a), *, key=None)

   Similar to :py:func:`~bisect.bisect_left`, but returns an insertion point which comes
   after (to the right of) any existing entries of *x* in *a*.

   The returned insertion point *ip* partitions the array *a* into two slices
   such that ``all(elem <= x for elem in a[lo : ip])`` is true for the left slice and
   ``all(elem > x for elem in a[ip : hi])`` is true for the right slice.

   .. versionchanged:: 3.10
      Added the *key* parameter.


.. function:: insort_left(a, x, lo=0, hi=len(a), *, key=None)

   Insert *x* in *a* in sorted order.

   This function first runs :py:func:`~bisect.bisect_left` to locate an insertion point.
   Next, it runs the :meth:`!insert` method on *a* to insert *x* at the
   appropriate position to maintain sort order.

   To support inserting records in a table, the *key* function (if any) is
   applied to *x* for the search step but not for the insertion step.

   Keep in mind that the *O*\ (log *n*) search is dominated by the slow *O*\ (*n*)
   insertion step.

   .. versionchanged:: 3.10
      Added the *key* parameter.


.. function:: insort_right(a, x, lo=0, hi=len(a), *, key=None)
              insort(a, x, lo=0, hi=len(a), *, key=None)

   Similar to :py:func:`~bisect.insort_left`, but inserting *x* in *a* after any existing
   entries of *x*.

   This function first runs :py:func:`~bisect.bisect_right` to locate an insertion point.
   Next, it runs the :meth:`!insert` method on *a* to insert *x* at the
   appropriate position to maintain sort order.

   To support inserting records in a table, the *key* function (if any) is
   applied to *x* for the search step but not for the insertion step.

   Keep in mind that the *O*\ (log *n*) search is dominated by the slow *O*\ (*n*)
   insertion step.

   .. versionchanged:: 3.10
      Added the *key* parameter.


Performance Notes
-----------------

When writing time sensitive code using *bisect()* and *insort()*, keep these
thoughts in mind:

* Bisection is effective for searching ranges of values.
  For locating specific values, dictionaries are more performant.

* The *insort()* functions are *O*\ (*n*) because the logarithmic search step
  is dominated by the linear time insertion step.

* The search functions are stateless and discard key function results after
  they are used.  Consequently, if the search functions are used in a loop,
  the key function may be called again and again on the same array elements.
  If the key function isn't fast, consider wrapping it with
  :py:func:`functools.cache` to avoid duplicate computations.  Alternatively,
  consider searching an array of precomputed keys to locate the insertion
  point (as shown in the examples section below).

.. seealso::

   * `Sorted Collections
     <https://grantjenks.com/docs/sortedcollections/>`_ is a high performance
     module that uses *bisect* to managed sorted collections of data.

   * The `SortedCollection recipe
     <https://code.activestate.com/recipes/577197-sortedcollection/>`_ uses
     bisect to build a full-featured collection class with straight-forward search
     methods and support for a key-function.  The keys are precomputed to save
     unnecessary calls to the key function during searches.


Searching Sorted Lists
----------------------

The above `bisect functions`_ are useful for finding insertion points but
can be tricky or awkward to use for common searching tasks. The following five
functions show how to transform them into the standard lookups for sorted
lists::

    def index(a, x):
        'Locate the leftmost value exactly equal to x'
        i = bisect_left(a, x)
        if i != len(a) and a[i] == x:
            return i
        raise ValueError

    def find_lt(a, x):
        'Find rightmost value less than x'
        i = bisect_left(a, x)
        if i:
            return a[i-1]
        raise ValueError

    def find_le(a, x):
        'Find rightmost value less than or equal to x'
        i = bisect_right(a, x)
        if i:
            return a[i-1]
        raise ValueError

    def find_gt(a, x):
        'Find leftmost value greater than x'
        i = bisect_right(a, x)
        if i != len(a):
            return a[i]
        raise ValueError

    def find_ge(a, x):
        'Find leftmost item greater than or equal to x'
        i = bisect_left(a, x)
        if i != len(a):
            return a[i]
        raise ValueError


Examples
--------

.. _bisect-example:

The :py:func:`~bisect.bisect` function can be useful for numeric table lookups. This
example uses :py:func:`~bisect.bisect` to look up a letter grade for an exam score (say)
based on a set of ordered numeric breakpoints: 90 and up is an 'A', 80 to 89 is
a 'B', and so on::

   >>> def grade(score, breakpoints=[60, 70, 80, 90], grades='FDCBA'):
   ...     i = bisect(breakpoints, score)
   ...     return grades[i]
   ...
   >>> [grade(score) for score in [33, 99, 77, 70, 89, 90, 100]]
   ['F', 'A', 'C', 'C', 'B', 'A', 'A']

The :py:func:`~bisect.bisect` and :py:func:`~bisect.insort` functions also work with
lists of tuples.  The *key* argument can serve to extract the field used for ordering
records in a table::

    >>> from collections import namedtuple
    >>> from operator import attrgetter
    >>> from bisect import bisect, insort
    >>> from pprint import pprint

    >>> Movie = namedtuple('Movie', ('name', 'released', 'director'))

    >>> movies = [
    ...     Movie('Jaws', 1975, 'Spielberg'),
    ...     Movie('Titanic', 1997, 'Cameron'),
    ...     Movie('The Birds', 1963, 'Hitchcock'),
    ...     Movie('Aliens', 1986, 'Cameron')
    ... ]

    >>> # Find the first movie released after 1960
    >>> by_year = attrgetter('released')
    >>> movies.sort(key=by_year)
    >>> movies[bisect(movies, 1960, key=by_year)]
    Movie(name='The Birds', released=1963, director='Hitchcock')

    >>> # Insert a movie while maintaining sort order
    >>> romance = Movie('Love Story', 1970, 'Hiller')
    >>> insort(movies, romance, key=by_year)
    >>> pprint(movies)
    [Movie(name='The Birds', released=1963, director='Hitchcock'),
     Movie(name='Love Story', released=1970, director='Hiller'),
     Movie(name='Jaws', released=1975, director='Spielberg'),
     Movie(name='Aliens', released=1986, director='Cameron'),
     Movie(name='Titanic', released=1997, director='Cameron')]

If the key function is expensive, it is possible to avoid repeated function
calls by searching a list of precomputed keys to find the index of a record::

    >>> data = [('red', 5), ('blue', 1), ('yellow', 8), ('black', 0)]
    >>> data.sort(key=lambda r: r[1])       # Or use operator.itemgetter(1).
    >>> keys = [r[1] for r in data]         # Precompute a list of keys.
    >>> data[bisect_left(keys, 0)]
    ('black', 0)
    >>> data[bisect_left(keys, 1)]
    ('blue', 1)
    >>> data[bisect_left(keys, 5)]
    ('red', 5)
    >>> data[bisect_left(keys, 8)]
    ('yellow', 8)


================================================
File: /Doc/library/builtins.rst
================================================
:mod:`!builtins` --- Built-in objects
=====================================

.. module:: builtins
   :synopsis: The module that provides the built-in namespace.

--------------

This module provides direct access to all 'built-in' identifiers of Python; for
example, ``builtins.open`` is the full name for the built-in function :func:`open`.

This module is not normally accessed explicitly by most applications, but can be
useful in modules that provide objects with the same name as a built-in value,
but in which the built-in of that name is also needed.  For example, in a module
that wants to implement an :func:`open` function that wraps the built-in
:func:`open`, this module can be used directly::

   import builtins

   def open(path):
       f = builtins.open(path, 'r')
       return UpperCaser(f)

   class UpperCaser:
       '''Wrapper around a file that converts output to uppercase.'''

       def __init__(self, f):
           self._f = f

       def read(self, count=-1):
           return self._f.read(count).upper()

       # ...

As an implementation detail, most modules have the name ``__builtins__`` made
available as part of their globals.  The value of ``__builtins__`` is normally
either this module or the value of this module's :attr:`~object.__dict__` attribute.
Since this is an implementation detail, it may not be used by alternate
implementations of Python.

.. seealso::

   * :ref:`built-in-consts`
   * :ref:`bltin-exceptions`
   * :ref:`built-in-funcs`
   * :ref:`bltin-types`


================================================
File: /Doc/library/bz2.rst
================================================
:mod:`!bz2` --- Support for :program:`bzip2` compression
========================================================

.. module:: bz2
   :synopsis: Interfaces for bzip2 compression and decompression.

.. moduleauthor:: Gustavo Niemeyer <niemeyer@conectiva.com>
.. moduleauthor:: Nadeem Vawda <nadeem.vawda@gmail.com>
.. sectionauthor:: Gustavo Niemeyer <niemeyer@conectiva.com>
.. sectionauthor:: Nadeem Vawda <nadeem.vawda@gmail.com>

**Source code:** :source:`Lib/bz2.py`

--------------

This module provides a comprehensive interface for compressing and
decompressing data using the bzip2 compression algorithm.

The :mod:`bz2` module contains:
