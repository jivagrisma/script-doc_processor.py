            "ENV_VAR_NAME": "PYTHONPATH",
            "ENV_VAR_VALUE": f"/{sysconfig_data}",
            "PYTHON_WASM": working_dir / "python.wasm"}
    # Check dynamically for wasmtime in case it was specified manually via
    # `--host-runner`.
    if WASMTIME_HOST_RUNNER_VAR in context.host_runner:
        if wasmtime := shutil.which("wasmtime"):
            args[WASMTIME_VAR_NAME] = wasmtime
        else:
            raise FileNotFoundError("wasmtime not found; download from "
                                    "https://github.com/bytecodealliance/wasmtime")
    host_runner = context.host_runner.format_map(args)
    env_additions = {"CONFIG_SITE": config_site, "HOSTRUNNER": host_runner}
    build_python = os.fsdecode(build_python_path())
    # The path to `configure` MUST be relative, else `python.wasm` is unable
    # to find the stdlib due to Python not recognizing that it's being
    # executed from within a checkout.
    configure = [os.path.relpath(CHECKOUT / 'configure', working_dir),
                    f"--host={context.host_triple}",
                    f"--build={build_platform()}",
                    f"--with-build-python={build_python}"]
    if pydebug:
        configure.append("--with-pydebug")
    if context.args:
        configure.extend(context.args)
    call(configure,
         env=updated_env(env_additions | wasi_sdk_env(context)),
         quiet=context.quiet)

    python_wasm = working_dir / "python.wasm"
    exec_script = working_dir / "python.sh"
    with exec_script.open("w", encoding="utf-8") as file:
        file.write(f'#!/bin/sh\nexec {host_runner} {python_wasm} "$@"\n')
    exec_script.chmod(0o755)
    print(f"üèÉ‚Äç‚ôÄÔ∏è Created {exec_script} ... ")
    sys.stdout.flush()


@subdir(lambda context: CROSS_BUILD_DIR / context.host_triple)
def make_wasi_python(context, working_dir):
    """Run `make` for the WASI/host build."""
    call(["make", "--jobs", str(cpu_count()), "all"],
             env=updated_env(),
             quiet=context.quiet)

    exec_script = working_dir / "python.sh"
    subprocess.check_call([exec_script, "--version"])


def build_all(context):
    """Build everything."""
    steps = [configure_build_python, make_build_python, configure_wasi_python,
             make_wasi_python]
    for step in steps:
        step(context)

def clean_contents(context):
    """Delete all files created by this script."""
    if CROSS_BUILD_DIR.exists():
        print(f"üßπ Deleting {CROSS_BUILD_DIR} ...")
        shutil.rmtree(CROSS_BUILD_DIR)

    if LOCAL_SETUP.exists():
        with LOCAL_SETUP.open("rb") as file:
            if file.read(len(LOCAL_SETUP_MARKER)) == LOCAL_SETUP_MARKER:
                print(f"üßπ Deleting generated {LOCAL_SETUP} ...")


def main():
    default_host_runner = (f"{WASMTIME_HOST_RUNNER_VAR} run "
                        # Make sure the stack size will work for a pydebug
                        # build.
                        # Use 16 MiB stack.
                        "--wasm max-wasm-stack=16777216 "
                        # Enable thread support; causes use of preview1.
                        #"--wasm threads=y --wasi threads=y "
                        # Map the checkout to / to load the stdlib from /Lib.
                        "--dir {HOST_DIR}::{GUEST_DIR} "
                        # Set PYTHONPATH to the sysconfig data.
                        "--env {ENV_VAR_NAME}={ENV_VAR_VALUE}")

    parser = argparse.ArgumentParser()
    subcommands = parser.add_subparsers(dest="subcommand")
    build = subcommands.add_parser("build", help="Build everything")
    configure_build = subcommands.add_parser("configure-build-python",
                                             help="Run `configure` for the "
                                             "build Python")
    make_build = subcommands.add_parser("make-build-python",
                                        help="Run `make` for the build Python")
    configure_host = subcommands.add_parser("configure-host",
                                            help="Run `configure` for the "
                                                 "host/WASI (pydebug builds "
                                                 "are inferred from the build "
                                                 "Python)")
    make_host = subcommands.add_parser("make-host",
                                       help="Run `make` for the host/WASI")
    clean = subcommands.add_parser("clean", help="Delete files and directories "
                                                 "created by this script")
    for subcommand in build, configure_build, make_build, configure_host, make_host:
        subcommand.add_argument("--quiet", action="store_true", default=False,
                        dest="quiet",
                        help="Redirect output from subprocesses to a log file")
    for subcommand in configure_build, configure_host:
        subcommand.add_argument("--clean", action="store_true", default=False,
                        dest="clean",
                        help="Delete any relevant directories before building")
    for subcommand in build, configure_build, configure_host:
        subcommand.add_argument("args", nargs="*",
                                help="Extra arguments to pass to `configure`")
    for subcommand in build, configure_host:
        subcommand.add_argument("--wasi-sdk", type=pathlib.Path,
                                dest="wasi_sdk_path",
                                default=find_wasi_sdk(),
                                help="Path to wasi-sdk; defaults to "
                                     "$WASI_SDK_PATH or /opt/wasi-sdk")
        subcommand.add_argument("--host-runner", action="store",
                        default=default_host_runner, dest="host_runner",
                        help="Command template for running the WASI host "
                             "(default designed for wasmtime 14 or newer: "
                                f"`{default_host_runner}`)")
    for subcommand in build, configure_host, make_host:
        subcommand.add_argument("--host-triple", action="store", default="wasm32-wasip1",
                        help="The target triple for the WASI host build")

    context = parser.parse_args()

    dispatch = {"configure-build-python": configure_build_python,
                "make-build-python": make_build_python,
                "configure-host": configure_wasi_python,
                "make-host": make_wasi_python,
                "build": build_all,
                "clean": clean_contents}
    dispatch[context.subcommand](context)


if  __name__ == "__main__":
    main()


================================================
File: /Tools/wasm/wasm_build.py
================================================
#!/usr/bin/env python3
"""Build script for Python on WebAssembly platforms.

  $ ./Tools/wasm/wasm_builder.py emscripten-browser build repl
  $ ./Tools/wasm/wasm_builder.py emscripten-node-dl build test
  $ ./Tools/wasm/wasm_builder.py wasi build test

Primary build targets are "emscripten-node-dl" (NodeJS, dynamic linking),
"emscripten-browser", and "wasi".

Emscripten builds require a recent Emscripten SDK. The tools looks for an
activated EMSDK environment (". /path/to/emsdk_env.sh"). System packages
(Debian, Homebrew) are not supported.

WASI builds require WASI SDK and wasmtime. The tool looks for 'WASI_SDK_PATH'
and falls back to /opt/wasi-sdk.

The 'build' Python interpreter must be rebuilt every time Python's byte code
changes.

  ./Tools/wasm/wasm_builder.py --clean build build

"""
import argparse
import enum
import dataclasses
import logging
import os
import pathlib
import re
import shlex
import shutil
import socket
import subprocess
import sys
import sysconfig
import tempfile
import time
import warnings
import webbrowser

# for Python 3.8
from typing import (
    cast,
    Any,
    Callable,
    Dict,
    Iterable,
    List,
    Optional,
    Tuple,
    Union,
)

logger = logging.getLogger("wasm_build")

SRCDIR = pathlib.Path(__file__).parent.parent.parent.absolute()
WASMTOOLS = SRCDIR / "Tools" / "wasm"
BUILDDIR = SRCDIR / "builddir"
CONFIGURE = SRCDIR / "configure"
SETUP_LOCAL = SRCDIR / "Modules" / "Setup.local"

HAS_CCACHE = shutil.which("ccache") is not None

# path to WASI-SDK root
WASI_SDK_PATH = pathlib.Path(os.environ.get("WASI_SDK_PATH", "/opt/wasi-sdk"))

# path to Emscripten SDK config file.
# auto-detect's EMSDK in /opt/emsdk without ". emsdk_env.sh".
EM_CONFIG = pathlib.Path(os.environ.setdefault("EM_CONFIG", "/opt/emsdk/.emscripten"))
EMSDK_MIN_VERSION = (3, 1, 19)
EMSDK_BROKEN_VERSION = {
    (3, 1, 14): "https://github.com/emscripten-core/emscripten/issues/17338",
    (3, 1, 16): "https://github.com/emscripten-core/emscripten/issues/17393",
    (3, 1, 20): "https://github.com/emscripten-core/emscripten/issues/17720",
}
_MISSING = pathlib.Path("MISSING")

WASM_WEBSERVER = WASMTOOLS / "wasm_webserver.py"

CLEAN_SRCDIR = f"""
Builds require a clean source directory. Please use a clean checkout or
run "make clean -C '{SRCDIR}'".
"""

INSTALL_NATIVE = """
Builds require a C compiler (gcc, clang), make, pkg-config, and development
headers for dependencies like zlib.

Debian/Ubuntu: sudo apt install build-essential git curl pkg-config zlib1g-dev
Fedora/CentOS: sudo dnf install gcc make git-core curl pkgconfig zlib-devel
"""

INSTALL_EMSDK = """
wasm32-emscripten builds need Emscripten SDK. Please follow instructions at
https://emscripten.org/docs/getting_started/downloads.html how to install
Emscripten and how to activate the SDK with "emsdk_env.sh".

    git clone https://github.com/emscripten-core/emsdk.git /path/to/emsdk
    cd /path/to/emsdk
    ./emsdk install latest
    ./emsdk activate latest
    source /path/to/emsdk_env.sh
"""

INSTALL_WASI_SDK = """
wasm32-wasi builds need WASI SDK. Please fetch the latest SDK from
https://github.com/WebAssembly/wasi-sdk/releases and install it to
"/opt/wasi-sdk". Alternatively you can install the SDK in a different location
and point the environment variable WASI_SDK_PATH to the root directory
of the SDK. The SDK is available for Linux x86_64, macOS x86_64, and MinGW.
"""

INSTALL_WASMTIME = """
wasm32-wasi tests require wasmtime on PATH. Please follow instructions at
https://wasmtime.dev/ to install wasmtime.
"""


def parse_emconfig(
    emconfig: pathlib.Path = EM_CONFIG,
) -> Tuple[pathlib.Path, pathlib.Path]:
    """Parse EM_CONFIG file and lookup EMSCRIPTEN_ROOT and NODE_JS.

    The ".emscripten" config file is a Python snippet that uses "EM_CONFIG"
    environment variable. EMSCRIPTEN_ROOT is the "upstream/emscripten"
    subdirectory with tools like "emconfigure".
    """
    if not emconfig.exists():
        return _MISSING, _MISSING
    with open(emconfig, encoding="utf-8") as f:
        code = f.read()
    # EM_CONFIG file is a Python snippet
    local: Dict[str, Any] = {}
    exec(code, globals(), local)
    emscripten_root = pathlib.Path(local["EMSCRIPTEN_ROOT"])
    node_js = pathlib.Path(local["NODE_JS"])
    return emscripten_root, node_js


EMSCRIPTEN_ROOT, NODE_JS = parse_emconfig()


def read_python_version(configure: pathlib.Path = CONFIGURE) -> str:
    """Read PACKAGE_VERSION from configure script

    configure and configure.ac are the canonical source for major and
    minor version number.
    """
    version_re = re.compile(r"^PACKAGE_VERSION='(\d\.\d+)'")
    with configure.open(encoding="utf-8") as f:
        for line in f:
            mo = version_re.match(line)
            if mo:
                return mo.group(1)
    raise ValueError(f"PACKAGE_VERSION not found in {configure}")


PYTHON_VERSION = read_python_version()


class ConditionError(ValueError):
    def __init__(self, info: str, text: str) -> None:
        self.info = info
        self.text = text

    def __str__(self) -> str:
        return f"{type(self).__name__}: '{self.info}'\n{self.text}"


class MissingDependency(ConditionError):
    pass


class DirtySourceDirectory(ConditionError):
    pass


@dataclasses.dataclass
class Platform:
    """Platform-specific settings

    - CONFIG_SITE override
    - configure wrapper (e.g. emconfigure)
    - make wrapper (e.g. emmake)
    - additional environment variables
    - check function to verify SDK
    """

    name: str
    pythonexe: str
    config_site: Optional[pathlib.PurePath]
    configure_wrapper: Optional[pathlib.Path]
    make_wrapper: Optional[pathlib.PurePath]
    environ: Dict[str, Any]
    check: Callable[[], None]
    # Used for build_emports().
    ports: Optional[pathlib.PurePath]
    cc: Optional[pathlib.PurePath]

    def getenv(self, profile: "BuildProfile") -> Dict[str, Any]:
        return self.environ.copy()


def _check_clean_src() -> None:
    candidates = [
        SRCDIR / "Programs" / "python.o",
        SRCDIR / "Python" / "frozen_modules" / "importlib._bootstrap.h",
    ]
    for candidate in candidates:
        if candidate.exists():
            raise DirtySourceDirectory(os.fspath(candidate), CLEAN_SRCDIR)


def _check_native() -> None:
    if not any(shutil.which(cc) for cc in ["cc", "gcc", "clang"]):
        raise MissingDependency("cc", INSTALL_NATIVE)
    if not shutil.which("make"):
        raise MissingDependency("make", INSTALL_NATIVE)
    if sys.platform == "linux":
        # skip pkg-config check on macOS
        if not shutil.which("pkg-config"):
            raise MissingDependency("pkg-config", INSTALL_NATIVE)
        # zlib is needed to create zip files
        for devel in ["zlib"]:
            try:
                subprocess.check_call(["pkg-config", "--exists", devel])
            except subprocess.CalledProcessError:
                raise MissingDependency(devel, INSTALL_NATIVE) from None
    _check_clean_src()


NATIVE = Platform(
    "native",
    # macOS has python.exe
    pythonexe=sysconfig.get_config_var("BUILDPYTHON") or "python",
    config_site=None,
    configure_wrapper=None,
    ports=None,
    cc=None,
    make_wrapper=None,
    environ={},
    check=_check_native,
)


def _check_emscripten() -> None:
    if EMSCRIPTEN_ROOT is _MISSING:
        raise MissingDependency("Emscripten SDK EM_CONFIG", INSTALL_EMSDK)
    # sanity check
    emconfigure = EMSCRIPTEN.configure_wrapper
    if emconfigure is not None and not emconfigure.exists():
        raise MissingDependency(os.fspath(emconfigure), INSTALL_EMSDK)
    # version check
    version_txt = EMSCRIPTEN_ROOT / "emscripten-version.txt"
    if not version_txt.exists():
        raise MissingDependency(os.fspath(version_txt), INSTALL_EMSDK)
    with open(version_txt) as f:
        version = f.read().strip().strip('"')
    if version.endswith("-git"):
        # git / upstream / tot-upstream installation
        version = version[:-4]
    version_tuple = cast(
        Tuple[int, int, int],
        tuple(int(v) for v in version.split("."))
    )
    if version_tuple < EMSDK_MIN_VERSION:
        raise ConditionError(
            os.fspath(version_txt),
            f"Emscripten SDK {version} in '{EMSCRIPTEN_ROOT}' is older than "
            "minimum required version "
            f"{'.'.join(str(v) for v in EMSDK_MIN_VERSION)}.",
        )
    broken = EMSDK_BROKEN_VERSION.get(version_tuple)
    if broken is not None:
        raise ConditionError(
            os.fspath(version_txt),
            (
                f"Emscripten SDK {version} in '{EMSCRIPTEN_ROOT}' has known "
                f"bugs, see {broken}."
            ),
        )
    if os.environ.get("PKG_CONFIG_PATH"):
        warnings.warn(
            "PKG_CONFIG_PATH is set and not empty. emconfigure overrides "
            "this environment variable. Use EM_PKG_CONFIG_PATH instead."
        )
    _check_clean_src()


EMSCRIPTEN = Platform(
    "emscripten",
    pythonexe="python.js",
    config_site=WASMTOOLS / "config.site-wasm32-emscripten",
    configure_wrapper=EMSCRIPTEN_ROOT / "emconfigure",
    ports=EMSCRIPTEN_ROOT / "embuilder",
    cc=EMSCRIPTEN_ROOT / "emcc",
    make_wrapper=EMSCRIPTEN_ROOT / "emmake",
    environ={
        # workaround for https://github.com/emscripten-core/emscripten/issues/17635
        "TZ": "UTC",
        "EM_COMPILER_WRAPPER": "ccache" if HAS_CCACHE else None,
        "PATH": [EMSCRIPTEN_ROOT, os.environ["PATH"]],
    },
    check=_check_emscripten,
)


def _check_wasi() -> None:
    wasm_ld = WASI_SDK_PATH / "bin" / "wasm-ld"
    if not wasm_ld.exists():
        raise MissingDependency(os.fspath(wasm_ld), INSTALL_WASI_SDK)
    wasmtime = shutil.which("wasmtime")
    if wasmtime is None:
        raise MissingDependency("wasmtime", INSTALL_WASMTIME)
    _check_clean_src()


WASI = Platform(
    "wasi",
    pythonexe="python.wasm",
    config_site=WASMTOOLS / "config.site-wasm32-wasi",
    configure_wrapper=WASMTOOLS / "wasi-env",
    ports=None,
    cc=WASI_SDK_PATH / "bin" / "clang",
    make_wrapper=None,
    environ={
        "WASI_SDK_PATH": WASI_SDK_PATH,
        # workaround for https://github.com/python/cpython/issues/95952
        "HOSTRUNNER": (
            "wasmtime run "
            "--wasm max-wasm-stack=16777216 "
            "--wasi preview2 "
            "--dir {srcdir}::/ "
            "--env PYTHONPATH=/{relbuilddir}/build/lib.wasi-wasm32-{version}:/Lib"
        ),
        "PATH": [WASI_SDK_PATH / "bin", os.environ["PATH"]],
    },
    check=_check_wasi,
)


class Host(enum.Enum):
    """Target host triplet"""

    wasm32_emscripten = "wasm32-unknown-emscripten"
    wasm64_emscripten = "wasm64-unknown-emscripten"
    wasm32_wasi = "wasm32-unknown-wasi"
    wasm64_wasi = "wasm64-unknown-wasi"
    # current platform
    build = sysconfig.get_config_var("BUILD_GNU_TYPE")

    @property
    def platform(self) -> Platform:
        if self.is_emscripten:
            return EMSCRIPTEN
        elif self.is_wasi:
            return WASI
        else:
            return NATIVE

    @property
    def is_emscripten(self) -> bool:
        cls = type(self)
        return self in {cls.wasm32_emscripten, cls.wasm64_emscripten}

    @property
    def is_wasi(self) -> bool:
        cls = type(self)
        return self in {cls.wasm32_wasi, cls.wasm64_wasi}

    def get_extra_paths(self) -> Iterable[pathlib.PurePath]:
        """Host-specific os.environ["PATH"] entries.

        Emscripten's Node version 14.x works well for wasm32-emscripten.
        wasm64-emscripten requires more recent v8 version, e.g. node 16.x.
        Attempt to use system's node command.
        """
        cls = type(self)
        if self == cls.wasm32_emscripten:
            return [NODE_JS.parent]
        elif self == cls.wasm64_emscripten:
            # TODO: look for recent node
            return []
        else:
            return []

    @property
    def emport_args(self) -> List[str]:
        """Host-specific port args (Emscripten)."""
        cls = type(self)
        if self is cls.wasm64_emscripten:
            return ["-sMEMORY64=1"]
        elif self is cls.wasm32_emscripten:
            return ["-sMEMORY64=0"]
        else:
            return []

    @property
    def embuilder_args(self) -> List[str]:
        """Host-specific embuilder args (Emscripten)."""
        cls = type(self)
        if self is cls.wasm64_emscripten:
            return ["--wasm64"]
        else:
            return []


class EmscriptenTarget(enum.Enum):
    """Emscripten-specific targets (--with-emscripten-target)"""

    browser = "browser"
    browser_debug = "browser-debug"
    node = "node"
    node_debug = "node-debug"

    @property
    def is_browser(self) -> bool:
        cls = type(self)
        return self in {cls.browser, cls.browser_debug}

    @property
    def emport_args(self) -> List[str]:
        """Target-specific port args."""
        cls = type(self)
        if self in {cls.browser_debug, cls.node_debug}:
            # some libs come in debug and non-debug builds
            return ["-O0"]
        else:
            return ["-O2"]


class SupportLevel(enum.Enum):
    supported = "tier 3, supported"
    working = "working, unsupported"
    experimental = "experimental, may be broken"
    broken = "broken / unavailable"

    def __bool__(self) -> bool:
        cls = type(self)
        return self in {cls.supported, cls.working}


@dataclasses.dataclass
class BuildProfile:
    name: str
    support_level: SupportLevel
    host: Host
    target: Union[EmscriptenTarget, None] = None
    dynamic_linking: Union[bool, None] = None
    pthreads: Union[bool, None] = None
    default_testopts: str = "-j2"

    @property
    def is_browser(self) -> bool:
        """Is this a browser build?"""
        return self.target is not None and self.target.is_browser

    @property
    def builddir(self) -> pathlib.Path:
        """Path to build directory"""
        return BUILDDIR / self.name

    @property
    def python_cmd(self) -> pathlib.Path:
        """Path to python executable"""
        return self.builddir / self.host.platform.pythonexe

    @property
    def makefile(self) -> pathlib.Path:
        """Path to Makefile"""
        return self.builddir / "Makefile"

    @property
    def configure_cmd(self) -> List[str]:
        """Generate configure command"""
        # use relative path, so WASI tests can find lib prefix.
        # pathlib.Path.relative_to() does not work here.
        configure = os.path.relpath(CONFIGURE, self.builddir)
        cmd = [configure, "-C"]
        platform = self.host.platform
        if platform.configure_wrapper:
            cmd.insert(0, os.fspath(platform.configure_wrapper))

        cmd.append(f"--host={self.host.value}")
        cmd.append(f"--build={Host.build.value}")

        if self.target is not None:
            assert self.host.is_emscripten
            cmd.append(f"--with-emscripten-target={self.target.value}")

        if self.dynamic_linking is not None:
            assert self.host.is_emscripten
            opt = "enable" if self.dynamic_linking else "disable"
            cmd.append(f"--{opt}-wasm-dynamic-linking")

        if self.pthreads is not None:
            opt = "enable" if self.pthreads else "disable"
            cmd.append(f"--{opt}-wasm-pthreads")

        if self.host != Host.build:
            cmd.append(f"--with-build-python={BUILD.python_cmd}")

        if platform.config_site is not None:
            cmd.append(f"CONFIG_SITE={platform.config_site}")

        return cmd

    @property
    def make_cmd(self) -> List[str]:
        """Generate make command"""
        cmd = ["make"]
        platform = self.host.platform
        if platform.make_wrapper:
            cmd.insert(0, os.fspath(platform.make_wrapper))
        return cmd

    def getenv(self) -> Dict[str, Any]:
        """Generate environ dict for platform"""
        env = os.environ.copy()
        if hasattr(os, 'process_cpu_count'):
            cpu_count = os.process_cpu_count()
        else:
            cpu_count = os.cpu_count()
        env.setdefault("MAKEFLAGS", f"-j{cpu_count}")
        platenv = self.host.platform.getenv(self)
        for key, value in platenv.items():
            if value is None:
                env.pop(key, None)
            elif key == "PATH":
                # list of path items, prefix with extra paths
                new_path: List[pathlib.PurePath] = []
                new_path.extend(self.host.get_extra_paths())
                new_path.extend(value)
                env[key] = os.pathsep.join(os.fspath(p) for p in new_path)
            elif isinstance(value, str):
                env[key] = value.format(
                    relbuilddir=self.builddir.relative_to(SRCDIR),
                    srcdir=SRCDIR,
                    version=PYTHON_VERSION,
                )
            else:
                env[key] = value
        return env

    def _run_cmd(
        self,
        cmd: Iterable[str],
        args: Iterable[str] = (),
        cwd: Optional[pathlib.Path] = None,
    ) -> int:
        cmd = list(cmd)
        cmd.extend(args)
        if cwd is None:
            cwd = self.builddir
        logger.info('Running "%s" in "%s"', shlex.join(cmd), cwd)
        return subprocess.check_call(
            cmd,
            cwd=os.fspath(cwd),
            env=self.getenv(),
        )

    def _check_execute(self) -> None:
        if self.is_browser:
            raise ValueError(f"Cannot execute on {self.target}")

    def run_build(self, *args: str) -> None:
        """Run configure (if necessary) and make"""
        if not self.makefile.exists():
            logger.info("Makefile not found, running configure")
            self.run_configure(*args)
        self.run_make("all", *args)

    def run_configure(self, *args: str) -> int:
        """Run configure script to generate Makefile"""
        os.makedirs(self.builddir, exist_ok=True)
        return self._run_cmd(self.configure_cmd, args)

    def run_make(self, *args: str) -> int:
        """Run make (defaults to build all)"""
        return self._run_cmd(self.make_cmd, args)

    def run_pythoninfo(self, *args: str) -> int:
        """Run 'make pythoninfo'"""
        self._check_execute()
        return self.run_make("pythoninfo", *args)

    def run_test(self, target: str, testopts: Optional[str] = None) -> int:
        """Run buildbottests"""
        self._check_execute()
        if testopts is None:
            testopts = self.default_testopts
        return self.run_make(target, f"TESTOPTS={testopts}")

    def run_py(self, *args: str) -> int:
        """Run Python with hostrunner"""
        self._check_execute()
        return self.run_make(
            "--eval", f"run: all; $(HOSTRUNNER) ./$(PYTHON) {shlex.join(args)}", "run"
        )

    def run_browser(self, bind: str = "127.0.0.1", port: int = 8000) -> None:
        """Run WASM webserver and open build in browser"""
        relbuilddir = self.builddir.relative_to(SRCDIR)
        url = f"http://{bind}:{port}/{relbuilddir}/python.html"
        args = [
            sys.executable,
            os.fspath(WASM_WEBSERVER),
            "--bind",
            bind,
            "--port",
            str(port),
        ]
        srv = subprocess.Popen(args, cwd=SRCDIR)
        # wait for server
        end = time.monotonic() + 3.0
        while time.monotonic() < end and srv.returncode is None:
            try:
                with socket.create_connection((bind, port), timeout=0.1) as _:
                    pass
            except OSError:
                time.sleep(0.01)
            else:
                break

        webbrowser.open(url)

        try:
            srv.wait()
        except KeyboardInterrupt:
            pass

    def clean(self, all: bool = False) -> None:
        """Clean build directory"""
        if all:
            if self.builddir.exists():
                shutil.rmtree(self.builddir)
        elif self.makefile.exists():
            self.run_make("clean")

    def build_emports(self, force: bool = False) -> None:
        """Pre-build emscripten ports."""
        platform = self.host.platform
        if platform.ports is None or platform.cc is None:
            raise ValueError("Need ports and CC command")

        embuilder_cmd = [os.fspath(platform.ports)]
        embuilder_cmd.extend(self.host.embuilder_args)
        if force:
            embuilder_cmd.append("--force")

        ports_cmd = [os.fspath(platform.cc)]
        ports_cmd.extend(self.host.emport_args)
        if self.target:
            ports_cmd.extend(self.target.emport_args)

        if self.dynamic_linking:
            # Trigger PIC build.
            ports_cmd.append("-sMAIN_MODULE")
            embuilder_cmd.append("--pic")

        if self.pthreads:
            # Trigger multi-threaded build.
            ports_cmd.append("-sUSE_PTHREADS")

        # Pre-build libbz2, libsqlite3, libz, and some system libs.
        ports_cmd.extend(["-sUSE_ZLIB", "-sUSE_BZIP2", "-sUSE_SQLITE3"])
        # Multi-threaded sqlite3 has different suffix
        embuilder_cmd.extend(
            ["build", "bzip2", "sqlite3-mt" if self.pthreads else "sqlite3", "zlib"]
        )

        self._run_cmd(embuilder_cmd, cwd=SRCDIR)

        with tempfile.TemporaryDirectory(suffix="-py-emport") as tmpdir:
            tmppath = pathlib.Path(tmpdir)
            main_c = tmppath / "main.c"
            main_js = tmppath / "main.js"
            with main_c.open("w") as f:
                f.write("int main(void) { return 0; }\n")
            args = [
                os.fspath(main_c),
                "-o",
                os.fspath(main_js),
            ]
            self._run_cmd(ports_cmd, args, cwd=tmppath)


# native build (build Python)
BUILD = BuildProfile(
    "build",
    support_level=SupportLevel.working,
    host=Host.build,
)

_profiles = [
    BUILD,
    # wasm32-emscripten
    BuildProfile(
        "emscripten-browser",
        support_level=SupportLevel.supported,
        host=Host.wasm32_emscripten,
        target=EmscriptenTarget.browser,
        dynamic_linking=True,
    ),
    BuildProfile(
        "emscripten-browser-debug",
        support_level=SupportLevel.working,
        host=Host.wasm32_emscripten,
        target=EmscriptenTarget.browser_debug,
        dynamic_linking=True,
    ),
    BuildProfile(
        "emscripten-node-dl",
        support_level=SupportLevel.supported,
        host=Host.wasm32_emscripten,
        target=EmscriptenTarget.node,
        dynamic_linking=True,
    ),
    BuildProfile(
        "emscripten-node-dl-debug",
        support_level=SupportLevel.working,
        host=Host.wasm32_emscripten,
        target=EmscriptenTarget.node_debug,
        dynamic_linking=True,
    ),
    BuildProfile(
        "emscripten-node-pthreads",
        support_level=SupportLevel.supported,
        host=Host.wasm32_emscripten,
        target=EmscriptenTarget.node,
        pthreads=True,
    ),
    BuildProfile(
        "emscripten-node-pthreads-debug",
        support_level=SupportLevel.working,
        host=Host.wasm32_emscripten,
        target=EmscriptenTarget.node_debug,
        pthreads=True,
    ),
    # Emscripten build with both pthreads and dynamic linking is crashing.
    BuildProfile(
        "emscripten-node-dl-pthreads-debug",
        support_level=SupportLevel.broken,
        host=Host.wasm32_emscripten,
        target=EmscriptenTarget.node_debug,
        dynamic_linking=True,
        pthreads=True,
    ),
    # wasm64-emscripten (requires Emscripten >= 3.1.21)
    BuildProfile(
        "wasm64-emscripten-node-debug",
        support_level=SupportLevel.experimental,
        host=Host.wasm64_emscripten,
        target=EmscriptenTarget.node_debug,
        # MEMORY64 is not compatible with dynamic linking
        dynamic_linking=False,
        pthreads=False,
    ),
    # wasm32-wasi
    BuildProfile(
        "wasi",
        support_level=SupportLevel.supported,
        host=Host.wasm32_wasi,
    ),
    # wasm32-wasi-threads
    BuildProfile(
        "wasi-threads",
        support_level=SupportLevel.experimental,
        host=Host.wasm32_wasi,
        pthreads=True,
    ),
    # no SDK available yet
    # BuildProfile(
    #    "wasm64-wasi",
    #    support_level=SupportLevel.broken,
    #    host=Host.wasm64_wasi,
    # ),
]

PROFILES = {p.name: p for p in _profiles}

parser = argparse.ArgumentParser(
    "wasm_build.py",
    description=__doc__,
    formatter_class=argparse.RawTextHelpFormatter,
)

parser.add_argument(
    "--clean",
    "-c",
    help="Clean build directories first",
    action="store_true",
)

parser.add_argument(
    "--verbose",
    "-v",
    help="Verbose logging",
    action="store_true",
)

parser.add_argument(
    "--silent",
    help="Run configure and make in silent mode",
    action="store_true",
)

parser.add_argument(
    "--testopts",
    help=(
        "Additional test options for 'test' and 'hostrunnertest', e.g. "
        "--testopts='-v test_os'."
    ),
    default=None,
)

# Don't list broken and experimental variants in help
platforms_choices = list(p.name for p in _profiles) + ["cleanall"]
platforms_help = list(p.name for p in _profiles if p.support_level) + ["cleanall"]
parser.add_argument(
    "platform",
    metavar="PLATFORM",
    help=f"Build platform: {', '.join(platforms_help)}",
    choices=platforms_choices,
)

ops = dict(
    build="auto build (build 'build' Python, emports, configure, compile)",
    configure="run ./configure",
    compile="run 'make all'",
    pythoninfo="run 'make pythoninfo'",
    test="run 'make buildbottest TESTOPTS=...' (supports parallel tests)",
    hostrunnertest="run 'make hostrunnertest TESTOPTS=...'",
    repl="start interactive REPL / webserver + browser session",
    clean="run 'make clean'",
    cleanall="remove all build directories",
    emports="build Emscripten port with embuilder (only Emscripten)",
)
ops_help = "\n".join(f"{op:16s} {help}" for op, help in ops.items())
parser.add_argument(
    "ops",
    metavar="OP",
    help=f"operation (default: build)\n\n{ops_help}",
    choices=tuple(ops),
    default="build",
    nargs="*",
)


def main() -> None:
    args = parser.parse_args()
    logging.basicConfig(
        level=logging.INFO if args.verbose else logging.ERROR,
        format="%(message)s",
    )

    if args.platform == "cleanall":
        for builder in PROFILES.values():
            builder.clean(all=True)
        parser.exit(0)

    # additional configure and make args
    cm_args = ("--silent",) if args.silent else ()

    # nargs=* with default quirk
    if args.ops == "build":
        args.ops = ["build"]

    builder = PROFILES[args.platform]
    try:
        builder.host.platform.check()
    except ConditionError as e:
        parser.error(str(e))

    if args.clean:
        builder.clean(all=False)

    # hack for WASI
    if builder.host.is_wasi and not SETUP_LOCAL.exists():
        SETUP_LOCAL.touch()

    # auto-build
    if "build" in args.ops:
        # check and create build Python
        if builder is not BUILD:
            logger.info("Auto-building 'build' Python.")
            try:
                BUILD.host.platform.check()
            except ConditionError as e:
                parser.error(str(e))
            if args.clean:
                BUILD.clean(all=False)
            BUILD.run_build(*cm_args)
        # build Emscripten ports with embuilder
        if builder.host.is_emscripten and "emports" not in args.ops:
            builder.build_emports()

    for op in args.ops:
        logger.info("\n*** %s %s", args.platform, op)
        if op == "build":
            builder.run_build(*cm_args)
        elif op == "configure":
            builder.run_configure(*cm_args)
        elif op == "compile":
            builder.run_make("all", *cm_args)
        elif op == "pythoninfo":
            builder.run_pythoninfo(*cm_args)
        elif op == "repl":
            if builder.is_browser:
                builder.run_browser()
            else:
                builder.run_py()
        elif op == "test":
            builder.run_test("buildbottest", testopts=args.testopts)
        elif op == "hostrunnertest":
            builder.run_test("hostrunnertest", testopts=args.testopts)
        elif op == "clean":
            builder.clean(all=False)
        elif op == "cleanall":
            builder.clean(all=True)
        elif op == "emports":
            builder.build_emports(force=args.clean)
        else:
            raise ValueError(op)

    print(builder.builddir)
    parser.exit(0)


if __name__ == "__main__":
    main()


================================================
File: /Tools/wasm/.editorconfig
================================================
# This extends the root .editorconfig
root = false

[*.{html,js}]
trim_trailing_whitespace = true
insert_final_newline = true
indent_style = space
indent_size = 4


================================================
File: /Tools/wasm/emscripten/__main__.py
================================================
#!/usr/bin/env python3

import argparse
import contextlib
import functools
import os
import shutil
import subprocess
import sys
import sysconfig
import tempfile
from urllib.request import urlopen
from pathlib import Path
from textwrap import dedent

try:
    from os import process_cpu_count as cpu_count
except ImportError:
    from os import cpu_count


EMSCRIPTEN_DIR = Path(__file__).parent
CHECKOUT = EMSCRIPTEN_DIR.parent.parent.parent

CROSS_BUILD_DIR = CHECKOUT / "cross-build"
NATIVE_BUILD_DIR = CROSS_BUILD_DIR / "build"
HOST_TRIPLE = "wasm32-emscripten"

DOWNLOAD_DIR = CROSS_BUILD_DIR / HOST_TRIPLE / "build"
HOST_BUILD_DIR = CROSS_BUILD_DIR / HOST_TRIPLE / "build"
HOST_DIR = HOST_BUILD_DIR / "python"
PREFIX_DIR = CROSS_BUILD_DIR / HOST_TRIPLE / "prefix"

LOCAL_SETUP = CHECKOUT / "Modules" / "Setup.local"
LOCAL_SETUP_MARKER = "# Generated by Tools/wasm/emscripten.py\n".encode("utf-8")


def updated_env(updates={}):
    """Create a new dict representing the environment to use.

    The changes made to the execution environment are printed out.
    """
    env_defaults = {}
    # https://reproducible-builds.org/docs/source-date-epoch/
    git_epoch_cmd = ["git", "log", "-1", "--pretty=%ct"]
    try:
        epoch = subprocess.check_output(git_epoch_cmd, encoding="utf-8").strip()
        env_defaults["SOURCE_DATE_EPOCH"] = epoch
    except subprocess.CalledProcessError:
        pass  # Might be building from a tarball.
    # This layering lets SOURCE_DATE_EPOCH from os.environ takes precedence.
    environment = env_defaults | os.environ | updates

    env_diff = {}
    for key, value in environment.items():
        if os.environ.get(key) != value:
            env_diff[key] = value

    print("üåé Environment changes:")
    for key in sorted(env_diff.keys()):
        print(f"  {key}={env_diff[key]}")

    return environment


def subdir(working_dir, *, clean_ok=False):
    """Decorator to change to a working directory."""

    def decorator(func):
        @functools.wraps(func)
        def wrapper(context):
            try:
                tput_output = subprocess.check_output(
                    ["tput", "cols"], encoding="utf-8"
                )
                terminal_width = int(tput_output.strip())
            except subprocess.CalledProcessError:
                terminal_width = 80
            print("‚éØ" * terminal_width)
            print("üìÅ", working_dir)
            if clean_ok and getattr(context, "clean", False) and working_dir.exists():
                print("üöÆ Deleting directory (--clean)...")
                shutil.rmtree(working_dir)

            working_dir.mkdir(parents=True, exist_ok=True)

            with contextlib.chdir(working_dir):
                return func(context, working_dir)

        return wrapper

    return decorator


def call(command, *, quiet, **kwargs):
    """Execute a command.

    If 'quiet' is true, then redirect stdout and stderr to a temporary file.
    """
    print("‚ùØ", " ".join(map(str, command)))
    if not quiet:
        stdout = None
        stderr = None
    else:
        stdout = tempfile.NamedTemporaryFile(
            "w",
            encoding="utf-8",
            delete=False,
            prefix="cpython-emscripten-",
            suffix=".log",
        )
        stderr = subprocess.STDOUT
        print(f"üìù Logging output to {stdout.name} (--quiet)...")

    subprocess.check_call(command, **kwargs, stdout=stdout, stderr=stderr)


def build_platform():
    """The name of the build/host platform."""
    # Can also be found via `config.guess`.`
    return sysconfig.get_config_var("BUILD_GNU_TYPE")


def build_python_path():
    """The path to the build Python binary."""
    binary = NATIVE_BUILD_DIR / "python"
    if not binary.is_file():
        binary = binary.with_suffix(".exe")
        if not binary.is_file():
            raise FileNotFoundError("Unable to find `python(.exe)` in " f"{NATIVE_BUILD_DIR}")

    return binary


@subdir(NATIVE_BUILD_DIR, clean_ok=True)
def configure_build_python(context, working_dir):
    """Configure the build/host Python."""
    if LOCAL_SETUP.exists():
        print(f"üëç {LOCAL_SETUP} exists ...")
    else:
        print(f"üìù Touching {LOCAL_SETUP} ...")
        LOCAL_SETUP.write_bytes(LOCAL_SETUP_MARKER)

    configure = [os.path.relpath(CHECKOUT / "configure", working_dir)]
    if context.args:
        configure.extend(context.args)

    call(configure, quiet=context.quiet)


@subdir(NATIVE_BUILD_DIR)
def make_build_python(context, working_dir):
    """Make/build the build Python."""
    call(["make", "--jobs", str(cpu_count()), "all"], quiet=context.quiet)

    binary = build_python_path()
    cmd = [
        binary,
        "-c",
        "import sys; " "print(f'{sys.version_info.major}.{sys.version_info.minor}')",
    ]
    version = subprocess.check_output(cmd, encoding="utf-8").strip()

    print(f"üéâ {binary} {version}")


@subdir(HOST_BUILD_DIR, clean_ok=True)
def make_emscripten_libffi(context, working_dir):
    shutil.rmtree(working_dir / "libffi-3.4.6", ignore_errors=True)
    with tempfile.NamedTemporaryFile(suffix=".tar.gz") as tmp_file:
        with urlopen(
            "https://github.com/libffi/libffi/releases/download/v3.4.6/libffi-3.4.6.tar.gz"
        ) as response:
            shutil.copyfileobj(response, tmp_file)
        shutil.unpack_archive(tmp_file.name, working_dir)
    call(
        [EMSCRIPTEN_DIR / "make_libffi.sh"],
        env=updated_env({"PREFIX": PREFIX_DIR}),
        cwd=working_dir / "libffi-3.4.6",
        quiet=context.quiet,
    )


@subdir(HOST_DIR, clean_ok=True)
def configure_emscripten_python(context, working_dir):
    """Configure the emscripten/host build."""
    config_site = os.fsdecode(
        CHECKOUT / "Tools" / "wasm" / "config.site-wasm32-emscripten"
    )

    emscripten_build_dir = working_dir.relative_to(CHECKOUT)

    python_build_dir = NATIVE_BUILD_DIR / "build"
    lib_dirs = list(python_build_dir.glob("lib.*"))
    assert (
        len(lib_dirs) == 1
    ), f"Expected a single lib.* directory in {python_build_dir}"
    lib_dir = os.fsdecode(lib_dirs[0])
    pydebug = lib_dir.endswith("-pydebug")
    python_version = lib_dir.removesuffix("-pydebug").rpartition("-")[-1]
    sysconfig_data = (
        f"{emscripten_build_dir}/build/lib.emscripten-wasm32-{python_version}"
    )
    if pydebug:
        sysconfig_data += "-pydebug"

    host_runner = context.host_runner
    pkg_config_path_dir = (PREFIX_DIR / "lib/pkgconfig/").resolve()
    env_additions = {
        "CONFIG_SITE": config_site,
        "HOSTRUNNER": host_runner,
        "EM_PKG_CONFIG_PATH": str(pkg_config_path_dir),
    }
    build_python = os.fsdecode(build_python_path())
    configure = [
        "emconfigure",
        os.path.relpath(CHECKOUT / "configure", working_dir),
        "CFLAGS=-DPY_CALL_TRAMPOLINE -sUSE_BZIP2",
        "PKG_CONFIG=pkg-config",
        f"--host={HOST_TRIPLE}",
        f"--build={build_platform()}",
        f"--with-build-python={build_python}",
        "--without-pymalloc",
        "--disable-shared",
        "--disable-ipv6",
        "--enable-big-digits=30",
        "--enable-wasm-dynamic-linking",
        f"--prefix={PREFIX_DIR}",
    ]
    if pydebug:
        configure.append("--with-pydebug")
    if context.args:
        configure.extend(context.args)
    call(
        configure,
        env=updated_env(env_additions),
        quiet=context.quiet,
    )

    shutil.copy(EMSCRIPTEN_DIR / "node_entry.mjs", working_dir / "node_entry.mjs")

    node_entry = working_dir / "node_entry.mjs"
    exec_script = working_dir / "python.sh"
    exec_script.write_text(
        dedent(
            f"""\
            #!/bin/sh

            # Macs come with FreeBSD coreutils which doesn't have the -s option
            # so feature detect and work around it.
            if which grealpath > /dev/null; then
                # It has brew installed gnu core utils, use that
                REALPATH="grealpath -s"
            elif which realpath > /dev/null && realpath --version > /dev/null 2> /dev/null && realpath --version | grep GNU > /dev/null; then
                # realpath points to GNU realpath so use it.
                REALPATH="realpath -s"
            else
                # Shim for macs without GNU coreutils
                abs_path () {{
                    echo "$(cd "$(dirname "$1")" || exit; pwd)/$(basename "$1")"
                }}
                REALPATH=abs_path
            fi

            # We compute our own path, not following symlinks and pass it in so that
            # node_entry.mjs can set sys.executable correctly.
            # Intentionally allow word splitting on NODEFLAGS.
            exec {host_runner} $NODEFLAGS {node_entry} --this-program="$($REALPATH "$0")" "$@"
            """
        )
    )
    exec_script.chmod(0o755)
    print(f"üèÉ‚Äç‚ôÄÔ∏è Created {exec_script} ... ")
    sys.stdout.flush()


@subdir(HOST_DIR)
def make_emscripten_python(context, working_dir):
    """Run `make` for the emscripten/host build."""
    call(
        ["make", "--jobs", str(cpu_count()), "all"],
        env=updated_env(),
        quiet=context.quiet,
    )

    exec_script = working_dir / "python.sh"
    subprocess.check_call([exec_script, "--version"])


def build_all(context):
    """Build everything."""
    steps = [
        configure_build_python,
        make_build_python,
        make_emscripten_libffi,
        configure_emscripten_python,
        make_emscripten_python,
    ]
    for step in steps:
        step(context)


def clean_contents(context):
    """Delete all files created by this script."""
    if CROSS_BUILD_DIR.exists():
        print(f"üßπ Deleting {CROSS_BUILD_DIR} ...")
        shutil.rmtree(CROSS_BUILD_DIR)

    if LOCAL_SETUP.exists():
        with LOCAL_SETUP.open("rb") as file:
            if file.read(len(LOCAL_SETUP_MARKER)) == LOCAL_SETUP_MARKER:
                print(f"üßπ Deleting generated {LOCAL_SETUP} ...")


def main():
    default_host_runner = "node"

    parser = argparse.ArgumentParser()
    subcommands = parser.add_subparsers(dest="subcommand")
    build = subcommands.add_parser("build", help="Build everything")
    configure_build = subcommands.add_parser(
        "configure-build-python", help="Run `configure` for the " "build Python"
    )
    make_libffi_cmd = subcommands.add_parser(
        "make-libffi", help="Clone libffi repo, configure and build it for emscripten"
    )
    make_build = subcommands.add_parser(
        "make-build-python", help="Run `make` for the build Python"
    )
    configure_host = subcommands.add_parser(
        "configure-host",
        help="Run `configure` for the host/emscripten (pydebug builds are inferred from the build Python)",
    )
    make_host = subcommands.add_parser(
        "make-host", help="Run `make` for the host/emscripten"
    )
    clean = subcommands.add_parser(
        "clean", help="Delete files and directories created by this script"
    )
    for subcommand in (
        build,
        configure_build,
        make_libffi_cmd,
        make_build,
        configure_host,
        make_host,
    ):
        subcommand.add_argument(
            "--quiet",
            action="store_true",
            default=False,
            dest="quiet",
            help="Redirect output from subprocesses to a log file",
        )
    for subcommand in configure_build, configure_host:
        subcommand.add_argument(
            "--clean",
            action="store_true",
            default=False,
            dest="clean",
            help="Delete any relevant directories before building",
        )
    for subcommand in build, configure_build, configure_host:
        subcommand.add_argument(
            "args", nargs="*", help="Extra arguments to pass to `configure`"
        )
    for subcommand in build, configure_host:
        subcommand.add_argument(
            "--host-runner",
            action="store",
            default=default_host_runner,
            dest="host_runner",
            help="Command template for running the emscripten host"
            f"`{default_host_runner}`)",
        )

    context = parser.parse_args()

    dispatch = {
        "make-libffi": make_emscripten_libffi,
        "configure-build-python": configure_build_python,
        "make-build-python": make_build_python,
        "configure-host": configure_emscripten_python,
        "make-host": make_emscripten_python,
        "build": build_all,
        "clean": clean_contents,
    }

    if not context.subcommand:
        # No command provided, display help and exit
        print("Expected one of", ", ".join(sorted(dispatch.keys())), file=sys.stderr)
        parser.print_help(sys.stderr)
        sys.exit(1)
    dispatch[context.subcommand](context)


if __name__ == "__main__":
    main()


================================================
File: /Tools/wasm/emscripten/make_libffi.sh
================================================
#!/bin/bash
set +e

export CFLAGS="-O2 -fPIC -DWASM_BIGINT"
export CXXFLAGS="$CFLAGS"

# Build paths
export CPATH="$PREFIX/include"
export PKG_CONFIG_PATH="$PREFIX/lib/pkgconfig"
export EM_PKG_CONFIG_PATH="$PKG_CONFIG_PATH"

# Specific variables for cross-compilation
export CHOST="wasm32-unknown-linux" # wasm32-unknown-emscripten

emconfigure ./configure --host=$CHOST --prefix="$PREFIX" --enable-static --disable-shared --disable-dependency-tracking \
  --disable-builddir --disable-multi-os-directory --disable-raw-api --disable-docs

make install
# Some forgotten headers?
cp fficonfig.h $PREFIX/include/
cp include/ffi_common.h $PREFIX/include/


================================================
File: /Tools/wasm/emscripten/node_entry.mjs
================================================
import EmscriptenModule from "./python.mjs";
import fs from "node:fs";

if (process?.versions?.node) {
  const nodeVersion = Number(process.versions.node.split(".", 1)[0]);
  if (nodeVersion < 18) {
    process.stderr.write(
      `Node version must be >= 18, got version ${process.version}\n`,
    );
    process.exit(1);
  }
}

function rootDirsToMount(Module) {
  return fs
    .readdirSync("/")
    .filter((dir) => !["dev", "lib", "proc"].includes(dir))
    .map((dir) => "/" + dir);
}

function mountDirectories(Module) {
  for (const dir of rootDirsToMount(Module)) {
    Module.FS.mkdirTree(dir);
    Module.FS.mount(Module.FS.filesystems.NODEFS, { root: dir }, dir);
  }
}

const thisProgram = "--this-program=";
const thisProgramIndex = process.argv.findIndex((x) =>
  x.startsWith(thisProgram),
);

const settings = {
  preRun(Module) {
    mountDirectories(Module);
    Module.FS.chdir(process.cwd());
    Object.assign(Module.ENV, process.env);
    delete Module.ENV.PATH;
  },
  // Ensure that sys.executable, sys._base_executable, etc point to python.sh
  // not to this file. To properly handle symlinks, python.sh needs to compute
  // its own path.
  thisProgram: process.argv[thisProgramIndex].slice(thisProgram.length),
  // After python.sh come the arguments thatthe user passed to python.sh.
  arguments: process.argv.slice(thisProgramIndex + 1),
};

await EmscriptenModule(settings);


================================================
File: /Tools/wasm/emscripten/web_example/python.html
================================================
<!doctype html>
<html lang="en">
    <head>
        <meta charset="UTF-8" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="viewport" content="width=device-width, initial-scale=1.0" />
        <meta name="author" content="Katie Bell" />
        <meta name="description" content="Simple REPL for Python WASM" />
        <title>wasm-python terminal</title>
        <link
            rel="stylesheet"
            href="https://unpkg.com/xterm@4.18.0/css/xterm.css"
            crossorigin
            integrity="sha384-4eEEn/eZgVHkElpKAzzPx/Kow/dTSgFk1BNe+uHdjHa+NkZJDh5Vqkq31+y7Eycd"
        />
        <style>
            body {
                font-family: arial;
                max-width: 800px;
                margin: 0 auto;
            }
            #code {
                width: 100%;
                height: 180px;
            }
            #info {
                padding-top: 20px;
            }
            .button-container {
                display: flex;
                justify-content: end;
                height: 50px;
                align-items: center;
                gap: 10px;
            }
            button {
                padding: 6px 18px;
            }
        </style>
        <script
            src="https://unpkg.com/xterm@4.18.0/lib/xterm.js"
            crossorigin
            integrity="sha384-yYdNmem1ioP5Onm7RpXutin5A8TimLheLNQ6tnMi01/ZpxXdAwIm2t4fJMx1Djs+"
        />
        <script type="module">
            class WorkerManager {
                constructor(
                    workerURL,
                    standardIO,
                    readyCallBack,
                    finishedCallback,
                ) {
                    this.workerURL = workerURL;
                    this.worker = null;
                    this.standardIO = standardIO;
                    this.readyCallBack = readyCallBack;
                    this.finishedCallback = finishedCallback;

                    this.initialiseWorker();
                }

                async initialiseWorker() {
                    if (!this.worker) {
                        this.worker = new Worker(this.workerURL, {
                            type: "module",
                        });
                        this.worker.addEventListener(
                            "message",
                            this.handleMessageFromWorker,
                        );
                    }
                }

                async run(options) {
                    this.worker.postMessage({
                        type: "run",
                        args: options.args || [],
                        files: options.files || {},
                    });
                }

                reset() {
                    if (this.worker) {
                        this.worker.terminate();
                        this.worker = null;
                    }
                    this.standardIO.message("Worker process terminated.");
                    this.initialiseWorker();
                }

                handleStdinData(inputValue) {
                    if (this.stdinbuffer && this.stdinbufferInt) {
                        let startingIndex = 1;
                        if (this.stdinbufferInt[0] > 0) {
                            startingIndex = this.stdinbufferInt[0];
                        }
                        const data = new TextEncoder().encode(inputValue);
                        data.forEach((value, index) => {
                            this.stdinbufferInt[startingIndex + index] = value;
                        });

                        this.stdinbufferInt[0] =
                            startingIndex + data.length - 1;
                        Atomics.notify(this.stdinbufferInt, 0, 1);
                    }
                }

                handleMessageFromWorker = (event) => {
                    const type = event.data.type;
                    if (type === "ready") {
                        this.readyCallBack();
                    } else if (type === "stdout") {
                        this.standardIO.stdout(event.data.stdout);
                    } else if (type === "stderr") {
                        this.standardIO.stderr(event.data.stderr);
                    } else if (type === "stdin") {
                        // Leave it to the terminal to decide whether to chunk it into lines
                        // or send characters depending on the use case.
                        this.stdinbuffer = event.data.buffer;
                        this.stdinbufferInt = new Int32Array(this.stdinbuffer);
                        this.standardIO.stdin().then((inputValue) => {
                            this.handleStdinData(inputValue);
                        });
                    } else if (type === "finished") {
                        this.standardIO.message(
                            `Exited with status: ${event.data.returnCode}`,
                        );
                        this.finishedCallback();
                    }
                };
            }

            class WasmTerminal {
                constructor() {
                    this.inputBuffer = new BufferQueue();
                    this.input = "";
                    this.resolveInput = null;
                    this.activeInput = false;
                    this.inputStartCursor = null;

                    this.xterm = new Terminal({
                        scrollback: 10000,
                        fontSize: 14,
                        theme: { background: "#1a1c1f" },
                        cols: 100,
                    });

                    this.xterm.onKey((keyEvent) => {
                        // Fix for iOS Keyboard Jumping on space
                        if (keyEvent.key === " ") {
                            keyEvent.domEvent.preventDefault();
                        }
                    });

                    this.xterm.onData(this.handleTermData);
                }

                open(container) {
                    this.xterm.open(container);
                }

                handleTermData = (data) => {
                    const ord = data.charCodeAt(0);
                    data = data.replace(/\r(?!\n)/g, "\n"); // Convert lone CRs to LF

                    // Handle pasted data
                    if (data.length > 1 && data.includes("\n")) {
                        let alreadyWrittenChars = 0;
                        // If line already had data on it, merge pasted data with it
                        if (this.input != "") {
                            this.inputBuffer.addData(this.input);
                            alreadyWrittenChars = this.input.length;
                            this.input = "";
                        }
                        this.inputBuffer.addData(data);
                        // If input is active, write the first line
                        if (this.activeInput) {
                            let line = this.inputBuffer.nextLine();
                            this.writeLine(line.slice(alreadyWrittenChars));
                            this.resolveInput(line);
                            this.activeInput = false;
                        }
                        // When input isn't active, add to line buffer
                    } else if (!this.activeInput) {
                        // Skip non-printable characters
                        if (!(ord === 0x1b || ord == 0x7f || ord < 32)) {
                            this.inputBuffer.addData(data);
                        }
                        // TODO: Handle ANSI escape sequences
                    } else if (ord === 0x1b) {
                        // Handle special characters
                    } else if (ord < 32 || ord === 0x7f) {
                        switch (data) {
                            case "\x0c": // CTRL+L
                                this.clear();
                                break;
                            case "\n": // ENTER
                            case "\x0a": // CTRL+J
                            case "\x0d": // CTRL+M
                                this.resolveInput(
                                    this.input + this.writeLine("\n"),
                                );
                                this.input = "";
                                this.activeInput = false;
                                break;
                            case "\x7F": // BACKSPACE
                            case "\x08": // CTRL+H
                                this.handleCursorErase(true);
                                break;
                            case "\x04": // CTRL+D
                                // Send empty input
                                if (this.input === "") {
                                    this.resolveInput("");
                                    this.activeInput = false;
                                }
                        }
                    } else {
                        this.handleCursorInsert(data);
                    }
                };

                writeLine(line) {
                    this.xterm.write(line.slice(0, -1));
                    this.xterm.write("\r\n");
                    return line;
                }

                handleCursorInsert(data) {
                    this.input += data;
                    this.xterm.write(data);
                }

                handleCursorErase() {
                    // Don't delete past the start of input
                    if (
                        this.xterm.buffer.active.cursorX <=
                        this.inputStartCursor
                    ) {
                        return;
                    }
                    this.input = this.input.slice(0, -1);
                    this.xterm.write("\x1B[D");
                    this.xterm.write("\x1B[P");
                }

                prompt = async () => {
                    this.activeInput = true;
                    // Hack to allow stdout/stderr to finish before we figure out where input starts
                    setTimeout(() => {
                        this.inputStartCursor =
                            this.xterm.buffer.active.cursorX;
                    }, 1);
                    // If line buffer has a line ready, send it immediately
                    if (this.inputBuffer.hasLineReady()) {
                        return new Promise((resolve, reject) => {
                            resolve(
                                this.writeLine(this.inputBuffer.nextLine()),
                            );
                            this.activeInput = false;
                        });
                        // If line buffer has an incomplete line, use it for the active line
                    } else if (this.inputBuffer.lastLineIsIncomplete()) {
                        // Hack to ensure cursor input start doesn't end up after user input
                        setTimeout(() => {
                            this.handleCursorInsert(
                                this.inputBuffer.nextLine(),
                            );
                        }, 1);
                    }
                    return new Promise((resolve, reject) => {
                        this.resolveInput = (value) => {
                            resolve(value);
                        };
                    });
                };

                clear() {
                    this.xterm.clear();
                }

                print(charCode) {
                    let array = [charCode];
                    if (charCode == 10) {
                        array = [13, 10]; // Replace \n with \r\n
                    }
                    this.xterm.write(new Uint8Array(array));
                }
            }

            class BufferQueue {
                constructor(xterm) {
                    this.buffer = [];
                }

                isEmpty() {
                    return this.buffer.length == 0;
                }

                lastLineIsIncomplete() {
                    return (
                        !this.isEmpty() &&
                        !this.buffer[this.buffer.length - 1].endsWith("\n")
                    );
                }

                hasLineReady() {
                    return !this.isEmpty() && this.buffer[0].endsWith("\n");
                }

                addData(data) {
                    let lines = data.match(/.*(\n|$)/g);
                    if (this.lastLineIsIncomplete()) {
                        this.buffer[this.buffer.length - 1] += lines.shift();
                    }
                    for (let line of lines) {
                        this.buffer.push(line);
                    }
                }

                nextLine() {
                    return this.buffer.shift();
                }
            }

            const runButton = document.getElementById("run");
            const replButton = document.getElementById("repl");
            const stopButton = document.getElementById("stop");
            const clearButton = document.getElementById("clear");

            const codeBox = document.getElementById("codebox");

            window.onload = () => {
                const terminal = new WasmTerminal();
                terminal.open(document.getElementById("terminal"));

                const stdio = {
                    stdout: (charCode) => {
                        terminal.print(charCode);
                    },
                    stderr: (charCode) => {
                        terminal.print(charCode);
                    },
                    stdin: async () => {
                        return await terminal.prompt();
                    },
                    message: (text) => {
                        terminal.writeLine(`\r\n${text}\r\n`);
                    },
                };

                const programRunning = (isRunning) => {
                    if (isRunning) {
                        replButton.setAttribute("disabled", true);
                        runButton.setAttribute("disabled", true);
                        stopButton.removeAttribute("disabled");
                    } else {
                        replButton.removeAttribute("disabled");
                        runButton.removeAttribute("disabled");
                        stopButton.setAttribute("disabled", true);
                    }
                };

                runButton.addEventListener("click", (e) => {
                    terminal.clear();
                    programRunning(true);
                    const code = codeBox.value;
                    pythonWorkerManager.run({
                        args: ["main.py"],
                        files: { "main.py": code },
                    });
                });

                replButton.addEventListener("click", (e) => {
                    terminal.clear();
                    programRunning(true);
                    // Need to use "-i -" to force interactive mode.
                    // Looks like isatty always returns false in emscripten
                    pythonWorkerManager.run({ args: ["-i", "-"], files: {} });
                });

                stopButton.addEventListener("click", (e) => {
                    programRunning(false);
                    pythonWorkerManager.reset();
                });

                clearButton.addEventListener("click", (e) => {
                    terminal.clear();
                });

                const readyCallback = () => {
                    replButton.removeAttribute("disabled");
                    runButton.removeAttribute("disabled");
                    clearButton.removeAttribute("disabled");
                };

                const finishedCallback = () => {
                    programRunning(false);
                };

                const pythonWorkerManager = new WorkerManager(
                    "./python.worker.mjs",
                    stdio,
                    readyCallback,
                    finishedCallback,
                );
            };
        </script>
    </head>
    <body>
        <h1>Simple REPL for Python WASM</h1>
        <textarea id="codebox" cols="108" rows="16">
print('Welcome to WASM!')
</textarea
        >
        <div class="button-container">
            <button id="run" disabled>Run</button>
            <button id="repl" disabled>Start REPL</button>
            <button id="stop" disabled>Stop</button>
            <button id="clear" disabled>Clear</button>
        </div>
        <div id="terminal"></div>
        <div id="info">
            The simple REPL provides a limited Python experience in the browser.
            <a
                href="https://github.com/python/cpython/blob/main/Tools/wasm/README.md"
            >
                Tools/wasm/README.md
            </a>
            contains a list of known limitations and issues. Networking,
            subprocesses, and threading are not available.
        </div>
    </body>
</html>


================================================
File: /Tools/wasm/emscripten/web_example/python.worker.mjs
================================================
import createEmscriptenModule from "./python.mjs";

class StdinBuffer {
  constructor() {
    this.sab = new SharedArrayBuffer(128 * Int32Array.BYTES_PER_ELEMENT);
    this.buffer = new Int32Array(this.sab);
    this.readIndex = 1;
    this.numberOfCharacters = 0;
    this.sentNull = true;
  }

  prompt() {
    this.readIndex = 1;
    Atomics.store(this.buffer, 0, -1);
    postMessage({
      type: "stdin",
      buffer: this.sab,
    });
    Atomics.wait(this.buffer, 0, -1);
    this.numberOfCharacters = this.buffer[0];
  }

  stdin = () => {
    while (this.numberOfCharacters + 1 === this.readIndex) {
      if (!this.sentNull) {
        // Must return null once to indicate we're done for now.
        this.sentNull = true;
        return null;
      }
      this.sentNull = false;
      // Prompt will reset this.readIndex to 1
      this.prompt();
    }
    const char = this.buffer[this.readIndex];
    this.readIndex += 1;
    return char;
  };
}

const stdout = (charCode) => {
  if (charCode) {
    postMessage({
      type: "stdout",
      stdout: charCode,
    });
  } else {
    console.log(typeof charCode, charCode);
  }
};

const stderr = (charCode) => {
  if (charCode) {
    postMessage({
      type: "stderr",
      stderr: charCode,
    });
  } else {
    console.log(typeof charCode, charCode);
  }
};

const stdinBuffer = new StdinBuffer();

const emscriptenSettings = {
  noInitialRun: true,
  stdin: stdinBuffer.stdin,
  stdout: stdout,
  stderr: stderr,
  onRuntimeInitialized: () => {
    postMessage({ type: "ready", stdinBuffer: stdinBuffer.sab });
  },
  async preRun(Module) {
    const versionHex = Module.HEAPU32[Module._Py_Version / 4].toString(16);
    const versionTuple = versionHex
      .padStart(8, "0")
      .match(/.{1,2}/g)
      .map((x) => parseInt(x, 16));
    const [major, minor, ..._] = versionTuple;
    // Prevent complaints about not finding exec-prefix by making a lib-dynload directory
    Module.FS.mkdirTree(`/lib/python${major}.${minor}/lib-dynload/`);
    Module.addRunDependency("install-stdlib");
    const resp = await fetch(`python${major}.${minor}.zip`);
    const stdlibBuffer = await resp.arrayBuffer();
    Module.FS.writeFile(
      `/lib/python${major}${minor}.zip`,
      new Uint8Array(stdlibBuffer),
      { canOwn: true },
    );
    Module.removeRunDependency("install-stdlib");
  },
};

const modulePromise = createEmscriptenModule(emscriptenSettings);

onmessage = async (event) => {
  if (event.data.type === "run") {
    const Module = await modulePromise;
    if (event.data.files) {
      for (const [filename, contents] of Object.entries(event.data.files)) {
        Module.FS.writeFile(filename, contents);
      }
    }
    const ret = Module.callMain(event.data.args);
    postMessage({
      type: "finished",
      returnCode: ret,
    });
  }
};


================================================
File: /Tools/wasm/emscripten/web_example/server.py
================================================
#!/usr/bin/env python
import argparse
from http import server

parser = argparse.ArgumentParser(
    description="Start a local webserver with a Python terminal."
)
parser.add_argument(
    "--port", type=int, default=8000, help="port for the http server to listen on"
)
parser.add_argument(
    "--bind", type=str, default="127.0.0.1", help="Bind address (empty for all)"
)


class MyHTTPRequestHandler(server.SimpleHTTPRequestHandler):
    def end_headers(self) -> None:
        self.send_my_headers()
        super().end_headers()

    def send_my_headers(self) -> None:
        self.send_header("Cross-Origin-Opener-Policy", "same-origin")
        self.send_header("Cross-Origin-Embedder-Policy", "require-corp")


def main() -> None:
    args = parser.parse_args()
    if not args.bind:
        args.bind = None

    server.test(  # type: ignore[attr-defined]
        HandlerClass=MyHTTPRequestHandler,
        protocol="HTTP/1.1",
        port=args.port,
        bind=args.bind,
    )


if __name__ == "__main__":
    main()


================================================
File: /Tools/wasm/emscripten/web_example/wasm_assets.py
================================================
#!/usr/bin/env python
"""Create a WASM asset bundle directory structure.

The WASM asset bundles are pre-loaded by the final WASM build. The bundle
contains:

- a stripped down, pyc-only stdlib zip file, e.g. {PREFIX}/lib/python311.zip
- os.py as marker module {PREFIX}/lib/python3.11/os.py
- empty lib-dynload directory, to make sure it is copied into the bundle:
    {PREFIX}/lib/python3.11/lib-dynload/.empty
"""

import argparse
import pathlib
import shutil
import sys
import sysconfig
import zipfile
from typing import Dict

# source directory
SRCDIR = pathlib.Path(__file__).parents[4].absolute()
SRCDIR_LIB = SRCDIR / "Lib"


# Library directory relative to $(prefix).
WASM_LIB = pathlib.PurePath("lib")
WASM_STDLIB_ZIP = (
    WASM_LIB / f"python{sys.version_info.major}{sys.version_info.minor}.zip"
)
WASM_STDLIB = WASM_LIB / f"python{sys.version_info.major}.{sys.version_info.minor}"
WASM_DYNLOAD = WASM_STDLIB / "lib-dynload"


# Don't ship large files / packages that are not particularly useful at
# the moment.
OMIT_FILES = (
    # regression tests
    "test/",
    # package management
    "ensurepip/",
    "venv/",
    # other platforms
    "_aix_support.py",
    "_osx_support.py",
    # webbrowser
    "antigravity.py",
    "webbrowser.py",
    # Pure Python implementations of C extensions
    "_pydecimal.py",
    "_pyio.py",
    # concurrent threading
    "concurrent/futures/thread.py",
    # Misc unused or large files
    "pydoc_data/",
)

# Synchronous network I/O and protocols are not supported; for example,
# socket.create_connection() raises an exception:
# "BlockingIOError: [Errno 26] Operation in progress".
OMIT_NETWORKING_FILES = (
    "email/",
    "ftplib.py",
    "http/",
    "imaplib.py",
    "mailbox.py",
    "poplib.py",
    "smtplib.py",
    "socketserver.py",
    # keep urllib.parse for pydoc
    "urllib/error.py",
    "urllib/request.py",
    "urllib/response.py",
    "urllib/robotparser.py",
    "wsgiref/",
)

OMIT_MODULE_FILES = {
    "_asyncio": ["asyncio/"],
    "_curses": ["curses/"],
    "_ctypes": ["ctypes/"],
    "_decimal": ["decimal.py"],
    "_dbm": ["dbm/ndbm.py"],
    "_gdbm": ["dbm/gnu.py"],
    "_json": ["json/"],
    "_multiprocessing": ["concurrent/futures/process.py", "multiprocessing/"],
    "pyexpat": ["xml/", "xmlrpc/"],
    "readline": ["rlcompleter.py"],
    "_sqlite3": ["sqlite3/"],
    "_ssl": ["ssl.py"],
    "_tkinter": ["idlelib/", "tkinter/", "turtle.py", "turtledemo/"],
    "_zoneinfo": ["zoneinfo/"],
}

SYSCONFIG_NAMES = (
    "_sysconfigdata__emscripten_wasm32-emscripten",
    "_sysconfigdata__emscripten_wasm32-emscripten",
    "_sysconfigdata__wasi_wasm32-wasi",
    "_sysconfigdata__wasi_wasm64-wasi",
)


def get_builddir(args: argparse.Namespace) -> pathlib.Path:
    """Get builddir path from pybuilddir.txt"""
    with open("pybuilddir.txt", encoding="utf-8") as f:
        builddir = f.read()
    return pathlib.Path(builddir)


def get_sysconfigdata(args: argparse.Namespace) -> pathlib.Path:
    """Get path to sysconfigdata relative to build root"""
    assert isinstance(args.builddir, pathlib.Path)
    data_name: str = sysconfig._get_sysconfigdata_name()  # type: ignore[attr-defined]
    if not data_name.startswith(SYSCONFIG_NAMES):
        raise ValueError(f"Invalid sysconfig data name '{data_name}'.", SYSCONFIG_NAMES)
    filename = data_name + ".py"
    return args.builddir / filename


def create_stdlib_zip(
    args: argparse.Namespace,
    *,
    optimize: int = 0,
) -> None:
    def filterfunc(filename: str) -> bool:
        pathname = pathlib.Path(filename).resolve()
        return pathname not in args.omit_files_absolute

    with zipfile.PyZipFile(
        args.output,
        mode="w",
        compression=args.compression,
        optimize=optimize,
    ) as pzf:
        if args.compresslevel is not None:
            pzf.compresslevel = args.compresslevel
        pzf.writepy(args.sysconfig_data)
        for entry in sorted(args.srcdir_lib.iterdir()):
            entry = entry.resolve()
            if entry.name == "__pycache__":
                continue
            if entry.name.endswith(".py") or entry.is_dir():
                # writepy() writes .pyc files (bytecode).
                pzf.writepy(entry, filterfunc=filterfunc)


def detect_extension_modules(args: argparse.Namespace) -> Dict[str, bool]:
    modules = {}

    # disabled by Modules/Setup.local ?
    with open(args.buildroot / "Makefile") as f:
        for line in f:
            if line.startswith("MODDISABLED_NAMES="):
                disabled = line.split("=", 1)[1].strip().split()
                for modname in disabled:
                    modules[modname] = False
                break

    # disabled by configure?
    with open(args.sysconfig_data) as f:
        data = f.read()
    loc: Dict[str, Dict[str, str]] = {}
    exec(data, globals(), loc)

    for key, value in loc["build_time_vars"].items():
        if not key.startswith("MODULE_") or not key.endswith("_STATE"):
            continue
        if value not in {"yes", "disabled", "missing", "n/a"}:
            raise ValueError(f"Unsupported value '{value}' for {key}")

        modname = key[7:-6].lower()
        if modname not in modules:
            modules[modname] = value == "yes"
    return modules


def path(val: str) -> pathlib.Path:
    return pathlib.Path(val).absolute()


parser = argparse.ArgumentParser()
parser.add_argument(
    "--buildroot",
    help="absolute path to build root",
    default=pathlib.Path(".").absolute(),
    type=path,
)
parser.add_argument(
    "--prefix",
    help="install prefix",
    default=pathlib.Path("/usr/local"),
    type=path,
)
parser.add_argument(
    "-o",
    "--output",
    help="output file",
    type=path,
)


def main() -> None:
    args = parser.parse_args()

    relative_prefix = args.prefix.relative_to(pathlib.Path("/"))
    args.srcdir = SRCDIR
    args.srcdir_lib = SRCDIR_LIB
    args.wasm_root = args.buildroot / relative_prefix
    args.wasm_stdlib = args.wasm_root / WASM_STDLIB
    args.wasm_dynload = args.wasm_root / WASM_DYNLOAD

    # bpo-17004: zipimport supports only zlib compression.
    # Emscripten ZIP_STORED + -sLZ4=1 linker flags results in larger file.
    args.compression = zipfile.ZIP_DEFLATED
    args.compresslevel = 9

    args.builddir = get_builddir(args)
    args.sysconfig_data = get_sysconfigdata(args)
    if not args.sysconfig_data.is_file():
        raise ValueError(f"sysconfigdata file {args.sysconfig_data} missing.")

    extmods = detect_extension_modules(args)
    omit_files = list(OMIT_FILES)
    if sysconfig.get_platform().startswith("emscripten"):
        omit_files.extend(OMIT_NETWORKING_FILES)
    for modname, modfiles in OMIT_MODULE_FILES.items():
        if not extmods.get(modname):
            omit_files.extend(modfiles)

    args.omit_files_absolute = {
        (args.srcdir_lib / name).resolve() for name in omit_files
    }

    # Empty, unused directory for dynamic libs, but required for site initialization.
    args.wasm_dynload.mkdir(parents=True, exist_ok=True)
    marker = args.wasm_dynload / ".empty"
    marker.touch()
    # The rest of stdlib that's useful in a WASM context.
    create_stdlib_zip(args)
    size = round(args.output.stat().st_size / 1024**2, 2)
    parser.exit(0, f"Created {args.output} ({size} MiB)\n")


if __name__ == "__main__":
    main()


================================================
File: /iOS/README.rst
================================================
====================
Python on iOS README
====================

:Authors:
    Russell Keith-Magee (2023-11)

This document provides a quick overview of some iOS specific features in the
Python distribution.

These instructions are only needed if you're planning to compile Python for iOS
yourself. Most users should *not* need to do this. If you're looking to
experiment with writing an iOS app in Python, tools such as `BeeWare's Briefcase
<https://briefcase.readthedocs.io>`__ and `Kivy's Buildozer
<https://buildozer.readthedocs.io>`__ will provide a much more approachable
user experience.

Compilers for building on iOS
=============================

Building for iOS requires the use of Apple's Xcode tooling. It is strongly
recommended that you use the most recent stable release of Xcode. This will
require the use of the most (or second-most) recently released macOS version,
as Apple does not maintain Xcode for older macOS versions. The Xcode Command
Line Tools are not sufficient for iOS development; you need a *full* Xcode
install.

If you want to run your code on the iOS simulator, you'll also need to install
an iOS Simulator Platform. You should be prompted to select an iOS Simulator
Platform when you first run Xcode. Alternatively, you can add an iOS Simulator
Platform by selecting an open the Platforms tab of the Xcode Settings panel.

iOS specific arguments to configure
===================================

* ``--enable-framework[=DIR]``

  This argument specifies the location where the Python.framework will be
  installed. If ``DIR`` is not specified, the framework will be installed into
  a subdirectory of the ``iOS/Frameworks`` folder.

  This argument *must* be provided when configuring iOS builds. iOS does not
  support non-framework builds.

* ``--with-framework-name=NAME``

  Specify the name for the Python framework; defaults to ``Python``.

  .. admonition:: Use this option with care!

    Unless you know what you're doing, changing the name of the Python
    framework on iOS is not advised. If you use this option, you won't be able
    to run the ``make testios`` target without making significant manual
    alterations, and you won't be able to use any binary packages unless you
    compile them yourself using your own framework name.

Building Python on iOS
======================

ABIs and Architectures
----------------------

iOS apps can be deployed on physical devices, and on the iOS simulator. Although
the API used on these devices is identical, the ABI is different - you need to
link against different libraries for an iOS device build (``iphoneos``) or an
iOS simulator build (``iphonesimulator``).

Apple uses the ``XCframework`` format to allow specifying a single dependency
that supports multiple ABIs. An ``XCframework`` is a wrapper around multiple
ABI-specific frameworks that share a common API.

iOS can also support different CPU architectures within each ABI. At present,
there is only a single supported architecture on physical devices - ARM64.
However, the *simulator* supports 2 architectures - ARM64 (for running on Apple
Silicon machines), and x86_64 (for running on older Intel-based machines).

To support multiple CPU architectures on a single platform, Apple uses a "fat
binary" format - a single physical file that contains support for multiple
architectures. It is possible to compile and use a "thin" single architecture
version of a binary for testing purposes; however, the "thin" binary will not be
portable to machines using other architectures.

Building a single-architecture framework
----------------------------------------

The Python build system will create a ``Python.framework`` that supports a
*single* ABI with a *single* architecture. Unlike macOS, iOS does not allow a
framework to contain non-library content, so the iOS build will produce a
``bin`` and ``lib`` folder in the same output folder as ``Python.framework``.
The ``lib`` folder will be needed at runtime to support the Python library.

If you want to use Python in a real iOS project, you need to produce multiple
``Python.framework`` builds, one for each ABI and architecture. iOS builds of
Python *must* be constructed as framework builds. To support this, you must
provide the ``--enable-framework`` flag when configuring the build. The build
also requires the use of cross-compilation. The minimal commands for building
Python for the ARM64 iOS simulator will look something like::

  $ export PATH="$(pwd)/iOS/Resources/bin:/usr/bin:/bin:/usr/sbin:/sbin:/Library/Apple/usr/bin"
  $ ./configure \
        --enable-framework \
        --host=arm64-apple-ios-simulator \
        --build=arm64-apple-darwin \
        --with-build-python=/path/to/python.exe
  $ make
  $ make install

In this invocation:

* ``iOS/Resources/bin`` has been added to the path, providing some shims for the
  compilers and linkers needed by the build. Xcode requires the use of ``xcrun``
  to invoke compiler tooling. However, if ``xcrun`` is pre-evaluated and the
  result passed to ``configure``, these results can embed user- and
  version-specific paths into the sysconfig data, which limits the portability
  of the compiled Python. Alternatively, if ``xcrun`` is used *as* the compiler,
  it requires that compiler variables like ``CC`` include spaces, which can
  cause significant problems with many C configuration systems which assume that
  ``CC`` will be a single executable.

  To work around this problem, the ``iOS/Resources/bin`` folder contains some
  wrapper scripts that present as simple compilers and linkers, but wrap
  underlying calls to ``xcrun``. This allows configure to use a ``CC``
  definition without spaces, and without user- or version-specific paths, while
  retaining the ability to adapt to the local Xcode install. These scripts are
  included in the ``bin`` directory of an iOS install.

  These scripts will, by default, use the currently active Xcode installation.
  If you want to use a different Xcode installation, you can use
  ``xcode-select`` to set a new default Xcode globally, or you can use the
  ``DEVELOPER_DIR`` environment variable to specify an Xcode install. The
  scripts will use the default ``iphoneos``/``iphonesimulator`` SDK version for
  the select Xcode install; if you want to use a different SDK, you can set the
  ``IOS_SDK_VERSION`` environment variable. (e.g, setting
  ``IOS_SDK_VERSION=17.1`` would cause the scripts to use the ``iphoneos17.1``
  and ``iphonesimulator17.1`` SDKs, regardless of the Xcode default.)

  The path has also been cleared of any user customizations. A common source of
  bugs is for tools like Homebrew to accidentally leak macOS binaries into an iOS
  build. Resetting the path to a known "bare bones" value is the easiest way to
  avoid these problems.

* ``--host`` is the architecture and ABI that you want to build, in GNU compiler
  triple format. This will be one of:

  - ``arm64-apple-ios`` for ARM64 iOS devices.
  - ``arm64-apple-ios-simulator`` for the iOS simulator running on Apple
    Silicon devices.
  - ``x86_64-apple-ios-simulator`` for the iOS simulator running on Intel
    devices.

* ``--build`` is the GNU compiler triple for the machine that will be running
  the compiler. This is one of:

  - ``arm64-apple-darwin`` for Apple Silicon devices.
  - ``x86_64-apple-darwin`` for Intel devices.

* ``/path/to/python.exe`` is the path to a Python binary on the machine that
  will be running the compiler. This is needed because the Python compilation
  process involves running some Python code. On a normal desktop build of
  Python, you can compile a python interpreter and then use that interpreter to
  run Python code. However, the binaries produced for iOS won't run on macOS, so
  you need to provide an external Python interpreter. This interpreter must be
  the same version as the Python that is being compiled. To be completely safe,
  this should be the *exact* same commit hash. However, the longer a Python
  release has been stable, the more likely it is that this constraint can be
  relaxed - the same micro version will often be sufficient.

* The ``install`` target for iOS builds is slightly different to other
  platforms. On most platforms, ``make install`` will install the build into
  the final runtime location. This won't be the case for iOS, as the final
  runtime location will be on a physical device.

  However, you still need to run the ``install`` target for iOS builds, as it
  performs some final framework assembly steps. The location specified with
  ``--enable-framework`` will be the location where ``make install`` will
  assemble the complete iOS framework. This completed framework can then
  be copied and relocated as required.

For a full CPython build, you also need to specify the paths to iOS builds of
the binary libraries that CPython depends on (XZ, BZip2, LibFFI and OpenSSL).
This can be done by defining the ``LIBLZMA_CFLAGS``, ``LIBLZMA_LIBS``,
``BZIP2_CFLAGS``, ``BZIP2_LIBS``, ``LIBFFI_CFLAGS``, and ``LIBFFI_LIBS``
environment variables, and the ``--with-openssl`` configure option. Versions of
these libraries pre-compiled for iOS can be found in `this repository
<https://github.com/beeware/cpython-apple-source-deps/releases>`__. LibFFI is
especially important, as many parts of the standard library (including the
``platform``, ``sysconfig`` and ``webbrowser`` modules) require the use of the
``ctypes`` module at runtime.

By default, Python will be compiled with an iOS deployment target (i.e., the
minimum supported iOS version) of 13.0. To specify a different deployment
target, provide the version number as part of the ``--host`` argument - for
example, ``--host=arm64-apple-ios15.4-simulator`` would compile an ARM64
simulator build with a deployment target of 15.4.

Merge thin frameworks into fat frameworks
-----------------------------------------

Once you've built a ``Python.framework`` for each ABI and and architecture, you
must produce a "fat" framework for each ABI that contains all the architectures
for that ABI.

The ``iphoneos`` build only needs to support a single architecture, so it can be
used without modification.

If you only want to support a single simulator architecture, (e.g., only support
ARM64 simulators), you can use a single architecture ``Python.framework`` build.
However, if you want to create ``Python.xcframework`` that supports *all*
architectures, you'll need to merge the ``iphonesimulator`` builds for ARM64 and
x86_64 into a single "fat" framework.

The "fat" framework can be constructed by performing a directory merge of the
content of the two "thin" ``Python.framework`` directories, plus the ``bin`` and
``lib`` folders for each thin framework. When performing this merge:

* The pure Python standard library content is identical for each architecture,
  except for a handful of platform-specific files (such as the ``sysconfig``
  module). Ensure that the "fat" framework has the union of all standard library
  files.

* Any binary files in the standard library, plus the main
  ``libPython3.X.dylib``, can be merged using the ``lipo`` tool, provide by
  Xcode::

    $ lipo -create -output module.dylib path/to/x86_64/module.dylib path/to/arm64/module.dylib

* The header files will be identical on both architectures, except for
  ``pyconfig.h``. Copy all the headers from one platform (say, arm64), rename
  ``pyconfig.h`` to ``pyconfig-arm64.h``, and copy the ``pyconfig.h`` for the
  other architecture into the merged header folder as ``pyconfig-x86_64.h``.
  Then copy the ``iOS/Resources/pyconfig.h`` file from the CPython sources into
  the merged headers folder. This will allow the two Python architectures to
  share a common ``pyconfig.h`` header file.

At this point, you should have 2 Python.framework folders - one for ``iphoneos``,
and one for ``iphonesimulator`` that is a merge of x86+64 and ARM64 content.

Merge frameworks into an XCframework
------------------------------------

Now that we have 2 (potentially fat) ABI-specific frameworks, we can merge those
frameworks into a single ``XCframework``.

The initial skeleton of an ``XCframework`` is built using::

    xcodebuild -create-xcframework -output Python.xcframework -framework path/to/iphoneos/Python.framework -framework path/to/iphonesimulator/Python.framework

Then, copy the ``bin`` and ``lib`` folders into the architecture-specific slices of
the XCframework::

    cp path/to/iphoneos/bin Python.xcframework/ios-arm64
    cp path/to/iphoneos/lib Python.xcframework/ios-arm64

    cp path/to/iphonesimulator/bin Python.xcframework/ios-arm64_x86_64-simulator
    cp path/to/iphonesimulator/lib Python.xcframework/ios-arm64_x86_64-simulator

Note that the name of the architecture-specific slice for the simulator will
depend on the CPU architecture(s) that you build.

You now have a Python.xcframework that can be used in a project.

Testing Python on iOS
=====================

The ``iOS/testbed`` folder that contains an Xcode project that is able to run
the iOS test suite. This project converts the Python test suite into a single
test case in Xcode's XCTest framework. The single XCTest passes if the test
suite passes.

To run the test suite, configure a Python build for an iOS simulator (i.e.,
``--host=arm64-apple-ios-simulator`` or ``--host=x86_64-apple-ios-simulator``
), specifying a framework build (i.e. ``--enable-framework``). Ensure that your
``PATH`` has been configured to include the ``iOS/Resources/bin`` folder and
exclude any non-iOS tools, then run::

    $ make all
    $ make install
    $ make testios

This will:

* Build an iOS framework for your chosen architecture;
* Finalize the single-platform framework;
* Make a clean copy of the testbed project;
* Install the Python iOS framework into the copy of the testbed project; and
* Run the test suite on an "iPhone SE (3rd generation)" simulator.

On success, the test suite will exit and report successful completion of the
test suite. On a 2022 M1 MacBook Pro, the test suite takes approximately 15
minutes to run; a couple of extra minutes is required to compile the testbed
project, and then boot and prepare the iOS simulator.

Debugging test failures
-----------------------

Running ``make test`` generates a standalone version of the ``iOS/testbed``
project, and runs the full test suite. It does this using ``iOS/testbed``
itself - the folder is an executable module that can be used to create and run
a clone of the testbed project.

You can generate your own standalone testbed instance by running::

    $ python iOS/testbed clone --framework iOS/Frameworks/arm64-iphonesimulator my-testbed

This invocation assumes that ``iOS/Frameworks/arm64-iphonesimulator`` is the
path to the iOS simulator framework for your platform (ARM64 in this case);
``my-testbed`` is the name of the folder for the new testbed clone.

You can then use the ``my-testbed`` folder to run the Python test suite,
passing in any command line arguments you may require. For example, if you're
trying to diagnose a failure in the ``os`` module, you might run::

    $ python my-testbed run -- test -W test_os

This is the equivalent of running ``python -m test -W test_os`` on a desktop
Python build. Any arguments after the ``--`` will be passed to testbed as if
they were arguments to ``python -m`` on a desktop machine.

You can also open the testbed project in Xcode by running::

    $ open my-testbed/iOSTestbed.xcodeproj

This will allow you to use the full Xcode suite of tools for debugging.

Testing on an iOS device
^^^^^^^^^^^^^^^^^^^^^^^^

To test on an iOS device, the app needs to be signed with known developer
credentials. To obtain these credentials, you must have an iOS Developer
account, and your Xcode install will need to be logged into your account (see
the Accounts tab of the Preferences dialog).

Once the project is open, and you're signed into your Apple Developer account,
select the root node of the project tree (labeled "iOSTestbed"), then the
"Signing & Capabilities" tab in the details page. Select a development team
(this will likely be your own name), and plug in a physical device to your
macOS machine with a USB cable. You should then be able to select your physical
device from the list of targets in the pulldown in the Xcode titlebar.

Running specific tests
^^^^^^^^^^^^^^^^^^^^^^

As the test suite is being executed on an iOS simulator, it is not possible to
pass in command line arguments to configure test suite operation. To work
around this limitation, the arguments that would normally be passed as command
line arguments are configured as part of the ``iOSTestbed-Info.plist`` file
that is used to configure the iOS testbed app. In this file, the ``TestArgs``
key is an array containing the arguments that would be passed to ``python -m``
on the command line (including ``test`` in position 0, the name of the test
module to be executed).

Disabling automated breakpoints
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

By default, Xcode will inserts an automatic breakpoint whenever a signal is
raised. The Python test suite raises many of these signals as part of normal
operation; unless you are trying to diagnose an issue with signals, the
automatic breakpoints can be inconvenient. However, they can be disabled by
creating a symbolic breakpoint that is triggered at the start of the test run.

Select "Debug > Breakpoints > Create Symbolic Breakpoint" from the Xcode menu, and
populate the new brewpoint with the following details:

* **Name**: IgnoreSignals
* **Symbol**: UIApplicationMain
* **Action**: Add debugger commands for:
  - ``process handle SIGINT -n true -p true -s false``
  - ``process handle SIGUSR1 -n true -p true -s false``
  - ``process handle SIGUSR2 -n true -p true -s false``
  - ``process handle SIGXFSZ -n true -p true -s false``
* Check the "Automatically continue after evaluating" box.

All other details can be left blank. When the process executes the
``UIApplicationMain`` entry point, the breakpoint will trigger, run the debugger
commands to disable the automatic breakpoints, and automatically resume.


================================================
File: /iOS/Resources/Info.plist.in
================================================
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist SYSTEM "file://localhost/System/Library/DTDs/PropertyList.dtd">
<plist version="0.9">
<dict>
	<key>CFBundleDevelopmentRegion</key>
	<string>en</string>
	<key>CFBundleExecutable</key>
	<string>Python</string>
	<key>CFBundleGetInfoString</key>
	<string>Python Runtime and Library</string>
	<key>CFBundleIdentifier</key>
	<string>@PYTHONFRAMEWORKIDENTIFIER@</string>
	<key>CFBundleInfoDictionaryVersion</key>
	<string>6.0</string>
	<key>CFBundleName</key>
	<string>Python</string>
	<key>CFBundlePackageType</key>
	<string>FMWK</string>
	<key>CFBundleShortVersionString</key>
	<string>@VERSION@</string>
	<key>CFBundleLongVersionString</key>
	<string>%VERSION%, (c) 2001-2024 Python Software Foundation.</string>
	<key>CFBundleSignature</key>
	<string>????</string>
	<key>CFBundleVersion</key>
	<string>1</string>
	<key>CFBundleSupportedPlatforms</key>
	<array>
		<string>iPhoneOS</string>
	</array>
	<key>MinimumOSVersion</key>
	<string>@IPHONEOS_DEPLOYMENT_TARGET@</string>
</dict>
</plist>


================================================
File: /iOS/Resources/dylib-Info-template.plist
================================================
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>CFBundleDevelopmentRegion</key>
	<string>en</string>
	<key>CFBundleExecutable</key>
	<string></string>
	<key>CFBundleIdentifier</key>
	<string></string>
	<key>CFBundleInfoDictionaryVersion</key>
	<string>6.0</string>
	<key>CFBundlePackageType</key>
	<string>APPL</string>
	<key>CFBundleShortVersionString</key>
	<string>1.0</string>
	<key>CFBundleSupportedPlatforms</key>
	<array>
		<string>iPhoneOS</string>
	</array>
	<key>MinimumOSVersion</key>
	<string>12.0</string>
	<key>CFBundleVersion</key>
	<string>1</string>
</dict>
</plist>


================================================
File: /iOS/Resources/pyconfig.h
================================================
#ifdef __arm64__
#include "pyconfig-arm64.h"
#endif

#ifdef __x86_64__
#include "pyconfig-x86_64.h"
#endif


================================================
File: /iOS/Resources/bin/arm64-apple-ios-ar
================================================
#!/bin/sh
xcrun --sdk iphoneos${IOS_SDK_VERSION} ar "$@"


================================================
File: /iOS/Resources/bin/arm64-apple-ios-clang
================================================
#!/bin/sh
xcrun --sdk iphoneos${IOS_SDK_VERSION} clang -target arm64-apple-ios "$@"


================================================
File: /iOS/Resources/bin/arm64-apple-ios-clang++
================================================
#!/bin/sh
xcrun --sdk iphoneos${IOS_SDK_VERSION} clang++ -target arm64-apple-ios "$@"


================================================
File: /iOS/Resources/bin/arm64-apple-ios-cpp
================================================
#!/bin/sh
xcrun --sdk iphoneos${IOS_SDK_VERSION} clang -target arm64-apple-ios -E "$@"


================================================
File: /iOS/Resources/bin/arm64-apple-ios-simulator-ar
================================================
#!/bin/sh
xcrun --sdk iphonesimulator${IOS_SDK_VERSION} ar "$@"


================================================
File: /iOS/Resources/bin/arm64-apple-ios-simulator-clang
================================================
#!/bin/sh
xcrun --sdk iphonesimulator${IOS_SDK_VERSION} clang -target arm64-apple-ios-simulator "$@"


================================================
File: /iOS/Resources/bin/arm64-apple-ios-simulator-clang++
================================================
#!/bin/sh
xcrun --sdk iphonesimulator${IOS_SDK_VERSION} clang++ -target arm64-apple-ios-simulator "$@"


================================================
File: /iOS/Resources/bin/arm64-apple-ios-simulator-cpp
================================================
#!/bin/sh
xcrun --sdk iphonesimulator${IOS_SDK_VERSION} clang -target arm64-apple-ios-simulator -E "$@"


================================================
File: /iOS/Resources/bin/x86_64-apple-ios-simulator-ar
================================================
#!/bin/sh
xcrun --sdk iphonesimulator${IOS_SDK_VERSION} ar "$@"


================================================
File: /iOS/Resources/bin/x86_64-apple-ios-simulator-clang
================================================
#!/bin/sh
xcrun --sdk iphonesimulator${IOS_SDK_VERSION} clang -target x86_64-apple-ios-simulator "$@"


================================================
File: /iOS/Resources/bin/x86_64-apple-ios-simulator-clang++
================================================
#!/bin/sh
xcrun --sdk iphonesimulator${IOS_SDK_VERSION} clang++ -target x86_64-apple-ios-simulator "$@"


================================================
File: /iOS/Resources/bin/x86_64-apple-ios-simulator-cpp
================================================
#!/bin/sh
xcrun --sdk iphonesimulator${IOS_SDK_VERSION} clang -target x86_64-apple-ios-simulator -E "$@"


================================================
File: /iOS/testbed/__main__.py
================================================
import argparse
import asyncio
import json
import plistlib
import shutil
import subprocess
import sys
from contextlib import asynccontextmanager
from datetime import datetime
from pathlib import Path


DECODE_ARGS = ("UTF-8", "backslashreplace")


# Work around a bug involving sys.exit and TaskGroups
# (https://github.com/python/cpython/issues/101515).
def exit(*args):
    raise MySystemExit(*args)


class MySystemExit(Exception):
    pass


# All subprocesses are executed through this context manager so that no matter
# what happens, they can always be cancelled from another task, and they will
# always be cleaned up on exit.
@asynccontextmanager
async def async_process(*args, **kwargs):
    process = await asyncio.create_subprocess_exec(*args, **kwargs)
    try:
        yield process
    finally:
        if process.returncode is None:
            # Allow a reasonably long time for Xcode to clean itself up,
            # because we don't want stale emulators left behind.
            timeout = 10
            process.terminate()
            try:
                await asyncio.wait_for(process.wait(), timeout)
            except TimeoutError:
                print(
                    f"Command {args} did not terminate after {timeout} seconds "
                    f" - sending SIGKILL"
                )
                process.kill()

                # Even after killing the process we must still wait for it,
                # otherwise we'll get the warning "Exception ignored in __del__".
                await asyncio.wait_for(process.wait(), timeout=1)


async def async_check_output(*args, **kwargs):
    async with async_process(
        *args, stdout=subprocess.PIPE, stderr=subprocess.PIPE, **kwargs
    ) as process:
        stdout, stderr = await process.communicate()
        if process.returncode == 0:
            return stdout.decode(*DECODE_ARGS)
        else:
            raise subprocess.CalledProcessError(
                process.returncode,
                args,
                stdout.decode(*DECODE_ARGS),
                stderr.decode(*DECODE_ARGS),
            )


# Return a list of UDIDs associated with booted simulators
async def list_devices():
    # List the testing simulators, in JSON format
    raw_json = await async_check_output(
        "xcrun", "simctl", "--set", "testing", "list", "-j"
    )
    json_data = json.loads(raw_json)

    # Filter out the booted iOS simulators
    return [
        simulator["udid"]
        for runtime, simulators in json_data["devices"].items()
        for simulator in simulators
        if runtime.split(".")[-1].startswith("iOS") and simulator["state"] == "Booted"
    ]


async def find_device(initial_devices):
    while True:
        new_devices = set(await list_devices()).difference(initial_devices)
        if len(new_devices) == 0:
            await asyncio.sleep(1)
        elif len(new_devices) == 1:
            udid = new_devices.pop()
            print(f"{datetime.now():%Y-%m-%d %H:%M:%S}: New test simulator detected")
            print(f"UDID: {udid}")
            return udid
        else:
            exit(f"Found more than one new device: {new_devices}")


async def log_stream_task(initial_devices):
    # Wait up to 5 minutes for the build to complete and the simulator to boot.
    udid = await asyncio.wait_for(find_device(initial_devices), 5 * 60)

    # Stream the iOS device's logs, filtering out messages that come from the
    # XCTest test suite (catching NSLog messages from the test method), or
    # Python itself (catching stdout/stderr content routed to the system log
    # with config->use_system_logger).
    args = [
        "xcrun",
        "simctl",
        "--set",
        "testing",
        "spawn",
        udid,
        "log",
        "stream",
        "--style",
        "compact",
        "--predicate",
        (
            'senderImagePath ENDSWITH "/iOSTestbedTests.xctest/iOSTestbedTests"'
            ' OR senderImagePath ENDSWITH "/Python.framework/Python"'
        ),
    ]

    async with async_process(
        *args,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
    ) as process:
        suppress_dupes = False
        while line := (await process.stdout.readline()).decode(*DECODE_ARGS):
            # The iOS log streamer can sometimes lag; when it does, it outputs
            # a warning about messages being dropped... often multiple times.
            # Only print the first of these duplicated warnings.
            if line.startswith("=== Messages dropped "):
                if not suppress_dupes:
                    suppress_dupes = True
                    sys.stdout.write(line)
            else:
                suppress_dupes = False
                sys.stdout.write(line)
            sys.stdout.flush()


async def xcode_test(location, simulator, verbose):
    # Run the test suite on the named simulator
    print("Starting xcodebuild...")
    args = [
        "xcodebuild",
        "test",
        "-project",
        str(location / "iOSTestbed.xcodeproj"),
        "-scheme",
        "iOSTestbed",
        "-destination",
        f"platform=iOS Simulator,name={simulator}",
        "-resultBundlePath",
        str(location / f"{datetime.now():%Y%m%d-%H%M%S}.xcresult"),
        "-derivedDataPath",
        str(location / "DerivedData"),
    ]
    if not verbose:
        args += ["-quiet"]

    async with async_process(
        *args,
        stdout=subprocess.PIPE,
        stderr=subprocess.STDOUT,
    ) as process:
        while line := (await process.stdout.readline()).decode(*DECODE_ARGS):
            sys.stdout.write(line)
            sys.stdout.flush()

        status = await asyncio.wait_for(process.wait(), timeout=1)
        exit(status)


def clone_testbed(
    source: Path,
    target: Path,
    framework: Path,
    apps: list[Path],
) -> None:
    if target.exists():
        print(f"{target} already exists; aborting without creating project.")
        sys.exit(10)

    if framework is None:
        if not (
            source / "Python.xcframework/ios-arm64_x86_64-simulator/bin"
        ).is_dir():
            print(
                f"The testbed being cloned ({source}) does not contain "
                f"a simulator framework. Re-run with --framework"
            )
            sys.exit(11)
    else:
        if not framework.is_dir():
            print(f"{framework} does not exist.")
            sys.exit(12)
        elif not (
            framework.suffix == ".xcframework"
            or (framework / "Python.framework").is_dir()
        ):
            print(
                f"{framework} is not an XCframework, "
                f"or a simulator slice of a framework build."
            )
            sys.exit(13)

    print("Cloning testbed project:")
    print(f"  Cloning {source}...", end="", flush=True)
    shutil.copytree(source, target, symlinks=True)
    print(" done")

    if framework is not None:
        if framework.suffix == ".xcframework":
            print("  Installing XCFramework...", end="", flush=True)
            xc_framework_path = (target / "Python.xcframework").resolve()
            if xc_framework_path.is_dir():
                shutil.rmtree(xc_framework_path)
            else:
                xc_framework_path.unlink()
            xc_framework_path.symlink_to(
                framework.relative_to(xc_framework_path.parent, walk_up=True)
            )
            print(" done")
        else:
            print("  Installing simulator framework...", end="", flush=True)
            sim_framework_path = (
                target / "Python.xcframework" / "ios-arm64_x86_64-simulator"
            ).resolve()
            if sim_framework_path.is_dir():
                shutil.rmtree(sim_framework_path)
            else:
                sim_framework_path.unlink()
            sim_framework_path.symlink_to(
                framework.relative_to(sim_framework_path.parent, walk_up=True)
            )
            print(" done")
    else:
        print("  Using pre-existing iOS framework.")

    for app_src in apps:
        print(f"  Installing app {app_src.name!r}...", end="", flush=True)
        app_target = target / f"iOSTestbed/app/{app_src.name}"
        if app_target.is_dir():
            shutil.rmtree(app_target)
        shutil.copytree(app_src, app_target)
        print(" done")

    print(f"Successfully cloned testbed: {target.resolve()}")


def update_plist(testbed_path, args):
    # Add the test runner arguments to the testbed's Info.plist file.
    info_plist = testbed_path / "iOSTestbed" / "iOSTestbed-Info.plist"
    with info_plist.open("rb") as f:
        info = plistlib.load(f)

    info["TestArgs"] = args

    with info_plist.open("wb") as f:
        plistlib.dump(info, f)


async def run_testbed(simulator: str, args: list[str], verbose: bool=False):
    location = Path(__file__).parent
    print("Updating plist...", end="", flush=True)
    update_plist(location, args)
    print(" done.")

    # Get the list of devices that are booted at the start of the test run.
    # The simulator started by the test suite will be detected as the new
    # entry that appears on the device list.
    initial_devices = await list_devices()

    try:
        async with asyncio.TaskGroup() as tg:
            tg.create_task(log_stream_task(initial_devices))
            tg.create_task(xcode_test(location, simulator=simulator, verbose=verbose))
    except* MySystemExit as e:
        raise SystemExit(*e.exceptions[0].args) from None
    except* subprocess.CalledProcessError as e:
        # Extract it from the ExceptionGroup so it can be handled by `main`.
        raise e.exceptions[0]


def main():
    parser = argparse.ArgumentParser(
        description=(
            "Manages the process of testing a Python project in the iOS simulator."
        ),
    )

    subcommands = parser.add_subparsers(dest="subcommand")

    clone = subcommands.add_parser(
        "clone",
        description=(
            "Clone the testbed project, copying in an iOS Python framework and"
            "any specified application code."
        ),
        help="Clone a testbed project to a new location.",
    )
    clone.add_argument(
        "--framework",
        help=(
            "The location of the XCFramework (or simulator-only slice of an "
            "XCFramework) to use when running the testbed"
        ),
    )
    clone.add_argument(
        "--app",
        dest="apps",
        action="append",
        default=[],
        help="The location of any code to include in the testbed project",
    )
    clone.add_argument(
        "location",
        help="The path where the testbed will be cloned.",
    )

    run = subcommands.add_parser(
        "run",
        usage="%(prog)s [-h] [--simulator SIMULATOR] -- <test arg> [<test arg> ...]",
        description=(
            "Run a testbed project. The arguments provided after `--` will be "
            "passed to the running iOS process as if they were arguments to "
            "`python -m`."
        ),
        help="Run a testbed project",
    )
    run.add_argument(
        "--simulator",
        default="iPhone SE (3rd Generation)",
        help="The name of the simulator to use (default: 'iPhone SE (3rd Generation)')",
    )
    run.add_argument(
        "-v", "--verbose",
        action="store_true",
        help="Enable verbose output",
    )

    try:
        pos = sys.argv.index("--")
        testbed_args = sys.argv[1:pos]
        test_args = sys.argv[pos + 1 :]
    except ValueError:
        testbed_args = sys.argv[1:]
        test_args = []

    context = parser.parse_args(testbed_args)

    if context.subcommand == "clone":
        clone_testbed(
            source=Path(__file__).parent,
            target=Path(context.location),
            framework=Path(context.framework).resolve() if context.framework else None,
            apps=[Path(app) for app in context.apps],
        )
    elif context.subcommand == "run":
        if test_args:
            if not (
                Path(__file__).parent / "Python.xcframework/ios-arm64_x86_64-simulator/bin"
            ).is_dir():
                print(
                    f"Testbed does not contain a compiled iOS framework. Use "
                    f"`python {sys.argv[0]} clone ...` to create a runnable "
                    f"clone of this testbed."
                )
                sys.exit(20)

            asyncio.run(
                run_testbed(
                    simulator=context.simulator,
                    verbose=context.verbose,
                    args=test_args,
                )
            )
        else:
            print(f"Must specify test arguments (e.g., {sys.argv[0]} run -- test)")
            print()
            parser.print_help(sys.stderr)
            sys.exit(21)
    else:
        parser.print_help(sys.stderr)
        sys.exit(1)


if __name__ == "__main__":
    main()


================================================
File: /iOS/testbed/Python.xcframework/Info.plist
================================================
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>AvailableLibraries</key>
	<array>
		<dict>
			<key>BinaryPath</key>
			<string>Python.framework/Python</string>
			<key>LibraryIdentifier</key>
			<string>ios-arm64</string>
			<key>LibraryPath</key>
			<string>Python.framework</string>
			<key>SupportedArchitectures</key>
			<array>
				<string>arm64</string>
			</array>
			<key>SupportedPlatform</key>
			<string>ios</string>
		</dict>
		<dict>
			<key>BinaryPath</key>
			<string>Python.framework/Python</string>
			<key>LibraryIdentifier</key>
			<string>ios-arm64_x86_64-simulator</string>
			<key>LibraryPath</key>
			<string>Python.framework</string>
			<key>SupportedArchitectures</key>
			<array>
				<string>arm64</string>
				<string>x86_64</string>
			</array>
			<key>SupportedPlatform</key>
			<string>ios</string>
			<key>SupportedPlatformVariant</key>
			<string>simulator</string>
		</dict>
	</array>
	<key>CFBundlePackageType</key>
	<string>XFWK</string>
	<key>XCFrameworkFormatVersion</key>
	<string>1.0</string>
</dict>
</plist>


================================================
File: /iOS/testbed/Python.xcframework/ios-arm64/README
================================================
This directory is intentionally empty.

It should be used as a target for `--enable-framework` when compiling an iOS on-device
build for testing purposes.


================================================
File: /iOS/testbed/Python.xcframework/ios-arm64_x86_64-simulator/README
================================================
This directory is intentionally empty.

It should be used as a target for `--enable-framework` when compiling an iOS simulator
build for testing purposes (either x86_64 or ARM64).


================================================
File: /iOS/testbed/iOSTestbed/AppDelegate.h
================================================
//
//  AppDelegate.h
//  iOSTestbed
//

#import <UIKit/UIKit.h>

@interface AppDelegate : UIResponder <UIApplicationDelegate>


@end


================================================
File: /iOS/testbed/iOSTestbed/AppDelegate.m
================================================
//
//  AppDelegate.m
//  iOSTestbed
//

#import "AppDelegate.h"

@interface AppDelegate ()

@end

@implementation AppDelegate


- (BOOL)application:(UIApplication *)application didFinishLaunchingWithOptions:(NSDictionary *)launchOptions {
    return YES;
}

@end


================================================
File: /iOS/testbed/iOSTestbed/dylib-Info-template.plist
================================================
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>CFBundleDevelopmentRegion</key>
	<string>en</string>
	<key>CFBundleExecutable</key>
	<string></string>
	<key>CFBundleIdentifier</key>
	<string></string>
	<key>CFBundleInfoDictionaryVersion</key>
	<string>6.0</string>
	<key>CFBundlePackageType</key>
	<string>APPL</string>
	<key>CFBundleShortVersionString</key>
	<string>1.0</string>
	<key>CFBundleSupportedPlatforms</key>
	<array>
		<string>iPhoneOS</string>
	</array>
	<key>MinimumOSVersion</key>
	<string>12.0</string>
	<key>CFBundleVersion</key>
	<string>1</string>
</dict>
</plist>


================================================
File: /iOS/testbed/iOSTestbed/iOSTestbed-Info.plist
================================================
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd">
<plist version="1.0">
<dict>
	<key>CFBundleDevelopmentRegion</key>
	<string>en</string>
	<key>CFBundleDisplayName</key>
	<string>${PRODUCT_NAME}</string>
	<key>CFBundleExecutable</key>
	<string>${EXECUTABLE_NAME}</string>
	<key>CFBundleIdentifier</key>
	<string>org.python.iOSTestbed</string>
	<key>CFBundleInfoDictionaryVersion</key>
	<string>6.0</string>
	<key>CFBundleName</key>
	<string>${PRODUCT_NAME}</string>
	<key>CFBundlePackageType</key>
	<string>APPL</string>
	<key>CFBundleShortVersionString</key>
	<string>1.0</string>
	<key>CFBundleSignature</key>
	<string>????</string>
	<key>CFBundleVersion</key>
	<string>1</string>
	<key>LSRequiresIPhoneOS</key>
	<true/>
	<key>UIRequiresFullScreen</key>
	<true/>
	<key>UILaunchStoryboardName</key>
	<string>Launch Screen</string>
	<key>UISupportedInterfaceOrientations</key>
	<array>
		<string>UIInterfaceOrientationPortrait</string>
		<string>UIInterfaceOrientationLandscapeLeft</string>
		<string>UIInterfaceOrientationLandscapeRight</string>
	</array>
	<key>UISupportedInterfaceOrientations~ipad</key>
	<array>
		<string>UIInterfaceOrientationPortrait</string>
		<string>UIInterfaceOrientationPortraitUpsideDown</string>
		<string>UIInterfaceOrientationLandscapeLeft</string>
		<string>UIInterfaceOrientationLandscapeRight</string>
	</array>
	<key>TestArgs</key>
	<array>
		<string>test</string> <!-- Invoke "python -m test" -->
        <string>-uall</string> <!-- Enable all resources -->
        <string>--single-process</string> <!-- always run all tests sequentially in a single process -->
        <string>--rerun</string> <!-- Re-run failed tests in verbose mode -->
        <string>-W</string> <!-- Display test output on failure -->
		<!-- To run a subset of tests, add the test names below; e.g.,
        <string>test_os</string>
        <string>test_sys</string>
		-->
    </array>
	<key>UIApplicationSceneManifest</key>
	<dict>
		<key>UIApplicationSupportsMultipleScenes</key>
		<false/>
		<key>UISceneConfigurations</key>
		<dict/>
	</dict>
</dict>
</plist>


================================================
File: /iOS/testbed/iOSTestbed/main.m
================================================
//
//  main.m
//  iOSTestbed
//

#import <UIKit/UIKit.h>
#import "AppDelegate.h"

int main(int argc, char * argv[]) {
    NSString * appDelegateClassName;
    @autoreleasepool {
        appDelegateClassName = NSStringFromClass([AppDelegate class]);

        return UIApplicationMain(argc, argv, nil, appDelegateClassName);
    }
}


================================================
File: /iOS/testbed/iOSTestbed/Assets.xcassets/Contents.json
================================================
{
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}


================================================
File: /iOS/testbed/iOSTestbed/Assets.xcassets/AccentColor.colorset/Contents.json
================================================
{
  "colors" : [
    {
      "idiom" : "universal"
    }
  ],
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}


================================================
File: /iOS/testbed/iOSTestbed/Assets.xcassets/AppIcon.appiconset/Contents.json
================================================
{
  "images" : [
    {
      "idiom" : "universal",
      "platform" : "ios",
      "size" : "1024x1024"
    }
  ],
  "info" : {
    "author" : "xcode",
    "version" : 1
  }
}


================================================
File: /iOS/testbed/iOSTestbed/Base.lproj/LaunchScreen.storyboard
================================================
<?xml version="1.0" encoding="UTF-8"?>
<document type="com.apple.InterfaceBuilder3.CocoaTouch.Storyboard.XIB" version="3.0" toolsVersion="22155" targetRuntime="iOS.CocoaTouch" propertyAccessControl="none" useAutolayout="YES" launchScreen="YES" useTraitCollections="YES" useSafeAreas="YES" colorMatched="YES">
    <device id="retina6_12" orientation="portrait" appearance="light"/>
    <dependencies>
        <deployment identifier="iOS"/>
        <plugIn identifier="com.apple.InterfaceBuilder.IBCocoaTouchPlugin" version="22131"/>
    </dependencies>
    <scenes/>
</document>


================================================
File: /iOS/testbed/iOSTestbed/app/README
================================================
This folder can contain any Python application code.

During the build, any binary modules found in this folder will be processed into
iOS Framework form.

When the test suite runs, this folder will be on the PYTHONPATH, and will be the
working directory for the test suite.


================================================
File: /iOS/testbed/iOSTestbed/app_packages/README
================================================
This folder can be a target for installing any Python dependencies needed by the
test suite.

During the build, any binary modules found in this folder will be processed into
iOS Framework form.

When the test suite runs, this folder will be on the PYTHONPATH.


================================================
File: /iOS/testbed/iOSTestbed.xcodeproj/project.pbxproj
================================================
// !$*UTF8*$!
{
	archiveVersion = 1;
	classes = {
	};
	objectVersion = 56;
	objects = {

/* Begin PBXBuildFile section */
		607A66172B0EFA380010BFC8 /* AppDelegate.m in Sources */ = {isa = PBXBuildFile; fileRef = 607A66162B0EFA380010BFC8 /* AppDelegate.m */; };
		607A66222B0EFA390010BFC8 /* Assets.xcassets in Resources */ = {isa = PBXBuildFile; fileRef = 607A66212B0EFA390010BFC8 /* Assets.xcassets */; };
		607A66252B0EFA390010BFC8 /* LaunchScreen.storyboard in Resources */ = {isa = PBXBuildFile; fileRef = 607A66232B0EFA390010BFC8 /* LaunchScreen.storyboard */; };
		607A66282B0EFA390010BFC8 /* main.m in Sources */ = {isa = PBXBuildFile; fileRef = 607A66272B0EFA390010BFC8 /* main.m */; };
		607A66322B0EFA3A0010BFC8 /* iOSTestbedTests.m in Sources */ = {isa = PBXBuildFile; fileRef = 607A66312B0EFA3A0010BFC8 /* iOSTestbedTests.m */; };
		607A664C2B0EFC080010BFC8 /* Python.xcframework in Frameworks */ = {isa = PBXBuildFile; fileRef = 607A664A2B0EFB310010BFC8 /* Python.xcframework */; };
		607A664D2B0EFC080010BFC8 /* Python.xcframework in Embed Frameworks */ = {isa = PBXBuildFile; fileRef = 607A664A2B0EFB310010BFC8 /* Python.xcframework */; settings = {ATTRIBUTES = (CodeSignOnCopy, RemoveHeadersOnCopy, ); }; };
		607A66502B0EFFE00010BFC8 /* Python.xcframework in Frameworks */ = {isa = PBXBuildFile; fileRef = 607A664A2B0EFB310010BFC8 /* Python.xcframework */; };
		607A66512B0EFFE00010BFC8 /* Python.xcframework in Embed Frameworks */ = {isa = PBXBuildFile; fileRef = 607A664A2B0EFB310010BFC8 /* Python.xcframework */; settings = {ATTRIBUTES = (CodeSignOnCopy, RemoveHeadersOnCopy, ); }; };
		607A66582B0F079F0010BFC8 /* dylib-Info-template.plist in Resources */ = {isa = PBXBuildFile; fileRef = 607A66572B0F079F0010BFC8 /* dylib-Info-template.plist */; };
		608619542CB77BA900F46182 /* app_packages in Resources */ = {isa = PBXBuildFile; fileRef = 608619532CB77BA900F46182 /* app_packages */; };
		608619562CB7819B00F46182 /* app in Resources */ = {isa = PBXBuildFile; fileRef = 608619552CB7819B00F46182 /* app */; };
/* End PBXBuildFile section */

/* Begin PBXContainerItemProxy section */
		607A662E2B0EFA3A0010BFC8 /* PBXContainerItemProxy */ = {
			isa = PBXContainerItemProxy;
			containerPortal = 607A660A2B0EFA380010BFC8 /* Project object */;
			proxyType = 1;
			remoteGlobalIDString = 607A66112B0EFA380010BFC8;
			remoteInfo = iOSTestbed;
		};
/* End PBXContainerItemProxy section */

/* Begin PBXCopyFilesBuildPhase section */
		607A664E2B0EFC080010BFC8 /* Embed Frameworks */ = {
			isa = PBXCopyFilesBuildPhase;
			buildActionMask = 2147483647;
			dstPath = "";
			dstSubfolderSpec = 10;
			files = (
				607A664D2B0EFC080010BFC8 /* Python.xcframework in Embed Frameworks */,
			);
			name = "Embed Frameworks";
			runOnlyForDeploymentPostprocessing = 0;
		};
		607A66522B0EFFE00010BFC8 /* Embed Frameworks */ = {
			isa = PBXCopyFilesBuildPhase;
			buildActionMask = 2147483647;
			dstPath = "";
			dstSubfolderSpec = 10;
			files = (
				607A66512B0EFFE00010BFC8 /* Python.xcframework in Embed Frameworks */,
			);
			name = "Embed Frameworks";
			runOnlyForDeploymentPostprocessing = 0;
		};
/* End PBXCopyFilesBuildPhase section */

/* Begin PBXFileReference section */
		607A66122B0EFA380010BFC8 /* iOSTestbed.app */ = {isa = PBXFileReference; explicitFileType = wrapper.application; includeInIndex = 0; path = iOSTestbed.app; sourceTree = BUILT_PRODUCTS_DIR; };
		607A66152B0EFA380010BFC8 /* AppDelegate.h */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.h; path = AppDelegate.h; sourceTree = "<group>"; };
		607A66162B0EFA380010BFC8 /* AppDelegate.m */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.objc; path = AppDelegate.m; sourceTree = "<group>"; };
		607A66212B0EFA390010BFC8 /* Assets.xcassets */ = {isa = PBXFileReference; lastKnownFileType = folder.assetcatalog; path = Assets.xcassets; sourceTree = "<group>"; };
		607A66242B0EFA390010BFC8 /* Base */ = {isa = PBXFileReference; lastKnownFileType = file.storyboard; name = Base; path = Base.lproj/LaunchScreen.storyboard; sourceTree = "<group>"; };
		607A66272B0EFA390010BFC8 /* main.m */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.objc; path = main.m; sourceTree = "<group>"; };
		607A662D2B0EFA3A0010BFC8 /* iOSTestbedTests.xctest */ = {isa = PBXFileReference; explicitFileType = wrapper.cfbundle; includeInIndex = 0; path = iOSTestbedTests.xctest; sourceTree = BUILT_PRODUCTS_DIR; };
		607A66312B0EFA3A0010BFC8 /* iOSTestbedTests.m */ = {isa = PBXFileReference; lastKnownFileType = sourcecode.c.objc; path = iOSTestbedTests.m; sourceTree = "<group>"; };
		607A664A2B0EFB310010BFC8 /* Python.xcframework */ = {isa = PBXFileReference; lastKnownFileType = wrapper.xcframework; path = Python.xcframework; sourceTree = "<group>"; };
		607A66572B0F079F0010BFC8 /* dylib-Info-template.plist */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = text.plist.xml; path = "dylib-Info-template.plist"; sourceTree = "<group>"; };
		607A66592B0F08600010BFC8 /* iOSTestbed-Info.plist */ = {isa = PBXFileReference; fileEncoding = 4; lastKnownFileType = text.plist.xml; path = "iOSTestbed-Info.plist"; sourceTree = "<group>"; };
		608619532CB77BA900F46182 /* app_packages */ = {isa = PBXFileReference; lastKnownFileType = folder; path = app_packages; sourceTree = "<group>"; };
		608619552CB7819B00F46182 /* app */ = {isa = PBXFileReference; lastKnownFileType = folder; path = app; sourceTree = "<group>"; };
/* End PBXFileReference section */

/* Begin PBXFrameworksBuildPhase section */
		607A660F2B0EFA380010BFC8 /* Frameworks */ = {
			isa = PBXFrameworksBuildPhase;
			buildActionMask = 2147483647;
			files = (
				607A664C2B0EFC080010BFC8 /* Python.xcframework in Frameworks */,
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
		607A662A2B0EFA3A0010BFC8 /* Frameworks */ = {
			isa = PBXFrameworksBuildPhase;
			buildActionMask = 2147483647;
			files = (
				607A66502B0EFFE00010BFC8 /* Python.xcframework in Frameworks */,
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
/* End PBXFrameworksBuildPhase section */

/* Begin PBXGroup section */
		607A66092B0EFA380010BFC8 = {
			isa = PBXGroup;
			children = (
				607A664A2B0EFB310010BFC8 /* Python.xcframework */,
				607A66142B0EFA380010BFC8 /* iOSTestbed */,
				607A66302B0EFA3A0010BFC8 /* iOSTestbedTests */,
				607A66132B0EFA380010BFC8 /* Products */,
				607A664F2B0EFFE00010BFC8 /* Frameworks */,
			);
			sourceTree = "<group>";
		};
		607A66132B0EFA380010BFC8 /* Products */ = {
			isa = PBXGroup;
			children = (
				607A66122B0EFA380010BFC8 /* iOSTestbed.app */,
				607A662D2B0EFA3A0010BFC8 /* iOSTestbedTests.xctest */,
			);
			name = Products;
			sourceTree = "<group>";
		};
		607A66142B0EFA380010BFC8 /* iOSTestbed */ = {
			isa = PBXGroup;
			children = (
				608619552CB7819B00F46182 /* app */,
				608619532CB77BA900F46182 /* app_packages */,
				607A66592B0F08600010BFC8 /* iOSTestbed-Info.plist */,
				607A66572B0F079F0010BFC8 /* dylib-Info-template.plist */,
				607A66152B0EFA380010BFC8 /* AppDelegate.h */,
				607A66162B0EFA380010BFC8 /* AppDelegate.m */,
				607A66212B0EFA390010BFC8 /* Assets.xcassets */,
				607A66232B0EFA390010BFC8 /* LaunchScreen.storyboard */,
				607A66272B0EFA390010BFC8 /* main.m */,
			);
			path = iOSTestbed;
			sourceTree = "<group>";
		};
		607A66302B0EFA3A0010BFC8 /* iOSTestbedTests */ = {
			isa = PBXGroup;
			children = (
				607A66312B0EFA3A0010BFC8 /* iOSTestbedTests.m */,
			);
			path = iOSTestbedTests;
			sourceTree = "<group>";
		};
		607A664F2B0EFFE00010BFC8 /* Frameworks */ = {
			isa = PBXGroup;
			children = (
			);
			name = Frameworks;
			sourceTree = "<group>";
		};
/* End PBXGroup section */

/* Begin PBXNativeTarget section */
		607A66112B0EFA380010BFC8 /* iOSTestbed */ = {
			isa = PBXNativeTarget;
			buildConfigurationList = 607A66412B0EFA3A0010BFC8 /* Build configuration list for PBXNativeTarget "iOSTestbed" */;
			buildPhases = (
				607A660E2B0EFA380010BFC8 /* Sources */,
				607A660F2B0EFA380010BFC8 /* Frameworks */,
				607A66102B0EFA380010BFC8 /* Resources */,
				607A66552B0F061D0010BFC8 /* Install Target Specific Python Standard Library */,
				607A66562B0F06200010BFC8 /* Prepare Python Binary Modules */,
				607A664E2B0EFC080010BFC8 /* Embed Frameworks */,
			);
			buildRules = (
			);
			dependencies = (
			);
			name = iOSTestbed;
			productName = iOSTestbed;
			productReference = 607A66122B0EFA380010BFC8 /* iOSTestbed.app */;
			productType = "com.apple.product-type.application";
		};
		607A662C2B0EFA3A0010BFC8 /* iOSTestbedTests */ = {
			isa = PBXNativeTarget;
			buildConfigurationList = 607A66442B0EFA3A0010BFC8 /* Build configuration list for PBXNativeTarget "iOSTestbedTests" */;
			buildPhases = (
				607A66292B0EFA3A0010BFC8 /* Sources */,
				607A662A2B0EFA3A0010BFC8 /* Frameworks */,
				607A662B2B0EFA3A0010BFC8 /* Resources */,
				607A66522B0EFFE00010BFC8 /* Embed Frameworks */,
			);
			buildRules = (
			);
			dependencies = (
				607A662F2B0EFA3A0010BFC8 /* PBXTargetDependency */,
			);
			name = iOSTestbedTests;
			productName = iOSTestbedTests;
			productReference = 607A662D2B0EFA3A0010BFC8 /* iOSTestbedTests.xctest */;
			productType = "com.apple.product-type.bundle.unit-test";
		};
/* End PBXNativeTarget section */

/* Begin PBXProject section */
		607A660A2B0EFA380010BFC8 /* Project object */ = {
			isa = PBXProject;
			attributes = {
				BuildIndependentTargetsInParallel = 1;
				LastUpgradeCheck = 1500;
				TargetAttributes = {
					607A66112B0EFA380010BFC8 = {
						CreatedOnToolsVersion = 15.0.1;
					};
					607A662C2B0EFA3A0010BFC8 = {
						CreatedOnToolsVersion = 15.0.1;
						TestTargetID = 607A66112B0EFA380010BFC8;
					};
				};
			};
			buildConfigurationList = 607A660D2B0EFA380010BFC8 /* Build configuration list for PBXProject "iOSTestbed" */;
			compatibilityVersion = "Xcode 14.0";
			developmentRegion = en;
			hasScannedForEncodings = 0;
			knownRegions = (
				en,
				Base,
			);
			mainGroup = 607A66092B0EFA380010BFC8;
			productRefGroup = 607A66132B0EFA380010BFC8 /* Products */;
			projectDirPath = "";
			projectRoot = "";
			targets = (
				607A66112B0EFA380010BFC8 /* iOSTestbed */,
				607A662C2B0EFA3A0010BFC8 /* iOSTestbedTests */,
			);
		};
/* End PBXProject section */

/* Begin PBXResourcesBuildPhase section */
		607A66102B0EFA380010BFC8 /* Resources */ = {
			isa = PBXResourcesBuildPhase;
			buildActionMask = 2147483647;
			files = (
				607A66252B0EFA390010BFC8 /* LaunchScreen.storyboard in Resources */,
				607A66582B0F079F0010BFC8 /* dylib-Info-template.plist in Resources */,
				608619562CB7819B00F46182 /* app in Resources */,
				607A66222B0EFA390010BFC8 /* Assets.xcassets in Resources */,
				608619542CB77BA900F46182 /* app_packages in Resources */,
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
		607A662B2B0EFA3A0010BFC8 /* Resources */ = {
			isa = PBXResourcesBuildPhase;
			buildActionMask = 2147483647;
			files = (
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
/* End PBXResourcesBuildPhase section */

/* Begin PBXShellScriptBuildPhase section */
		607A66552B0F061D0010BFC8 /* Install Target Specific Python Standard Library */ = {
			isa = PBXShellScriptBuildPhase;
			alwaysOutOfDate = 1;
			buildActionMask = 2147483647;
			files = (
			);
			inputFileListPaths = (
			);
			inputPaths = (
			);
			name = "Install Target Specific Python Standard Library";
			outputFileListPaths = (
			);
			outputPaths = (
			);
			runOnlyForDeploymentPostprocessing = 0;
			shellPath = /bin/sh;
			shellScript = "set -e\n\nmkdir -p \"$CODESIGNING_FOLDER_PATH/python/lib\"\nif [ \"$EFFECTIVE_PLATFORM_NAME\" = \"-iphonesimulator\" ]; then\n    echo \"Installing Python modules for iOS Simulator\"\n    rsync -au --delete \"$PROJECT_DIR/Python.xcframework/ios-arm64_x86_64-simulator/lib/\" \"$CODESIGNING_FOLDER_PATH/python/lib/\" \nelse\n    echo \"Installing Python modules for iOS Device\"\n    rsync -au --delete \"$PROJECT_DIR/Python.xcframework/ios-arm64/lib/\" \"$CODESIGNING_FOLDER_PATH/python/lib/\" \nfi\n";
			showEnvVarsInLog = 0;
		};
		607A66562B0F06200010BFC8 /* Prepare Python Binary Modules */ = {
			isa = PBXShellScriptBuildPhase;
			alwaysOutOfDate = 1;
			buildActionMask = 2147483647;
			files = (
			);
			inputFileListPaths = (
			);
			inputPaths = (
			);
			name = "Prepare Python Binary Modules";
			outputFileListPaths = (
			);
			outputPaths = (
			);
			runOnlyForDeploymentPostprocessing = 0;
			shellPath = /bin/sh;
			shellScript = "set -e\n\ninstall_dylib () {\n    INSTALL_BASE=$1\n    FULL_EXT=$2\n\n    # The name of the extension file\n    EXT=$(basename \"$FULL_EXT\")\n    # The location of the extension file, relative to the bundle\n    RELATIVE_EXT=${FULL_EXT#$CODESIGNING_FOLDER_PATH/} \n    # The path to the extension file, relative to the install base\n    PYTHON_EXT=${RELATIVE_EXT/$INSTALL_BASE/}\n    # The full dotted name of the extension module, constructed from the file path.\n    FULL_MODULE_NAME=$(echo $PYTHON_EXT | cut -d \".\" -f 1 | tr \"/\" \".\"); \n    # A bundle identifier; not actually used, but required by Xcode framework packaging\n    FRAMEWORK_BUNDLE_ID=$(echo $PRODUCT_BUNDLE_IDENTIFIER.$FULL_MODULE_NAME | tr \"_\" \"-\")\n    # The name of the framework folder.\n    FRAMEWORK_FOLDER=\"Frameworks/$FULL_MODULE_NAME.framework\"\n\n    # If the framework folder doesn't exist, create it.\n    if [ ! -d \"$CODESIGNING_FOLDER_PATH/$FRAMEWORK_FOLDER\" ]; then\n        echo \"Creating framework for $RELATIVE_EXT\" \n        mkdir -p \"$CODESIGNING_FOLDER_PATH/$FRAMEWORK_FOLDER\"\n        cp \"$CODESIGNING_FOLDER_PATH/dylib-Info-template.plist\" \"$CODESIGNING_FOLDER_PATH/$FRAMEWORK_FOLDER/Info.plist\"\n        plutil -replace CFBundleExecutable -string \"$FULL_MODULE_NAME\" \"$CODESIGNING_FOLDER_PATH/$FRAMEWORK_FOLDER/Info.plist\"\n        plutil -replace CFBundleIdentifier -string \"$FRAMEWORK_BUNDLE_ID\" \"$CODESIGNING_FOLDER_PATH/$FRAMEWORK_FOLDER/Info.plist\"\n    fi\n    \n    echo \"Installing binary for $FRAMEWORK_FOLDER/$FULL_MODULE_NAME\" \n    mv \"$FULL_EXT\" \"$CODESIGNING_FOLDER_PATH/$FRAMEWORK_FOLDER/$FULL_MODULE_NAME\"\n    # Create a placeholder .fwork file where the .so was\n    echo \"$FRAMEWORK_FOLDER/$FULL_MODULE_NAME\" > ${FULL_EXT%.so}.fwork\n    # Create a back reference to the .so file location in the framework\n    echo \"${RELATIVE_EXT%.so}.fwork\" > \"$CODESIGNING_FOLDER_PATH/$FRAMEWORK_FOLDER/$FULL_MODULE_NAME.origin\"             \n}\n\nPYTHON_VER=$(ls -1 \"$CODESIGNING_FOLDER_PATH/python/lib\")\necho \"Install Python $PYTHON_VER standard library extension modules...\"\nfind \"$CODESIGNING_FOLDER_PATH/python/lib/$PYTHON_VER/lib-dynload\" -name \"*.so\" | while read FULL_EXT; do\n    install_dylib python/lib/$PYTHON_VER/lib-dynload/ \"$FULL_EXT\"\ndone\necho \"Install app package extension modules...\"\nfind \"$CODESIGNING_FOLDER_PATH/app_packages\" -name \"*.so\" | while read FULL_EXT; do\n    install_dylib app_packages/ \"$FULL_EXT\"\ndone\necho \"Install app extension modules...\"\nfind \"$CODESIGNING_FOLDER_PATH/app\" -name \"*.so\" | while read FULL_EXT; do\n    install_dylib app/ \"$FULL_EXT\"\ndone\n\n# Clean up dylib template \nrm -f \"$CODESIGNING_FOLDER_PATH/dylib-Info-template.plist\"\necho \"Signing frameworks as $EXPANDED_CODE_SIGN_IDENTITY_NAME ($EXPANDED_CODE_SIGN_IDENTITY)...\"\nfind \"$CODESIGNING_FOLDER_PATH/Frameworks\" -name \"*.framework\" -exec /usr/bin/codesign --force --sign \"$EXPANDED_CODE_SIGN_IDENTITY\" ${OTHER_CODE_SIGN_FLAGS:-} -o runtime --timestamp=none --preserve-metadata=identifier,entitlements,flags --generate-entitlement-der \"{}\" \\; \n";
			showEnvVarsInLog = 0;
		};
/* End PBXShellScriptBuildPhase section */

/* Begin PBXSourcesBuildPhase section */
		607A660E2B0EFA380010BFC8 /* Sources */ = {
			isa = PBXSourcesBuildPhase;
			buildActionMask = 2147483647;
			files = (
				607A66172B0EFA380010BFC8 /* AppDelegate.m in Sources */,
				607A66282B0EFA390010BFC8 /* main.m in Sources */,
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
		607A66292B0EFA3A0010BFC8 /* Sources */ = {
			isa = PBXSourcesBuildPhase;
			buildActionMask = 2147483647;
			files = (
				607A66322B0EFA3A0010BFC8 /* iOSTestbedTests.m in Sources */,
			);
			runOnlyForDeploymentPostprocessing = 0;
		};
/* End PBXSourcesBuildPhase section */

/* Begin PBXTargetDependency section */
		607A662F2B0EFA3A0010BFC8 /* PBXTargetDependency */ = {
			isa = PBXTargetDependency;
			target = 607A66112B0EFA380010BFC8 /* iOSTestbed */;
			targetProxy = 607A662E2B0EFA3A0010BFC8 /* PBXContainerItemProxy */;
		};
/* End PBXTargetDependency section */

/* Begin PBXVariantGroup section */
		607A66232B0EFA390010BFC8 /* LaunchScreen.storyboard */ = {
			isa = PBXVariantGroup;
			children = (
				607A66242B0EFA390010BFC8 /* Base */,
			);
			name = LaunchScreen.storyboard;
			sourceTree = "<group>";
		};
/* End PBXVariantGroup section */

/* Begin XCBuildConfiguration section */
		607A663F2B0EFA3A0010BFC8 /* Debug */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				ALWAYS_SEARCH_USER_PATHS = NO;
				ASSETCATALOG_COMPILER_GENERATE_SWIFT_ASSET_SYMBOL_EXTENSIONS = YES;
				CLANG_ANALYZER_NONNULL = YES;
				CLANG_ANALYZER_NUMBER_OBJECT_CONVERSION = YES_AGGRESSIVE;
				CLANG_CXX_LANGUAGE_STANDARD = "gnu++20";
				CLANG_ENABLE_MODULES = YES;
				CLANG_ENABLE_OBJC_ARC = YES;
				CLANG_ENABLE_OBJC_WEAK = YES;
				CLANG_WARN_BLOCK_CAPTURE_AUTORELEASING = YES;
				CLANG_WARN_BOOL_CONVERSION = YES;
				CLANG_WARN_COMMA = YES;
				CLANG_WARN_CONSTANT_CONVERSION = YES;
				CLANG_WARN_DEPRECATED_OBJC_IMPLEMENTATIONS = YES;
				CLANG_WARN_DIRECT_OBJC_ISA_USAGE = YES_ERROR;
				CLANG_WARN_DOCUMENTATION_COMMENTS = YES;
				CLANG_WARN_EMPTY_BODY = YES;
				CLANG_WARN_ENUM_CONVERSION = YES;
				CLANG_WARN_INFINITE_RECURSION = YES;
				CLANG_WARN_INT_CONVERSION = YES;
				CLANG_WARN_NON_LITERAL_NULL_CONVERSION = YES;
				CLANG_WARN_OBJC_IMPLICIT_RETAIN_SELF = YES;
				CLANG_WARN_OBJC_LITERAL_CONVERSION = YES;
				CLANG_WARN_OBJC_ROOT_CLASS = YES_ERROR;
				CLANG_WARN_QUOTED_INCLUDE_IN_FRAMEWORK_HEADER = YES;
				CLANG_WARN_RANGE_LOOP_ANALYSIS = YES;
				CLANG_WARN_STRICT_PROTOTYPES = YES;
				CLANG_WARN_SUSPICIOUS_MOVE = YES;
				CLANG_WARN_UNGUARDED_AVAILABILITY = YES_AGGRESSIVE;
				CLANG_WARN_UNREACHABLE_CODE = YES;
				CLANG_WARN__DUPLICATE_METHOD_MATCH = YES;
				COPY_PHASE_STRIP = NO;
				DEBUG_INFORMATION_FORMAT = dwarf;
				ENABLE_STRICT_OBJC_MSGSEND = YES;
				ENABLE_TESTABILITY = YES;
				ENABLE_USER_SCRIPT_SANDBOXING = YES;
				GCC_C_LANGUAGE_STANDARD = gnu17;
				GCC_DYNAMIC_NO_PIC = NO;
				GCC_NO_COMMON_BLOCKS = YES;
				GCC_OPTIMIZATION_LEVEL = 0;
				GCC_PREPROCESSOR_DEFINITIONS = (
					"DEBUG=1",
					"$(inherited)",
				);
				GCC_WARN_64_TO_32_BIT_CONVERSION = YES;
				GCC_WARN_ABOUT_RETURN_TYPE = YES_ERROR;
				GCC_WARN_UNDECLARED_SELECTOR = YES;
				GCC_WARN_UNINITIALIZED_AUTOS = YES_AGGRESSIVE;
				GCC_WARN_UNUSED_FUNCTION = YES;
				GCC_WARN_UNUSED_VARIABLE = YES;
				IPHONEOS_DEPLOYMENT_TARGET = 12.0;
				LOCALIZATION_PREFERS_STRING_CATALOGS = YES;
				MTL_ENABLE_DEBUG_INFO = INCLUDE_SOURCE;
				MTL_FAST_MATH = YES;
				ONLY_ACTIVE_ARCH = YES;
				SDKROOT = iphoneos;
			};
			name = Debug;
		};
		607A66402B0EFA3A0010BFC8 /* Release */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				ALWAYS_SEARCH_USER_PATHS = NO;
				ASSETCATALOG_COMPILER_GENERATE_SWIFT_ASSET_SYMBOL_EXTENSIONS = YES;
				CLANG_ANALYZER_NONNULL = YES;
				CLANG_ANALYZER_NUMBER_OBJECT_CONVERSION = YES_AGGRESSIVE;
				CLANG_CXX_LANGUAGE_STANDARD = "gnu++20";
				CLANG_ENABLE_MODULES = YES;
				CLANG_ENABLE_OBJC_ARC = YES;
				CLANG_ENABLE_OBJC_WEAK = YES;
				CLANG_WARN_BLOCK_CAPTURE_AUTORELEASING = YES;
				CLANG_WARN_BOOL_CONVERSION = YES;
				CLANG_WARN_COMMA = YES;
				CLANG_WARN_CONSTANT_CONVERSION = YES;
				CLANG_WARN_DEPRECATED_OBJC_IMPLEMENTATIONS = YES;
				CLANG_WARN_DIRECT_OBJC_ISA_USAGE = YES_ERROR;
				CLANG_WARN_DOCUMENTATION_COMMENTS = YES;
				CLANG_WARN_EMPTY_BODY = YES;
				CLANG_WARN_ENUM_CONVERSION = YES;
				CLANG_WARN_INFINITE_RECURSION = YES;
				CLANG_WARN_INT_CONVERSION = YES;
				CLANG_WARN_NON_LITERAL_NULL_CONVERSION = YES;
				CLANG_WARN_OBJC_IMPLICIT_RETAIN_SELF = YES;
				CLANG_WARN_OBJC_LITERAL_CONVERSION = YES;
				CLANG_WARN_OBJC_ROOT_CLASS = YES_ERROR;
				CLANG_WARN_QUOTED_INCLUDE_IN_FRAMEWORK_HEADER = YES;
				CLANG_WARN_RANGE_LOOP_ANALYSIS = YES;
				CLANG_WARN_STRICT_PROTOTYPES = YES;
				CLANG_WARN_SUSPICIOUS_MOVE = YES;
				CLANG_WARN_UNGUARDED_AVAILABILITY = YES_AGGRESSIVE;
				CLANG_WARN_UNREACHABLE_CODE = YES;
				CLANG_WARN__DUPLICATE_METHOD_MATCH = YES;
				COPY_PHASE_STRIP = NO;
				DEBUG_INFORMATION_FORMAT = "dwarf-with-dsym";
				ENABLE_NS_ASSERTIONS = NO;
				ENABLE_STRICT_OBJC_MSGSEND = YES;
				ENABLE_USER_SCRIPT_SANDBOXING = YES;
				GCC_C_LANGUAGE_STANDARD = gnu17;
				GCC_NO_COMMON_BLOCKS = YES;
				GCC_WARN_64_TO_32_BIT_CONVERSION = YES;
				GCC_WARN_ABOUT_RETURN_TYPE = YES_ERROR;
				GCC_WARN_UNDECLARED_SELECTOR = YES;
				GCC_WARN_UNINITIALIZED_AUTOS = YES_AGGRESSIVE;
				GCC_WARN_UNUSED_FUNCTION = YES;
				GCC_WARN_UNUSED_VARIABLE = YES;
				IPHONEOS_DEPLOYMENT_TARGET = 12.0;
				LOCALIZATION_PREFERS_STRING_CATALOGS = YES;
				MTL_ENABLE_DEBUG_INFO = NO;
				MTL_FAST_MATH = YES;
				SDKROOT = iphoneos;
				VALIDATE_PRODUCT = YES;
			};
			name = Release;
		};
		607A66422B0EFA3A0010BFC8 /* Debug */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				ASSETCATALOG_COMPILER_APPICON_NAME = AppIcon;
				ASSETCATALOG_COMPILER_GLOBAL_ACCENT_COLOR_NAME = AccentColor;
				CLANG_WARN_QUOTED_INCLUDE_IN_FRAMEWORK_HEADER = NO;
				CODE_SIGN_STYLE = Automatic;
				CURRENT_PROJECT_VERSION = 1;
				DEVELOPMENT_TEAM = "";
				ENABLE_USER_SCRIPT_SANDBOXING = NO;
				HEADER_SEARCH_PATHS = "\"$(BUILT_PRODUCTS_DIR)/Python.framework/Headers\"";
				INFOPLIST_FILE = "iOSTestbed/iOSTestbed-Info.plist";
				INFOPLIST_KEY_UIApplicationSupportsIndirectInputEvents = YES;
				INFOPLIST_KEY_UILaunchStoryboardName = LaunchScreen;
				INFOPLIST_KEY_UIMainStoryboardFile = Main;
				INFOPLIST_KEY_UISupportedInterfaceOrientations_iPad = "UIInterfaceOrientationPortrait UIInterfaceOrientationPortraitUpsideDown UIInterfaceOrientationLandscapeLeft UIInterfaceOrientationLandscapeRight";
				INFOPLIST_KEY_UISupportedInterfaceOrientations_iPhone = "UIInterfaceOrientationPortrait UIInterfaceOrientationLandscapeLeft UIInterfaceOrientationLandscapeRight";
				IPHONEOS_DEPLOYMENT_TARGET = 12.0;
				LD_RUNPATH_SEARCH_PATHS = (
					"$(inherited)",
					"@executable_path/Frameworks",
				);
				MARKETING_VERSION = 3.13.0a1;
				PRODUCT_BUNDLE_IDENTIFIER = org.python.iOSTestbed;
				PRODUCT_NAME = "$(TARGET_NAME)";
				SWIFT_EMIT_LOC_STRINGS = YES;
				TARGETED_DEVICE_FAMILY = "1,2";
			};
			name = Debug;
		};
		607A66432B0EFA3A0010BFC8 /* Release */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				ASSETCATALOG_COMPILER_APPICON_NAME = AppIcon;
				ASSETCATALOG_COMPILER_GLOBAL_ACCENT_COLOR_NAME = AccentColor;
				CLANG_WARN_QUOTED_INCLUDE_IN_FRAMEWORK_HEADER = NO;
				CODE_SIGN_STYLE = Automatic;
				CURRENT_PROJECT_VERSION = 1;
				DEVELOPMENT_TEAM = "";
				ENABLE_TESTABILITY = YES;
				ENABLE_USER_SCRIPT_SANDBOXING = NO;
				HEADER_SEARCH_PATHS = "\"$(BUILT_PRODUCTS_DIR)/Python.framework/Headers\"";
				INFOPLIST_FILE = "iOSTestbed/iOSTestbed-Info.plist";
				INFOPLIST_KEY_UIApplicationSupportsIndirectInputEvents = YES;
				INFOPLIST_KEY_UILaunchStoryboardName = LaunchScreen;
				INFOPLIST_KEY_UIMainStoryboardFile = Main;
				INFOPLIST_KEY_UISupportedInterfaceOrientations_iPad = "UIInterfaceOrientationPortrait UIInterfaceOrientationPortraitUpsideDown UIInterfaceOrientationLandscapeLeft UIInterfaceOrientationLandscapeRight";
				INFOPLIST_KEY_UISupportedInterfaceOrientations_iPhone = "UIInterfaceOrientationPortrait UIInterfaceOrientationLandscapeLeft UIInterfaceOrientationLandscapeRight";
				IPHONEOS_DEPLOYMENT_TARGET = 12.0;
				LD_RUNPATH_SEARCH_PATHS = (
					"$(inherited)",
					"@executable_path/Frameworks",
				);
				MARKETING_VERSION = 3.13.0a1;
				PRODUCT_BUNDLE_IDENTIFIER = org.python.iOSTestbed;
				PRODUCT_NAME = "$(TARGET_NAME)";
				SWIFT_EMIT_LOC_STRINGS = YES;
				TARGETED_DEVICE_FAMILY = "1,2";
			};
			name = Release;
		};
		607A66452B0EFA3A0010BFC8 /* Debug */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				BUNDLE_LOADER = "$(TEST_HOST)";
				CLANG_WARN_QUOTED_INCLUDE_IN_FRAMEWORK_HEADER = NO;
				CODE_SIGN_STYLE = Automatic;
				CURRENT_PROJECT_VERSION = 1;
				DEVELOPMENT_TEAM = 3HEZE76D99;
				GENERATE_INFOPLIST_FILE = YES;
				HEADER_SEARCH_PATHS = "\"$(BUILT_PRODUCTS_DIR)/Python.framework/Headers\"";
				IPHONEOS_DEPLOYMENT_TARGET = 12.0;
				MARKETING_VERSION = 1.0;
				PRODUCT_BUNDLE_IDENTIFIER = org.python.iOSTestbedTests;
				PRODUCT_NAME = "$(TARGET_NAME)";
				SWIFT_EMIT_LOC_STRINGS = NO;
				TARGETED_DEVICE_FAMILY = "1,2";
				TEST_HOST = "$(BUILT_PRODUCTS_DIR)/iOSTestbed.app/$(BUNDLE_EXECUTABLE_FOLDER_PATH)/iOSTestbed";
			};
			name = Debug;
		};
		607A66462B0EFA3A0010BFC8 /* Release */ = {
			isa = XCBuildConfiguration;
			buildSettings = {
				BUNDLE_LOADER = "$(TEST_HOST)";
				CLANG_WARN_QUOTED_INCLUDE_IN_FRAMEWORK_HEADER = NO;
				CODE_SIGN_STYLE = Automatic;
				CURRENT_PROJECT_VERSION = 1;
				DEVELOPMENT_TEAM = 3HEZE76D99;
				GENERATE_INFOPLIST_FILE = YES;
				HEADER_SEARCH_PATHS = "\"$(BUILT_PRODUCTS_DIR)/Python.framework/Headers\"";
				IPHONEOS_DEPLOYMENT_TARGET = 12.0;
				MARKETING_VERSION = 1.0;
				PRODUCT_BUNDLE_IDENTIFIER = org.python.iOSTestbedTests;
				PRODUCT_NAME = "$(TARGET_NAME)";
				SWIFT_EMIT_LOC_STRINGS = NO;
				TARGETED_DEVICE_FAMILY = "1,2";
				TEST_HOST = "$(BUILT_PRODUCTS_DIR)/iOSTestbed.app/$(BUNDLE_EXECUTABLE_FOLDER_PATH)/iOSTestbed";
			};
			name = Release;
		};
/* End XCBuildConfiguration section */

/* Begin XCConfigurationList section */
		607A660D2B0EFA380010BFC8 /* Build configuration list for PBXProject "iOSTestbed" */ = {
			isa = XCConfigurationList;
			buildConfigurations = (
				607A663F2B0EFA3A0010BFC8 /* Debug */,
				607A66402B0EFA3A0010BFC8 /* Release */,
			);
			defaultConfigurationIsVisible = 0;
			defaultConfigurationName = Release;
		};
		607A66412B0EFA3A0010BFC8 /* Build configuration list for PBXNativeTarget "iOSTestbed" */ = {
			isa = XCConfigurationList;
			buildConfigurations = (
				607A66422B0EFA3A0010BFC8 /* Debug */,
				607A66432B0EFA3A0010BFC8 /* Release */,
			);
			defaultConfigurationIsVisible = 0;
			defaultConfigurationName = Release;
		};
		607A66442B0EFA3A0010BFC8 /* Build configuration list for PBXNativeTarget "iOSTestbedTests" */ = {
			isa = XCConfigurationList;
			buildConfigurations = (
				607A66452B0EFA3A0010BFC8 /* Debug */,
				607A66462B0EFA3A0010BFC8 /* Release */,
			);
			defaultConfigurationIsVisible = 0;
			defaultConfigurationName = Release;
		};
/* End XCConfigurationList section */
	};
	rootObject = 607A660A2B0EFA380010BFC8 /* Project object */;
}


================================================
File: /iOS/testbed/iOSTestbedTests/iOSTestbedTests.m
================================================
#import <XCTest/XCTest.h>
#import <Python/Python.h>

@interface iOSTestbedTests : XCTestCase

@end

@implementation iOSTestbedTests


- (void)testPython {
    const char **argv;
    int exit_code;
    int failed;
    PyStatus status;
    PyPreConfig preconfig;
    PyConfig config;
    PyObject *sys_module;
    PyObject *sys_path_attr;
    NSArray *test_args;
    NSString *python_home;
    NSString *path;
    wchar_t *wtmp_str;

    NSString *resourcePath = [[NSBundle mainBundle] resourcePath];

    // Set some other common environment indicators to disable color, as the
    // Xcode log can't display color. Stdout will report that it is *not* a
    // TTY.
    setenv("NO_COLOR", "1", true);
    setenv("PY_COLORS", "0", true);

    // Arguments to pass into the test suite runner.
    // argv[0] must identify the process; any subsequent arg
    // will be handled as if it were an argument to `python -m test`
    test_args = [[NSBundle mainBundle] objectForInfoDictionaryKey:@"TestArgs"];
    if (test_args == NULL) {
        NSLog(@"Unable to identify test arguments.");
    }
    argv = malloc(sizeof(char *) * ([test_args count] + 1));
    argv[0] = "iOSTestbed";
    for (int i = 1; i < [test_args count]; i++) {
        argv[i] = [[test_args objectAtIndex:i] UTF8String];
    }
    NSLog(@"Test command: %@", test_args);

    // Generate an isolated Python configuration.
    NSLog(@"Configuring isolated Python...");
    PyPreConfig_InitIsolatedConfig(&preconfig);
    PyConfig_InitIsolatedConfig(&config);

    // Configure the Python interpreter:
    // Enforce UTF-8 encoding for stderr, stdout, file-system encoding and locale.
    // See https://docs.python.org/3/library/os.html#python-utf-8-mode.
    preconfig.utf8_mode = 1;
    // Use the system logger for stdout/err
    config.use_system_logger = 1;
    // Don't buffer stdio. We want output to appears in the log immediately
    config.buffered_stdio = 0;
    // Don't write bytecode; we can't modify the app bundle
    // after it has been signed.
    config.write_bytecode = 0;
    // Ensure that signal handlers are installed
    config.install_signal_handlers = 1;
    // Run the test module.
    config.run_module = Py_DecodeLocale([[test_args objectAtIndex:0] UTF8String], NULL);
    // For debugging - enable verbose mode.
    // config.verbose = 1;

    NSLog(@"Pre-initializing Python runtime...");
    status = Py_PreInitialize(&preconfig);
    if (PyStatus_Exception(status)) {
        XCTFail(@"Unable to pre-initialize Python interpreter: %s", status.err_msg);
        PyConfig_Clear(&config);
        return;
    }

    // Set the home for the Python interpreter
    python_home = [NSString stringWithFormat:@"%@/python", resourcePath, nil];
    NSLog(@"PythonHome: %@", python_home);
    wtmp_str = Py_DecodeLocale([python_home UTF8String], NULL);
    status = PyConfig_SetString(&config, &config.home, wtmp_str);
    if (PyStatus_Exception(status)) {
        XCTFail(@"Unable to set PYTHONHOME: %s", status.err_msg);
        PyConfig_Clear(&config);
        return;
    }
    PyMem_RawFree(wtmp_str);

    // Read the site config
    status = PyConfig_Read(&config);
    if (PyStatus_Exception(status)) {
        XCTFail(@"Unable to read site config: %s", status.err_msg);
        PyConfig_Clear(&config);
        return;
    }

    NSLog(@"Configure argc/argv...");
    status = PyConfig_SetBytesArgv(&config, [test_args count], (char**) argv);
    if (PyStatus_Exception(status)) {
        XCTFail(@"Unable to configure argc/argv: %s", status.err_msg);
        PyConfig_Clear(&config);
        return;
    }

    NSLog(@"Initializing Python runtime...");
    status = Py_InitializeFromConfig(&config);
    if (PyStatus_Exception(status)) {
        XCTFail(@"Unable to initialize Python interpreter: %s", status.err_msg);
        PyConfig_Clear(&config);
        return;
    }

    sys_module = PyImport_ImportModule("sys");
    if (sys_module == NULL) {
        XCTFail(@"Could not import sys module");
        return;
    }

    sys_path_attr = PyObject_GetAttrString(sys_module, "path");
    if (sys_path_attr == NULL) {
        XCTFail(@"Could not access sys.path");
        return;
    }

    // Add the app packages path
    path = [NSString stringWithFormat:@"%@/app_packages", resourcePath, nil];
    NSLog(@"App packages path: %@", path);
    wtmp_str = Py_DecodeLocale([path UTF8String], NULL);
    failed = PyList_Insert(sys_path_attr, 0, PyUnicode_FromString([path UTF8String]));
    if (failed) {
        XCTFail(@"Unable to add app packages to sys.path");
        return;
    }
    PyMem_RawFree(wtmp_str);

    path = [NSString stringWithFormat:@"%@/app", resourcePath, nil];
    NSLog(@"App path: %@", path);
    wtmp_str = Py_DecodeLocale([path UTF8String], NULL);
    failed = PyList_Insert(sys_path_attr, 0, PyUnicode_FromString([path UTF8String]));
    if (failed) {
        XCTFail(@"Unable to add app to sys.path");
        return;
    }
    PyMem_RawFree(wtmp_str);

    // Ensure the working directory is the app folder.
    chdir([path UTF8String]);

    // Start the test suite. Print a separator to differentiate Python startup logs from app logs
    NSLog(@"---------------------------------------------------------------------------");

    exit_code = Py_RunMain();
    XCTAssertEqual(exit_code, 0, @"Test suite did not pass");

    NSLog(@"---------------------------------------------------------------------------");

    Py_Finalize();
}


@end


================================================
File: /.azure-pipelines/ci.yml
================================================
trigger: ['main', '3.13', '3.12', '3.11', '3.10', '3.9', '3.8']

jobs:
- job: Prebuild
  displayName: Pre-build checks

  pool:
    vmImage: ubuntu-24.04

  steps:
  - template: ./prebuild-checks.yml


- job: Windows_CI_Tests
  displayName: Windows CI Tests
  dependsOn: Prebuild
  condition: and(succeeded(), eq(dependencies.Prebuild.outputs['tests.run'], 'true'))

  pool:
    vmImage: windows-2022

  strategy:
    matrix:
      win32:
        arch: win32
        buildOpt: '-p Win32'
        testRunTitle: '$(Build.SourceBranchName)-win32'
        testRunPlatform: win32
      win64:
        arch: amd64
        buildOpt: '-p x64'
        testRunTitle: '$(Build.SourceBranchName)-win64'
        testRunPlatform: win64
    maxParallel: 4

  steps:
  - template: ./windows-steps.yml

  - template: ./windows-layout-steps.yml
    parameters:
      kind: nuget
  - template: ./windows-layout-steps.yml
    parameters:
      kind: embed
  - template: ./windows-layout-steps.yml
    parameters:
      kind: appx
      fulltest: true


================================================
File: /.azure-pipelines/prebuild-checks.yml
================================================
steps:
- checkout: self
  fetchDepth: 5

- script: echo "##vso[task.setvariable variable=diffTarget]HEAD~1"
  displayName: Set default diff target

- script: |
    git fetch -q origin $(System.PullRequest.TargetBranch)
    echo "##vso[task.setvariable variable=diffTarget]HEAD \$(git merge-base HEAD FETCH_HEAD)"
  displayName: Fetch comparison tree
  condition: and(succeeded(), variables['System.PullRequest.TargetBranch'])

- script: |
   if ! git diff --name-only $(diffTarget) | grep -qvE '(\.rst$|^Doc|^Misc)'
   then
     echo "Only docs were updated: tests.run=false"
     echo "##vso[task.setvariable variable=run;isOutput=true]false"
   else
     echo "Code was updated: tests.run=true"
     echo "##vso[task.setvariable variable=run;isOutput=true]true"
   fi
  displayName: Detect source changes
  name: tests


================================================
File: /.azure-pipelines/windows-layout-steps.yml
================================================
parameters:
  kind: nuget
  extraOpts: --precompile
  fulltest: false

steps:
- script: .\python.bat PC\layout -vv -s "$(Build.SourcesDirectory)" -b "$(Py_OutDir)\$(arch)" -t "$(Build.BinariesDirectory)\layout-tmp-${{ parameters.kind }}-$(arch)" --copy "$(Build.BinariesDirectory)\layout-${{ parameters.kind }}-$(arch)" ${{ parameters.extraOpts }} --preset-${{ parameters.kind }} --include-tests
  displayName: Create ${{ parameters.kind }} layout

- script: .\python.exe -m test.pythoninfo
  workingDirectory: $(Build.BinariesDirectory)\layout-${{ parameters.kind }}-$(arch)
  displayName: Show layout info (${{ parameters.kind }})

- ${{ if eq(parameters.fulltest, 'true') }}:
  - script: .\python.exe -m test -q -uall -u-cpu -rwW --slowest --timeout=1200 -j0 --junit-xml="$(Build.BinariesDirectory)\test-results-${{ parameters.kind }}.xml" --tempdir "$(Build.BinariesDirectory)\tmp-${{ parameters.kind }}-$(arch)" -i test_launcher
    workingDirectory: $(Build.BinariesDirectory)\layout-${{ parameters.kind }}-$(arch)
    displayName: ${{ parameters.kind }} Tests
    env:
      PREFIX: $(Build.BinariesDirectory)\layout-${{ parameters.kind }}-$(arch)

  - task: PublishTestResults@2
    displayName: Publish ${{ parameters.kind }} Test Results
    inputs:
      testResultsFiles: $(Build.BinariesDirectory)\test-results-${{ parameters.kind }}.xml
      mergeTestResults: true
      testRunTitle: ${{ parameters.kind }}-$(testRunTitle)
      platform: $(testRunPlatform)
    condition: succeededOrFailed()


================================================
File: /.azure-pipelines/windows-steps.yml
================================================
steps:
- checkout: self
  clean: false
  fetchDepth: 5

- powershell: |
    # Relocate build outputs outside of source directory to make cleaning faster
    Write-Host '##vso[task.setvariable variable=Py_IntDir]$(Build.BinariesDirectory)\obj'
    # UNDONE: Do not build to a different directory because of broken tests
    Write-Host '##vso[task.setvariable variable=Py_OutDir]$(Build.SourcesDirectory)\PCbuild'
    #Write-Host '##vso[task.setvariable variable=Py_OutDir]$(Build.BinariesDirectory)\bin'
    Write-Host '##vso[task.setvariable variable=EXTERNALS_DIR]$(Build.BinariesDirectory)\externals'
  displayName: Update build locations

- script: PCbuild\build.bat -e $(buildOpt)
  displayName: 'Build CPython'
  env:
    IncludeUwp: true

- script: python.bat -m test.pythoninfo
  displayName: 'Display build info'
  condition: and(succeeded(), variables['testRunPlatform'])

- script: PCbuild\rt.bat -q -uall -u-cpu -rwW --slowest --timeout=1200 -j0 --junit-xml="$(Build.BinariesDirectory)\test-results.xml" --tempdir="$(Build.BinariesDirectory)\test"
  displayName: 'Tests'
  condition: and(succeeded(), variables['testRunPlatform'])
  env:
    PREFIX: $(Py_OutDir)\$(arch)

- task: PublishTestResults@2
  displayName: 'Publish Test Results'
  inputs:
    testResultsFiles: '$(Build.BinariesDirectory)\test-results.xml'
    mergeTestResults: true
    testRunTitle: $(testRunTitle)
    platform: $(testRunPlatform)
  condition: and(succeededOrFailed(), variables['testRunPlatform'])


================================================
File: /.devcontainer/devcontainer.json
================================================
{
    "image": "ghcr.io/python/devcontainer:2024.09.25.11038928730",
    "onCreateCommand": [
        // Install common tooling.
        "dnf",
        "install",
        "-y",
        "which",
        "zsh",
        "fish",
        // For umask fix below.
        "/usr/bin/setfacl"
    ],
    "updateContentCommand": {
        // Using the shell for `nproc` usage.
        "python": "./configure --config-cache --with-pydebug && make -s -j `nproc`",
        "docs": [
            "make",
            "--directory",
            "Doc",
            "venv",
            "html"
        ]
    },
    "postCreateCommand": {
        // https://github.com/orgs/community/discussions/26026
        "umask fix: workspace": ["sudo", "setfacl", "-bnR", "."],
        "umask fix: /tmp": ["sudo", "setfacl", "-bnR", "/tmp"]
    },
    "customizations": {
        "vscode": {
            "extensions": [
                // Highlighting for Parser/Python.asdl.
                "brettcannon.zephyr-asdl",
                // Highlighting for configure.ac.
                "maelvalais.autoconf",
                // C auto-complete.
                "ms-vscode.cpptools",
                // To view HTML build of docs.
                "ms-vscode.live-server",
                // Python auto-complete.
                "ms-python.python"
            ],
            "settings": {
                "C_Cpp.default.compilerPath": "/usr/bin/clang",
                "C_Cpp.default.cStandard": "c11",
                "C_Cpp.default.defines": [
                    "CONFIG_64",
                    "Py_BUILD_CORE"
                ],
                "C_Cpp.default.includePath": [
                    "${workspaceFolder}/*",
                    "${workspaceFolder}/Include/**"
                ],
                // https://github.com/microsoft/vscode-cpptools/issues/10732
                "C_Cpp.errorSquiggles": "disabled",
                "editor.insertSpaces": true,
                "editor.rulers": [
                    80
                ],
                "editor.tabSize": 4,
                "editor.trimAutoWhitespace": true,
                "files.associations": {
                    "*.h": "c"
                },
                "files.encoding": "utf8",
                "files.eol": "\n",
                "files.insertFinalNewline": true,
                "files.trimTrailingWhitespace": true,
                "python.analysis.diagnosticSeverityOverrides": {
                    // Complains about shadowing the stdlib w/ the stdlib.
                    "reportShadowedImports": "none",
                    // Doesn't like _frozen_importlib.
                    "reportMissingImports": "none"
                },
                "python.analysis.extraPaths": [
                    "Lib"
                ],
                "python.defaultInterpreterPath": "./python",
                "[restructuredtext]": {
                    "editor.tabSize": 3
                }
            }
        }
    }
}


================================================
File: /.github/CODEOWNERS
================================================
# See https://help.github.com/articles/about-codeowners/
# for more info about CODEOWNERS file

# It uses the same pattern rule for gitignore file
# https://git-scm.com/docs/gitignore#_pattern_format

# GitHub
.github/**                    @ezio-melotti @hugovk

# pre-commit
.pre-commit-config.yaml       @hugovk @AlexWaygood
.ruff.toml                    @hugovk @AlexWaygood

# Build system
configure*                    @erlend-aasland @corona10
Makefile.pre.in               @erlend-aasland
Modules/Setup*                @erlend-aasland

# argparse
**/*argparse*                 @savannahostrowski

# asyncio
**/*asyncio*                  @1st1 @asvetlov @kumaraditya303 @willingc

# Core
**/*context*                  @1st1
**/*genobject*                @markshannon
**/*hamt*                     @1st1
**/*jit*                      @brandtbucher @savannahostrowski
Objects/set*                  @rhettinger
Objects/dict*                 @methane @markshannon
Objects/typevarobject.c       @JelleZijlstra
Objects/type*                 @markshannon
Objects/codeobject.c          @markshannon
Objects/frameobject.c         @markshannon
Objects/call.c                @markshannon
Python/ceval*.c               @markshannon
Python/ceval*.h               @markshannon
Python/codegen.c              @markshannon @iritkatriel
Python/compile.c              @markshannon @iritkatriel
Python/assemble.c             @markshannon @iritkatriel
Python/flowgraph.c            @markshannon @iritkatriel
Python/instruction_sequence.c @iritkatriel
Python/bytecodes.c            @markshannon
Python/optimizer*.c           @markshannon
Python/optimizer_analysis.c   @Fidget-Spinner
Python/optimizer_bytecodes.c  @Fidget-Spinner
Python/symtable.c             @JelleZijlstra @carljm
Lib/_pyrepl/*                 @pablogsal @lysnikolaou @ambv
Lib/test/test_patma.py        @brandtbucher
Lib/test/test_type_*.py       @JelleZijlstra
Lib/test/test_capi/test_misc.py  @markshannon
Lib/test/test_pyrepl/*        @pablogsal @lysnikolaou @ambv
Tools/c-analyzer/             @ericsnowcurrently

# dbm
**/*dbm*                      @corona10 @erlend-aasland @serhiy-storchaka

# runtime state/lifecycle
**/*pylifecycle*              @ericsnowcurrently
**/*pystate*                  @ericsnowcurrently
**/*preconfig*                @ericsnowcurrently
**/*initconfig*               @ericsnowcurrently
**/*pathconfig*               @ericsnowcurrently
**/*sysmodule*                @ericsnowcurrently
**/*bltinmodule*              @ericsnowcurrently
**/*gil*                      @ericsnowcurrently
Include/internal/pycore_runtime.h   @ericsnowcurrently
Include/internal/pycore_interp.h    @ericsnowcurrently
Include/internal/pycore_tstate.h    @ericsnowcurrently
Include/internal/pycore_*_state.h   @ericsnowcurrently
Include/internal/pycore_*_init.h    @ericsnowcurrently
Include/internal/pycore_atexit.h    @ericsnowcurrently
Include/internal/pycore_freelist.h  @ericsnowcurrently
Include/internal/pycore_global_objects.h  @ericsnowcurrently
Include/internal/pycore_obmalloc.h  @ericsnowcurrently
Include/internal/pycore_pymem.h     @ericsnowcurrently
Include/internal/pycore_stackref.h  @Fidget-Spinner
Modules/main.c                @ericsnowcurrently
Programs/_bootstrap_python.c  @ericsnowcurrently
Programs/python.c             @ericsnowcurrently
Tools/build/generate_global_objects.py  @ericsnowcurrently

# Initialization
Doc/library/sys_path_init.rst @FFY00
Doc/c-api/init_config.rst     @FFY00

# getpath
**/*getpath*                  @FFY00

# site
**/*site.py                   @FFY00
Doc/library/site.rst          @FFY00

# Exceptions
Lib/test/test_except*.py      @iritkatriel
Objects/exceptions.c          @iritkatriel

# Hashing
**/*hashlib*                  @gpshead @tiran
**/*pyhash*                   @gpshead @tiran
**/sha*                       @gpshead @tiran
Modules/md5*                  @gpshead @tiran
**/*blake*                    @gpshead @tiran
Modules/_hacl/**              @gpshead

# logging
**/*logging*                  @vsajip

# venv
**/*venv*                     @vsajip @FFY00

# Launcher
/PC/launcher.c                @vsajip

# HTML
/Lib/html/                    @ezio-melotti
/Lib/_markupbase.py           @ezio-melotti
/Lib/test/test_html*.py       @ezio-melotti
/Tools/build/parse_html5_entities.py   @ezio-melotti

# Import (including importlib).
**/*import*                   @brettcannon @ericsnowcurrently @ncoghlan @warsaw
/Python/import.c              @kumaraditya303
Python/dynload_*.c            @ericsnowcurrently
**/*freeze*                   @ericsnowcurrently
**/*frozen*                   @ericsnowcurrently
**/*modsupport*               @ericsnowcurrently
**/*modulefinder*             @ericsnowcurrently
**/*moduleobject*             @ericsnowcurrently
**/*multiphase*               @ericsnowcurrently
**/*pkgutil*                  @ericsnowcurrently
**/*pythonrun*                @ericsnowcurrently
**/*runpy*                    @ericsnowcurrently
**/*singlephase*              @ericsnowcurrently
Lib/test/test_module/         @ericsnowcurrently
Doc/c-api/module.rst          @ericsnowcurrently
**/*importlib/resources/*     @jaraco @warsaw @FFY00
**/*importlib/metadata/*       @jaraco @warsaw

# Dates and times
**/*datetime*                 @pganssle @abalkin
**/*str*time*                 @pganssle @abalkin
Doc/library/time.rst          @pganssle @abalkin
Lib/test/test_time.py         @pganssle @abalkin
Modules/timemodule.c          @pganssle @abalkin
Python/pytime.c               @pganssle @abalkin
Include/internal/pycore_time.h  @pganssle @abalkin

# Email and related
**/*mail*                     @python/email-team
**/*smtp*                     @python/email-team
**/*mime*                     @python/email-team
**/*imap*                     @python/email-team
**/*poplib*                   @python/email-team

# Garbage collector
/Modules/gcmodule.c           @pablogsal
/Doc/library/gc.rst           @pablogsal

# Parser
/Parser/                      @pablogsal @lysnikolaou
/Tools/peg_generator/         @pablogsal @lysnikolaou
/Lib/test/test_peg_generator/ @pablogsal @lysnikolaou
/Grammar/python.gram          @pablogsal @lysnikolaou
/Lib/tokenize.py              @pablogsal @lysnikolaou
/Lib/test/test_tokenize.py    @pablogsal @lysnikolaou

# Code generator
/Tools/cases_generator/        @markshannon

# AST
Python/ast.c                  @isidentical @JelleZijlstra @eclips4
Python/ast_opt.c              @isidentical @eclips4
Parser/asdl.py                @isidentical @JelleZijlstra @eclips4
Parser/asdl_c.py              @isidentical @JelleZijlstra @eclips4
Lib/ast.py                    @isidentical @JelleZijlstra @eclips4
Lib/test/test_ast/            @eclips4

# Mock
/Lib/unittest/mock.py         @cjw296
/Lib/test/test_unittest/testmock/* @cjw296

# multiprocessing
**/*multiprocessing*          @gpshead

# SQLite 3
**/*sqlite*                   @berkerpeksag @erlend-aasland

# subprocess
/Lib/subprocess.py            @gpshead
/Lib/test/test_subprocess.py  @gpshead
/Modules/*subprocess*         @gpshead

# debugger
**/*pdb*                      @gaogaotiantian
**/*bdb*                      @gaogaotiantian

# Limited C API & stable ABI
Tools/build/stable_abi.py     @encukou
Misc/stable_abi.toml          @encukou
Doc/data/*.abi                @encukou
Doc/c-api/stable.rst          @encukou

# Windows
/PC/                          @python/windows-team
/PCbuild/                     @python/windows-team

# Urllib
**/*robotparser*              @berkerpeksag

# Windows installer packages
/Tools/msi/                   @python/windows-team
/Tools/nuget/                 @python/windows-team

# Misc
**/*itertools*                @rhettinger
**/*collections*              @rhettinger
**/*random*                   @rhettinger
**/*bisect*                   @rhettinger
**/*heapq*                    @rhettinger
**/*functools*                @rhettinger

**/*dataclasses*              @ericvsmith

**/*ensurepip*                @pfmoore @pradyunsg

/Doc/library/idle.rst         @terryjreedy
**/*idlelib*                  @terryjreedy
**/*turtledemo*               @terryjreedy

**/*annotationlib*            @JelleZijlstra
**/*typing*                   @JelleZijlstra @AlexWaygood

**/*ftplib                    @giampaolo
**/*shutil                    @giampaolo

**/*enum*                     @ethanfurman
**/*cgi*                      @ethanfurman
**/*tarfile*                  @ethanfurman

**/*tomllib*                  @encukou @hauntsaninja

**/*sysconfig*                @FFY00

**/*cjkcodecs*                @corona10

# macOS
/Mac/                         @python/macos-team
**/*osx_support*              @python/macos-team

# pathlib
**/*pathlib*                  @barneygale

# zipfile.Path
**/*zipfile/_path/*           @jaraco

# Argument Clinic
/Tools/clinic/**              @erlend-aasland
/Lib/test/test_clinic.py      @erlend-aasland
Doc/howto/clinic.rst          @erlend-aasland

# Subinterpreters
**/*interpreteridobject.*     @ericsnowcurrently
**/*crossinterp*              @ericsnowcurrently
Lib/test/support/interpreters/  @ericsnowcurrently
Modules/_interp*module.c      @ericsnowcurrently
Lib/test/test_interpreters/   @ericsnowcurrently

# Android
**/*Android*                  @mhsmith @freakboy3742
**/*android*                  @mhsmith @freakboy3742

# iOS (but not termios)
**/iOS*                       @freakboy3742
**/ios*                       @freakboy3742
**/*_iOS*                     @freakboy3742
**/*_ios*                     @freakboy3742
**/*-iOS*                     @freakboy3742
**/*-ios*                     @freakboy3742

# WebAssembly
/Tools/wasm/                  @brettcannon @freakboy3742

# SBOM
/Misc/externals.spdx.json     @sethmlarson
/Misc/sbom.spdx.json          @sethmlarson
/Tools/build/generate_sbom.py @sethmlarson

# Config Parser
Lib/configparser.py           @jaraco
Lib/test/test_configparser.py @jaraco

# Doc sections
Doc/reference/                @willingc

**/*weakref*                  @kumaraditya303


================================================
File: /.github/CONTRIBUTING.rst
================================================
Contributing to Python
======================

Build Status
------------

- `Buildbot status overview <https://buildbot.python.org/all/#/release_status>`_

- `GitHub Actions status <https://github.com/python/cpython/actions/workflows/build.yml>`_


Thank You
---------
First off, thanks for contributing to the maintenance of the Python programming
language and the CPython interpreter! Even if your contribution is not
ultimately accepted, the fact you put time and effort into helping out is
greatly appreciated.


Contribution Guidelines
-----------------------
Please read the `devguide <https://devguide.python.org/>`_ for
guidance on how to contribute to this project. The documentation covers
everything from how to build the code to submitting a pull request. There are
also suggestions on how you can most effectively help the project.

Please be aware that our workflow does deviate slightly from the typical GitHub
project. Details on how to properly submit a pull request are covered in
`Lifecycle of a Pull Request <https://devguide.python.org/getting-started/pull-request-lifecycle.html>`_.
We utilize various bots and status checks to help with this, so do follow the
comments they leave and their "Details" links, respectively. The key points of
our workflow that are not covered by a bot or status check are:

- All discussions that are not directly related to the code in the pull request
  should happen on `GitHub Issues <https://github.com/python/cpython/issues>`_.
- Upon your first non-trivial pull request (which includes documentation changes),
  feel free to add yourself to ``Misc/ACKS``


Setting Expectations
--------------------
Due to the fact that this project is entirely volunteer-run (i.e. no one is paid
to work on Python full-time), we unfortunately can make no guarantees as to if
or when a core developer will get around to reviewing your pull request.
If no core developer has done a review or responded to changes made because of a
"changes requested" review, please feel free to email python-dev to ask if
someone could take a look at your pull request.


Code of Conduct
---------------
All interactions for this project are covered by the
`PSF Code of Conduct <https://www.python.org/psf/codeofconduct/>`_. Everyone is
expected to be open, considerate, and respectful of others no matter their
position within the project.


================================================
File: /.github/PULL_REQUEST_TEMPLATE.md
================================================
<!--
Thanks for your contribution!
Please read this comment in its entirety. It's quite important.

# Pull Request title

It should be in the following format:

```
gh-NNNNN: Summary of the changes made
```

Where: gh-NNNNN refers to the GitHub issue number.

Most PRs will require an issue number. Trivial changes, like fixing a typo, do not need an issue.

# Backport Pull Request title

If this is a backport PR (PR made against branches other than `main`),
please ensure that the PR title is in the following format:

```
[X.Y] <title from the original PR> (GH-NNNN)
```

Where: [X.Y] is the branch name, e.g. [3.6].

GH-NNNN refers to the PR number from `main`.

-->


================================================
File: /.github/SECURITY.md
================================================
# Security Policy

## Supported Versions

The Python team applies security fixes according to the table
in [the devguide](
https://devguide.python.org/versions/#supported-versions
).

## Reporting a Vulnerability

Please read the guidelines on reporting security issues [on the
official website](https://www.python.org/dev/security/) for
instructions on how to report a security-related problem to
the Python team responsibly.

To reach the response team, email `security at python dot org`.


================================================
File: /.github/actionlint.yaml
================================================
self-hosted-runner:
  labels: ["ubuntu-24.04-aarch64", "windows-aarch64"]

config-variables: null

paths:
  .github/workflows/**/*.yml:
     ignore:
     - 1st argument of function call is not assignable
     - SC2(015|038|086|091|097|098|129|155)

================================================
File: /.github/dependabot.yml
================================================
version: 2
updates:
  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: "monthly"
    labels:
      - "skip issue"
      - "skip news"
    ignore:
      - dependency-name: "*"
        update-types:
          - "version-update:semver-minor"
          - "version-update:semver-patch"
  - package-ecosystem: "pip"
    directory: "/Tools/"
    schedule:
      interval: "monthly"
    labels:
      - "skip issue"
      - "skip news"


================================================
File: /.github/zizmor.yml
================================================
# Configuration for the zizmor static analysis tool, run via pre-commit in CI
# https://woodruffw.github.io/zizmor/configuration/
rules:
  dangerous-triggers:
    ignore:
      - documentation-links.yml


================================================
File: /.github/ISSUE_TEMPLATE/bug.yml
================================================
name: Bug report
description: Submit a bug report
labels: ["type-bug"]
body:
  - type: markdown
    attributes:
      value: |
        **New to Python?**

        For help or advice on using Python, try one of the following options instead of opening a GitHub issue:

          - Asking on [Discourse](https://discuss.python.org/c/users/7) or [Stack Overflow](https://stackoverflow.com)
          - Reading the [Python tutorial](https://docs.python.org/3/tutorial/)
          - Emailing [python-list](https://mail.python.org/mailman/listinfo/python-list)

        Make sure to also search the [CPython issue tracker](https://github.com/python/cpython/issues?q=is%3Aissue+sort%3Acreated-desc) to check that the bug has not already been reported.
  - type: textarea
    attributes:
      label: "Bug description:"
      description: >
        Give a clear and concise description of what happened.
        Include a [minimal, reproducible example](https://stackoverflow.com/help/minimal-reproducible-example) if possible.
        [Copy and paste code where possible rather than using screenshots](https://meta.stackoverflow.com/a/285557/13990016),
        and put any code blocks inside triple backticks.

      value: |
        ```python
        # Add a code block here, if required
        ```
    validations:
      required: true
  - type: dropdown
    attributes:
      label: "CPython versions tested on:"
      multiple: true
      options:
        - "3.9"
        - "3.10"
        - "3.11"
        - "3.12"
        - "3.13"
        - "3.14"
        - "CPython main branch"
    validations:
      required: true
  - type: dropdown
    attributes:
      label: "Operating systems tested on:"
      multiple: true
      options:
        - Linux
        - macOS
        - Windows
        - Other
    validations:
      required: false


================================================
File: /.github/ISSUE_TEMPLATE/config.yml
================================================
contact_links:
  - name: "Getting help"
    about: "Ask questions about using Python and debugging errors on Discourse."
    url: "https://discuss.python.org/c/users/7"
  - name: "Proposing new features"
    about: "Submit major feature proposal (e.g. syntax changes) to an ideas forum first."
    url: "https://discuss.python.org/c/ideas/6"


================================================
File: /.github/ISSUE_TEMPLATE/crash.yml
================================================
name: Crash report
description: A hard crash of the interpreter, possibly with a core dump
labels: ["type-crash"]
body:
  - type: markdown
    attributes:
      value: |
          This form is for hard crashes of the Python interpreter, segmentation faults, failed C-level assertions, and similar. Unexpected exceptions raised from Python functions in the standard library count as bugs rather than crashes.

          The CPython interpreter is written in a different programming language, C. A "CPython crash" is when Python itself fails, leading to a traceback in the C stack.
  - type: textarea
    attributes:
      label: What happened?
      description: >
        Include a [minimal, reproducible example](https://stackoverflow.com/help/minimal-reproducible-example) if possible.
        [Copy and paste code where possible rather than using screenshots](https://meta.stackoverflow.com/a/285557/13990016),
        and put any code blocks inside triple backticks.

      value: |
        ```python
        # Add a code block here, if required
        ```
    validations:
      required: true
  - type: dropdown
    attributes:
      label: "CPython versions tested on:"
      multiple: true
      options:
        - "3.9"
        - "3.10"
        - "3.11"
        - "3.12"
        - "3.13"
        - "3.14"
        - "CPython main branch"
    validations:
      required: true
  - type: dropdown
    attributes:
      label: "Operating systems tested on:"
      multiple: true
      options:
        - Linux
        - macOS
        - Windows
        - Other
    validations:
      required: false
  - type: input
    attributes:
      label: "Output from running 'python -VV' on the command line:"
      description: If you tested with multiple operating systems or architectures, feel free to provide details in the main bug description.
    validations:
      required: false


================================================
File: /.github/ISSUE_TEMPLATE/documentation.md
================================================
---
name: Documentation
about: Report a problem with the documentation
labels: "docs"
---

# Documentation

(A clear and concise description of the issue.)


================================================
File: /.github/ISSUE_TEMPLATE/feature.yml
================================================
name: Feature or enhancement
description: Submit a proposal for a new CPython feature or enhancement
labels: ["type-feature"]
body:
  - type: markdown
    attributes:
      value: |
        # Proposing a feature to CPython?

        You'll need to demonstrate widespread support for your idea among the community.

        Major feature proposals should generally be discussed on [Discourse](https://discuss.python.org/c/ideas/6) before opening a GitHub issue. Wait until it's clear that most people support your idea before filling in this form.
  - type: textarea
    attributes:
      label: "Proposal:"
      description: >
        Explain your proposal, why it should be implemented, and how it would be used.
        Add examples, if applicable.
        Put any code blocks inside triple backticks.
      value: |
        ```python
        # Add a code block here, if required
        ```
    validations:
      required: true
  - type: dropdown
    attributes:
      label: Has this already been discussed elsewhere?
      options:
        - No response given
        - I have already discussed this feature proposal on Discourse
        - This is a minor feature, which does not need previous discussion elsewhere
      multiple: false
    validations:
      required: true
  - type: textarea
    attributes:
      label: "Links to previous discussion of this feature:"
    validations:
      required: false


================================================
File: /.github/problem-matchers/gcc.json
================================================
{
    "__comment": "Taken from vscode-cpptools's Extension/package.json gcc rule",
    "problemMatcher": [
        {
            "owner": "gcc-problem-matcher",
            "pattern": [
                {
                    "regexp": "^(.*):(\\d+):(\\d+):\\s+(?:fatal\\s+)?(warning|error):\\s+(.*)$",
                    "file": 1,
                    "line": 2,
                    "column": 3,
                    "severity": 4,
                    "message": 5
                }
            ]
        }
    ]
}

================================================
File: /.github/problem-matchers/msvc.json
================================================
{
    "__comment": "Taken from vscode's vs/workbench/contrib/tasks/common/problemMatcher.ts msCompile rule",
    "problemMatcher": [
      {
        "owner": "msvc-problem-matcher",
        "pattern": [
          {
            "regexp": "^(?:\\s+\\d+\\>)?([^\\s].*)\\((\\d+),?(\\d+)?(?:,\\d+,\\d+)?\\)\\s*:\\s+(error|warning|info)\\s+(\\w{1,2}\\d+)\\s*:\\s*(.*)$",
            "file": 1,
            "line": 2,
            "column": 3,
            "severity": 4,
            "code": 5,
            "message": 6
          }
        ]
      }
    ]
  }

================================================
File: /.github/workflows/add-issue-header.yml
================================================
name: Add issue header
# Automatically edits an issue's descriptions with a header,
# one of:
#
# - Bug report
# - Crash report
# - Feature or enhancement

on:
  issues:
    types:
      # Only ever run once
      - opened


jobs:
  add-header:
    runs-on: ubuntu-latest
    permissions:
      issues: write
    steps:
      - uses: actions/github-script@v7
        with:
          # language=JavaScript
          script: |
            // https://devguide.python.org/triage/labels/#type-labels
            const HEADERS = new Map([
              ['type-bug', 'Bug report'],
              ['type-crash', 'Crash report'],
              ['type-feature', 'Feature or enhancement'],
            ]);
            let issue_data = await github.rest.issues.get({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo
            }).then(issue => issue.data);
            let header = '';
            for (const label_data of issue_data.labels) {
                const label_name = (typeof label_data === 'string') ? label_data : label_data.name;
                if (HEADERS.has(label_name)) {
                    header = HEADERS.get(label_name);
                    break;
                }
            }
            if (header !== '') {
              console.log(`Setting new header: ${header}`);
              await github.rest.issues.update({
                  issue_number: context.issue.number,
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  body: `# ${header}\n\n${issue_data.body.replaceAll('\r', '')}`
              });
            }


================================================
File: /.github/workflows/build.yml
================================================
name: Tests

on:
  workflow_dispatch:
  push:
    branches:
    - 'main'
    - '3.*'
  pull_request:
    branches:
    - 'main'
    - '3.*'

permissions:
  contents: read

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}-reusable
  cancel-in-progress: true

jobs:
  check_source:
    name: Change detection
    # To use boolean outputs from this job, parse them as JSON.
    # Here's some examples:
    #
    #   if: fromJSON(needs.check_source.outputs.run-docs)
    #
    #   ${{
    #        fromJSON(needs.check_source.outputs.run_tests)
    #        && 'truthy-branch'
    #        || 'falsy-branch'
    #   }}
    #
    uses: ./.github/workflows/reusable-change-detection.yml

  check-docs:
    name: Docs
    needs: check_source
    if: fromJSON(needs.check_source.outputs.run-docs)
    uses: ./.github/workflows/reusable-docs.yml

  check_autoconf_regen:
    name: 'Check if Autoconf files are up to date'
    # Don't use ubuntu-latest but a specific version to make the job
    # reproducible: to get the same tools versions (autoconf, aclocal, ...)
    runs-on: ubuntu-24.04
    container:
      image: ghcr.io/python/autoconf:2025.01.02.12581854023
    timeout-minutes: 60
    needs: check_source
    if: needs.check_source.outputs.run_tests == 'true'
    steps:
      - name: Install Git
        run: |
          apt update && apt install git -yq
          git config --global --add safe.directory "$GITHUB_WORKSPACE"
      - uses: actions/checkout@v4
        with:
          fetch-depth: 1
          persist-credentials: false
      - name: Runner image version
        run: echo "IMAGE_VERSION=${ImageVersion}" >> "$GITHUB_ENV"
      - name: Check Autoconf and aclocal versions
        run: |
          grep "Generated by GNU Autoconf 2.72" configure
          grep "aclocal 1.16.5" aclocal.m4
          grep -q "runstatedir" configure
          grep -q "PKG_PROG_PKG_CONFIG" aclocal.m4
      - name: Regenerate autoconf files
        # Same command used by Tools/build/regen-configure.sh ($AUTORECONF)
        run: autoreconf -ivf -Werror
      - name: Check for changes
        run: |
          git add -u
          changes=$(git status --porcelain)
          # Check for changes in regenerated files
          if test -n "$changes"; then
            echo "Generated files not up to date."
            echo "Perhaps you forgot to run make regen-configure ;)"
            echo "configure files must be regenerated with a specific version of autoconf."
            echo "$changes"
            echo ""
            git diff --staged || true
            exit 1
          fi

  check_generated_files:
    name: 'Check if generated files are up to date'
    # Don't use ubuntu-latest but a specific version to make the job
    # reproducible: to get the same tools versions (autoconf, aclocal, ...)
    runs-on: ubuntu-24.04
    timeout-minutes: 60
    needs: check_source
    if: needs.check_source.outputs.run_tests == 'true'
    steps:
      - uses: actions/checkout@v4
        with:
          persist-credentials: false
      - uses: actions/setup-python@v5
        with:
          python-version: '3.x'
      - name: Runner image version
        run: echo "IMAGE_VERSION=${ImageVersion}" >> "$GITHUB_ENV"
      - name: Restore config.cache
        uses: actions/cache@v4
        with:
          path: config.cache
          # Include env.pythonLocation in key to avoid changes in environment when setup-python updates Python
          key: ${{ github.job }}-${{ runner.os }}-${{ env.IMAGE_VERSION }}-${{ needs.check_source.outputs.config_hash }}-${{ env.pythonLocation }}
      - name: Install Dependencies
        run: sudo ./.github/workflows/posix-deps-apt.sh
      - name: Add ccache to PATH
        run: echo "PATH=/usr/lib/ccache:$PATH" >> "$GITHUB_ENV"
      - name: Configure ccache action
        uses: hendrikmuhs/ccache-action@v1.2
        with:
          save: false
      - name: Configure CPython
        run: |
          # Build Python with the libpython dynamic library
          ./configure --config-cache --with-pydebug --enable-shared
      - name: Build CPython
        run: |
          make -j4 regen-all
          make regen-stdlib-module-names regen-sbom regen-unicodedata
      - name: Check for changes
        run: |
          git add -u
          changes=$(git status --porcelain)
          # Check for changes in regenerated files
          if test -n "$changes"; then
            echo "Generated files not up to date."
            echo "Perhaps you forgot to run make regen-all or build.bat --regen. ;)"
            echo "configure files must be regenerated with a specific version of autoconf."
            echo "$changes"
            echo ""
            git diff --staged || true
            exit 1
          fi
      - name: Check exported libpython symbols
        run: make smelly
      - name: Check limited ABI symbols
        run: make check-limited-abi
      - name: Check for unsupported C global variables
        if: github.event_name == 'pull_request'  # $GITHUB_EVENT_NAME
        run: make check-c-globals

  build_windows:
    name: >-
      Windows
      ${{ fromJSON(matrix.free-threading) && '(free-threading)' || '' }}
    needs: check_source
    if: fromJSON(needs.check_source.outputs.run_tests)
    strategy:
      fail-fast: false
      matrix:
        os:
          - windows-latest
        arch:
          - x64
        free-threading:
          - false
          - true
        include:
          - os: windows-latest # FIXME(diegorusso): change to os: windows-aarch64
            arch: arm64
            free-threading: false
          - os: windows-latest # FIXME(diegorusso): change to os: windows-aarch64
            arch: arm64
            free-threading: true
          - os: windows-latest
            arch: Win32
            free-threading: false
    uses: ./.github/workflows/reusable-windows.yml
    with:
      os: ${{ matrix.os }}
      arch: ${{ matrix.arch }}
      free-threading: ${{ matrix.free-threading }}

  build_windows_msi:
    name: >-  # ${{ '' } is a hack to nest jobs under the same sidebar category
      Windows MSI${{ '' }}
    needs: check_source
    if: fromJSON(needs.check_source.outputs.run-win-msi)
    strategy:
      matrix:
        arch:
        - x86
        - x64
        - arm64
    uses: ./.github/workflows/reusable-windows-msi.yml
    with:
      arch: ${{ matrix.arch }}

  build_macos:
    name: >-
      macOS
      ${{ fromJSON(matrix.free-threading) && '(free-threading)' || '' }}
    needs: check_source
    if: needs.check_source.outputs.run_tests == 'true'
    strategy:
      fail-fast: false
      matrix:
        # Cirrus and macos-14 are M1, macos-13 is default GHA Intel.
        # macOS 13 only runs tests against the GIL-enabled CPython.
        # Cirrus used for upstream, macos-14 for forks.
        os:
        - ghcr.io/cirruslabs/macos-runner:sonoma
        - macos-14
        - macos-13
        is-fork:  # only used for the exclusion trick
        - ${{ github.repository_owner != 'python' }}
        free-threading:
        - false
        - true
        exclude:
        - os: ghcr.io/cirruslabs/macos-runner:sonoma
          is-fork: true
        - os: macos-14
          is-fork: false
        - os: macos-13
          free-threading: true
    uses: ./.github/workflows/reusable-macos.yml
    with:
      config_hash: ${{ needs.check_source.outputs.config_hash }}
      free-threading: ${{ matrix.free-threading }}
      os: ${{ matrix.os }}

  build_ubuntu:
    name: >-
      Ubuntu
      ${{ fromJSON(matrix.free-threading) && '(free-threading)' || '' }}
    needs: check_source
    if: needs.check_source.outputs.run_tests == 'true'
    strategy:
      matrix:
        free-threading:
        - false
        - true
        os:
        - ubuntu-24.04
        - ubuntu-24.04-aarch64
        is-fork:  # only used for the exclusion trick
        - ${{ github.repository_owner != 'python' }}
        exclude:
        - os: ubuntu-24.04-aarch64
          is-fork: true
    uses: ./.github/workflows/reusable-ubuntu.yml
    with:
      config_hash: ${{ needs.check_source.outputs.config_hash }}
      free-threading: ${{ matrix.free-threading }}
      os: ${{ matrix.os }}

  build_ubuntu_ssltests:
    name: 'Ubuntu SSL tests with OpenSSL'
    runs-on: ${{ matrix.os }}
    timeout-minutes: 60
    needs: check_source
    if: needs.check_source.outputs.run_tests == 'true'
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-24.04]
        openssl_ver: [3.0.15, 3.1.7, 3.2.3, 3.3.2, 3.4.0]
        # See Tools/ssl/make_ssl_data.py for notes on adding a new version
    env:
      OPENSSL_VER: ${{ matrix.openssl_ver }}
      MULTISSL_DIR: ${{ github.workspace }}/multissl
      OPENSSL_DIR: ${{ github.workspace }}/multissl/openssl/${{ matrix.openssl_ver }}
      LD_LIBRARY_PATH: ${{ github.workspace }}/multissl/openssl/${{ matrix.openssl_ver }}/lib
    steps:
    - uses: actions/checkout@v4
      with:
        persist-credentials: false
    - name: Runner image version
      run: echo "IMAGE_VERSION=${ImageVersion}" >> "$GITHUB_ENV"
    - name: Restore config.cache
      uses: actions/cache@v4
      with:
        path: config.cache
        key: ${{ github.job }}-${{ runner.os }}-${{ env.IMAGE_VERSION }}-${{ needs.check_source.outputs.config_hash }}
    - name: Register gcc problem matcher
      run: echo "::add-matcher::.github/problem-matchers/gcc.json"
    - name: Install Dependencies
      run: sudo ./.github/workflows/posix-deps-apt.sh
    - name: Configure OpenSSL env vars
      run: |
        echo "MULTISSL_DIR=${GITHUB_WORKSPACE}/multissl" >> "$GITHUB_ENV"
        echo "OPENSSL_DIR=${GITHUB_WORKSPACE}/multissl/openssl/${OPENSSL_VER}" >> "$GITHUB_ENV"
        echo "LD_LIBRARY_PATH=${GITHUB_WORKSPACE}/multissl/openssl/${OPENSSL_VER}/lib" >> "$GITHUB_ENV"
    - name: 'Restore OpenSSL build'
      id: cache-openssl
      uses: actions/cache@v4
      with:
        path: ./multissl/openssl/${{ env.OPENSSL_VER }}
        key: ${{ matrix.os }}-multissl-openssl-${{ env.OPENSSL_VER }}
    - name: Install OpenSSL
      if: steps.cache-openssl.outputs.cache-hit != 'true'
      run: python3 Tools/ssl/multissltests.py --steps=library --base-directory "$MULTISSL_DIR" --openssl "$OPENSSL_VER" --system Linux
    - name: Add ccache to PATH
      run: |
        echo "PATH=/usr/lib/ccache:$PATH" >> "$GITHUB_ENV"
    - name: Configure ccache action
      uses: hendrikmuhs/ccache-action@v1.2
      with:
        save: false
    - name: Configure CPython
      run: ./configure CFLAGS="-fdiagnostics-format=json" --config-cache --enable-slower-safety --with-pydebug --with-openssl="$OPENSSL_DIR"
    - name: Build CPython
      run: make -j4
    - name: Display build info
      run: make pythoninfo
    - name: SSL tests
      run: ./python Lib/test/ssltests.py

  build_wasi:
    name: 'WASI'
    needs: check_source
    if: needs.check_source.outputs.run_tests == 'true'
    uses: ./.github/workflows/reusable-wasi.yml
    with:
      config_hash: ${{ needs.check_source.outputs.config_hash }}

  test_hypothesis:
    name: "Hypothesis tests on Ubuntu"
    runs-on: ubuntu-24.04
    timeout-minutes: 60
    needs: check_source
    if: needs.check_source.outputs.run_tests == 'true' && needs.check_source.outputs.run_hypothesis == 'true'
    env:
      OPENSSL_VER: 3.0.15
      PYTHONSTRICTEXTENSIONBUILD: 1
    steps:
    - uses: actions/checkout@v4
      with:
        persist-credentials: false
    - name: Register gcc problem matcher
      run: echo "::add-matcher::.github/problem-matchers/gcc.json"
    - name: Install Dependencies
      run: sudo ./.github/workflows/posix-deps-apt.sh
    - name: Configure OpenSSL env vars
      run: |
        echo "MULTISSL_DIR=${GITHUB_WORKSPACE}/multissl" >> "$GITHUB_ENV"
        echo "OPENSSL_DIR=${GITHUB_WORKSPACE}/multissl/openssl/${OPENSSL_VER}" >> "$GITHUB_ENV"
        echo "LD_LIBRARY_PATH=${GITHUB_WORKSPACE}/multissl/openssl/${OPENSSL_VER}/lib" >> "$GITHUB_ENV"
    - name: 'Restore OpenSSL build'
      id: cache-openssl
      uses: actions/cache@v4
      with:
        path: ./multissl/openssl/${{ env.OPENSSL_VER }}
        key: ${{ runner.os }}-multissl-openssl-${{ env.OPENSSL_VER }}
    - name: Install OpenSSL
      if: steps.cache-openssl.outputs.cache-hit != 'true'
      run: python3 Tools/ssl/multissltests.py --steps=library --base-directory "$MULTISSL_DIR" --openssl "$OPENSSL_VER" --system Linux
    - name: Add ccache to PATH
      run: |
        echo "PATH=/usr/lib/ccache:$PATH" >> "$GITHUB_ENV"
    - name: Configure ccache action
      uses: hendrikmuhs/ccache-action@v1.2
      with:
        save: false
    - name: Setup directory envs for out-of-tree builds
      run: |
        echo "CPYTHON_RO_SRCDIR=$(realpath -m "${GITHUB_WORKSPACE}"/../cpython-ro-srcdir)" >> "$GITHUB_ENV"
        echo "CPYTHON_BUILDDIR=$(realpath -m "${GITHUB_WORKSPACE}"/../cpython-builddir)" >> "$GITHUB_ENV"
    - name: Create directories for read-only out-of-tree builds
      run: mkdir -p "$CPYTHON_RO_SRCDIR" "$CPYTHON_BUILDDIR"
    - name: Bind mount sources read-only
      run: sudo mount --bind -o ro "$GITHUB_WORKSPACE" "$CPYTHON_RO_SRCDIR"
    - name: Runner image version
      run: echo "IMAGE_VERSION=${ImageVersion}" >> "$GITHUB_ENV"
    - name: Restore config.cache
      uses: actions/cache@v4
      with:
        path: ${{ env.CPYTHON_BUILDDIR }}/config.cache
        key: ${{ github.job }}-${{ runner.os }}-${{ env.IMAGE_VERSION }}-${{ needs.check_source.outputs.config_hash }}
    - name: Configure CPython out-of-tree
      working-directory: ${{ env.CPYTHON_BUILDDIR }}
      run: |
        ../cpython-ro-srcdir/configure \
          --config-cache \
          --with-pydebug \
          --enable-slower-safety \
          --with-openssl="$OPENSSL_DIR"
    - name: Build CPython out-of-tree
      working-directory: ${{ env.CPYTHON_BUILDDIR }}
      run: make -j4
    - name: Display build info
      working-directory: ${{ env.CPYTHON_BUILDDIR }}
      run: make pythoninfo
    - name: Remount sources writable for tests
      # some tests write to srcdir, lack of pyc files slows down testing
      run: sudo mount "$CPYTHON_RO_SRCDIR" -oremount,rw
    - name: Setup directory envs for out-of-tree builds
      run: |
        echo "CPYTHON_BUILDDIR=$(realpath -m "${GITHUB_WORKSPACE}"/../cpython-builddir)" >> "$GITHUB_ENV"
    - name: "Create hypothesis venv"
      working-directory: ${{ env.CPYTHON_BUILDDIR }}
      run: |
        VENV_LOC=$(realpath -m .)/hypovenv
        VENV_PYTHON=$VENV_LOC/bin/python
        echo "HYPOVENV=${VENV_LOC}" >> "$GITHUB_ENV"
        echo "VENV_PYTHON=${VENV_PYTHON}" >> "$GITHUB_ENV"
        ./python -m venv "$VENV_LOC" && "$VENV_PYTHON" -m pip install -r "${GITHUB_WORKSPACE}/Tools/requirements-hypothesis.txt"
    - name: 'Restore Hypothesis database'
      id: cache-hypothesis-database
      uses: actions/cache@v4
      with:
        path: ${{ env.CPYTHON_BUILDDIR }}/.hypothesis/
        key: hypothesis-database-${{ github.head_ref || github.run_id }}
        restore-keys: |
          hypothesis-database-
    - name: "Run tests"
      working-directory: ${{ env.CPYTHON_BUILDDIR }}
      run: |
        # Most of the excluded tests are slow test suites with no property tests
        #
        # (GH-104097) test_sysconfig is skipped because it has tests that are
        # failing when executed from inside a virtual environment.
        "${VENV_PYTHON}" -m test \
          -W \
          -o \
          -j4 \
          -x test_asyncio \
          -x test_multiprocessing_fork \
          -x test_multiprocessing_forkserver \
          -x test_multiprocessing_spawn \
          -x test_concurrent_futures \
          -x test_socket \
          -x test_subprocess \
          -x test_signal \
          -x test_sysconfig
    - uses: actions/upload-artifact@v4
      if: always()
      with:
        name: hypothesis-example-db
        path: ${{ env.CPYTHON_BUILDDIR }}/.hypothesis/examples/


  build_asan:
    name: 'Address sanitizer'
    runs-on: ${{ matrix.os }}
    timeout-minutes: 60
    needs: check_source
    if: needs.check_source.outputs.run_tests == 'true'
    strategy:
      matrix:
        os: [ubuntu-24.04]
    env:
      OPENSSL_VER: 3.0.15
      PYTHONSTRICTEXTENSIONBUILD: 1
      ASAN_OPTIONS: detect_leaks=0:allocator_may_return_null=1:handle_segv=0
    steps:
    - uses: actions/checkout@v4
      with:
        persist-credentials: false
    - name: Runner image version
      run: echo "IMAGE_VERSION=${ImageVersion}" >> "$GITHUB_ENV"
    - name: Restore config.cache
      uses: actions/cache@v4
      with:
        path: config.cache
        key: ${{ github.job }}-${{ runner.os }}-${{ env.IMAGE_VERSION }}-${{ needs.check_source.outputs.config_hash }}
    - name: Register gcc problem matcher
      run: echo "::add-matcher::.github/problem-matchers/gcc.json"
    - name: Install Dependencies
      run: sudo ./.github/workflows/posix-deps-apt.sh
    - name: Set up GCC-10 for ASAN
      uses: egor-tensin/setup-gcc@v1
      with:
        version: 10
    - name: Configure OpenSSL env vars
      run: |
        echo "MULTISSL_DIR=${GITHUB_WORKSPACE}/multissl" >> "$GITHUB_ENV"
        echo "OPENSSL_DIR=${GITHUB_WORKSPACE}/multissl/openssl/${OPENSSL_VER}" >> "$GITHUB_ENV"
        echo "LD_LIBRARY_PATH=${GITHUB_WORKSPACE}/multissl/openssl/${OPENSSL_VER}/lib" >> "$GITHUB_ENV"
    - name: 'Restore OpenSSL build'
      id: cache-openssl
      uses: actions/cache@v4
      with:
        path: ./multissl/openssl/${{ env.OPENSSL_VER }}
        key: ${{ matrix.os }}-multissl-openssl-${{ env.OPENSSL_VER }}
    - name: Install OpenSSL
      if: steps.cache-openssl.outputs.cache-hit != 'true'
      run: python3 Tools/ssl/multissltests.py --steps=library --base-directory "$MULTISSL_DIR" --openssl "$OPENSSL_VER" --system Linux
    - name: Add ccache to PATH
      run: |
        echo "PATH=/usr/lib/ccache:$PATH" >> "$GITHUB_ENV"
    - name: Configure ccache action
      uses: hendrikmuhs/ccache-action@v1.2
      with:
        save: ${{ github.event_name == 'push' }}
        max-size: "200M"
    - name: Configure CPython
      run: ./configure --config-cache --with-address-sanitizer --without-pymalloc
    - name: Build CPython
      run: make -j4
    - name: Display build info
      run: make pythoninfo
    - name: Tests
      run: xvfb-run make ci

  build_tsan:
    name: 'Thread sanitizer'
    needs: check_source
    if: needs.check_source.outputs.run_tests == 'true'
    uses: ./.github/workflows/reusable-tsan.yml
    with:
      config_hash: ${{ needs.check_source.outputs.config_hash }}
      options: ./configure --config-cache --with-thread-sanitizer --with-pydebug
      suppressions_path: Tools/tsan/supressions.txt
      tsan_logs_artifact_name: tsan-logs-default

  build_tsan_free_threading:
    name: 'Thread sanitizer (free-threading)'
    needs: check_source
    if: needs.check_source.outputs.run_tests == 'true'
    uses: ./.github/workflows/reusable-tsan.yml
    with:
      config_hash: ${{ needs.check_source.outputs.config_hash }}
      options: ./configure --config-cache --disable-gil --with-thread-sanitizer --with-pydebug
      suppressions_path: Tools/tsan/suppressions_free_threading.txt
      tsan_logs_artifact_name: tsan-logs-free-threading

  # CIFuzz job based on https://google.github.io/oss-fuzz/getting-started/continuous-integration/
  cifuzz:
    name: CIFuzz
    runs-on: ubuntu-latest
    timeout-minutes: 60
    needs: check_source
    if: needs.check_source.outputs.run_cifuzz == 'true'
    permissions:
      security-events: write
    strategy:
      fail-fast: false
      matrix:
        sanitizer: [address, undefined, memory]
    steps:
      - name: Build fuzzers (${{ matrix.sanitizer }})
        id: build
        uses: google/oss-fuzz/infra/cifuzz/actions/build_fuzzers@master
        with:
          oss-fuzz-project-name: cpython3
          sanitizer: ${{ matrix.sanitizer }}
      - name: Run fuzzers (${{ matrix.sanitizer }})
        uses: google/oss-fuzz/infra/cifuzz/actions/run_fuzzers@master
        with:
          fuzz-seconds: 600
          oss-fuzz-project-name: cpython3
          output-sarif: true
          sanitizer: ${{ matrix.sanitizer }}
      - name: Upload crash
        uses: actions/upload-artifact@v4
        if: failure() && steps.build.outcome == 'success'
        with:
          name: ${{ matrix.sanitizer }}-artifacts
          path: ./out/artifacts
      - name: Upload SARIF
        if: always() && steps.build.outcome == 'success'
        uses: github/codeql-action/upload-sarif@v3
        with:
          sarif_file: cifuzz-sarif/results.sarif
          checkout_path: cifuzz-sarif

  all-required-green:  # This job does nothing and is only used for the branch protection
    name: All required checks pass
    if: always()

    needs:
    - check_source  # Transitive dependency, needed to access `run_tests` value
    - check-docs
    - check_autoconf_regen
    - check_generated_files
    - build_macos
    - build_ubuntu
    - build_ubuntu_ssltests
    - build_wasi
    - build_windows
    - build_windows_msi
    - test_hypothesis
    - build_asan
    - build_tsan
    - build_tsan_free_threading
    - cifuzz

    runs-on: ubuntu-latest

    steps:
    - name: Check whether the needed jobs succeeded or failed
      uses: re-actors/alls-green@05ac9388f0aebcb5727afa17fcccfecd6f8ec5fe
      with:
        allowed-failures: >-
          build_ubuntu_ssltests,
          build_windows_msi,
          cifuzz,
          test_hypothesis,
        allowed-skips: >-
          ${{
            !fromJSON(needs.check_source.outputs.run-docs)
            && '
            check-docs,
            '
            || ''
          }}
          ${{
            needs.check_source.outputs.run_tests != 'true'
            && '
            check_autoconf_regen,
            check_generated_files,
            build_macos,
            build_ubuntu,
            build_ubuntu_ssltests,
            build_wasi,
            build_windows,
            build_asan,
            build_tsan,
            build_tsan_free_threading,
            '
            || ''
          }}
          ${{
            !fromJSON(needs.check_source.outputs.run_cifuzz)
            && '
            cifuzz,
            '
            || ''
          }}
          ${{
            !fromJSON(needs.check_source.outputs.run_hypothesis)
            && '
            test_hypothesis,
            '
            || ''
          }}
        jobs: ${{ toJSON(needs) }}


================================================
File: /.github/workflows/documentation-links.yml
================================================
name: Read the Docs PR preview
# Automatically edits a pull request's descriptions with a link
# to the documentation's preview on Read the Docs.

on:
  pull_request_target:
    types:
      - opened
    paths:
    - 'Doc/**'
    - '.github/workflows/doc.yml'

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

jobs:
  documentation-links:
    runs-on: ubuntu-latest
    permissions:
      pull-requests: write

    steps:
      - uses: readthedocs/actions/preview@v1
        with:
          project-slug: "cpython-previews"
          single-version: "true"


================================================
File: /.github/workflows/jit.yml
================================================
name: JIT
on:
  pull_request:
    paths:
      - '**jit**'
      - 'Python/bytecodes.c'
      - 'Python/optimizer*.c'
      - '!Python/perf_jit_trampoline.c'
      - '!**/*.md'
      - '!**/*.ini'
  push:
    paths:
      - '**jit**'
      - 'Python/bytecodes.c'
      - 'Python/optimizer*.c'
      - '!Python/perf_jit_trampoline.c'
      - '!**/*.md'
      - '!**/*.ini'
  workflow_dispatch:

permissions:
  contents: read

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

jobs:
  interpreter:
    name: Interpreter (Debug)
    runs-on: ubuntu-24.04
    timeout-minutes: 90
    steps:
      - uses: actions/checkout@v4
        with:
          persist-credentials: false
      - name: Build tier two interpreter
        run: |
          ./configure --enable-experimental-jit=interpreter --with-pydebug
          make all --jobs 4
      - name: Test tier two interpreter
        run: |
          ./python -m test --multiprocess 0 --timeout 4500 --verbose2 --verbose3
  jit:
    name: ${{ matrix.target }} (${{ matrix.debug && 'Debug' || 'Release' }})
    needs: interpreter
    runs-on: ${{ matrix.runner }}
    timeout-minutes: 90
    strategy:
      fail-fast: false
      matrix:
        target:
          - i686-pc-windows-msvc/msvc
          - x86_64-pc-windows-msvc/msvc
          - aarch64-pc-windows-msvc/msvc
          - x86_64-apple-darwin/clang
          - aarch64-apple-darwin/clang
          - x86_64-unknown-linux-gnu/gcc
          - aarch64-unknown-linux-gnu/gcc
        debug:
          - true
          - false
        llvm:
          - 19
        include:
          - target: i686-pc-windows-msvc/msvc
            architecture: Win32
            runner: windows-latest
          - target: x86_64-pc-windows-msvc/msvc
            architecture: x64
            runner: windows-latest
          - target: aarch64-pc-windows-msvc/msvc
            architecture: ARM64
            runner: windows-latest
          - target: x86_64-apple-darwin/clang
            architecture: x86_64
            runner: macos-13
          - target: aarch64-apple-darwin/clang
            architecture: aarch64
            runner: macos-14
          - target: x86_64-unknown-linux-gnu/gcc
            architecture: x86_64
            runner: ubuntu-24.04
          - target: aarch64-unknown-linux-gnu/gcc
            architecture: aarch64
            # Forks don't have access to our paid AArch64 runners. These jobs are skipped below:
            runner: ${{ github.repository_owner == 'python' && 'ubuntu-24.04-aarch64' || 'ubuntu-24.04' }}
    steps:
      - uses: actions/checkout@v4
        with:
          persist-credentials: false
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Native Windows
        if: runner.os == 'Windows' && matrix.architecture != 'ARM64'
        run: |
          choco install llvm --allow-downgrade --no-progress --version ${{ matrix.llvm }}.1.0
          ./PCbuild/build.bat --experimental-jit ${{ matrix.debug && '-d' || '' }} -p ${{ matrix.architecture }}
          ./PCbuild/rt.bat ${{ matrix.debug && '-d' || '' }} -p ${{ matrix.architecture }} -q --multiprocess 0 --timeout 4500 --verbose2 --verbose3

      # No tests (yet):
      - name: Emulated Windows
        if: runner.os == 'Windows' && matrix.architecture == 'ARM64'
        run: |
          choco install llvm --allow-downgrade --no-progress --version ${{ matrix.llvm }}.1.0
          ./PCbuild/build.bat --experimental-jit ${{ matrix.debug && '-d' || '' }} -p ${{ matrix.architecture }}

        # The `find` line is required as a result of https://github.com/actions/runner-images/issues/9966.
        # This is a bug in the macOS runner image where the pre-installed Python is installed in the same
        # directory as the Homebrew Python, which causes the build to fail for macos-13. This line removes
        # the symlink to the pre-installed Python so that the Homebrew Python is used instead.
      - name: Native macOS
        if: runner.os == 'macOS'
        run: |
          brew update
          find /usr/local/bin -lname '*/Library/Frameworks/Python.framework/*' -delete
          brew install llvm@${{ matrix.llvm }}
          export SDKROOT="$(xcrun --show-sdk-path)"
          ./configure --enable-experimental-jit ${{ matrix.debug && '--with-pydebug' || '' }}
          make all --jobs 4
          ./python.exe -m test --multiprocess 0 --timeout 4500 --verbose2 --verbose3

      - name: Native Linux
        # Forks don't have access to our paid AArch64 runners. Skip those:
        if: runner.os == 'Linux' && (matrix.architecture == 'x86_64' || github.repository_owner == 'python')
        run: |
          sudo bash -c "$(wget -O - https://apt.llvm.org/llvm.sh)" ./llvm.sh ${{ matrix.llvm }}
          export PATH="$(llvm-config-${{ matrix.llvm }} --bindir):$PATH"
          ./configure --enable-experimental-jit ${{ matrix.debug && '--with-pydebug' || '' }}
          make all --jobs 4
          ./python -m test --multiprocess 0 --timeout 4500 --verbose2 --verbose3

  jit-with-disabled-gil:
    name: Free-Threaded (Debug)
    needs: interpreter
    runs-on: ubuntu-24.04
    strategy:
      matrix:
        llvm:
          - 19
    steps:
      - uses: actions/checkout@v4
        with:
          persist-credentials: false
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Build with JIT enabled and GIL disabled
        run: |
          sudo bash -c "$(wget -O - https://apt.llvm.org/llvm.sh)" ./llvm.sh ${{ matrix.llvm }}
          export PATH="$(llvm-config-${{ matrix.llvm }} --bindir):$PATH"
          ./configure --enable-experimental-jit --with-pydebug --disable-gil
          make all --jobs 4
      - name: Run tests
        run: |
          ./python -m test --multiprocess 0 --timeout 4500 --verbose2 --verbose3


================================================
File: /.github/workflows/lint.yml
================================================
name: Lint

on: [push, pull_request, workflow_dispatch]

permissions:
  contents: read

env:
  FORCE_COLOR: 1
  RUFF_OUTPUT_FORMAT: github

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

jobs:
  lint:
    runs-on: ubuntu-latest
    timeout-minutes: 10

    steps:
      - uses: actions/checkout@v4
        with:
          persist-credentials: false
      - uses: actions/setup-python@v5
        with:
          python-version: "3.x"
      - uses: pre-commit/action@v3.0.1


================================================
File: /.github/workflows/mypy.yml
================================================
# Workflow to run mypy on select parts of the CPython repo
name: mypy

on:
  push:
    branches:
      - main
  pull_request:
    paths:
      - ".github/workflows/mypy.yml"
      - "Lib/_pyrepl/**"
      - "Lib/test/libregrtest/**"
      - "Tools/build/generate_sbom.py"
      - "Tools/cases_generator/**"
      - "Tools/clinic/**"
      - "Tools/jit/**"
      - "Tools/peg_generator/**"
      - "Tools/requirements-dev.txt"
      - "Tools/wasm/**"
  workflow_dispatch:

permissions:
  contents: read

env:
  PIP_DISABLE_PIP_VERSION_CHECK: 1
  FORCE_COLOR: 1
  TERM: xterm-256color  # needed for FORCE_COLOR to work on mypy on Ubuntu, see https://github.com/python/mypy/issues/13817

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

jobs:
  mypy:
    strategy:
      fail-fast: false
      matrix:
        target: [
          "Lib/_pyrepl",
          "Lib/test/libregrtest",
          "Tools/build",
          "Tools/cases_generator",
          "Tools/clinic",
          "Tools/jit",
          "Tools/peg_generator",
          "Tools/wasm",
        ]
    name: Run mypy on ${{ matrix.target }}
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v4
        with:
          persist-credentials: false
      - uses: actions/setup-python@v5
        with:
          python-version: "3.13"
          cache: pip
          cache-dependency-path: Tools/requirements-dev.txt
      - run: pip install -r Tools/requirements-dev.txt
      - run: mypy --config-file ${{ matrix.target }}/mypy.ini


================================================
File: /.github/workflows/new-bugs-announce-notifier.yml
================================================
name: new-bugs-announce notifier

on:
  issues:
    types:
      - opened

permissions:
  issues: read

jobs:
  notify-new-bugs-announce:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - uses: actions/setup-node@v4
        with:
          node-version: 20
      - run: npm install mailgun.js form-data
      - name: Send notification
        uses: actions/github-script@v7
        env:
          MAILGUN_API_KEY: ${{ secrets.MAILGUN_PYTHON_ORG_MAILGUN_KEY }}
        with:
          script: |
            const Mailgun = require("mailgun.js");
            const formData = require('form-data');
            const mailgun = new Mailgun(formData);
            const DOMAIN = "mailgun.python.org";
            const mg = mailgun.client({username: 'api', key: process.env.MAILGUN_API_KEY});
            github.rest.issues.get({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
            })
            .then(function(issue) {
              const payload = {
                author : issue.data.user.login,
                issue  : issue.data.number,
                title  : issue.data.title,
                url    : issue.data.html_url,
                labels : issue.data.labels.map(label => { return label.name }).join(", "),
                assignee : issue.data.assignees.map(assignee => { return assignee.login }),
                // We need to truncate the body size, because the max size for
                // the whole payload is 16kb. We want to be safe and assume that
                // body can take up to ~8kb of space.
                body   : issue.data.body.substring(0, 8000)
              };

              const data = {
                from: "CPython Issues <github@mailgun.python.org>",
                to: "new-bugs-announce@python.org",
                subject: `[Issue ${issue.data.number}] ${issue.data.title}`,
                template: "new-github-issue",
                'o:tracking-clicks': 'no',
                'h:X-Mailgun-Variables': JSON.stringify(payload)
              };
              return mg.messages.create(DOMAIN, data)
            })
            .then(msg => console.log(msg));


================================================
File: /.github/workflows/posix-deps-apt.sh
================================================
#!/bin/sh
apt-get update

apt-get -yq install \
    build-essential \
    pkg-config \
    ccache \
    gdb \
    lcov \
    libb2-dev \
    libbz2-dev \
    libffi-dev \
    libgdbm-dev \
    libgdbm-compat-dev \
    liblzma-dev \
    libncurses5-dev \
    libreadline6-dev \
    libsqlite3-dev \
    libssl-dev \
    lzma \
    lzma-dev \
    strace \
    tk-dev \
    uuid-dev \
    xvfb \
    zlib1g-dev


================================================
File: /.github/workflows/project-updater.yml
================================================
name: Update GH projects

on:
  issues:
    types:
      - opened
      - labeled

permissions:
  contents: read

jobs:
  add-to-project:
    name: Add issues to projects
    runs-on: ubuntu-latest
    timeout-minutes: 10
    strategy:
      matrix:
        include:
          # if an issue has any of these labels, it will be added
          # to the corresponding project
          - { project:  2, label: "release-blocker, deferred-blocker" }
          - { project: 32, label: sprint }

    steps:
      - uses: actions/add-to-project@v1.0.0
        with:
          project-url: https://github.com/orgs/python/projects/${{ matrix.project }}
          github-token: ${{ secrets.ADD_TO_PROJECT_PAT }}
          labeled: ${{ matrix.label }}


================================================
File: /.github/workflows/regen-abidump.sh
================================================
set -ex

export DEBIAN_FRONTEND=noninteractive
./.github/workflows/posix-deps-apt.sh
apt-get install -yq abigail-tools python3
export CFLAGS="-g3 -O0"
./configure --enable-shared && make
make regen-abidump


================================================
File: /.github/workflows/require-pr-label.yml
================================================
name: Check labels

on:
  pull_request:
    types: [opened, reopened, labeled, unlabeled, synchronize]

jobs:
  label-dnm:
    name: DO-NOT-MERGE
    if: github.repository_owner == 'python'
    runs-on: ubuntu-latest
    permissions:
      issues: write
      pull-requests: write
    timeout-minutes: 10

    steps:
      - name: Check there's no DO-NOT-MERGE
        uses: mheap/github-action-required-labels@v5
        with:
          mode: exactly
          count: 0
          labels: |
            DO-NOT-MERGE

  label-reviews:
    name: Unresolved review
    if: github.repository_owner == 'python'
    runs-on: ubuntu-latest
    permissions:
      issues: write
      pull-requests: write
    timeout-minutes: 10

    steps:
      # Check that the PR is not awaiting changes from the author due to previous review.
      - name: Check there's no required changes
        uses: mheap/github-action-required-labels@v5
        with:
          mode: exactly
          count: 0
          labels: |
            awaiting changes
            awaiting change review
      - id: is-feature
        name: Check whether this PR is a feature (contains a "type-feature" label)
        uses: mheap/github-action-required-labels@v5
        with:
          mode: exactly
          count: 1
          labels: |
            type-feature
          exit_type: success  # don't fail the check if the PR is not a feature, just record the result
      # In case of a feature PR, check for a complete review (contains an "awaiting merge" label).
      - id: awaiting-merge
        if: steps.is-feature.outputs.status == 'success'
        name: Check for complete review
        uses: mheap/github-action-required-labels@v5
        with:
          mode: exactly
          count: 1
          labels: |
            awaiting merge


================================================
File: /.github/workflows/reusable-change-detection.yml
================================================
name: Reusable change detection

on:  # yamllint disable-line rule:truthy
  workflow_call:
    outputs:
      # Some of the referenced steps set outputs conditionally and there may be
      # cases when referencing them evaluates to empty strings. It is nice to
      # work with proper booleans so they have to be evaluated through JSON
      # conversion in the expressions. However, empty strings used like that
      # may trigger all sorts of undefined and hard-to-debug behaviors in
      # GitHub Actions CI/CD. To help with this, all of the outputs set here
      # that are meant to be used as boolean flags (and not arbitrary strings),
      # MUST have fallbacks with default values set. A common pattern would be
      # to add ` || false` to all such expressions here, in the output
      # definitions. They can then later be safely used through the following
      # idiom in job conditionals and other expressions. Here's some examples:
      #
      #   if: fromJSON(needs.change-detection.outputs.run-docs)
      #
      #   ${{
      #        fromJSON(needs.change-detection.outputs.run-tests)
      #        && 'truthy-branch'
      #        || 'falsy-branch'
      #   }}
      #
      config_hash:
        description: Config hash value for use in cache keys
        value: ${{ jobs.compute-changes.outputs.config-hash }}  # str
      run-docs:
        description: Whether to build the docs
        value: ${{ jobs.compute-changes.outputs.run-docs || false }}  # bool
      run_tests:
        description: Whether to run the regular tests
        value: ${{ jobs.compute-changes.outputs.run-tests || false }}  # bool
      run-win-msi:
        description: Whether to run the MSI installer smoke tests
        value: >-  # bool
          ${{ jobs.compute-changes.outputs.run-win-msi || false }}
      run_hypothesis:
        description: Whether to run the Hypothesis tests
        value: >-  # bool
          ${{ jobs.compute-changes.outputs.run-hypothesis || false }}
      run_cifuzz:
        description: Whether to run the CIFuzz job
        value: >-  # bool
          ${{ jobs.compute-changes.outputs.run-cifuzz || false }}

jobs:
  compute-changes:
    name: Compute changed files
    runs-on: ubuntu-latest
    timeout-minutes: 10
    outputs:
      config-hash: ${{ steps.config-hash.outputs.hash }}
      run-cifuzz: ${{ steps.check.outputs.run-cifuzz }}
      run-docs: ${{ steps.docs-changes.outputs.run-docs }}
      run-hypothesis: ${{ steps.check.outputs.run-hypothesis }}
      run-tests: ${{ steps.check.outputs.run-tests }}
      run-win-msi: ${{ steps.win-msi-changes.outputs.run-win-msi }}
    steps:
    - run: >-
        echo '${{ github.event_name }}'
    - uses: actions/checkout@v4
      with:
        persist-credentials: false
    - name: Check for source changes
      id: check
      run: |
        if [ -z "$GITHUB_BASE_REF" ]; then
          echo "run-tests=true" >> "$GITHUB_OUTPUT"
        else
          git fetch origin "$GITHUB_BASE_REF" --depth=1
          # git diff "origin/$GITHUB_BASE_REF..." (3 dots) may be more
          # reliable than git diff "origin/$GITHUB_BASE_REF.." (2 dots),
          # but it requires to download more commits (this job uses
          # "git fetch --depth=1").
          #
          # git diff "origin/$GITHUB_BASE_REF..." (3 dots) works with Git
          # 2.26, but Git 2.28 is stricter and fails with "no merge base".
          #
          # git diff "origin/$GITHUB_BASE_REF.." (2 dots) should be enough on
          # GitHub, since GitHub starts by merging origin/$GITHUB_BASE_REF
          # into the PR branch anyway.
          #
          # https://github.com/python/core-workflow/issues/373
          git diff --name-only "origin/$GITHUB_BASE_REF.." | grep -qvE '(\.rst$|^Doc|^Misc|^\.pre-commit-config\.yaml$|\.ruff\.toml$|\.md$|mypy\.ini$)' && echo "run-tests=true" >> "$GITHUB_OUTPUT" || true
        fi

        # Check if we should run hypothesis tests
        GIT_BRANCH=${GITHUB_BASE_REF:-${GITHUB_REF#refs/heads/}}
        echo "$GIT_BRANCH"
        if $(echo "$GIT_BRANCH" | grep -q -w '3\.\(8\|9\|10\|11\)'); then
          echo "Branch too old for hypothesis tests"
          echo "run-hypothesis=false" >> "$GITHUB_OUTPUT"
        else
          echo "Run hypothesis tests"
          echo "run-hypothesis=true" >> "$GITHUB_OUTPUT"
        fi

        # oss-fuzz maintains a configuration for fuzzing the main branch of
        # CPython, so CIFuzz should be run only for code that is likely to be
        # merged into the main branch; compatibility with older branches may
        # be broken.
        FUZZ_RELEVANT_FILES='(\.c$|\.h$|\.cpp$|^configure$|^\.github/workflows/build\.yml$|^Modules/_xxtestfuzz)'
        if [ "$GITHUB_BASE_REF" = "main" ] && [ "$(git diff --name-only "origin/$GITHUB_BASE_REF.." | grep -qE $FUZZ_RELEVANT_FILES; echo $?)" -eq 0 ]; then
          # The tests are pretty slow so they are executed only for PRs
          # changing relevant files.
          echo "Run CIFuzz tests"
          echo "run-cifuzz=true" >> "$GITHUB_OUTPUT"
        else
          echo "Branch too old for CIFuzz tests; or no C files were changed"
          echo "run-cifuzz=false" >> "$GITHUB_OUTPUT"
        fi
    - name: Compute hash for config cache key
      id: config-hash
      run: |
        echo "hash=${{ hashFiles('configure', 'configure.ac', '.github/workflows/build.yml') }}" >> "$GITHUB_OUTPUT"
    - name: Get a list of the changed documentation-related files
      if: github.event_name == 'pull_request'
      id: changed-docs-files
      uses: Ana06/get-changed-files@v2.3.0
      with:
        filter: |
          Doc/**
          Misc/**
          .github/workflows/reusable-docs.yml
        format: csv  # works for paths with spaces
    - name: Check for docs changes
      # We only want to run this on PRs when related files are changed,
      # or when user triggers manual workflow run.
      if: >-
        (
          github.event_name == 'pull_request'
          && steps.changed-docs-files.outputs.added_modified_renamed != ''
        ) || github.event_name == 'workflow_dispatch'
      id: docs-changes
      run: |
        echo "run-docs=true" >> "${GITHUB_OUTPUT}"
    - name: Get a list of the MSI installer-related files
      if: github.event_name == 'pull_request'
      id: changed-win-msi-files
      uses: Ana06/get-changed-files@v2.3.0
      with:
        filter: |
          Tools/msi/**
          .github/workflows/reusable-windows-msi.yml
        format: csv  # works for paths with spaces
    - name: Check for changes in MSI installer-related files
      # We only want to run this on PRs when related files are changed,
      # or when user triggers manual workflow run.
      if: >-
        (
          github.event_name == 'pull_request'
          && steps.changed-win-msi-files.outputs.added_modified_renamed != ''
        ) || github.event_name == 'workflow_dispatch'
      id: win-msi-changes
      run: |
        echo "run-win-msi=true" >> "${GITHUB_OUTPUT}"


================================================
File: /.github/workflows/reusable-docs.yml
================================================
name: Reusable Docs

on:
  workflow_call:
  workflow_dispatch:

permissions:
  contents: read

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

env:
  FORCE_COLOR: 1

jobs:
  build_doc:
    name: 'Docs'
    runs-on: ubuntu-latest
    timeout-minutes: 60
    env:
      branch_base: 'origin/${{ github.event.pull_request.base.ref }}'
      branch_pr: 'origin/${{ github.event.pull_request.head.ref }}'
      commits: ${{ github.event.pull_request.commits }}
      refspec_base: '+${{ github.event.pull_request.base.sha }}:remotes/origin/${{ github.event.pull_request.base.ref }}'
      refspec_pr: '+${{ github.event.pull_request.head.sha }}:remotes/origin/${{ github.event.pull_request.head.ref }}'
    steps:
    - name: 'Check out latest PR branch commit'
      uses: actions/checkout@v4
      with:
        persist-credentials: false
        ref: >-
          ${{
            github.event_name == 'pull_request'
            && github.event.pull_request.head.sha
            || ''
          }}
    # Adapted from https://github.com/actions/checkout/issues/520#issuecomment-1167205721
    - name: 'Fetch commits to get branch diff'
      if: github.event_name == 'pull_request'
      run: |
        # Fetch enough history to find a common ancestor commit (aka merge-base):
        git fetch origin "${refspec_pr}" --depth=$(( commits + 1 )) \
          --no-tags --prune --no-recurse-submodules

        # This should get the oldest commit in the local fetched history (which may not be the commit the PR branched from):
        COMMON_ANCESTOR=$( git rev-list --first-parent --max-parents=0 --max-count=1 "${branch_pr}" )
        DATE=$( git log --date=iso8601 --format=%cd "${COMMON_ANCESTOR}" )

        # Get all commits since that commit date from the base branch (eg: master or main):
        git fetch origin "${refspec_base}" --shallow-since="${DATE}" \
          --no-tags --prune --no-recurse-submodules
    - name: 'Set up Python'
      uses: actions/setup-python@v5
      with:
        python-version: '3'
        cache: 'pip'
        cache-dependency-path: 'Doc/requirements.txt'
    - name: 'Install build dependencies'
      run: make -C Doc/ venv

    # To annotate PRs with Sphinx nitpicks (missing references)
    - name: 'Build HTML documentation'
      continue-on-error: true
      run: |
        set -Eeuo pipefail
        # Build docs with the '-n' (nit-picky) option; write warnings to file
        make -C Doc/ PYTHON=../python SPHINXOPTS="-q -n -W --keep-going -w sphinx-warnings.txt" html
    - name: 'Check warnings'
      if: github.event_name == 'pull_request'
      run: |
        python Doc/tools/check-warnings.py \
          --annotate-diff "${branch_base}" "${branch_pr}" \
          --fail-if-regression \
          --fail-if-improved \
          --fail-if-new-news-nit

  # This build doesn't use problem matchers or check annotations
  build_doc_oldest_supported_sphinx:
    name: 'Docs (Oldest Sphinx)'
    runs-on: ubuntu-latest
    timeout-minutes: 60
    steps:
    - uses: actions/checkout@v4
      with:
        persist-credentials: false
    - name: 'Set up Python'
      uses: actions/setup-python@v5
      with:
        python-version: '3.13'  # known to work with Sphinx 7.2.6
        cache: 'pip'
        cache-dependency-path: 'Doc/requirements-oldest-sphinx.txt'
    - name: 'Install build dependencies'
      run: make -C Doc/ venv REQUIREMENTS="requirements-oldest-sphinx.txt"
    - name: 'Build HTML documentation'
      run: make -C Doc/ SPHINXOPTS="-q" SPHINXERRORHANDLING="-W --keep-going" html

  # Run "doctest" on HEAD as new syntax doesn't exist in the latest stable release
  doctest:
    name: 'Doctest'
    runs-on: ubuntu-24.04
    timeout-minutes: 60
    steps:
    - uses: actions/checkout@v4
      with:
        persist-credentials: false
    - uses: actions/cache@v4
      with:
        path: ~/.cache/pip
        key: ubuntu-doc-${{ hashFiles('Doc/requirements.txt') }}
        restore-keys: |
          ubuntu-doc-
    - name: 'Install Dependencies'
      run: sudo ./.github/workflows/posix-deps-apt.sh && sudo apt-get install wamerican
    - name: 'Configure CPython'
      run: ./configure --with-pydebug
    - name: 'Build CPython'
      run: make -j4
    - name: 'Install build dependencies'
      run: make -C Doc/ PYTHON=../python venv
    # Use "xvfb-run" since some doctest tests open GUI windows
    - name: 'Run documentation doctest'
      run: xvfb-run make -C Doc/ PYTHON=../python SPHINXERRORHANDLING="-W --keep-going" doctest


================================================
File: /.github/workflows/reusable-macos.yml
================================================
name: Reusable macOS

on:
  workflow_call:
    inputs:
      config_hash:
        required: true
        type: string
      free-threading:
        required: false
        type: boolean
        default: false
      os:
        description: OS to run the job
        required: true
        type: string

jobs:
  build_macos:
    name: build and test (${{ inputs.os }})
    timeout-minutes: 60
    env:
      HOMEBREW_NO_ANALYTICS: 1
      HOMEBREW_NO_AUTO_UPDATE: 1
      HOMEBREW_NO_INSTALL_CLEANUP: 1
      HOMEBREW_NO_INSTALLED_DEPENDENTS_CHECK: 1
      PYTHONSTRICTEXTENSIONBUILD: 1
      TERM: linux
    runs-on: ${{ inputs.os }}
    steps:
    - uses: actions/checkout@v4
      with:
        persist-credentials: false
    - name: Runner image version
      run: echo "IMAGE_VERSION=${ImageVersion}" >> "$GITHUB_ENV"
    - name: Restore config.cache
      uses: actions/cache@v4
      with:
        path: config.cache
        key: ${{ github.job }}-${{ inputs.os }}-${{ env.IMAGE_VERSION }}-${{ inputs.config_hash }}
    - name: Install Homebrew dependencies
      run: |
        brew install pkg-config openssl@3.0 xz gdbm tcl-tk@8 make
        # Because alternate versions are not symlinked into place by default:
        brew link --overwrite tcl-tk@8
    - name: Configure CPython
      run: |
        MACOSX_DEPLOYMENT_TARGET=10.15 \
        GDBM_CFLAGS="-I$(brew --prefix gdbm)/include" \
        GDBM_LIBS="-L$(brew --prefix gdbm)/lib -lgdbm" \
        ./configure \
          --config-cache \
          --with-pydebug \
          --enable-slower-safety \
          --enable-safety \
          ${{ inputs.free-threading && '--disable-gil' || '' }} \
          --prefix=/opt/python-dev \
          --with-openssl="$(brew --prefix openssl@3.0)"
    - name: Build CPython
      if : ${{ inputs.free-threading || inputs.os != 'macos-13' }}
      run: gmake -j8
    - name: Build CPython for compiler warning check
      if : ${{ !inputs.free-threading && inputs.os == 'macos-13' }}
      run: set -o pipefail; gmake -j8 --output-sync 2>&1 | tee compiler_output_macos.txt
    - name: Display build info
      run: make pythoninfo
    - name: Check compiler warnings
      if : ${{ !inputs.free-threading && inputs.os == 'macos-13' }}
      run: >-
        python3 Tools/build/check_warnings.py
        --compiler-output-file-path=compiler_output_macos.txt
        --warning-ignore-file-path=Tools/build/.warningignore_macos
        --compiler-output-type=clang
        --fail-on-regression
        --fail-on-improvement
        --path-prefix="./"
    - name: Tests
      run: make ci


================================================
File: /.github/workflows/reusable-tsan.yml
================================================
name: Reusable Thread Sanitizer

on:
  workflow_call:
    inputs:
      config_hash:
        required: true
        type: string
      options:
        required: true
        type: string
      suppressions_path:
        description: 'A repo relative path to the suppressions file'
        required: true
        type: string
      tsan_logs_artifact_name:
        description: 'Name of the TSAN logs artifact. Must be unique for each job.'
        required: true
        type: string

jobs:
  build_tsan_reusable:
    name: 'Thread sanitizer'
    runs-on: ubuntu-24.04
    timeout-minutes: 60
    env:
      OPTIONS: ${{ inputs.options }}
      SUPPRESSIONS_PATH: ${{ inputs.suppressions_path }}
    steps:
    - uses: actions/checkout@v4
      with:
        persist-credentials: false
    - name: Runner image version
      run: echo "IMAGE_VERSION=${ImageVersion}" >> "$GITHUB_ENV"
    - name: Restore config.cache
      uses: actions/cache@v4
      with:
        path: config.cache
        key: ${{ github.job }}-${{ runner.os }}-${{ env.IMAGE_VERSION }}-${{ inputs.config_hash }}
    - name: Install Dependencies
      run: |
        sudo ./.github/workflows/posix-deps-apt.sh
        # Install clang-18
        wget https://apt.llvm.org/llvm.sh
        chmod +x llvm.sh
        sudo ./llvm.sh 17  # gh-121946: llvm-18 package is temporarily broken
        sudo update-alternatives --install /usr/bin/clang clang /usr/bin/clang-17 100
        sudo update-alternatives --set clang /usr/bin/clang-17
        sudo update-alternatives --install /usr/bin/clang++ clang++ /usr/bin/clang++-17 100
        sudo update-alternatives --set clang++ /usr/bin/clang++-17
        # Reduce ASLR to avoid TSAN crashing
        sudo sysctl -w vm.mmap_rnd_bits=28
    - name: TSAN Option Setup
      run: |
        echo "TSAN_OPTIONS=log_path=${GITHUB_WORKSPACE}/tsan_log suppressions=${GITHUB_WORKSPACE}/${SUPPRESSIONS_PATH} handle_segv=0" >> "$GITHUB_ENV"
        echo "CC=clang" >> "$GITHUB_ENV"
        echo "CXX=clang++" >> "$GITHUB_ENV"
    - name: Add ccache to PATH
      run: |
        echo "PATH=/usr/lib/ccache:$PATH" >> "$GITHUB_ENV"
    - name: Configure ccache action
      uses: hendrikmuhs/ccache-action@v1.2
      with:
        save: ${{ github.event_name == 'push' }}
        max-size: "200M"
    - name: Configure CPython
      run: "${OPTIONS}"
    - name: Build CPython
      run: make -j4
    - name: Display build info
      run: make pythoninfo
    - name: Tests
      run: ./python -m test --tsan -j4
    - name: Display TSAN logs
      if: always()
      run: find "${GITHUB_WORKSPACE}" -name 'tsan_log.*' | xargs head -n 1000
    - name: Archive TSAN logs
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: ${{ inputs.tsan_logs_artifact_name }}
        path: tsan_log.*
        if-no-files-found: ignore


================================================
File: /.github/workflows/reusable-ubuntu.yml
================================================
name: Reusable Ubuntu

on:
  workflow_call:
    inputs:
      config_hash:
        required: true
        type: string
      free-threading:
        description: Whether to use free-threaded mode
        required: false
        type: boolean
        default: false
      os:
         description: OS to run the job
         required: true
         type: string

jobs:
  build_ubuntu_reusable:
    name: build and test (${{ inputs.os }})
    timeout-minutes: 60
    runs-on: ${{ inputs.os }}
    env:
      FORCE_COLOR: 1
      OPENSSL_VER: 3.0.15
      PYTHONSTRICTEXTENSIONBUILD: 1
      TERM: linux
    steps:
    - uses: actions/checkout@v4
      with:
        persist-credentials: false
    - name: Register gcc problem matcher
      run: echo "::add-matcher::.github/problem-matchers/gcc.json"
    - name: Install dependencies
      run: sudo ./.github/workflows/posix-deps-apt.sh
    - name: Configure OpenSSL env vars
      run: |
        echo "MULTISSL_DIR=${GITHUB_WORKSPACE}/multissl" >> "$GITHUB_ENV"
        echo "OPENSSL_DIR=${GITHUB_WORKSPACE}/multissl/openssl/${OPENSSL_VER}" >> "$GITHUB_ENV"
        echo "LD_LIBRARY_PATH=${GITHUB_WORKSPACE}/multissl/openssl/${OPENSSL_VER}/lib" >> "$GITHUB_ENV"
    - name: 'Restore OpenSSL build'
      id: cache-openssl
      uses: actions/cache@v4
      with:
        path: ./multissl/openssl/${{ env.OPENSSL_VER }}
        key: ${{ inputs.os }}-multissl-openssl-${{ env.OPENSSL_VER }}
    - name: Install OpenSSL
      if: steps.cache-openssl.outputs.cache-hit != 'true'
      run: python3 Tools/ssl/multissltests.py --steps=library --base-directory "$MULTISSL_DIR" --openssl "$OPENSSL_VER" --system Linux
    - name: Add ccache to PATH
      run: |
        echo "PATH=/usr/lib/ccache:$PATH" >> "$GITHUB_ENV"
    - name: Configure ccache action
      uses: hendrikmuhs/ccache-action@v1.2
      with:
        save: ${{ github.event_name == 'push' }}
        max-size: "200M"
    - name: Setup directory envs for out-of-tree builds
      run: |
        echo "CPYTHON_RO_SRCDIR=$(realpath -m "${GITHUB_WORKSPACE}"/../cpython-ro-srcdir)" >> "$GITHUB_ENV"
        echo "CPYTHON_BUILDDIR=$(realpath -m "${GITHUB_WORKSPACE}"/../cpython-builddir)" >> "$GITHUB_ENV"
    - name: Create directories for read-only out-of-tree builds
      run: mkdir -p "$CPYTHON_RO_SRCDIR" "$CPYTHON_BUILDDIR"
    - name: Bind mount sources read-only
      run: sudo mount --bind -o ro "$GITHUB_WORKSPACE" "$CPYTHON_RO_SRCDIR"
    - name: Runner image version
      run: echo "IMAGE_VERSION=${ImageVersion}" >> "$GITHUB_ENV"
    - name: Restore config.cache
      uses: actions/cache@v4
      with:
        path: ${{ env.CPYTHON_BUILDDIR }}/config.cache
        key: ${{ github.job }}-${{ runner.os }}-${{ env.IMAGE_VERSION }}-${{ inputs.config_hash }}
    - name: Configure CPython out-of-tree
      working-directory: ${{ env.CPYTHON_BUILDDIR }}
      run: >-
        ../cpython-ro-srcdir/configure
        --config-cache
        --with-pydebug
        --enable-slower-safety
        --enable-safety
        --with-openssl="$OPENSSL_DIR"
        ${{ fromJSON(inputs.free-threading) && '--disable-gil' || '' }}
    - name: Build CPython out-of-tree
      if: ${{ inputs.free-threading }}
      working-directory: ${{ env.CPYTHON_BUILDDIR }}
      run: make -j
    - name: Build CPython out-of-tree (for compiler warning check)
      if: ${{ !inputs.free-threading }}
      working-directory: ${{ env.CPYTHON_BUILDDIR }}
      run: set -o pipefail; make -j --output-sync 2>&1 | tee compiler_output_ubuntu.txt
    - name: Display build info
      working-directory: ${{ env.CPYTHON_BUILDDIR }}
      run: make pythoninfo
    - name: Check compiler warnings
      if: ${{ !inputs.free-threading }}
      run: >-
        python Tools/build/check_warnings.py
        --compiler-output-file-path="${CPYTHON_BUILDDIR}/compiler_output_ubuntu.txt"
        --warning-ignore-file-path "${GITHUB_WORKSPACE}/Tools/build/.warningignore_ubuntu"
        --compiler-output-type=gcc
        --fail-on-regression
        --fail-on-improvement
        --path-prefix="../cpython-ro-srcdir/"
    - name: Remount sources writable for tests
      # some tests write to srcdir, lack of pyc files slows down testing
      run: sudo mount "$CPYTHON_RO_SRCDIR" -oremount,rw
    - name: Tests
      working-directory: ${{ env.CPYTHON_BUILDDIR }}
      run: xvfb-run make ci


================================================
File: /.github/workflows/reusable-wasi.yml
================================================
name: Reusable WASI

on:
  workflow_call:
    inputs:
      config_hash:
        required: true
        type: string

jobs:
  build_wasi_reusable:
    name: 'build and test'
    timeout-minutes: 60
    runs-on: ubuntu-24.04
    env:
      WASMTIME_VERSION: 22.0.0
      WASI_SDK_VERSION: 24
      WASI_SDK_PATH: /opt/wasi-sdk
      CROSS_BUILD_PYTHON: cross-build/build
      CROSS_BUILD_WASI: cross-build/wasm32-wasip1
    steps:
    - uses: actions/checkout@v4
      with:
        persist-credentials: false
    # No problem resolver registered as one doesn't currently exist for Clang.
    - name: "Install wasmtime"
      uses: bytecodealliance/actions/wasmtime/setup@v1
      with:
        version: ${{ env.WASMTIME_VERSION }}
    - name: "Restore WASI SDK"
      id: cache-wasi-sdk
      uses: actions/cache@v4
      with:
        path: ${{ env.WASI_SDK_PATH }}
        key: ${{ runner.os }}-wasi-sdk-${{ env.WASI_SDK_VERSION }}
    - name: "Install WASI SDK"  # Hard-coded to x64.
      if: steps.cache-wasi-sdk.outputs.cache-hit != 'true'
      run: |
        mkdir "${WASI_SDK_PATH}" && \
        curl -s -S --location "https://github.com/WebAssembly/wasi-sdk/releases/download/wasi-sdk-${WASI_SDK_VERSION}/wasi-sdk-${WASI_SDK_VERSION}.0-x86_64-linux.tar.gz" | \
        tar --strip-components 1 --directory "${WASI_SDK_PATH}" --extract --gunzip
    - name: "Configure ccache action"
      uses: hendrikmuhs/ccache-action@v1.2
      with:
        save: ${{ github.event_name == 'push' }}
        max-size: "200M"
    - name: "Add ccache to PATH"
      run: echo "PATH=/usr/lib/ccache:$PATH" >> "$GITHUB_ENV"
    - name: "Install Python"
      uses: actions/setup-python@v5
      with:
        python-version: '3.x'
    - name: "Restore Python build config.cache"
      uses: actions/cache@v4
      with:
        path: ${{ env.CROSS_BUILD_PYTHON }}/config.cache
        # Include env.pythonLocation in key to avoid changes in environment when setup-python updates Python.
        # Include the hash of `Tools/wasm/wasi.py` as it may change the environment variables.
        # (Make sure to keep the key in sync with the other config.cache step below.)
        key: ${{ github.job }}-${{ runner.os }}-${{ env.IMAGE_VERSION }}-${{ env.WASI_SDK_VERSION }}-${{ env.WASMTIME_VERSION }}-${{ inputs.config_hash }}-${{ hashFiles('Tools/wasm/wasi.py') }}-${{ env.pythonLocation }}
    - name: "Configure build Python"
      run: python3 Tools/wasm/wasi.py configure-build-python -- --config-cache --with-pydebug
    - name: "Make build Python"
      run: python3 Tools/wasm/wasi.py make-build-python
    - name: "Restore host config.cache"
      uses: actions/cache@v4
      with:
        path: ${{ env.CROSS_BUILD_WASI }}/config.cache
        # Should be kept in sync with the other config.cache step above.
        key: ${{ github.job }}-${{ runner.os }}-${{ env.IMAGE_VERSION }}-${{ env.WASI_SDK_VERSION }}-${{ env.WASMTIME_VERSION }}-${{ inputs.config_hash }}-${{ hashFiles('Tools/wasm/wasi.py') }}-${{ env.pythonLocation }}
    - name: "Configure host"
      # `--with-pydebug` inferred from configure-build-python
      run: python3 Tools/wasm/wasi.py configure-host -- --config-cache
    - name: "Make host"
      run: python3 Tools/wasm/wasi.py make-host
    - name: "Display build info"
      run: make --directory "${CROSS_BUILD_WASI}" pythoninfo
    - name: "Test"
      run: make --directory "${CROSS_BUILD_WASI}" test


================================================
File: /.github/workflows/reusable-windows-msi.yml
================================================
name: Reusable Windows MSI

on:
  workflow_call:
    inputs:
      arch:
        description: CPU architecture
        required: true
        type: string

permissions:
  contents: read

jobs:
  build:
    name: installer for ${{ inputs.arch }}
    runs-on: windows-latest
    timeout-minutes: 60
    env:
      ARCH: ${{ inputs.arch }}
      IncludeFreethreaded: true
    steps:
    - uses: actions/checkout@v4
      with:
        persist-credentials: false
    - name: Build CPython installer
      run: ./Tools/msi/build.bat --doc -"${ARCH}"
      shell: bash


================================================
File: /.github/workflows/reusable-windows.yml
================================================
name: Reusable Windows

on:
  workflow_call:
    inputs:
      os:
        description: OS to run on
        required: true
        type: string
      arch:
        description: CPU architecture
        required: true
        type: string
      free-threading:
        description: Whether to compile CPython in free-threading mode
        required: false
        type: boolean
        default: false

env:
  IncludeUwp: >-
    true

jobs:
  build:
    name: 'build and test (${{ inputs.arch }})'
    runs-on: ${{ inputs.os }}
    timeout-minutes: 60
    env:
      ARCH: ${{ inputs.arch }}
    steps:
    - uses: actions/checkout@v4
      with:
        persist-credentials: false
    - name: Register MSVC problem matcher
      if: inputs.arch != 'Win32'
      run: echo "::add-matcher::.github/problem-matchers/msvc.json"
    - name: Build CPython
      run: >-
        .\\PCbuild\\build.bat
        -e -d -v
        -p "${ARCH}"
        ${{ fromJSON(inputs.free-threading) && '--disable-gil' || '' }}
      shell: bash
    - name: Display build info  # FIXME(diegorusso): remove the `if`
      if: inputs.arch != 'arm64'
      run: .\\python.bat -m test.pythoninfo
    - name: Tests  # FIXME(diegorusso): remove the `if`
      if: inputs.arch != 'arm64'
      run: >-
        .\\PCbuild\\rt.bat
        -p "${ARCH}"
        -d -q --fast-ci
        ${{ fromJSON(inputs.free-threading) && '--disable-gil' || '' }}
      shell: bash


================================================
File: /.github/workflows/stale.yml
================================================
name: Mark stale pull requests

on:
  schedule:
  - cron: "0 */6 * * *"

jobs:
  stale:
    if: github.repository_owner == 'python'

    runs-on: ubuntu-latest
    permissions:
      pull-requests: write
    timeout-minutes: 10

    steps:
    - name: "Check PRs"
      uses: actions/stale@v9
      with:
        repo-token: ${{ secrets.GITHUB_TOKEN }}
        stale-pr-message: 'This PR is stale because it has been open for 30 days with no activity.'
        stale-pr-label: 'stale'
        days-before-issue-stale: -1
        days-before-pr-stale: 30
        days-before-close: -1
        ascending: true
        operations-per-run: 120


================================================
File: /.github/workflows/verify-ensurepip-wheels.yml
================================================
name: Verify bundled wheels

on:
  workflow_dispatch:
  push:
    paths:
      - 'Lib/ensurepip/_bundled/**'
      - '.github/workflows/verify-ensurepip-wheels.yml'
      - 'Tools/build/verify_ensurepip_wheels.py'
  pull_request:
    paths:
      - 'Lib/ensurepip/_bundled/**'
      - '.github/workflows/verify-ensurepip-wheels.yml'
      - 'Tools/build/verify_ensurepip_wheels.py'

permissions:
  contents: read

concurrency:
  group: ${{ github.workflow }}-${{ github.head_ref || github.run_id }}
  cancel-in-progress: true

jobs:
  verify:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@v4
        with:
          persist-credentials: false
      - uses: actions/setup-python@v5
        with:
          python-version: '3'
      - name: Compare checksum of bundled wheels to the ones published on PyPI
        run: ./Tools/build/verify_ensurepip_wheels.py


