   .. method:: MimeTypes.guess_type(url, strict=True)

      Similar to the :func:`guess_type` function, using the tables stored as part of
      the object.


   .. method:: MimeTypes.guess_file_type(path, *, strict=True)

      Similar to the :func:`guess_file_type` function, using the tables stored
      as part of the object.

      .. versionadded:: 3.13


   .. method:: MimeTypes.guess_all_extensions(type, strict=True)

      Similar to the :func:`guess_all_extensions` function, using the tables stored
      as part of the object.


   .. method:: MimeTypes.read(filename, strict=True)

      Load MIME information from a file named *filename*.  This uses :meth:`readfp` to
      parse the file.

      If *strict* is ``True``, information will be added to list of standard types,
      else to the list of non-standard types.


   .. method:: MimeTypes.readfp(fp, strict=True)

      Load MIME type information from an open file *fp*.  The file must have the format of
      the standard :file:`mime.types` files.

      If *strict* is ``True``, information will be added to the list of standard
      types, else to the list of non-standard types.


   .. method:: MimeTypes.read_windows_registry(strict=True)

      Load MIME type information from the Windows registry.

      .. availability:: Windows.

      If *strict* is ``True``, information will be added to the list of standard
      types, else to the list of non-standard types.

      .. versionadded:: 3.2


   .. method:: MimeTypes.add_type(type, ext, strict=True)

      Add a mapping from the MIME type *type* to the extension *ext*. When the
      extension is already known, the new type will replace the old one. When the type
      is already known the extension will be added to the list of known extensions.

      When *strict* is ``True`` (the default), the mapping will be added to the
      official MIME types, otherwise to the non-standard ones.


================================================
File: /Doc/library/mm.rst
================================================
.. _mmedia:

*******************
Multimedia Services
*******************

The modules described in this chapter implement various algorithms or interfaces
that are mainly useful for multimedia applications.  They are available at the
discretion of the installation.  Here's an overview:


.. toctree::

   wave.rst
   colorsys.rst


================================================
File: /Doc/library/mmap.rst
================================================
:mod:`!mmap` --- Memory-mapped file support
===========================================

.. module:: mmap
   :synopsis: Interface to memory-mapped files for Unix and Windows.

--------------

.. include:: ../includes/wasm-notavail.rst

Memory-mapped file objects behave like both :class:`bytearray` and like
:term:`file objects <file object>`.  You can use mmap objects in most places
where :class:`bytearray` are expected; for example, you can use the :mod:`re`
module to search through a memory-mapped file.  You can also change a single
byte by doing ``obj[index] = 97``, or change a subsequence by assigning to a
slice: ``obj[i1:i2] = b'...'``.  You can also read and write data starting at
the current file position, and :meth:`seek` through the file to different positions.

A memory-mapped file is created by the :class:`~mmap.mmap` constructor, which is
different on Unix and on Windows.  In either case you must provide a file
descriptor for a file opened for update. If you wish to map an existing Python
file object, use its :meth:`~io.IOBase.fileno` method to obtain the correct value for the
*fileno* parameter.  Otherwise, you can open the file using the
:func:`os.open` function, which returns a file descriptor directly (the file
still needs to be closed when done).

.. note::
   If you want to create a memory-mapping for a writable, buffered file, you
   should :func:`~io.IOBase.flush` the file first.  This is necessary to ensure
   that local modifications to the buffers are actually available to the
   mapping.

For both the Unix and Windows versions of the constructor, *access* may be
specified as an optional keyword parameter. *access* accepts one of four
values: :const:`ACCESS_READ`, :const:`ACCESS_WRITE`, or :const:`ACCESS_COPY` to
specify read-only, write-through or copy-on-write memory respectively, or
:const:`ACCESS_DEFAULT` to defer to *prot*.  *access* can be used on both Unix
and Windows.  If *access* is not specified, Windows mmap returns a
write-through mapping.  The initial memory values for all three access types
are taken from the specified file.  Assignment to an :const:`ACCESS_READ`
memory map raises a :exc:`TypeError` exception.  Assignment to an
:const:`ACCESS_WRITE` memory map affects both memory and the underlying file.
Assignment to an :const:`ACCESS_COPY` memory map affects memory but does not
update the underlying file.

.. versionchanged:: 3.7
   Added :const:`ACCESS_DEFAULT` constant.

To map anonymous memory, -1 should be passed as the fileno along with the length.

.. class:: mmap(fileno, length, tagname=None, access=ACCESS_DEFAULT, offset=0)

   **(Windows version)** Maps *length* bytes from the file specified by the
   file handle *fileno*, and creates a mmap object.  If *length* is larger
   than the current size of the file, the file is extended to contain *length*
   bytes.  If *length* is ``0``, the maximum length of the map is the current
   size of the file, except that if the file is empty Windows raises an
   exception (you cannot create an empty mapping on Windows).

   *tagname*, if specified and not ``None``, is a string giving a tag name for
   the mapping.  Windows allows you to have many different mappings against
   the same file.  If you specify the name of an existing tag, that tag is
   opened, otherwise a new tag of this name is created.  If this parameter is
   omitted or ``None``, the mapping is created without a name.  Avoiding the
   use of the *tagname* parameter will assist in keeping your code portable
   between Unix and Windows.

   *offset* may be specified as a non-negative integer offset. mmap references
   will be relative to the offset from the beginning of the file. *offset*
   defaults to 0.  *offset* must be a multiple of the :const:`ALLOCATIONGRANULARITY`.

   .. audit-event:: mmap.__new__ fileno,length,access,offset mmap.mmap

.. class:: mmap(fileno, length, flags=MAP_SHARED, prot=PROT_WRITE|PROT_READ, \
                access=ACCESS_DEFAULT, offset=0, *, trackfd=True)
   :noindex:

   **(Unix version)** Maps *length* bytes from the file specified by the file
   descriptor *fileno*, and returns a mmap object.  If *length* is ``0``, the
   maximum length of the map will be the current size of the file when
   :class:`~mmap.mmap` is called.

   *flags* specifies the nature of the mapping. :const:`MAP_PRIVATE` creates a
   private copy-on-write mapping, so changes to the contents of the mmap
   object will be private to this process, and :const:`MAP_SHARED` creates a
   mapping that's shared with all other processes mapping the same areas of
   the file.  The default value is :const:`MAP_SHARED`. Some systems have
   additional possible flags with the full list specified in
   :ref:`MAP_* constants <map-constants>`.

   *prot*, if specified, gives the desired memory protection; the two most
   useful values are :const:`PROT_READ` and :const:`PROT_WRITE`, to specify
   that the pages may be read or written.  *prot* defaults to
   :const:`PROT_READ \| PROT_WRITE`.

   *access* may be specified in lieu of *flags* and *prot* as an optional
   keyword parameter.  It is an error to specify both *flags*, *prot* and
   *access*.  See the description of *access* above for information on how to
   use this parameter.

   *offset* may be specified as a non-negative integer offset. mmap references
   will be relative to the offset from the beginning of the file. *offset*
   defaults to 0. *offset* must be a multiple of :const:`ALLOCATIONGRANULARITY`
   which is equal to :const:`PAGESIZE` on Unix systems.

   If *trackfd* is ``False``, the file descriptor specified by *fileno* will
   not be duplicated, and the resulting :class:`!mmap` object will not
   be associated with the map's underlying file.
   This means that the :meth:`~mmap.mmap.size` and :meth:`~mmap.mmap.resize`
   methods will fail.
   This mode is useful to limit the number of open file descriptors.

   To ensure validity of the created memory mapping the file specified
   by the descriptor *fileno* is internally automatically synchronized
   with the physical backing store on macOS.

   .. versionchanged:: 3.13
      The *trackfd* parameter was added.

   This example shows a simple way of using :class:`~mmap.mmap`::

      import mmap

      # write a simple example file
      with open("hello.txt", "wb") as f:
          f.write(b"Hello Python!\n")

      with open("hello.txt", "r+b") as f:
          # memory-map the file, size 0 means whole file
          mm = mmap.mmap(f.fileno(), 0)
          # read content via standard file methods
          print(mm.readline())  # prints b"Hello Python!\n"
          # read content via slice notation
          print(mm[:5])  # prints b"Hello"
          # update content using slice notation;
          # note that new content must have same size
          mm[6:] = b" world!\n"
          # ... and read again using standard file methods
          mm.seek(0)
          print(mm.readline())  # prints b"Hello  world!\n"
          # close the map
          mm.close()


   :class:`~mmap.mmap` can also be used as a context manager in a :keyword:`with`
   statement::

      import mmap

      with mmap.mmap(-1, 13) as mm:
          mm.write(b"Hello world!")

   .. versionadded:: 3.2
      Context manager support.


   The next example demonstrates how to create an anonymous map and exchange
   data between the parent and child processes::

      import mmap
      import os

      mm = mmap.mmap(-1, 13)
      mm.write(b"Hello world!")

      pid = os.fork()

      if pid == 0:  # In a child process
          mm.seek(0)
          print(mm.readline())

          mm.close()

   .. audit-event:: mmap.__new__ fileno,length,access,offset mmap.mmap

   Memory-mapped file objects support the following methods:

   .. method:: close()

      Closes the mmap. Subsequent calls to other methods of the object will
      result in a ValueError exception being raised. This will not close
      the open file.


   .. attribute:: closed

      ``True`` if the file is closed.

      .. versionadded:: 3.2


   .. method:: find(sub[, start[, end]])

      Returns the lowest index in the object where the subsequence *sub* is
      found, such that *sub* is contained in the range [*start*, *end*].
      Optional arguments *start* and *end* are interpreted as in slice notation.
      Returns ``-1`` on failure.

      .. versionchanged:: 3.5
         Writable :term:`bytes-like object` is now accepted.


   .. method:: flush([offset[, size]])

      Flushes changes made to the in-memory copy of a file back to disk. Without
      use of this call there is no guarantee that changes are written back before
      the object is destroyed.  If *offset* and *size* are specified, only
      changes to the given range of bytes will be flushed to disk; otherwise, the
      whole extent of the mapping is flushed.  *offset* must be a multiple of the
      :const:`PAGESIZE` or :const:`ALLOCATIONGRANULARITY`.

      ``None`` is returned to indicate success.  An exception is raised when the
      call failed.

      .. versionchanged:: 3.8
         Previously, a nonzero value was returned on success; zero was returned
         on error under Windows.  A zero value was returned on success; an
         exception was raised on error under Unix.


   .. method:: madvise(option[, start[, length]])

      Send advice *option* to the kernel about the memory region beginning at
      *start* and extending *length* bytes.  *option* must be one of the
      :ref:`MADV_* constants <madvise-constants>` available on the system.  If
      *start* and *length* are omitted, the entire mapping is spanned.  On
      some systems (including Linux), *start* must be a multiple of the
      :const:`PAGESIZE`.

      Availability: Systems with the ``madvise()`` system call.

      .. versionadded:: 3.8


   .. method:: move(dest, src, count)

      Copy the *count* bytes starting at offset *src* to the destination index
      *dest*.  If the mmap was created with :const:`ACCESS_READ`, then calls to
      move will raise a :exc:`TypeError` exception.


   .. method:: read([n])

      Return a :class:`bytes` containing up to *n* bytes starting from the
      current file position. If the argument is omitted, ``None`` or negative,
      return all bytes from the current file position to the end of the
      mapping. The file position is updated to point after the bytes that were
      returned.

      .. versionchanged:: 3.3
         Argument can be omitted or ``None``.

   .. method:: read_byte()

      Returns a byte at the current file position as an integer, and advances
      the file position by 1.


   .. method:: readline()

      Returns a single line, starting at the current file position and up to the
      next newline. The file position is updated to point after the bytes that were
      returned.


   .. method:: resize(newsize)

      Resizes the map and the underlying file, if any.

      Resizing a map created with *access* of :const:`ACCESS_READ` or
      :const:`ACCESS_COPY`, will raise a :exc:`TypeError` exception.
      Resizing a map created with with *trackfd* set to ``False``,
      will raise a :exc:`ValueError` exception.

      **On Windows**: Resizing the map will raise an :exc:`OSError` if there are other
      maps against the same named file. Resizing an anonymous map (ie against the
      pagefile) will silently create a new map with the original data copied over
      up to the length of the new size.

      .. versionchanged:: 3.11
         Correctly fails if attempting to resize when another map is held
         Allows resize against an anonymous map on Windows

   .. method:: rfind(sub[, start[, end]])

      Returns the highest index in the object where the subsequence *sub* is
      found, such that *sub* is contained in the range [*start*, *end*].
      Optional arguments *start* and *end* are interpreted as in slice notation.
      Returns ``-1`` on failure.

      .. versionchanged:: 3.5
         Writable :term:`bytes-like object` is now accepted.


   .. method:: seek(pos[, whence])

      Set the file's current position.  *whence* argument is optional and
      defaults to ``os.SEEK_SET`` or ``0`` (absolute file positioning); other
      values are ``os.SEEK_CUR`` or ``1`` (seek relative to the current
      position) and ``os.SEEK_END`` or ``2`` (seek relative to the file's end).

      .. versionchanged:: 3.13
         Return the new absolute position instead of ``None``.

   .. method:: seekable()

      Return whether the file supports seeking, and the return value is always ``True``.

      .. versionadded:: 3.13

   .. method:: size()

      Return the length of the file, which can be larger than the size of the
      memory-mapped area.


   .. method:: tell()

      Returns the current position of the file pointer.


   .. method:: write(bytes)

      Write the bytes in *bytes* into memory at the current position of the
      file pointer and return the number of bytes written (never less than
      ``len(bytes)``, since if the write fails, a :exc:`ValueError` will be
      raised).  The file position is updated to point after the bytes that
      were written.  If the mmap was created with :const:`ACCESS_READ`, then
      writing to it will raise a :exc:`TypeError` exception.

      .. versionchanged:: 3.5
         Writable :term:`bytes-like object` is now accepted.

      .. versionchanged:: 3.6
         The number of bytes written is now returned.


   .. method:: write_byte(byte)

      Write the integer *byte* into memory at the current
      position of the file pointer; the file position is advanced by ``1``. If
      the mmap was created with :const:`ACCESS_READ`, then writing to it will
      raise a :exc:`TypeError` exception.

.. _madvise-constants:

MADV_* Constants
++++++++++++++++

.. data:: MADV_NORMAL
          MADV_RANDOM
          MADV_SEQUENTIAL
          MADV_WILLNEED
          MADV_DONTNEED
          MADV_REMOVE
          MADV_DONTFORK
          MADV_DOFORK
          MADV_HWPOISON
          MADV_MERGEABLE
          MADV_UNMERGEABLE
          MADV_SOFT_OFFLINE
          MADV_HUGEPAGE
          MADV_NOHUGEPAGE
          MADV_DONTDUMP
          MADV_DODUMP
          MADV_FREE
          MADV_NOSYNC
          MADV_AUTOSYNC
          MADV_NOCORE
          MADV_CORE
          MADV_PROTECT
          MADV_FREE_REUSABLE
          MADV_FREE_REUSE

   These options can be passed to :meth:`mmap.madvise`.  Not every option will
   be present on every system.

   Availability: Systems with the madvise() system call.

   .. versionadded:: 3.8

.. _map-constants:

MAP_* Constants
+++++++++++++++

.. data:: MAP_SHARED
          MAP_PRIVATE
          MAP_32BIT
          MAP_ALIGNED_SUPER
          MAP_ANON
          MAP_ANONYMOUS
          MAP_CONCEAL
          MAP_DENYWRITE
          MAP_EXECUTABLE
          MAP_HASSEMAPHORE
          MAP_JIT
          MAP_NOCACHE
          MAP_NOEXTEND
          MAP_NORESERVE
          MAP_POPULATE
          MAP_RESILIENT_CODESIGN
          MAP_RESILIENT_MEDIA
          MAP_STACK
          MAP_TPRO
          MAP_TRANSLATED_ALLOW_EXECUTE
          MAP_UNIX03

    These are the various flags that can be passed to :meth:`mmap.mmap`.  :data:`MAP_ALIGNED_SUPER`
    is only available at FreeBSD and :data:`MAP_CONCEAL` is only available at OpenBSD.  Note
    that some options might not be present on some systems.

    .. versionchanged:: 3.10
       Added :data:`MAP_POPULATE` constant.

    .. versionadded:: 3.11
       Added :data:`MAP_STACK` constant.

    .. versionadded:: 3.12
       Added :data:`MAP_ALIGNED_SUPER` and :data:`MAP_CONCEAL` constants.

    .. versionadded:: 3.13
       Added :data:`MAP_32BIT`, :data:`MAP_HASSEMAPHORE`, :data:`MAP_JIT`,
       :data:`MAP_NOCACHE`, :data:`MAP_NOEXTEND`, :data:`MAP_NORESERVE`,
       :data:`MAP_RESILIENT_CODESIGN`, :data:`MAP_RESILIENT_MEDIA`,
       :data:`MAP_TPRO`, :data:`MAP_TRANSLATED_ALLOW_EXECUTE`, and
       :data:`MAP_UNIX03` constants.



================================================
File: /Doc/library/modulefinder.rst
================================================
:mod:`!modulefinder` --- Find modules used by a script
======================================================

.. module:: modulefinder
   :synopsis: Find modules used by a script.

.. sectionauthor:: A.M. Kuchling <amk@amk.ca>

**Source code:** :source:`Lib/modulefinder.py`

--------------

This module provides a :class:`ModuleFinder` class that can be used to determine
the set of modules imported by a script. ``modulefinder.py`` can also be run as
a script, giving the filename of a Python script as its argument, after which a
report of the imported modules will be printed.


.. function:: AddPackagePath(pkg_name, path)

   Record that the package named *pkg_name* can be found in the specified *path*.


.. function:: ReplacePackage(oldname, newname)

   Allows specifying that the module named *oldname* is in fact the package named
   *newname*.


.. class:: ModuleFinder(path=None, debug=0, excludes=[], replace_paths=[])

   This class provides :meth:`run_script` and :meth:`report` methods to determine
   the set of modules imported by a script. *path* can be a list of directories to
   search for modules; if not specified, ``sys.path`` is used.  *debug* sets the
   debugging level; higher values make the class print debugging messages about
   what it's doing. *excludes* is a list of module names to exclude from the
   analysis. *replace_paths* is a list of ``(oldpath, newpath)`` tuples that will
   be replaced in module paths.


   .. method:: report()

      Print a report to standard output that lists the modules imported by the
      script and their paths, as well as modules that are missing or seem to be
      missing.

   .. method:: run_script(pathname)

      Analyze the contents of the *pathname* file, which must contain Python
      code.

   .. attribute:: modules

      A dictionary mapping module names to modules. See
      :ref:`modulefinder-example`.


.. _modulefinder-example:

Example usage of :class:`ModuleFinder`
--------------------------------------

The script that is going to get analyzed later on (bacon.py)::

   import re, itertools

   try:
       import baconhameggs
   except ImportError:
       pass

   try:
       import guido.python.ham
   except ImportError:
       pass


The script that will output the report of bacon.py::

   from modulefinder import ModuleFinder

   finder = ModuleFinder()
   finder.run_script('bacon.py')

   print('Loaded modules:')
   for name, mod in finder.modules.items():
       print('%s: ' % name, end='')
       print(','.join(list(mod.globalnames.keys())[:3]))

   print('-'*50)
   print('Modules not imported:')
   print('\n'.join(finder.badmodules.keys()))

Sample output (may vary depending on the architecture)::

    Loaded modules:
    _types:
    copyreg:  _inverted_registry,_slotnames,__all__
    re._compiler:  isstring,_sre,_optimize_unicode
    _sre:
    re._constants:  REPEAT_ONE,makedict,AT_END_LINE
    sys:
    re:  __module__,finditer,_expand
    itertools:
    __main__:  re,itertools,baconhameggs
    re._parser:  _PATTERNENDERS,SRE_FLAG_UNICODE
    array:
    types:  __module__,IntType,TypeType
    ---------------------------------------------------
    Modules not imported:
    guido.python.ham
    baconhameggs




================================================
File: /Doc/library/modules.rst
================================================
.. _modules:

*****************
Importing Modules
*****************

The modules described in this chapter provide new ways to import other Python
modules and hooks for customizing the import process.

The full list of modules described in this chapter is:


.. toctree::

   zipimport.rst
   pkgutil.rst
   modulefinder.rst
   runpy.rst
   importlib.rst
   importlib.resources.rst
   importlib.resources.abc.rst
   importlib.metadata.rst
   sys_path_init.rst


================================================
File: /Doc/library/msilib.rst
================================================
:mod:`!msilib` --- Read and write Microsoft Installer files
===========================================================

.. module:: msilib
   :synopsis: Removed in 3.13.
   :deprecated:

.. deprecated-removed:: 3.11 3.13

This module is no longer part of the Python standard library.
It was :ref:`removed in Python 3.13 <whatsnew313-pep594>` after
being deprecated in Python 3.11.  The removal was decided in :pep:`594`.

The last version of Python that provided the :mod:`!msilib` module was
`Python 3.12 <https://docs.python.org/3.12/library/msilib.html>`_.


================================================
File: /Doc/library/msvcrt.rst
================================================
:mod:`!msvcrt` --- Useful routines from the MS VC++ runtime
===========================================================

.. module:: msvcrt
   :platform: Windows
   :synopsis: Miscellaneous useful routines from the MS VC++ runtime.

.. sectionauthor:: Fred L. Drake, Jr. <fdrake@acm.org>

--------------

These functions provide access to some useful capabilities on Windows platforms.
Some higher-level modules use these functions to build the Windows
implementations of their services. For example, the :mod:`getpass` module uses
this in the implementation of the :func:`getpass` function.

Further documentation on these functions can be found in the Platform API
documentation.

The module implements both the normal and wide char variants of the console I/O
api. The normal API deals only with ASCII characters and is of limited use
for internationalized applications. The wide char API should be used where
ever possible.

.. versionchanged:: 3.3
   Operations in this module now raise :exc:`OSError` where :exc:`IOError`
   was raised.


.. _msvcrt-files:

File Operations
---------------


.. function:: locking(fd, mode, nbytes)

   Lock part of a file based on file descriptor *fd* from the C runtime. Raises
   :exc:`OSError` on failure. The locked region of the file extends from the
   current file position for *nbytes* bytes, and may continue beyond the end of the
   file. *mode* must be one of the :const:`!LK_\*` constants listed below. Multiple
   regions in a file may be locked at the same time, but may not overlap. Adjacent
   regions are not merged; they must be unlocked individually.

   .. audit-event:: msvcrt.locking fd,mode,nbytes msvcrt.locking


.. data:: LK_LOCK
          LK_RLCK

   Locks the specified bytes. If the bytes cannot be locked, the program
   immediately tries again after 1 second. If, after 10 attempts, the bytes cannot
   be locked, :exc:`OSError` is raised.


.. data:: LK_NBLCK
          LK_NBRLCK

   Locks the specified bytes. If the bytes cannot be locked, :exc:`OSError` is
   raised.


.. data:: LK_UNLCK

   Unlocks the specified bytes, which must have been previously locked.


.. function:: setmode(fd, flags)

   Set the line-end translation mode for the file descriptor *fd*. To set it to
   text mode, *flags* should be :const:`os.O_TEXT`; for binary, it should be
   :const:`os.O_BINARY`.


.. function:: open_osfhandle(handle, flags)

   Create a C runtime file descriptor from the file handle *handle*. The *flags*
   parameter should be a bitwise OR of :const:`os.O_APPEND`,
   :const:`os.O_RDONLY`, :const:`os.O_TEXT` and :const:`os.O_NOINHERIT`.
   The returned file descriptor may be used as a parameter
   to :func:`os.fdopen` to create a file object.

   The file descriptor is inheritable by default. Pass :const:`os.O_NOINHERIT`
   flag to make it non inheritable.

   .. audit-event:: msvcrt.open_osfhandle handle,flags msvcrt.open_osfhandle


.. function:: get_osfhandle(fd)

   Return the file handle for the file descriptor *fd*. Raises :exc:`OSError` if
   *fd* is not recognized.

   .. audit-event:: msvcrt.get_osfhandle fd msvcrt.get_osfhandle


.. _msvcrt-console:

Console I/O
-----------


.. function:: kbhit()

   Returns a nonzero value if a keypress is waiting to be read. Otherwise,
   return 0.


.. function:: getch()

   Read a keypress and return the resulting character as a byte string.
   Nothing is echoed to the console. This call will block if a keypress
   is not already available, but will not wait for :kbd:`Enter` to be
   pressed. If the pressed key was a special function key, this will
   return ``'\000'`` or ``'\xe0'``; the next call will return the keycode.
   The :kbd:`Control-C` keypress cannot be read with this function.


.. function:: getwch()

   Wide char variant of :func:`getch`, returning a Unicode value.


.. function:: getche()

   Similar to :func:`getch`, but the keypress will be echoed if it represents a
   printable character.


.. function:: getwche()

   Wide char variant of :func:`getche`, returning a Unicode value.


.. function:: putch(char)

   Print the byte string *char* to the console without buffering.


.. function:: putwch(unicode_char)

   Wide char variant of :func:`putch`, accepting a Unicode value.


.. function:: ungetch(char)

   Cause the byte string *char* to be "pushed back" into the console buffer;
   it will be the next character read by :func:`getch` or :func:`getche`.


.. function:: ungetwch(unicode_char)

   Wide char variant of :func:`ungetch`, accepting a Unicode value.


.. _msvcrt-other:

Other Functions
---------------


.. function:: heapmin()

   Force the :c:func:`malloc` heap to clean itself up and return unused blocks to
   the operating system. On failure, this raises :exc:`OSError`.


.. function:: set_error_mode(mode)

   Changes the location where the C runtime writes an error message for an error
   that might end the program. *mode* must be one of the :const:`!OUT_\*`
   constants listed below  or :const:`REPORT_ERRMODE`. Returns the old setting
   or -1 if an error occurs. Only available in
   :ref:`debug build of Python <debug-build>`.


.. data:: OUT_TO_DEFAULT

   Error sink is determined by the app's type. Only available in
   :ref:`debug build of Python <debug-build>`.


.. data:: OUT_TO_STDERR

   Error sink is a standard error. Only available in
   :ref:`debug build of Python <debug-build>`.


.. data:: OUT_TO_MSGBOX

   Error sink is a message box. Only available in
   :ref:`debug build of Python <debug-build>`.


.. data:: REPORT_ERRMODE

   Report the current error mode value. Only available in
   :ref:`debug build of Python <debug-build>`.


.. function:: CrtSetReportMode(type, mode)

   Specifies the destination or destinations for a specific report type
   generated by :c:func:`!_CrtDbgReport` in the MS VC++ runtime. *type* must be
   one of the :const:`!CRT_\*` constants listed below. *mode* must be one of the
   :const:`!CRTDBG_\*` constants listed below. Only available in
   :ref:`debug build of Python <debug-build>`.


.. function:: CrtSetReportFile(type, file)

   After you use :func:`CrtSetReportMode` to specify :const:`CRTDBG_MODE_FILE`,
   you can specify the file handle to receive the message text. *type* must be
   one of the :const:`!CRT_\*` constants listed below. *file* should be the file
   handle your want specified. Only available in
   :ref:`debug build of Python <debug-build>`.


.. data:: CRT_WARN

   Warnings, messages, and information that doesn't need immediate attention.


.. data:: CRT_ERROR

   Errors, unrecoverable problems, and issues that require immediate attention.


.. data:: CRT_ASSERT

   Assertion failures.


.. data:: CRTDBG_MODE_DEBUG

   Writes the message to the debugger's output window.


.. data:: CRTDBG_MODE_FILE

   Writes the message to a user-supplied file handle. :func:`CrtSetReportFile`
   should be called to define the specific file or stream to use as
   the destination.


.. data:: CRTDBG_MODE_WNDW

   Creates a message box to display the message along with the ``Abort``,
   ``Retry``, and ``Ignore`` buttons.


.. data:: CRTDBG_REPORT_MODE

   Returns current *mode* for the specified *type*.


.. data:: CRT_ASSEMBLY_VERSION

   The CRT Assembly version, from the :file:`crtassem.h` header file.


.. data:: VC_ASSEMBLY_PUBLICKEYTOKEN

   The VC Assembly public key token, from the :file:`crtassem.h` header file.


.. data:: LIBRARIES_ASSEMBLY_NAME_PREFIX

   The Libraries Assembly name prefix, from the :file:`crtassem.h` header file.


================================================
File: /Doc/library/multiprocessing.shared_memory.rst
================================================
:mod:`!multiprocessing.shared_memory` --- Shared memory for direct access across processes
==========================================================================================

.. module:: multiprocessing.shared_memory
   :synopsis: Provides shared memory for direct access across processes.

**Source code:** :source:`Lib/multiprocessing/shared_memory.py`

.. versionadded:: 3.8

.. index::
   single: Shared Memory
   single: POSIX Shared Memory
   single: Named Shared Memory

--------------

This module provides a class, :class:`SharedMemory`, for the allocation
and management of shared memory to be accessed by one or more processes
on a multicore or symmetric multiprocessor (SMP) machine.  To assist with
the life-cycle management of shared memory especially across distinct
processes, a :class:`~multiprocessing.managers.BaseManager` subclass,
:class:`~multiprocessing.managers.SharedMemoryManager`, is also provided in the
:mod:`multiprocessing.managers` module.

In this module, shared memory refers to "POSIX style" shared memory blocks
(though is not necessarily implemented explicitly as such) and does not refer
to "distributed shared memory".  This style of shared memory permits distinct
processes to potentially read and write to a common (or shared) region of
volatile memory.  Processes are conventionally limited to only have access to
their own process memory space but shared memory permits the sharing
of data between processes, avoiding the need to instead send messages between
processes containing that data.  Sharing data directly via memory can provide
significant performance benefits compared to sharing data via disk or socket
or other communications requiring the serialization/deserialization and
copying of data.


.. class:: SharedMemory(name=None, create=False, size=0, *, track=True)

   Create an instance of the :class:`!SharedMemory` class for either
   creating a new shared memory block or attaching to an existing shared
   memory block.  Each shared memory block is assigned a unique name.
   In this way, one process can create a shared memory block with a
   particular name and a different process can attach to that same shared
   memory block using that same name.

   As a resource for sharing data across processes, shared memory blocks
   may outlive the original process that created them.  When one process
   no longer needs access to a shared memory block that might still be
   needed by other processes, the :meth:`close` method should be called.
   When a shared memory block is no longer needed by any process, the
   :meth:`unlink` method should be called to ensure proper cleanup.

   :param name:
      The unique name for the requested shared memory, specified as a string.
      When creating a new shared memory block, if ``None`` (the default)
      is supplied for the name, a novel name will be generated.
   :type name: str | None

   :param bool create:
      Control whether a new shared memory block is created (``True``)
      or an existing shared memory block is attached (``False``).

   :param int size:
      The requested number of bytes when creating a new shared memory block.
      Because some platforms choose to allocate chunks of memory
      based upon that platform's memory page size, the exact size of the shared
      memory block may be larger or equal to the size requested.
      When attaching to an existing shared memory block,
      the *size* parameter is ignored.

   :param bool track:
      When ``True``, register the shared memory block with a resource
      tracker process on platforms where the OS does not do this automatically.
      The resource tracker ensures proper cleanup of the shared memory even
      if all other processes with access to the memory exit without doing so.
      Python processes created from a common ancestor using :mod:`multiprocessing`
      facilities share a single resource tracker process, and the lifetime of
      shared memory segments is handled automatically among these processes.
      Python processes created in any other way will receive their own
      resource tracker when accessing shared memory with *track* enabled.
      This will cause the shared memory to be deleted by the resource tracker
      of the first process that terminates.
      To avoid this issue, users of :mod:`subprocess` or standalone Python
      processes should set *track* to ``False`` when there is already another
      process in place that does the bookkeeping.
      *track* is ignored on Windows, which has its own tracking and
      automatically deletes shared memory when all handles to it have been closed.

   .. versionchanged:: 3.13
      Added the *track* parameter.

   .. method:: close()

      Close the file descriptor/handle to the shared memory from this
      instance.  :meth:`close` should be called once access to the shared
      memory block from this instance is no longer needed.  Depending
      on operating system, the underlying memory may or may not be freed
      even if all handles to it have been closed.  To ensure proper cleanup,
      use the :meth:`unlink` method.

   .. method:: unlink()

      Delete the underlying shared memory block.  This should be called only
      once per shared memory block regardless of the number of handles to it,
      even in other processes.
      :meth:`unlink` and :meth:`close` can be called in any order, but
      trying to access data inside a shared memory block after :meth:`unlink`
      may result in memory access errors, depending on platform.

      This method has no effect on Windows, where the only way to delete a
      shared memory block is to close all handles.

   .. attribute:: buf

      A memoryview of contents of the shared memory block.

   .. attribute:: name

      Read-only access to the unique name of the shared memory block.

   .. attribute:: size

      Read-only access to size in bytes of the shared memory block.


The following example demonstrates low-level use of :class:`SharedMemory`
instances::

   >>> from multiprocessing import shared_memory
   >>> shm_a = shared_memory.SharedMemory(create=True, size=10)
   >>> type(shm_a.buf)
   <class 'memoryview'>
   >>> buffer = shm_a.buf
   >>> len(buffer)
   10
   >>> buffer[:4] = bytearray([22, 33, 44, 55])  # Modify multiple at once
   >>> buffer[4] = 100                           # Modify single byte at a time
   >>> # Attach to an existing shared memory block
   >>> shm_b = shared_memory.SharedMemory(shm_a.name)
   >>> import array
   >>> array.array('b', shm_b.buf[:5])  # Copy the data into a new array.array
   array('b', [22, 33, 44, 55, 100])
   >>> shm_b.buf[:5] = b'howdy'  # Modify via shm_b using bytes
   >>> bytes(shm_a.buf[:5])      # Access via shm_a
   b'howdy'
   >>> shm_b.close()   # Close each SharedMemory instance
   >>> shm_a.close()
   >>> shm_a.unlink()  # Call unlink only once to release the shared memory



The following example demonstrates a practical use of the :class:`SharedMemory`
class with `NumPy arrays <https://numpy.org/>`_, accessing the
same :class:`!numpy.ndarray` from two distinct Python shells:

.. doctest::
   :options: +SKIP

   >>> # In the first Python interactive shell
   >>> import numpy as np
   >>> a = np.array([1, 1, 2, 3, 5, 8])  # Start with an existing NumPy array
   >>> from multiprocessing import shared_memory
   >>> shm = shared_memory.SharedMemory(create=True, size=a.nbytes)
   >>> # Now create a NumPy array backed by shared memory
   >>> b = np.ndarray(a.shape, dtype=a.dtype, buffer=shm.buf)
   >>> b[:] = a[:]  # Copy the original data into shared memory
   >>> b
   array([1, 1, 2, 3, 5, 8])
   >>> type(b)
   <class 'numpy.ndarray'>
   >>> type(a)
   <class 'numpy.ndarray'>
   >>> shm.name  # We did not specify a name so one was chosen for us
   'psm_21467_46075'

   >>> # In either the same shell or a new Python shell on the same machine
   >>> import numpy as np
   >>> from multiprocessing import shared_memory
   >>> # Attach to the existing shared memory block
   >>> existing_shm = shared_memory.SharedMemory(name='psm_21467_46075')
   >>> # Note that a.shape is (6,) and a.dtype is np.int64 in this example
   >>> c = np.ndarray((6,), dtype=np.int64, buffer=existing_shm.buf)
   >>> c
   array([1, 1, 2, 3, 5, 8])
   >>> c[-1] = 888
   >>> c
   array([  1,   1,   2,   3,   5, 888])

   >>> # Back in the first Python interactive shell, b reflects this change
   >>> b
   array([  1,   1,   2,   3,   5, 888])

   >>> # Clean up from within the second Python shell
   >>> del c  # Unnecessary; merely emphasizing the array is no longer used
   >>> existing_shm.close()

   >>> # Clean up from within the first Python shell
   >>> del b  # Unnecessary; merely emphasizing the array is no longer used
   >>> shm.close()
   >>> shm.unlink()  # Free and release the shared memory block at the very end


.. class:: SharedMemoryManager([address[, authkey]])
   :module: multiprocessing.managers

   A subclass of :class:`multiprocessing.managers.BaseManager` which can be
   used for the management of shared memory blocks across processes.

   A call to :meth:`~multiprocessing.managers.BaseManager.start` on a
   :class:`!SharedMemoryManager` instance causes a new process to be started.
   This new process's sole purpose is to manage the life cycle
   of all shared memory blocks created through it.  To trigger the release
   of all shared memory blocks managed by that process, call
   :meth:`~multiprocessing.managers.BaseManager.shutdown` on the instance.
   This triggers a :meth:`~multiprocessing.shared_memory.SharedMemory.unlink` call
   on all of the :class:`SharedMemory` objects managed by that process and then
   stops the process itself.  By creating :class:`!SharedMemory` instances
   through a :class:`!SharedMemoryManager`, we avoid the need to manually track
   and trigger the freeing of shared memory resources.

   This class provides methods for creating and returning :class:`SharedMemory`
   instances and for creating a list-like object (:class:`ShareableList`)
   backed by shared memory.

   Refer to :class:`~multiprocessing.managers.BaseManager` for a description
   of the inherited *address* and *authkey* optional input arguments and how
   they may be used to connect to an existing :class:`!SharedMemoryManager` service
   from other processes.

   .. method:: SharedMemory(size)

      Create and return a new :class:`SharedMemory` object with the
      specified *size* in bytes.

   .. method:: ShareableList(sequence)

      Create and return a new :class:`ShareableList` object, initialized
      by the values from the input *sequence*.


The following example demonstrates the basic mechanisms of a
:class:`~multiprocessing.managers.SharedMemoryManager`:

.. doctest::
   :options: +SKIP

   >>> from multiprocessing.managers import SharedMemoryManager
   >>> smm = SharedMemoryManager()
   >>> smm.start()  # Start the process that manages the shared memory blocks
   >>> sl = smm.ShareableList(range(4))
   >>> sl
   ShareableList([0, 1, 2, 3], name='psm_6572_7512')
   >>> raw_shm = smm.SharedMemory(size=128)
   >>> another_sl = smm.ShareableList('alpha')
   >>> another_sl
   ShareableList(['a', 'l', 'p', 'h', 'a'], name='psm_6572_12221')
   >>> smm.shutdown()  # Calls unlink() on sl, raw_shm, and another_sl

The following example depicts a potentially more convenient pattern for using
:class:`~multiprocessing.managers.SharedMemoryManager` objects via the
:keyword:`with` statement to ensure that all shared memory blocks are released
after they are no longer needed:

.. doctest::
   :options: +SKIP

   >>> with SharedMemoryManager() as smm:
   ...     sl = smm.ShareableList(range(2000))
   ...     # Divide the work among two processes, storing partial results in sl
   ...     p1 = Process(target=do_work, args=(sl, 0, 1000))
   ...     p2 = Process(target=do_work, args=(sl, 1000, 2000))
   ...     p1.start()
   ...     p2.start()  # A multiprocessing.Pool might be more efficient
   ...     p1.join()
   ...     p2.join()   # Wait for all work to complete in both processes
   ...     total_result = sum(sl)  # Consolidate the partial results now in sl

When using a :class:`~multiprocessing.managers.SharedMemoryManager`
in a :keyword:`with` statement, the shared memory blocks created using that
manager are all released when the :keyword:`!with` statement's code block
finishes execution.


.. class:: ShareableList(sequence=None, *, name=None)

   Provide a mutable list-like object where all values stored within are
   stored in a shared memory block.
   This constrains storable values to the following built-in data types:

   * :class:`int` (signed 64-bit)
   * :class:`float`
   * :class:`bool`
   * :class:`str` (less than 10M bytes each when encoded as UTF-8)
   * :class:`bytes` (less than 10M bytes each)
   * ``None``

   It also notably differs from the built-in :class:`list` type
   in that these lists can not change their overall length
   (i.e. no :meth:`!append`, :meth:`!insert`, etc.) and do not
   support the dynamic creation of new :class:`!ShareableList` instances
   via slicing.

   *sequence* is used in populating a new :class:`!ShareableList` full of values.
   Set to ``None`` to instead attach to an already existing
   :class:`!ShareableList` by its unique shared memory name.

   *name* is the unique name for the requested shared memory, as described
   in the definition for :class:`SharedMemory`.  When attaching to an
   existing :class:`!ShareableList`, specify its shared memory block's unique
   name while leaving *sequence* set to ``None``.

   .. note::

      A known issue exists for :class:`bytes` and :class:`str` values.
      If they end with ``\x00`` nul bytes or characters, those may be
      *silently stripped* when fetching them by index from the
      :class:`!ShareableList`. This ``.rstrip(b'\x00')`` behavior is
      considered a bug and may go away in the future. See :gh:`106939`.

   For applications where rstripping of trailing nulls is a problem,
   work around it by always unconditionally appending an extra non-0
   byte to the end of such values when storing and unconditionally
   removing it when fetching:

   .. doctest::

       >>> from multiprocessing import shared_memory
       >>> nul_bug_demo = shared_memory.ShareableList(['?\x00', b'\x03\x02\x01\x00\x00\x00'])
       >>> nul_bug_demo[0]
       '?'
       >>> nul_bug_demo[1]
       b'\x03\x02\x01'
       >>> nul_bug_demo.shm.unlink()
       >>> padded = shared_memory.ShareableList(['?\x00\x07', b'\x03\x02\x01\x00\x00\x00\x07'])
       >>> padded[0][:-1]
       '?\x00'
       >>> padded[1][:-1]
       b'\x03\x02\x01\x00\x00\x00'
       >>> padded.shm.unlink()

   .. method:: count(value)

      Return the number of occurrences of *value*.

   .. method:: index(value)

      Return first index position of *value*.
      Raise :exc:`ValueError` if *value* is not present.

   .. attribute:: format

      Read-only attribute containing the :mod:`struct` packing format used by
      all currently stored values.

   .. attribute:: shm

      The :class:`SharedMemory` instance where the values are stored.


The following example demonstrates basic use of a :class:`ShareableList`
instance:

   >>> from multiprocessing import shared_memory
   >>> a = shared_memory.ShareableList(['howdy', b'HoWdY', -273.154, 100, None, True, 42])
   >>> [ type(entry) for entry in a ]
   [<class 'str'>, <class 'bytes'>, <class 'float'>, <class 'int'>, <class 'NoneType'>, <class 'bool'>, <class 'int'>]
   >>> a[2]
   -273.154
   >>> a[2] = -78.5
   >>> a[2]
   -78.5
   >>> a[2] = 'dry ice'  # Changing data types is supported as well
   >>> a[2]
   'dry ice'
   >>> a[2] = 'larger than previously allocated storage space'
   Traceback (most recent call last):
     ...
   ValueError: exceeds available storage for existing str
   >>> a[2]
   'dry ice'
   >>> len(a)
   7
   >>> a.index(42)
   6
   >>> a.count(b'howdy')
   0
   >>> a.count(b'HoWdY')
   1
   >>> a.shm.close()
   >>> a.shm.unlink()
   >>> del a  # Use of a ShareableList after call to unlink() is unsupported

The following example depicts how one, two, or many processes may access the
same :class:`ShareableList` by supplying the name of the shared memory block
behind it:

   >>> b = shared_memory.ShareableList(range(5))         # In a first process
   >>> c = shared_memory.ShareableList(name=b.shm.name)  # In a second process
   >>> c
   ShareableList([0, 1, 2, 3, 4], name='...')
   >>> c[-1] = -999
   >>> b[-1]
   -999
   >>> b.shm.close()
   >>> c.shm.close()
   >>> c.shm.unlink()

The following examples demonstrates that :class:`ShareableList`
(and underlying :class:`SharedMemory`) objects
can be pickled and unpickled if needed.
Note, that it will still be the same shared object.
This happens, because the deserialized object has
the same unique name and is just attached to an existing
object with the same name (if the object is still alive):

   >>> import pickle
   >>> from multiprocessing import shared_memory
   >>> sl = shared_memory.ShareableList(range(10))
   >>> list(sl)
   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

   >>> deserialized_sl = pickle.loads(pickle.dumps(sl))
   >>> list(deserialized_sl)
   [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]

   >>> sl[0] = -1
   >>> deserialized_sl[1] = -2
   >>> list(sl)
   [-1, -2, 2, 3, 4, 5, 6, 7, 8, 9]
   >>> list(deserialized_sl)
   [-1, -2, 2, 3, 4, 5, 6, 7, 8, 9]

   >>> sl.shm.close()
   >>> sl.shm.unlink()


================================================
File: /Doc/library/netdata.rst
================================================

.. _netdata:

**********************
Internet Data Handling
**********************

This chapter describes modules which support handling data formats commonly used
on the internet.


.. toctree::

   email.rst
   json.rst
   mailbox.rst
   mimetypes.rst
   base64.rst
   binascii.rst
   quopri.rst


================================================
File: /Doc/library/netrc.rst
================================================
:mod:`!netrc` --- netrc file processing
=======================================

.. module:: netrc
   :synopsis: Loading of .netrc files.

.. moduleauthor:: Eric S. Raymond <esr@snark.thyrsus.com>
.. sectionauthor:: Eric S. Raymond <esr@snark.thyrsus.com>

**Source code:** :source:`Lib/netrc.py`

--------------

The :class:`~netrc.netrc` class parses and encapsulates the netrc file format used by
the Unix :program:`ftp` program and other FTP clients.


.. class:: netrc([file])

   A :class:`~netrc.netrc` instance or subclass instance encapsulates data from  a netrc
   file.  The initialization argument, if present, specifies the file to parse.  If
   no argument is given, the file :file:`.netrc` in the user's home directory --
   as determined by :func:`os.path.expanduser` -- will be read.  Otherwise,
   a :exc:`FileNotFoundError` exception will be raised.
   Parse errors will raise :exc:`NetrcParseError` with diagnostic
   information including the file name, line number, and terminating token.
   If no argument is specified on a POSIX system, the presence of passwords in
   the :file:`.netrc` file will raise a :exc:`NetrcParseError` if the file
   ownership or permissions are insecure (owned by a user other than the user
   running the process, or accessible for read or write by any other user).
   This implements security behavior equivalent to that of ftp and other
   programs that use :file:`.netrc`.

   .. versionchanged:: 3.4 Added the POSIX permission check.

   .. versionchanged:: 3.7
      :func:`os.path.expanduser` is used to find the location of the
      :file:`.netrc` file when *file* is not passed as argument.

   .. versionchanged:: 3.10
      :class:`netrc` try UTF-8 encoding before using locale specific
      encoding.
      The entry in the netrc file no longer needs to contain all tokens.  The missing
      tokens' value default to an empty string.  All the tokens and their values now
      can contain arbitrary characters, like whitespace and non-ASCII characters.
      If the login name is anonymous, it won't trigger the security check.


.. exception:: NetrcParseError

   Exception raised by the :class:`~netrc.netrc` class when syntactical errors are
   encountered in source text.  Instances of this exception provide three
   interesting attributes:

   .. attribute:: msg

      Textual explanation of the error.

   .. attribute:: filename

      The name of the source file.

   .. attribute:: lineno

      The line number on which the error was found.


.. _netrc-objects:

netrc Objects
-------------

A :class:`~netrc.netrc` instance has the following methods:


.. method:: netrc.authenticators(host)

   Return a 3-tuple ``(login, account, password)`` of authenticators for *host*.
   If the netrc file did not contain an entry for the given host, return the tuple
   associated with the 'default' entry.  If neither matching host nor default entry
   is available, return ``None``.


.. method:: netrc.__repr__()

   Dump the class data as a string in the format of a netrc file. (This discards
   comments and may reorder the entries.)

Instances of :class:`~netrc.netrc` have public instance variables:


.. attribute:: netrc.hosts

   Dictionary mapping host names to ``(login, account, password)`` tuples.  The
   'default' entry, if any, is represented as a pseudo-host by that name.


.. attribute:: netrc.macros

   Dictionary mapping macro names to string lists.


================================================
File: /Doc/library/nis.rst
================================================
:mod:`!nis` --- Interface to Sun’s NIS (Yellow Pages)
=====================================================

.. module:: nis
   :synopsis: Removed in 3.13.
   :deprecated:

.. deprecated-removed:: 3.11 3.13

This module is no longer part of the Python standard library.
It was :ref:`removed in Python 3.13 <whatsnew313-pep594>` after
being deprecated in Python 3.11.  The removal was decided in :pep:`594`.

The last version of Python that provided the :mod:`!nis` module was
`Python 3.12 <https://docs.python.org/3.12/library/nis.html>`_.


================================================
File: /Doc/library/nntplib.rst
================================================
:mod:`!nntplib` --- NNTP protocol client
========================================

.. module:: nntplib
   :synopsis: Removed in 3.13.
   :deprecated:

.. deprecated-removed:: 3.11 3.13

This module is no longer part of the Python standard library.
It was :ref:`removed in Python 3.13 <whatsnew313-pep594>` after
being deprecated in Python 3.11.  The removal was decided in :pep:`594`.

The last version of Python that provided the :mod:`!nntplib` module was
`Python 3.12 <https://docs.python.org/3.12/library/nntplib.html>`_.


================================================
File: /Doc/library/numbers.rst
================================================
:mod:`!numbers` --- Numeric abstract base classes
=================================================

.. module:: numbers
   :synopsis: Numeric abstract base classes (Complex, Real, Integral, etc.).

**Source code:** :source:`Lib/numbers.py`

--------------

The :mod:`!numbers` module (:pep:`3141`) defines a hierarchy of numeric
:term:`abstract base classes <abstract base class>` which progressively define
more operations.  None of the types defined in this module are intended to be instantiated.


.. class:: Number

   The root of the numeric hierarchy. If you just want to check if an argument
   *x* is a number, without caring what kind, use ``isinstance(x, Number)``.


The numeric tower
-----------------

.. class:: Complex

   Subclasses of this type describe complex numbers and include the operations
   that work on the built-in :class:`complex` type. These are: conversions to
   :class:`complex` and :class:`bool`, :attr:`.real`, :attr:`.imag`, ``+``,
   ``-``, ``*``, ``/``, ``**``, :func:`abs`, :meth:`conjugate`, ``==``, and
   ``!=``. All except ``-`` and ``!=`` are abstract.

   .. attribute:: real

      Abstract. Retrieves the real component of this number.

   .. attribute:: imag

      Abstract. Retrieves the imaginary component of this number.

   .. abstractmethod:: conjugate()

      Abstract. Returns the complex conjugate. For example, ``(1+3j).conjugate()
      == (1-3j)``.

.. class:: Real

   To :class:`Complex`, :class:`!Real` adds the operations that work on real
   numbers.

   In short, those are: a conversion to :class:`float`, :func:`math.trunc`,
   :func:`round`, :func:`math.floor`, :func:`math.ceil`, :func:`divmod`, ``//``,
   ``%``, ``<``, ``<=``, ``>``, and ``>=``.

   Real also provides defaults for :func:`complex`, :attr:`~Complex.real`,
   :attr:`~Complex.imag`, and :meth:`~Complex.conjugate`.


.. class:: Rational

   Subtypes :class:`Real` and adds :attr:`~Rational.numerator` and
   :attr:`~Rational.denominator` properties. It also provides a default for
   :func:`float`.

   The :attr:`~Rational.numerator` and :attr:`~Rational.denominator` values
   should be instances of :class:`Integral` and should be in lowest terms with
   :attr:`~Rational.denominator` positive.

   .. attribute:: numerator

      Abstract.

   .. attribute:: denominator

      Abstract.


.. class:: Integral

   Subtypes :class:`Rational` and adds a conversion to :class:`int`.  Provides
   defaults for :func:`float`, :attr:`~Rational.numerator`, and
   :attr:`~Rational.denominator`.  Adds abstract methods for :func:`pow` with
   modulus and bit-string operations: ``<<``, ``>>``, ``&``, ``^``, ``|``,
   ``~``.


Notes for type implementers
---------------------------

Implementers should be careful to make equal numbers equal and hash
them to the same values. This may be subtle if there are two different
extensions of the real numbers. For example, :class:`fractions.Fraction`
implements :func:`hash` as follows::

    def __hash__(self):
        if self.denominator == 1:
            # Get integers right.
            return hash(self.numerator)
        # Expensive check, but definitely correct.
        if self == float(self):
            return hash(float(self))
        else:
            # Use tuple's hash to avoid a high collision rate on
            # simple fractions.
            return hash((self.numerator, self.denominator))


Adding More Numeric ABCs
~~~~~~~~~~~~~~~~~~~~~~~~

There are, of course, more possible ABCs for numbers, and this would
be a poor hierarchy if it precluded the possibility of adding
those. You can add ``MyFoo`` between :class:`Complex` and
:class:`Real` with::

    class MyFoo(Complex): ...
    MyFoo.register(Real)


.. _implementing-the-arithmetic-operations:

Implementing the arithmetic operations
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

We want to implement the arithmetic operations so that mixed-mode
operations either call an implementation whose author knew about the
types of both arguments, or convert both to the nearest built in type
and do the operation there. For subtypes of :class:`Integral`, this
means that :meth:`~object.__add__` and :meth:`~object.__radd__` should be
defined as::

    class MyIntegral(Integral):

        def __add__(self, other):
            if isinstance(other, MyIntegral):
                return do_my_adding_stuff(self, other)
            elif isinstance(other, OtherTypeIKnowAbout):
                return do_my_other_adding_stuff(self, other)
            else:
                return NotImplemented

        def __radd__(self, other):
            if isinstance(other, MyIntegral):
                return do_my_adding_stuff(other, self)
            elif isinstance(other, OtherTypeIKnowAbout):
                return do_my_other_adding_stuff(other, self)
            elif isinstance(other, Integral):
                return int(other) + int(self)
            elif isinstance(other, Real):
                return float(other) + float(self)
            elif isinstance(other, Complex):
                return complex(other) + complex(self)
            else:
                return NotImplemented


There are 5 different cases for a mixed-type operation on subclasses
of :class:`Complex`. I'll refer to all of the above code that doesn't
refer to ``MyIntegral`` and ``OtherTypeIKnowAbout`` as
"boilerplate". ``a`` will be an instance of ``A``, which is a subtype
of :class:`Complex` (``a : A <: Complex``), and ``b : B <:
Complex``. I'll consider ``a + b``:

1. If ``A`` defines an :meth:`~object.__add__` which accepts ``b``, all is
   well.
2. If ``A`` falls back to the boilerplate code, and it were to
   return a value from :meth:`~object.__add__`, we'd miss the possibility
   that ``B`` defines a more intelligent :meth:`~object.__radd__`, so the
   boilerplate should return :data:`NotImplemented` from
   :meth:`!__add__`. (Or ``A`` may not implement :meth:`!__add__` at
   all.)
3. Then ``B``'s :meth:`~object.__radd__` gets a chance. If it accepts
   ``a``, all is well.
4. If it falls back to the boilerplate, there are no more possible
   methods to try, so this is where the default implementation
   should live.
5. If ``B <: A``, Python tries ``B.__radd__`` before
   ``A.__add__``. This is ok, because it was implemented with
   knowledge of ``A``, so it can handle those instances before
   delegating to :class:`Complex`.

If ``A <: Complex`` and ``B <: Real`` without sharing any other knowledge,
then the appropriate shared operation is the one involving the built
in :class:`complex`, and both :meth:`~object.__radd__` s land there, so ``a+b
== b+a``.

Because most of the operations on any given type will be very similar,
it can be useful to define a helper function which generates the
forward and reverse instances of any given operator. For example,
:class:`fractions.Fraction` uses::

    def _operator_fallbacks(monomorphic_operator, fallback_operator):
        def forward(a, b):
            if isinstance(b, (int, Fraction)):
                return monomorphic_operator(a, b)
            elif isinstance(b, float):
                return fallback_operator(float(a), b)
            elif isinstance(b, complex):
                return fallback_operator(complex(a), b)
            else:
                return NotImplemented
        forward.__name__ = '__' + fallback_operator.__name__ + '__'
        forward.__doc__ = monomorphic_operator.__doc__

        def reverse(b, a):
            if isinstance(a, Rational):
                # Includes ints.
                return monomorphic_operator(a, b)
            elif isinstance(a, Real):
                return fallback_operator(float(a), float(b))
            elif isinstance(a, Complex):
                return fallback_operator(complex(a), complex(b))
            else:
                return NotImplemented
        reverse.__name__ = '__r' + fallback_operator.__name__ + '__'
        reverse.__doc__ = monomorphic_operator.__doc__

        return forward, reverse

    def _add(a, b):
        """a + b"""
        return Fraction(a.numerator * b.denominator +
                        b.numerator * a.denominator,
                        a.denominator * b.denominator)

    __add__, __radd__ = _operator_fallbacks(_add, operator.add)

    # ...


================================================
File: /Doc/library/numeric.rst
================================================

.. _numeric:

********************************
Numeric and Mathematical Modules
********************************

The modules described in this chapter provide numeric and math-related functions
and data types. The :mod:`numbers` module defines an abstract hierarchy of
numeric types. The :mod:`math` and :mod:`cmath` modules contain various
mathematical functions for floating-point and complex numbers. The :mod:`decimal`
module supports exact representations of decimal numbers, using arbitrary precision
arithmetic.

The following modules are documented in this chapter:


.. toctree::

   numbers.rst
   math.rst
   cmath.rst
   decimal.rst
   fractions.rst
   random.rst
   statistics.rst


================================================
File: /Doc/library/operator.rst
================================================
:mod:`!operator` --- Standard operators as functions
====================================================

.. module:: operator
   :synopsis: Functions corresponding to the standard operators.

.. sectionauthor:: Skip Montanaro <skip@automatrix.com>

**Source code:** :source:`Lib/operator.py`

.. testsetup::

   import operator
   from operator import itemgetter, iadd

--------------

The :mod:`operator` module exports a set of efficient functions corresponding to
the intrinsic operators of Python.  For example, ``operator.add(x, y)`` is
equivalent to the expression ``x+y``. Many function names are those used for
special methods, without the double underscores.  For backward compatibility,
many of these have a variant with the double underscores kept. The variants
without the double underscores are preferred for clarity.

The functions fall into categories that perform object comparisons, logical
operations, mathematical operations and sequence operations.

The object comparison functions are useful for all objects, and are named after
the rich comparison operators they support:


.. function:: lt(a, b)
              le(a, b)
              eq(a, b)
              ne(a, b)
              ge(a, b)
              gt(a, b)
              __lt__(a, b)
              __le__(a, b)
              __eq__(a, b)
              __ne__(a, b)
              __ge__(a, b)
              __gt__(a, b)

   Perform "rich comparisons" between *a* and *b*. Specifically, ``lt(a, b)`` is
   equivalent to ``a < b``, ``le(a, b)`` is equivalent to ``a <= b``, ``eq(a,
   b)`` is equivalent to ``a == b``, ``ne(a, b)`` is equivalent to ``a != b``,
   ``gt(a, b)`` is equivalent to ``a > b`` and ``ge(a, b)`` is equivalent to ``a
   >= b``.  Note that these functions can return any value, which may
   or may not be interpretable as a Boolean value.  See
   :ref:`comparisons` for more information about rich comparisons.


The logical operations are also generally applicable to all objects, and support
truth tests, identity tests, and boolean operations:


.. function:: not_(obj)
              __not__(obj)

   Return the outcome of :keyword:`not` *obj*.  (Note that there is no
   :meth:`!__not__` method for object instances; only the interpreter core defines
   this operation.  The result is affected by the :meth:`~object.__bool__` and
   :meth:`~object.__len__` methods.)


.. function:: truth(obj)

   Return :const:`True` if *obj* is true, and :const:`False` otherwise.  This is
   equivalent to using the :class:`bool` constructor.


.. function:: is_(a, b)

   Return ``a is b``.  Tests object identity.


.. function:: is_not(a, b)

   Return ``a is not b``.  Tests object identity.


.. function:: is_none(a)

   Return ``a is None``.  Tests object identity.

   .. versionadded:: 3.14


.. function:: is_not_none(a)

   Return ``a is not None``.  Tests object identity.

   .. versionadded:: 3.14


The mathematical and bitwise operations are the most numerous:


.. function:: abs(obj)
              __abs__(obj)

   Return the absolute value of *obj*.


.. function:: add(a, b)
              __add__(a, b)

   Return ``a + b``, for *a* and *b* numbers.


.. function:: and_(a, b)
              __and__(a, b)

   Return the bitwise and of *a* and *b*.


.. function:: floordiv(a, b)
              __floordiv__(a, b)

   Return ``a // b``.


.. function:: index(a)
              __index__(a)

   Return *a* converted to an integer.  Equivalent to ``a.__index__()``.

   .. versionchanged:: 3.10
      The result always has exact type :class:`int`.  Previously, the result
      could have been an instance of a subclass of ``int``.


.. function:: inv(obj)
              invert(obj)
              __inv__(obj)
              __invert__(obj)

   Return the bitwise inverse of the number *obj*.  This is equivalent to ``~obj``.


.. function:: lshift(a, b)
              __lshift__(a, b)

   Return *a* shifted left by *b*.


.. function:: mod(a, b)
              __mod__(a, b)

   Return ``a % b``.


.. function:: mul(a, b)
              __mul__(a, b)

   Return ``a * b``, for *a* and *b* numbers.


.. function:: matmul(a, b)
              __matmul__(a, b)

   Return ``a @ b``.

   .. versionadded:: 3.5


.. function:: neg(obj)
              __neg__(obj)

   Return *obj* negated (``-obj``).


.. function:: or_(a, b)
              __or__(a, b)

   Return the bitwise or of *a* and *b*.


.. function:: pos(obj)
              __pos__(obj)

   Return *obj* positive (``+obj``).


.. function:: pow(a, b)
              __pow__(a, b)

   Return ``a ** b``, for *a* and *b* numbers.


.. function:: rshift(a, b)
              __rshift__(a, b)

   Return *a* shifted right by *b*.


.. function:: sub(a, b)
              __sub__(a, b)

   Return ``a - b``.


.. function:: truediv(a, b)
              __truediv__(a, b)

   Return ``a / b`` where 2/3 is .66 rather than 0.  This is also known as
   "true" division.


.. function:: xor(a, b)
              __xor__(a, b)

   Return the bitwise exclusive or of *a* and *b*.


Operations which work with sequences (some of them with mappings too) include:

.. function:: concat(a, b)
              __concat__(a, b)

   Return ``a + b`` for *a* and *b* sequences.


.. function:: contains(a, b)
              __contains__(a, b)

   Return the outcome of the test ``b in a``. Note the reversed operands.


.. function:: countOf(a, b)

   Return the number of occurrences of *b* in *a*.


.. function:: delitem(a, b)
              __delitem__(a, b)

   Remove the value of *a* at index *b*.


.. function:: getitem(a, b)
              __getitem__(a, b)

   Return the value of *a* at index *b*.


.. function:: indexOf(a, b)

   Return the index of the first of occurrence of *b* in *a*.


.. function:: setitem(a, b, c)
              __setitem__(a, b, c)

   Set the value of *a* at index *b* to *c*.


.. function:: length_hint(obj, default=0)

   Return an estimated length for the object *obj*. First try to return its
   actual length, then an estimate using :meth:`object.__length_hint__`, and
   finally return the default value.

   .. versionadded:: 3.4


The following operation works with callables:

.. function:: call(obj, /, *args, **kwargs)
              __call__(obj, /, *args, **kwargs)

   Return ``obj(*args, **kwargs)``.

   .. versionadded:: 3.11


The :mod:`operator` module also defines tools for generalized attribute and item
lookups.  These are useful for making fast field extractors as arguments for
:func:`map`, :func:`sorted`, :meth:`itertools.groupby`, or other functions that
expect a function argument.


.. function:: attrgetter(attr)
              attrgetter(*attrs)

   Return a callable object that fetches *attr* from its operand.
   If more than one attribute is requested, returns a tuple of attributes.
   The attribute names can also contain dots. For example:

   * After ``f = attrgetter('name')``, the call ``f(b)`` returns ``b.name``.

   * After ``f = attrgetter('name', 'date')``, the call ``f(b)`` returns
     ``(b.name, b.date)``.

   * After ``f = attrgetter('name.first', 'name.last')``, the call ``f(b)``
     returns ``(b.name.first, b.name.last)``.

   Equivalent to::

      def attrgetter(*items):
          if any(not isinstance(item, str) for item in items):
              raise TypeError('attribute name must be a string')
          if len(items) == 1:
              attr = items[0]
              def g(obj):
                  return resolve_attr(obj, attr)
          else:
              def g(obj):
                  return tuple(resolve_attr(obj, attr) for attr in items)
          return g

      def resolve_attr(obj, attr):
          for name in attr.split("."):
              obj = getattr(obj, name)
          return obj


.. function:: itemgetter(item)
              itemgetter(*items)

   Return a callable object that fetches *item* from its operand using the
   operand's :meth:`~object.__getitem__` method.  If multiple items are specified,
   returns a tuple of lookup values.  For example:

   * After ``f = itemgetter(2)``, the call ``f(r)`` returns ``r[2]``.

   * After ``g = itemgetter(2, 5, 3)``, the call ``g(r)`` returns
     ``(r[2], r[5], r[3])``.

   Equivalent to::

      def itemgetter(*items):
          if len(items) == 1:
              item = items[0]
              def g(obj):
                  return obj[item]
          else:
              def g(obj):
                  return tuple(obj[item] for item in items)
          return g

   The items can be any type accepted by the operand's :meth:`~object.__getitem__`
   method.  Dictionaries accept any :term:`hashable` value.  Lists, tuples, and
   strings accept an index or a slice:

      >>> itemgetter(1)('ABCDEFG')
      'B'
      >>> itemgetter(1, 3, 5)('ABCDEFG')
      ('B', 'D', 'F')
      >>> itemgetter(slice(2, None))('ABCDEFG')
      'CDEFG'
      >>> soldier = dict(rank='captain', name='dotterbart')
      >>> itemgetter('rank')(soldier)
      'captain'

   Example of using :func:`itemgetter` to retrieve specific fields from a
   tuple record:

      >>> inventory = [('apple', 3), ('banana', 2), ('pear', 5), ('orange', 1)]
      >>> getcount = itemgetter(1)
      >>> list(map(getcount, inventory))
      [3, 2, 5, 1]
      >>> sorted(inventory, key=getcount)
      [('orange', 1), ('banana', 2), ('apple', 3), ('pear', 5)]


.. function:: methodcaller(name, /, *args, **kwargs)

   Return a callable object that calls the method *name* on its operand.  If
   additional arguments and/or keyword arguments are given, they will be given
   to the method as well.  For example:

   * After ``f = methodcaller('name')``, the call ``f(b)`` returns ``b.name()``.

   * After ``f = methodcaller('name', 'foo', bar=1)``, the call ``f(b)``
     returns ``b.name('foo', bar=1)``.

   Equivalent to::

      def methodcaller(name, /, *args, **kwargs):
          def caller(obj):
              return getattr(obj, name)(*args, **kwargs)
          return caller


.. _operator-map:

Mapping Operators to Functions
------------------------------

This table shows how abstract operations correspond to operator symbols in the
Python syntax and the functions in the :mod:`operator` module.

+-----------------------+-------------------------+---------------------------------------+
| Operation             | Syntax                  | Function                              |
+=======================+=========================+=======================================+
| Addition              | ``a + b``               | ``add(a, b)``                         |
+-----------------------+-------------------------+---------------------------------------+
| Concatenation         | ``seq1 + seq2``         | ``concat(seq1, seq2)``                |
+-----------------------+-------------------------+---------------------------------------+
| Containment Test      | ``obj in seq``          | ``contains(seq, obj)``                |
+-----------------------+-------------------------+---------------------------------------+
| Division              | ``a / b``               | ``truediv(a, b)``                     |
+-----------------------+-------------------------+---------------------------------------+
| Division              | ``a // b``              | ``floordiv(a, b)``                    |
+-----------------------+-------------------------+---------------------------------------+
| Bitwise And           | ``a & b``               | ``and_(a, b)``                        |
+-----------------------+-------------------------+---------------------------------------+
| Bitwise Exclusive Or  | ``a ^ b``               | ``xor(a, b)``                         |
+-----------------------+-------------------------+---------------------------------------+
| Bitwise Inversion     | ``~ a``                 | ``invert(a)``                         |
+-----------------------+-------------------------+---------------------------------------+
| Bitwise Or            | ``a | b``               | ``or_(a, b)``                         |
+-----------------------+-------------------------+---------------------------------------+
| Exponentiation        | ``a ** b``              | ``pow(a, b)``                         |
+-----------------------+-------------------------+---------------------------------------+
| Identity              | ``a is b``              | ``is_(a, b)``                         |
+-----------------------+-------------------------+---------------------------------------+
| Identity              | ``a is not b``          | ``is_not(a, b)``                      |
+-----------------------+-------------------------+---------------------------------------+
| Identity              | ``a is None``           | ``is_none(a)``                        |
+-----------------------+-------------------------+---------------------------------------+
| Identity              | ``a is not None``       | ``is_not_none(a)``                    |
+-----------------------+-------------------------+---------------------------------------+
| Indexed Assignment    | ``obj[k] = v``          | ``setitem(obj, k, v)``                |
+-----------------------+-------------------------+---------------------------------------+
| Indexed Deletion      | ``del obj[k]``          | ``delitem(obj, k)``                   |
+-----------------------+-------------------------+---------------------------------------+
| Indexing              | ``obj[k]``              | ``getitem(obj, k)``                   |
+-----------------------+-------------------------+---------------------------------------+
| Left Shift            | ``a << b``              | ``lshift(a, b)``                      |
+-----------------------+-------------------------+---------------------------------------+
| Modulo                | ``a % b``               | ``mod(a, b)``                         |
+-----------------------+-------------------------+---------------------------------------+
| Multiplication        | ``a * b``               | ``mul(a, b)``                         |
+-----------------------+-------------------------+---------------------------------------+
| Matrix Multiplication | ``a @ b``               | ``matmul(a, b)``                      |
+-----------------------+-------------------------+---------------------------------------+
| Negation (Arithmetic) | ``- a``                 | ``neg(a)``                            |
+-----------------------+-------------------------+---------------------------------------+
| Negation (Logical)    | ``not a``               | ``not_(a)``                           |
+-----------------------+-------------------------+---------------------------------------+
| Positive              | ``+ a``                 | ``pos(a)``                            |
+-----------------------+-------------------------+---------------------------------------+
| Right Shift           | ``a >> b``              | ``rshift(a, b)``                      |
+-----------------------+-------------------------+---------------------------------------+
| Slice Assignment      | ``seq[i:j] = values``   | ``setitem(seq, slice(i, j), values)`` |
+-----------------------+-------------------------+---------------------------------------+
| Slice Deletion        | ``del seq[i:j]``        | ``delitem(seq, slice(i, j))``         |
+-----------------------+-------------------------+---------------------------------------+
| Slicing               | ``seq[i:j]``            | ``getitem(seq, slice(i, j))``         |
+-----------------------+-------------------------+---------------------------------------+
| String Formatting     | ``s % obj``             | ``mod(s, obj)``                       |
+-----------------------+-------------------------+---------------------------------------+
| Subtraction           | ``a - b``               | ``sub(a, b)``                         |
+-----------------------+-------------------------+---------------------------------------+
| Truth Test            | ``obj``                 | ``truth(obj)``                        |
+-----------------------+-------------------------+---------------------------------------+
| Ordering              | ``a < b``               | ``lt(a, b)``                          |
+-----------------------+-------------------------+---------------------------------------+
| Ordering              | ``a <= b``              | ``le(a, b)``                          |
+-----------------------+-------------------------+---------------------------------------+
| Equality              | ``a == b``              | ``eq(a, b)``                          |
+-----------------------+-------------------------+---------------------------------------+
| Difference            | ``a != b``              | ``ne(a, b)``                          |
+-----------------------+-------------------------+---------------------------------------+
| Ordering              | ``a >= b``              | ``ge(a, b)``                          |
+-----------------------+-------------------------+---------------------------------------+
| Ordering              | ``a > b``               | ``gt(a, b)``                          |
+-----------------------+-------------------------+---------------------------------------+

In-place Operators
------------------

Many operations have an "in-place" version.  Listed below are functions
providing a more primitive access to in-place operators than the usual syntax
does; for example, the :term:`statement` ``x += y`` is equivalent to
``x = operator.iadd(x, y)``.  Another way to put it is to say that
``z = operator.iadd(x, y)`` is equivalent to the compound statement
``z = x; z += y``.

In those examples, note that when an in-place method is called, the computation
and assignment are performed in two separate steps.  The in-place functions
listed below only do the first step, calling the in-place method.  The second
step, assignment, is not handled.

For immutable targets such as strings, numbers, and tuples, the updated
value is computed, but not assigned back to the input variable:

>>> a = 'hello'
>>> iadd(a, ' world')
'hello world'
>>> a
'hello'

For mutable targets such as lists and dictionaries, the in-place method
will perform the update, so no subsequent assignment is necessary:

>>> s = ['h', 'e', 'l', 'l', 'o']
>>> iadd(s, [' ', 'w', 'o', 'r', 'l', 'd'])
['h', 'e', 'l', 'l', 'o', ' ', 'w', 'o', 'r', 'l', 'd']
>>> s
['h', 'e', 'l', 'l', 'o', ' ', 'w', 'o', 'r', 'l', 'd']

.. function:: iadd(a, b)
              __iadd__(a, b)

   ``a = iadd(a, b)`` is equivalent to ``a += b``.


.. function:: iand(a, b)
              __iand__(a, b)

   ``a = iand(a, b)`` is equivalent to ``a &= b``.


.. function:: iconcat(a, b)
              __iconcat__(a, b)

   ``a = iconcat(a, b)`` is equivalent to ``a += b`` for *a* and *b* sequences.


.. function:: ifloordiv(a, b)
              __ifloordiv__(a, b)

   ``a = ifloordiv(a, b)`` is equivalent to ``a //= b``.


.. function:: ilshift(a, b)
              __ilshift__(a, b)

   ``a = ilshift(a, b)`` is equivalent to ``a <<= b``.


.. function:: imod(a, b)
              __imod__(a, b)

   ``a = imod(a, b)`` is equivalent to ``a %= b``.


.. function:: imul(a, b)
              __imul__(a, b)

   ``a = imul(a, b)`` is equivalent to ``a *= b``.


.. function:: imatmul(a, b)
              __imatmul__(a, b)

   ``a = imatmul(a, b)`` is equivalent to ``a @= b``.

   .. versionadded:: 3.5


.. function:: ior(a, b)
              __ior__(a, b)

   ``a = ior(a, b)`` is equivalent to ``a |= b``.


.. function:: ipow(a, b)
              __ipow__(a, b)

   ``a = ipow(a, b)`` is equivalent to ``a **= b``.


.. function:: irshift(a, b)
              __irshift__(a, b)

   ``a = irshift(a, b)`` is equivalent to ``a >>= b``.


.. function:: isub(a, b)
              __isub__(a, b)

   ``a = isub(a, b)`` is equivalent to ``a -= b``.


.. function:: itruediv(a, b)
              __itruediv__(a, b)

   ``a = itruediv(a, b)`` is equivalent to ``a /= b``.


.. function:: ixor(a, b)
              __ixor__(a, b)

   ``a = ixor(a, b)`` is equivalent to ``a ^= b``.


================================================
File: /Doc/library/os.path.rst
================================================
:mod:`!os.path` --- Common pathname manipulations
=================================================

.. module:: os.path
   :synopsis: Operations on pathnames.

**Source code:** :source:`Lib/genericpath.py`, :source:`Lib/posixpath.py` (for POSIX) and
:source:`Lib/ntpath.py` (for Windows).

.. index:: single: path; operations

--------------

This module implements some useful functions on pathnames. To read or write
files see :func:`open`, and for accessing the filesystem see the :mod:`os`
module. The path parameters can be passed as strings, or bytes, or any object
implementing the :class:`os.PathLike` protocol.

Unlike a Unix shell, Python does not do any *automatic* path expansions.
Functions such as :func:`expanduser` and :func:`expandvars` can be invoked
explicitly when an application desires shell-like path expansion.  (See also
the :mod:`glob` module.)


.. seealso::
   The :mod:`pathlib` module offers high-level path objects.


.. note::

   All of these functions accept either only bytes or only string objects as
   their parameters.  The result is an object of the same type, if a path or
   file name is returned.

.. note::

   Since different operating systems have different path name conventions, there
   are several versions of this module in the standard library.  The
   :mod:`os.path` module is always the path module suitable for the operating
   system Python is running on, and therefore usable for local paths.  However,
   you can also import and use the individual modules if you want to manipulate
   a path that is *always* in one of the different formats.  They all have the
   same interface:

   * :mod:`posixpath` for UNIX-style paths
   * :mod:`ntpath` for Windows paths


.. versionchanged:: 3.8

   :func:`exists`, :func:`lexists`, :func:`isdir`, :func:`isfile`,
   :func:`islink`, and :func:`ismount` now return ``False`` instead of
   raising an exception for paths that contain characters or bytes
   unrepresentable at the OS level.


.. function:: abspath(path)

   Return a normalized absolutized version of the pathname *path*. On most
   platforms, this is equivalent to calling the function :func:`normpath` as
   follows: ``normpath(join(os.getcwd(), path))``.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


.. function:: basename(path)

   Return the base name of pathname *path*.  This is the second element of the
   pair returned by passing *path* to the function :func:`split`.  Note that
   the result of this function is different
   from the Unix :program:`basename` program; where :program:`basename` for
   ``'/foo/bar/'`` returns ``'bar'``, the :func:`basename` function returns an
   empty string (``''``).

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


.. function:: commonpath(paths)

   Return the longest common sub-path of each pathname in the iterable
   *paths*.  Raise :exc:`ValueError` if *paths* contain both absolute
   and relative pathnames, if *paths* are on different drives, or
   if *paths* is empty.  Unlike :func:`commonprefix`, this returns a
   valid path.

   .. versionadded:: 3.5

   .. versionchanged:: 3.6
      Accepts a sequence of :term:`path-like objects <path-like object>`.

   .. versionchanged:: 3.13
      Any iterable can now be passed, rather than just sequences.


.. function:: commonprefix(list)

   Return the longest path prefix (taken character-by-character) that is a
   prefix of all paths in  *list*.  If *list* is empty, return the empty string
   (``''``).

   .. note::

      This function may return invalid paths because it works a
      character at a time.  To obtain a valid path, see
      :func:`commonpath`.

      ::

        >>> os.path.commonprefix(['/usr/lib', '/usr/local/lib'])
        '/usr/l'

        >>> os.path.commonpath(['/usr/lib', '/usr/local/lib'])
        '/usr'

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


.. function:: dirname(path)

   Return the directory name of pathname *path*.  This is the first element of
   the pair returned by passing *path* to the function :func:`split`.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


.. function:: exists(path)

   Return ``True`` if *path* refers to an existing path or an open
   file descriptor.  Returns ``False`` for broken symbolic links.  On
   some platforms, this function may return ``False`` if permission is
   not granted to execute :func:`os.stat` on the requested file, even
   if the *path* physically exists.

   .. versionchanged:: 3.3
      *path* can now be an integer: ``True`` is returned if it is an
       open file descriptor, ``False`` otherwise.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


.. function:: lexists(path)

   Return ``True`` if *path* refers to an existing path, including
   broken symbolic links.   Equivalent to :func:`exists` on platforms lacking
   :func:`os.lstat`.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


.. index:: single: ~ (tilde); home directory expansion

.. function:: expanduser(path)

   On Unix and Windows, return the argument with an initial component of ``~`` or
   ``~user`` replaced by that *user*'s home directory.

   .. index:: pair: module; pwd

   On Unix, an initial ``~`` is replaced by the environment variable :envvar:`HOME`
   if it is set; otherwise the current user's home directory is looked up in the
   password directory through the built-in module :mod:`pwd`. An initial ``~user``
   is looked up directly in the password directory.

   On Windows, :envvar:`USERPROFILE` will be used if set, otherwise a combination
   of :envvar:`HOMEPATH` and :envvar:`HOMEDRIVE` will be used.  An initial
   ``~user`` is handled by checking that the last directory component of the current
   user's home directory matches :envvar:`USERNAME`, and replacing it if so.

   If the expansion fails or if the path does not begin with a tilde, the path is
   returned unchanged.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.

   .. versionchanged:: 3.8
      No longer uses :envvar:`HOME` on Windows.

.. index::
   single: $ (dollar); environment variables expansion
   single: % (percent); environment variables expansion (Windows)

.. function:: expandvars(path)

   Return the argument with environment variables expanded.  Substrings of the form
   ``$name`` or ``${name}`` are replaced by the value of environment variable
   *name*.  Malformed variable names and references to non-existing variables are
   left unchanged.

   On Windows, ``%name%`` expansions are supported in addition to ``$name`` and
   ``${name}``.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


.. function:: getatime(path)

   Return the time of last access of *path*.  The return value is a floating-point number giving
   the number of seconds since the epoch (see the  :mod:`time` module).  Raise
   :exc:`OSError` if the file does not exist or is inaccessible.


.. function:: getmtime(path)

   Return the time of last modification of *path*.  The return value is a floating-point number
   giving the number of seconds since the epoch (see the  :mod:`time` module).
   Raise :exc:`OSError` if the file does not exist or is inaccessible.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


.. function:: getctime(path)

   Return the system's ctime which, on some systems (like Unix) is the time of the
   last metadata change, and, on others (like Windows), is the creation time for *path*.
   The return value is a number giving the number of seconds since the epoch (see
   the  :mod:`time` module).  Raise :exc:`OSError` if the file does not exist or
   is inaccessible.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


.. function:: getsize(path)

   Return the size, in bytes, of *path*.  Raise :exc:`OSError` if the file does
   not exist or is inaccessible.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


.. function:: isabs(path)

   Return ``True`` if *path* is an absolute pathname.  On Unix, that means it
   begins with a slash, on Windows that it begins with two (back)slashes, or a
   drive letter, colon, and (back)slash together.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.

   .. versionchanged:: 3.13
      On Windows, returns ``False`` if the given path starts with exactly one
      (back)slash.


.. function:: isfile(path)

   Return ``True`` if *path* is an :func:`existing <exists>` regular file.
   This follows symbolic links, so both :func:`islink` and :func:`isfile` can
   be true for the same path.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


.. function:: isdir(path)

   Return ``True`` if *path* is an :func:`existing <exists>` directory.  This
   follows symbolic links, so both :func:`islink` and :func:`isdir` can be true
   for the same path.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


.. function:: isjunction(path)

   Return ``True`` if *path* refers to an :func:`existing <lexists>` directory
   entry that is a junction.  Always return ``False`` if junctions are not
   supported on the current platform.

   .. versionadded:: 3.12


.. function:: islink(path)

   Return ``True`` if *path* refers to an :func:`existing <exists>` directory
   entry that is a symbolic link.  Always ``False`` if symbolic links are not
   supported by the Python runtime.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


.. function:: ismount(path)

   Return ``True`` if pathname *path* is a :dfn:`mount point`: a point in a
   file system where a different file system has been mounted.  On POSIX, the
   function checks whether *path*'s parent, :file:`{path}/..`, is on a different
   device than *path*, or whether :file:`{path}/..` and *path* point to the same
   i-node on the same device --- this should detect mount points for all Unix
   and POSIX variants.  It is not able to reliably detect bind mounts on the
   same filesystem.  On Windows, a drive letter root and a share UNC are
   always mount points, and for any other path ``GetVolumePathName`` is called
   to see if it is different from the input path.

   .. versionchanged:: 3.4
      Added support for detecting non-root mount points on Windows.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


.. function:: isdevdrive(path)

   Return ``True`` if pathname *path* is located on a Windows Dev Drive.
   A Dev Drive is optimized for developer scenarios, and offers faster
   performance for reading and writing files. It is recommended for use for
   source code, temporary build directories, package caches, and other
   IO-intensive operations.

   May raise an error for an invalid path, for example, one without a
   recognizable drive, but returns ``False`` on platforms that do not support
   Dev Drives. See `the Windows documentation <https://learn.microsoft.com/windows/dev-drive/>`_
   for information on enabling and creating Dev Drives.

   .. versionadded:: 3.12

   .. versionchanged:: 3.13
      The function is now available on all platforms, and will always return ``False`` on those that have no support for Dev Drives


.. function:: isreserved(path)

   Return ``True`` if *path* is a reserved pathname on the current system.

   On Windows, reserved filenames include those that end with a space or dot;
   those that contain colons (i.e. file streams such as "name:stream"),
   wildcard characters (i.e. ``'*?"<>'``), pipe, or ASCII control characters;
   as well as DOS device names such as "NUL", "CON", "CONIN$", "CONOUT$",
   "AUX", "PRN", "COM1", and "LPT1".

   .. note::

      This function approximates rules for reserved paths on most Windows
      systems. These rules change over time in various Windows releases.
      This function may be updated in future Python releases as changes to
      the rules become broadly available.

   .. availability:: Windows.

   .. versionadded:: 3.13


.. function:: join(path, *paths)

   Join one or more path segments intelligently.  The return value is the
   concatenation of *path* and all members of *\*paths*, with exactly one
   directory separator following each non-empty part, except the last. That is,
   the result will only end in a separator if the last part is either empty or
   ends in a separator. If a segment is an absolute path (which on Windows
   requires both a drive and a root), then all previous segments are ignored and
   joining continues from the absolute path segment.

   On Windows, the drive is not reset when a rooted path segment (e.g.,
   ``r'\foo'``) is encountered. If a segment is on a different drive or is an
   absolute path, all previous segments are ignored and the drive is reset. Note
   that since there is a current directory for each drive,
   ``os.path.join("c:", "foo")`` represents a path relative to the current
   directory on drive :file:`C:` (:file:`c:foo`), not :file:`c:\\foo`.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object` for *path* and *paths*.


.. function:: normcase(path)

   Normalize the case of a pathname.  On Windows, convert all characters in the
   pathname to lowercase, and also convert forward slashes to backward slashes.
   On other operating systems, return the path unchanged.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


.. function:: normpath(path)

   Normalize a pathname by collapsing redundant separators and up-level
   references so that ``A//B``, ``A/B/``, ``A/./B`` and ``A/foo/../B`` all
   become ``A/B``.  This string manipulation may change the meaning of a path
   that contains symbolic links.  On Windows, it converts forward slashes to
   backward slashes. To normalize case, use :func:`normcase`.

   .. note::
      On POSIX systems, in accordance with `IEEE Std 1003.1 2013 Edition; 4.13
      Pathname Resolution <https://pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap04.html#tag_04_13>`_,
      if a pathname begins with exactly two slashes, the first component
      following the leading characters may be interpreted in an implementation-defined
      manner, although more than two leading characters shall be treated as a
      single character.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


.. function:: realpath(path, *, strict=False)

   Return the canonical path of the specified filename, eliminating any symbolic
   links encountered in the path (if they are supported by the operating
   system). On Windows, this function will also resolve MS-DOS (also called 8.3)
   style names such as ``C:\\PROGRA~1`` to ``C:\\Program Files``.

   If a path doesn't exist or a symlink loop is encountered, and *strict* is
   ``True``, :exc:`OSError` is raised. If *strict* is ``False`` these errors
   are ignored, and so the result might be missing or otherwise inaccessible.

   .. note::
      This function emulates the operating system's procedure for making a path
      canonical, which differs slightly between Windows and UNIX with respect
      to how links and subsequent path components interact.

      Operating system APIs make paths canonical as needed, so it's not
      normally necessary to call this function.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.

   .. versionchanged:: 3.8
      Symbolic links and junctions are now resolved on Windows.

   .. versionchanged:: 3.10
      The *strict* parameter was added.


.. function:: relpath(path, start=os.curdir)

   Return a relative filepath to *path* either from the current directory or
   from an optional *start* directory.  This is a path computation:  the
   filesystem is not accessed to confirm the existence or nature of *path* or
   *start*.  On Windows, :exc:`ValueError` is raised when *path* and *start*
   are on different drives.

   *start* defaults to :data:`os.curdir`.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


.. function:: samefile(path1, path2)

   Return ``True`` if both pathname arguments refer to the same file or directory.
   This is determined by the device number and i-node number and raises an
   exception if an :func:`os.stat` call on either pathname fails.

   .. versionchanged:: 3.2
      Added Windows support.

   .. versionchanged:: 3.4
      Windows now uses the same implementation as all other platforms.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


.. function:: sameopenfile(fp1, fp2)

   Return ``True`` if the file descriptors *fp1* and *fp2* refer to the same file.

   .. versionchanged:: 3.2
      Added Windows support.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


.. function:: samestat(stat1, stat2)

   Return ``True`` if the stat tuples *stat1* and *stat2* refer to the same file.
   These structures may have been returned by :func:`os.fstat`,
   :func:`os.lstat`, or :func:`os.stat`.  This function implements the
   underlying comparison used by :func:`samefile` and :func:`sameopenfile`.

   .. versionchanged:: 3.4
      Added Windows support.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


.. function:: split(path)

   Split the pathname *path* into a pair, ``(head, tail)`` where *tail* is the
   last pathname component and *head* is everything leading up to that.  The
   *tail* part will never contain a slash; if *path* ends in a slash, *tail*
   will be empty.  If there is no slash in *path*, *head* will be empty.  If
   *path* is empty, both *head* and *tail* are empty.  Trailing slashes are
   stripped from *head* unless it is the root (one or more slashes only).  In
   all cases, ``join(head, tail)`` returns a path to the same location as *path*
   (but the strings may differ).  Also see the functions :func:`dirname` and
   :func:`basename`.

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


.. function:: splitdrive(path)

   Split the pathname *path* into a pair ``(drive, tail)`` where *drive* is either
   a mount point or the empty string.  On systems which do not use drive
   specifications, *drive* will always be the empty string.  In all cases, ``drive
   + tail`` will be the same as *path*.

   On Windows, splits a pathname into drive/UNC sharepoint and relative path.

   If the path contains a drive letter, drive will contain everything
   up to and including the colon::

      >>> splitdrive("c:/dir")
      ("c:", "/dir")

   If the path contains a UNC path, drive will contain the host name
   and share::

      >>> splitdrive("//host/computer/dir")
      ("//host/computer", "/dir")

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


.. function:: splitroot(path)

   Split the pathname *path* into a 3-item tuple ``(drive, root, tail)`` where
   *drive* is a device name or mount point, *root* is a string of separators
   after the drive, and *tail* is everything after the root. Any of these
   items may be the empty string. In all cases, ``drive + root + tail`` will
   be the same as *path*.

   On POSIX systems, *drive* is always empty. The *root* may be empty (if *path* is
   relative), a single forward slash (if *path* is absolute), or two forward slashes
   (implementation-defined per `IEEE Std 1003.1-2017; 4.13 Pathname Resolution
   <https://pubs.opengroup.org/onlinepubs/9699919799/basedefs/V1_chap04.html#tag_04_13>`_.)
   For example::

      >>> splitroot('/home/sam')
      ('', '/', 'home/sam')
      >>> splitroot('//home/sam')
      ('', '//', 'home/sam')
      >>> splitroot('///home/sam')
      ('', '/', '//home/sam')

   On Windows, *drive* may be empty, a drive-letter name, a UNC share, or a device
   name. The *root* may be empty, a forward slash, or a backward slash. For
   example::

      >>> splitroot('C:/Users/Sam')
      ('C:', '/', 'Users/Sam')
      >>> splitroot('//Server/Share/Users/Sam')
      ('//Server/Share', '/', 'Users/Sam')

   .. versionadded:: 3.12


.. function:: splitext(path)

   Split the pathname *path* into a pair ``(root, ext)``  such that ``root + ext ==
   path``, and the extension, *ext*, is empty or begins with a period and contains at
   most one period.

   If the path contains no extension, *ext* will be ``''``::

      >>> splitext('bar')
      ('bar', '')

   If the path contains an extension, then *ext* will be set to this extension,
   including the leading period. Note that previous periods will be ignored::

      >>> splitext('foo.bar.exe')
      ('foo.bar', '.exe')
      >>> splitext('/foo/bar.exe')
      ('/foo/bar', '.exe')

   Leading periods of the last component of the path are considered to
   be part of the root::

      >>> splitext('.cshrc')
      ('.cshrc', '')
      >>> splitext('/foo/....jpg')
      ('/foo/....jpg', '')

   .. versionchanged:: 3.6
      Accepts a :term:`path-like object`.


.. data:: supports_unicode_filenames

   ``True`` if arbitrary Unicode strings can be used as file names (within limitations
   imposed by the file system).


================================================
File: /Doc/library/ossaudiodev.rst
================================================
:mod:`!ossaudiodev` --- Access to OSS-compatible audio devices
==============================================================

.. module:: ossaudiodev
   :synopsis: Removed in 3.13.
   :deprecated:

.. deprecated-removed:: 3.11 3.13

This module is no longer part of the Python standard library.
It was :ref:`removed in Python 3.13 <whatsnew313-pep594>` after
being deprecated in Python 3.11.  The removal was decided in :pep:`594`.

The last version of Python that provided the :mod:`!ossaudiodev` module was
`Python 3.12 <https://docs.python.org/3.12/library/ossaudiodev.html>`_.


================================================
File: /Doc/library/pdb.rst
================================================
.. _debugger:

:mod:`pdb` --- The Python Debugger
==================================

.. module:: pdb
   :synopsis: The Python debugger for interactive interpreters.

**Source code:** :source:`Lib/pdb.py`

.. index:: single: debugging

--------------

The module :mod:`pdb` defines an interactive source code debugger for Python
programs.  It supports setting (conditional) breakpoints and single stepping at
the source line level, inspection of stack frames, source code listing, and
evaluation of arbitrary Python code in the context of any stack frame.  It also
supports post-mortem debugging and can be called under program control.

.. index::
   single: Pdb (class in pdb)
   pair: module; bdb
   pair: module; cmd

The debugger is extensible -- it is actually defined as the class :class:`Pdb`.
This is currently undocumented but easily understood by reading the source.  The
extension interface uses the modules :mod:`bdb` and :mod:`cmd`.

.. seealso::

   Module :mod:`faulthandler`
      Used to dump Python tracebacks explicitly, on a fault, after a timeout,
      or on a user signal.

   Module :mod:`traceback`
      Standard interface to extract, format and print stack traces of Python programs.

The typical usage to break into the debugger is to insert::

   import pdb; pdb.set_trace()

Or::

   breakpoint()

at the location you want to break into the debugger, and then run the program.
You can then step through the code following this statement, and continue
running without the debugger using the :pdbcmd:`continue` command.

.. versionchanged:: 3.7
   The built-in :func:`breakpoint`, when called with defaults, can be used
   instead of ``import pdb; pdb.set_trace()``.

::

   def double(x):
      breakpoint()
      return x * 2
   val = 3
   print(f"{val} * 2 is {double(val)}")

The debugger's prompt is ``(Pdb)``, which is the indicator that you are in debug mode::

   > ...(2)double()
   -> breakpoint()
   (Pdb) p x
   3
   (Pdb) continue
   3 * 2 is 6

.. versionchanged:: 3.3
   Tab-completion via the :mod:`readline` module is available for commands and
   command arguments, e.g. the current global and local names are offered as
   arguments of the ``p`` command.


You can also invoke :mod:`pdb` from the command line to debug other scripts.  For
example::

   python -m pdb myscript.py

When invoked as a module, pdb will automatically enter post-mortem debugging if
the program being debugged exits abnormally.  After post-mortem debugging (or
after normal exit of the program), pdb will restart the program.  Automatic
restarting preserves pdb's state (such as breakpoints) and in most cases is more
useful than quitting the debugger upon program's exit.

.. versionchanged:: 3.2
   Added the ``-c`` option to execute commands as if given
   in a :file:`.pdbrc` file; see :ref:`debugger-commands`.

.. versionchanged:: 3.7
   Added the ``-m`` option to execute modules similar to the way
   ``python -m`` does. As with a script, the debugger will pause execution just
   before the first line of the module.

Typical usage to execute a statement under control of the debugger is::

   >>> import pdb
   >>> def f(x):
   ...     print(1 / x)
   >>> pdb.run("f(2)")
   > <string>(1)<module>()
   (Pdb) continue
   0.5
   >>>

The typical usage to inspect a crashed program is::

   >>> import pdb
   >>> def f(x):
   ...     print(1 / x)
   ...
   >>> f(0)
   Traceback (most recent call last):
     File "<stdin>", line 1, in <module>
     File "<stdin>", line 2, in f
   ZeroDivisionError: division by zero
   >>> pdb.pm()
   > <stdin>(2)f()
   (Pdb) p x
   0
   (Pdb)

.. versionchanged:: 3.13
   The implementation of :pep:`667` means that name assignments made via ``pdb``
   will immediately affect the active scope, even when running inside an
   :term:`optimized scope`.


The module defines the following functions; each enters the debugger in a
slightly different way:

.. function:: run(statement, globals=None, locals=None)

   Execute the *statement* (given as a string or a code object) under debugger
   control.  The debugger prompt appears before any code is executed; you can
   set breakpoints and type :pdbcmd:`continue`, or you can step through the
   statement using :pdbcmd:`step` or :pdbcmd:`next` (all these commands are
   explained below).  The optional *globals* and *locals* arguments specify the
   environment in which the code is executed; by default the dictionary of the
   module :mod:`__main__` is used.  (See the explanation of the built-in
   :func:`exec` or :func:`eval` functions.)


.. function:: runeval(expression, globals=None, locals=None)

   Evaluate the *expression* (given as a string or a code object) under debugger
   control.  When :func:`runeval` returns, it returns the value of the
   *expression*.  Otherwise this function is similar to :func:`run`.


.. function:: runcall(function, *args, **kwds)

   Call the *function* (a function or method object, not a string) with the
   given arguments.  When :func:`runcall` returns, it returns whatever the
   function call returned.  The debugger prompt appears as soon as the function
   is entered.


.. function:: set_trace(*, header=None, commands=None)

   Enter the debugger at the calling stack frame.  This is useful to hard-code
   a breakpoint at a given point in a program, even if the code is not
   otherwise being debugged (e.g. when an assertion fails).  If given,
   *header* is printed to the console just before debugging begins.
   The *commands* argument, if given, is a list of commands to execute
   when the debugger starts.


   .. versionchanged:: 3.7
      The keyword-only argument *header*.

   .. versionchanged:: 3.13
      :func:`set_trace` will enter the debugger immediately, rather than
      on the next line of code to be executed.

   .. versionadded:: 3.14
      The *commands* argument.

.. function:: post_mortem(t=None)

   Enter post-mortem debugging of the given exception or
   :ref:`traceback object <traceback-objects>`. If no value is given, it uses
   the exception that is currently being handled, or raises ``ValueError`` if
   there isn’t one.

   .. versionchanged:: 3.13
      Support for exception objects was added.

.. function:: pm()

   Enter post-mortem debugging of the exception found in
   :data:`sys.last_exc`.


The ``run*`` functions and :func:`set_trace` are aliases for instantiating the
:class:`Pdb` class and calling the method of the same name.  If you want to
access further features, you have to do this yourself:

.. class:: Pdb(completekey='tab', stdin=None, stdout=None, skip=None, \
               nosigint=False, readrc=True, mode=None)

   :class:`Pdb` is the debugger class.

   The *completekey*, *stdin* and *stdout* arguments are passed to the
   underlying :class:`cmd.Cmd` class; see the description there.

   The *skip* argument, if given, must be an iterable of glob-style module name
   patterns.  The debugger will not step into frames that originate in a module
   that matches one of these patterns. [1]_

   By default, Pdb sets a handler for the SIGINT signal (which is sent when the
   user presses :kbd:`Ctrl-C` on the console) when you give a :pdbcmd:`continue` command.
   This allows you to break into the debugger again by pressing :kbd:`Ctrl-C`.  If you
   want Pdb not to touch the SIGINT handler, set *nosigint* to true.

   The *readrc* argument defaults to true and controls whether Pdb will load
   .pdbrc files from the filesystem.

   The *mode* argument specifies how the debugger was invoked.
   It impacts the workings of some debugger commands.
   Valid values are ``'inline'`` (used by the breakpoint() builtin),
   ``'cli'`` (used by the command line invocation)
   or ``None`` (for backwards compatible behaviour, as before the *mode*
   argument was added).

   Example call to enable tracing with *skip*::

      import pdb; pdb.Pdb(skip=['django.*']).set_trace()

   .. audit-event:: pdb.Pdb "" pdb.Pdb

   .. versionchanged:: 3.1
      Added the *skip* parameter.

   .. versionchanged:: 3.2
      Added the *nosigint* parameter.
      Previously, a SIGINT handler was never set by Pdb.

   .. versionchanged:: 3.6
      The *readrc* argument.

   .. versionadded:: 3.14
      Added the *mode* argument.

   .. method:: run(statement, globals=None, locals=None)
               runeval(expression, globals=None, locals=None)
               runcall(function, *args, **kwds)
               set_trace()

      See the documentation for the functions explained above.


.. _debugger-commands:

Debugger Commands
-----------------

The commands recognized by the debugger are listed below.  Most commands can be
abbreviated to one or two letters as indicated; e.g. ``h(elp)`` means that
either ``h`` or ``help`` can be used to enter the help command (but not ``he``
or ``hel``, nor ``H`` or ``Help`` or ``HELP``).  Arguments to commands must be
separated by whitespace (spaces or tabs).  Optional arguments are enclosed in
square brackets (``[]``) in the command syntax; the square brackets must not be
typed.  Alternatives in the command syntax are separated by a vertical bar
(``|``).

Entering a blank line repeats the last command entered.  Exception: if the last
command was a :pdbcmd:`list` command, the next 11 lines are listed.

Commands that the debugger doesn't recognize are assumed to be Python statements
and are executed in the context of the program being debugged.  Python
statements can also be prefixed with an exclamation point (``!``).  This is a
powerful way to inspect the program being debugged; it is even possible to
change a variable or call a function.  When an exception occurs in such a
statement, the exception name is printed but the debugger's state is not
changed.

.. versionchanged:: 3.13
   Expressions/Statements whose prefix is a pdb command are now correctly
   identified and executed.

The debugger supports :ref:`aliases <debugger-aliases>`.  Aliases can have
parameters which allows one a certain level of adaptability to the context under
examination.

Multiple commands may be entered on a single line, separated by ``;;``.  (A
single ``;`` is not used as it is the separator for multiple commands in a line
that is passed to the Python parser.)  No intelligence is applied to separating
the commands; the input is split at the first ``;;`` pair, even if it is in the
middle of a quoted string. A workaround for strings with double semicolons
is to use implicit string concatenation ``';'';'`` or ``";"";"``.

To set a temporary global variable, use a *convenience variable*. A *convenience
variable* is a variable whose name starts with ``$``.  For example, ``$foo = 1``
sets a global variable ``$foo`` which you can use in the debugger session.  The
*convenience variables* are cleared when the program resumes execution so it's
less likely to interfere with your program compared to using normal variables
like ``foo = 1``.

There are three preset *convenience variables*:

* ``$_frame``: the current frame you are debugging
* ``$_retval``: the return value if the frame is returning
* ``$_exception``: the exception if the frame is raising an exception

.. versionadded:: 3.12

   Added the *convenience variable* feature.

.. index::
   pair: .pdbrc; file
   triple: debugger; configuration; file

If a file :file:`.pdbrc` exists in the user's home directory or in the current
directory, it is read with ``'utf-8'`` encoding and executed as if it had been
typed at the debugger prompt, with the exception that empty lines and lines
starting with ``#`` are ignored.  This is particularly useful for aliases.  If both
files exist, the one in the home directory is read first and aliases defined there
can be overridden by the local file.

.. versionchanged:: 3.2
   :file:`.pdbrc` can now contain commands that continue debugging, such as
   :pdbcmd:`continue` or :pdbcmd:`next`.  Previously, these commands had no
   effect.

.. versionchanged:: 3.11
   :file:`.pdbrc` is now read with ``'utf-8'`` encoding. Previously, it was read
   with the system locale encoding.


.. pdbcommand:: h(elp) [command]

   Without argument, print the list of available commands.  With a *command* as
   argument, print help about that command.  ``help pdb`` displays the full
   documentation (the docstring of the :mod:`pdb` module).  Since the *command*
   argument must be an identifier, ``help exec`` must be entered to get help on
   the ``!`` command.

.. pdbcommand:: w(here) [count]

   Print a stack trace, with the most recent frame at the bottom.  if *count*
   is 0, print the current frame entry. If *count* is negative, print the least
   recent - *count* frames. If *count* is positive, print the most recent
   *count* frames.  An arrow (``>``)
   indicates the current frame, which determines the context of most commands.

   .. versionchanged:: 3.14
      *count* argument is added.

.. pdbcommand:: d(own) [count]

   Move the current frame *count* (default one) levels down in the stack trace
   (to a newer frame).

.. pdbcommand:: u(p) [count]

   Move the current frame *count* (default one) levels up in the stack trace (to
   an older frame).

.. pdbcommand:: b(reak) [([filename:]lineno | function) [, condition]]

   With a *lineno* argument, set a break at line *lineno* in the current file.
   The line number may be prefixed with a *filename* and a colon,
   to specify a breakpoint in another file (possibly one that hasn't been loaded
   yet).  The file is searched on :data:`sys.path`.  Acceptable forms of *filename*
   are ``/abspath/to/file.py``, ``relpath/file.py``, ``module`` and
   ``package.module``.

   With a *function* argument, set a break at the first executable statement within
   that function. *function* can be any expression that evaluates to a function
   in the current namespace.

   If a second argument is present, it is an expression which must evaluate to
   true before the breakpoint is honored.

   Without argument, list all breaks, including for each breakpoint, the number
   of times that breakpoint has been hit, the current ignore count, and the
   associated condition if any.

   Each breakpoint is assigned a number to which all the other
   breakpoint commands refer.

.. pdbcommand:: tbreak [([filename:]lineno | function) [, condition]]

   Temporary breakpoint, which is removed automatically when it is first hit.
   The arguments are the same as for :pdbcmd:`break`.

.. pdbcommand:: cl(ear) [filename:lineno | bpnumber ...]

   With a *filename:lineno* argument, clear all the breakpoints at this line.
   With a space separated list of breakpoint numbers, clear those breakpoints.
   Without argument, clear all breaks (but first ask confirmation).

.. pdbcommand:: disable bpnumber [bpnumber ...]

   Disable the breakpoints given as a space separated list of breakpoint
   numbers.  Disabling a breakpoint means it cannot cause the program to stop
   execution, but unlike clearing a breakpoint, it remains in the list of
   breakpoints and can be (re-)enabled.

.. pdbcommand:: enable bpnumber [bpnumber ...]

   Enable the breakpoints specified.

.. pdbcommand:: ignore bpnumber [count]

   Set the ignore count for the given breakpoint number.  If *count* is omitted,
   the ignore count is set to 0.  A breakpoint becomes active when the ignore
   count is zero.  When non-zero, the *count* is decremented each time the
   breakpoint is reached and the breakpoint is not disabled and any associated
   condition evaluates to true.

.. pdbcommand:: condition bpnumber [condition]

   Set a new *condition* for the breakpoint, an expression which must evaluate
   to true before the breakpoint is honored.  If *condition* is absent, any
   existing condition is removed; i.e., the breakpoint is made unconditional.

.. pdbcommand:: commands [bpnumber]

   Specify a list of commands for breakpoint number *bpnumber*.  The commands
   themselves appear on the following lines.  Type a line containing just
   ``end`` to terminate the commands. An example::

      (Pdb) commands 1
      (com) p some_variable
      (com) end
      (Pdb)

   To remove all commands from a breakpoint, type ``commands`` and follow it
   immediately with ``end``; that is, give no commands.

   With no *bpnumber* argument, ``commands`` refers to the last breakpoint set.

   You can use breakpoint commands to start your program up again.  Simply use
   the :pdbcmd:`continue` command, or :pdbcmd:`step`,
   or any other command that resumes execution.

   Specifying any command resuming execution
   (currently :pdbcmd:`continue`, :pdbcmd:`step`, :pdbcmd:`next`,
   :pdbcmd:`return`, :pdbcmd:`until`, :pdbcmd:`jump`, :pdbcmd:`quit` and their abbreviations)
   terminates the command list (as if
   that command was immediately followed by end). This is because any time you
   resume execution (even with a simple next or step), you may encounter another
   breakpoint—which could have its own command list, leading to ambiguities about
   which list to execute.

   If the list of commands contains the ``silent`` command, or a command that
   resumes execution, then the breakpoint message containing information about
   the frame is not displayed.

   .. versionchanged:: 3.14
      Frame information will not be displayed if a command that resumes execution
      is present in the command list.

.. pdbcommand:: s(tep)

   Execute the current line, stop at the first possible occasion (either in a
   function that is called or on the next line in the current function).

.. pdbcommand:: n(ext)

   Continue execution until the next line in the current function is reached or
   it returns.  (The difference between :pdbcmd:`next` and :pdbcmd:`step` is
   that :pdbcmd:`step` stops inside a called function, while :pdbcmd:`next`
   executes called functions at (nearly) full speed, only stopping at the next
   line in the current function.)

.. pdbcommand:: unt(il) [lineno]

   Without argument, continue execution until the line with a number greater
   than the current one is reached.

   With *lineno*, continue execution until a line with a number greater or
   equal to *lineno* is reached.  In both cases, also stop when the current frame
   returns.

   .. versionchanged:: 3.2
      Allow giving an explicit line number.

.. pdbcommand:: r(eturn)

   Continue execution until the current function returns.

.. pdbcommand:: c(ont(inue))

   Continue execution, only stop when a breakpoint is encountered.

.. pdbcommand:: j(ump) lineno

   Set the next line that will be executed.  Only available in the bottom-most
   frame.  This lets you jump back and execute code again, or jump forward to
   skip code that you don't want to run.

   It should be noted that not all jumps are allowed -- for instance it is not
   possible to jump into the middle of a :keyword:`for` loop or out of a
   :keyword:`finally` clause.

.. pdbcommand:: l(ist) [first[, last]]

   List source code for the current file.  Without arguments, list 11 lines
   around the current line or continue the previous listing.  With ``.`` as
   argument, list 11 lines around the current line.  With one argument,
   list 11 lines around at that line.  With two arguments, list the given range;
   if the second argument is less than the first, it is interpreted as a count.

   The current line in the current frame is indicated by ``->``.  If an
   exception is being debugged, the line where the exception was originally
   raised or propagated is indicated by ``>>``, if it differs from the current
   line.

   .. versionchanged:: 3.2
      Added the ``>>`` marker.

.. pdbcommand:: ll | longlist

   List all source code for the current function or frame.  Interesting lines
   are marked as for :pdbcmd:`list`.

   .. versionadded:: 3.2

.. pdbcommand:: a(rgs)

   Print the arguments of the current function and their current values.

.. pdbcommand:: p expression

   Evaluate *expression* in the current context and print its value.

   .. note::

      ``print()`` can also be used, but is not a debugger command --- this executes the
      Python :func:`print` function.


.. pdbcommand:: pp expression

   Like the :pdbcmd:`p` command, except the value of *expression* is
   pretty-printed using the :mod:`pprint` module.

.. pdbcommand:: whatis expression

   Print the type of *expression*.

.. pdbcommand:: source expression

   Try to get source code of *expression* and display it.

   .. versionadded:: 3.2

.. pdbcommand:: display [expression]

   Display the value of *expression* if it changed, each time execution stops
   in the current frame.

   Without *expression*, list all display expressions for the current frame.

   .. note::

      Display evaluates *expression* and compares to the result of the previous
      evaluation of *expression*, so when the result is mutable, display may not
      be able to pick up the changes.

   Example::

      lst = []
      breakpoint()
      pass
      lst.append(1)
      print(lst)

   Display won't realize ``lst`` has been changed because the result of evaluation
   is modified in place by ``lst.append(1)`` before being compared::

      > example.py(3)<module>()
      -> pass
      (Pdb) display lst
      display lst: []
      (Pdb) n
      > example.py(4)<module>()
      -> lst.append(1)
      (Pdb) n
      > example.py(5)<module>()
      -> print(lst)
      (Pdb)

   You can do some tricks with copy mechanism to make it work::

      > example.py(3)<module>()
      -> pass
      (Pdb) display lst[:]
      display lst[:]: []
      (Pdb) n
      > example.py(4)<module>()
      -> lst.append(1)
      (Pdb) n
      > example.py(5)<module>()
      -> print(lst)
      display lst[:]: [1]  [old: []]
      (Pdb)

   .. versionadded:: 3.2

.. pdbcommand:: undisplay [expression]

   Do not display *expression* anymore in the current frame.  Without
   *expression*, clear all display expressions for the current frame.

   .. versionadded:: 3.2

.. pdbcommand:: interact

   Start an interactive interpreter (using the :mod:`code` module) in a new
   global namespace initialised from the local and global namespaces for the
   current scope. Use ``exit()`` or ``quit()`` to exit the interpreter and
   return to the debugger.

   .. note::

      As ``interact`` creates a new dedicated namespace for code execution,
      assignments to variables will not affect the original namespaces.
      However, modifications to any referenced mutable objects will be reflected
      in the original namespaces as usual.

   .. versionadded:: 3.2

   .. versionchanged:: 3.13
      ``exit()`` and ``quit()`` can be used to exit the :pdbcmd:`interact`
      command.

   .. versionchanged:: 3.13
      :pdbcmd:`interact` directs its output to the debugger's
      output channel rather than :data:`sys.stderr`.

.. _debugger-aliases:

.. pdbcommand:: alias [name [command]]

   Create an alias called *name* that executes *command*.  The *command* must
   *not* be enclosed in quotes.  Replaceable parameters can be indicated by
   ``%1``, ``%2``, ... and ``%9``, while ``%*`` is replaced by all the parameters.
   If *command* is omitted, the current alias for *name* is shown. If no
   arguments are given, all aliases are listed.

   Aliases may be nested and can contain anything that can be legally typed at
   the pdb prompt.  Note that internal pdb commands *can* be overridden by
   aliases.  Such a command is then hidden until the alias is removed.  Aliasing
   is recursively applied to the first word of the command line; all other words
   in the line are left alone.

   As an example, here are two useful aliases (especially when placed in the
   :file:`.pdbrc` file)::

      # Print instance variables (usage "pi classInst")
      alias pi for k in %1.__dict__.keys(): print(f"%1.{k} = {%1.__dict__[k]}")
      # Print instance variables in self
      alias ps pi self

.. pdbcommand:: unalias name

   Delete the specified alias *name*.

.. pdbcommand:: ! statement

   Execute the (one-line) *statement* in the context of the current stack frame.
   The exclamation point can be omitted unless the first word of the statement
   resembles a debugger command, e.g.:

   .. code-block:: none

      (Pdb) ! n=42
      (Pdb)

   To set a global variable, you can prefix the assignment command with a
   :keyword:`global` statement on the same line, e.g.:

   .. code-block:: none

      (Pdb) global list_options; list_options = ['-l']
      (Pdb)

.. pdbcommand:: run [args ...]
                restart [args ...]

   Restart the debugged Python program.  If *args* is supplied, it is split
   with :mod:`shlex` and the result is used as the new :data:`sys.argv`.
   History, breakpoints, actions and debugger options are preserved.
   :pdbcmd:`restart` is an alias for :pdbcmd:`run`.

   .. versionchanged:: 3.14
      :pdbcmd:`run` and :pdbcmd:`restart` commands are disabled when the
      debugger is invoked in ``'inline'`` mode.

.. pdbcommand:: q(uit)

   Quit from the debugger.  The program being executed is aborted.

.. pdbcommand:: debug code

   Enter a recursive debugger that steps through *code*
   (which is an arbitrary expression or statement to be
   executed in the current environment).

.. pdbcommand:: retval

   Print the return value for the last return of the current function.

.. pdbcommand:: exceptions [excnumber]

   List or jump between chained exceptions.

   When using ``pdb.pm()``  or ``Pdb.post_mortem(...)`` with a chained exception
   instead of a traceback, it allows the user to move between the
   chained exceptions using ``exceptions`` command to list exceptions, and
   ``exception <number>`` to switch to that exception.


   Example::

        def out():
            try:
                middle()
            except Exception as e:
                raise ValueError("reraise middle() error") from e

        def middle():
            try:
                return inner(0)
            except Exception as e:
                raise ValueError("Middle fail")

        def inner(x):
            1 / x

         out()

   calling ``pdb.pm()`` will allow to move between exceptions::

    > example.py(5)out()
    -> raise ValueError("reraise middle() error") from e

    (Pdb) exceptions
      0 ZeroDivisionError('division by zero')
      1 ValueError('Middle fail')
    > 2 ValueError('reraise middle() error')

    (Pdb) exceptions 0
    > example.py(16)inner()
    -> 1 / x

    (Pdb) up
    > example.py(10)middle()
    -> return inner(0)

   .. versionadded:: 3.13

.. rubric:: Footnotes

.. [1] Whether a frame is considered to originate in a certain module
       is determined by the ``__name__`` in the frame globals.


================================================
File: /Doc/library/persistence.rst
================================================
.. _persistence:

****************
Data Persistence
****************

The modules described in this chapter support storing Python data in a
persistent form on disk.  The :mod:`pickle` and :mod:`marshal` modules can turn
many Python data types into a stream of bytes and then recreate the objects from
the bytes.  The various DBM-related modules support a family of hash-based file
formats that store a mapping of strings to other strings.

The list of modules described in this chapter is:


.. toctree::

   pickle.rst
   copyreg.rst
   shelve.rst
   marshal.rst
   dbm.rst
   sqlite3.rst


================================================
File: /Doc/library/pickle.rst
================================================
:mod:`!pickle` --- Python object serialization
==============================================

.. module:: pickle
   :synopsis: Convert Python objects to streams of bytes and back.

.. sectionauthor:: Jim Kerr <jbkerr@sr.hp.com>.
.. sectionauthor:: Barry Warsaw <barry@python.org>

**Source code:** :source:`Lib/pickle.py`

.. index::
   single: persistence
   pair: persistent; objects
   pair: serializing; objects
   pair: marshalling; objects
   pair: flattening; objects
   pair: pickling; objects

--------------

The :mod:`pickle` module implements binary protocols for serializing and
de-serializing a Python object structure.  *"Pickling"* is the process
whereby a Python object hierarchy is converted into a byte stream, and
*"unpickling"* is the inverse operation, whereby a byte stream
(from a :term:`binary file` or :term:`bytes-like object`) is converted
back into an object hierarchy.  Pickling (and unpickling) is alternatively
known as "serialization", "marshalling," [#]_ or "flattening"; however, to
avoid confusion, the terms used here are "pickling" and "unpickling".

.. warning::

   The ``pickle`` module **is not secure**. Only unpickle data you trust.

   It is possible to construct malicious pickle data which will **execute
   arbitrary code during unpickling**. Never unpickle data that could have come
   from an untrusted source, or that could have been tampered with.

   Consider signing data with :mod:`hmac` if you need to ensure that it has not
   been tampered with.

   Safer serialization formats such as :mod:`json` may be more appropriate if
   you are processing untrusted data. See :ref:`comparison-with-json`.


Relationship to other Python modules
------------------------------------

Comparison with ``marshal``
^^^^^^^^^^^^^^^^^^^^^^^^^^^

Python has a more primitive serialization module called :mod:`marshal`, but in
general :mod:`pickle` should always be the preferred way to serialize Python
objects.  :mod:`marshal` exists primarily to support Python's :file:`.pyc`
files.

The :mod:`pickle` module differs from :mod:`marshal` in several significant ways:

* The :mod:`pickle` module keeps track of the objects it has already serialized,
  so that later references to the same object won't be serialized again.
  :mod:`marshal` doesn't do this.

  This has implications both for recursive objects and object sharing.  Recursive
  objects are objects that contain references to themselves.  These are not
  handled by marshal, and in fact, attempting to marshal recursive objects will
  crash your Python interpreter.  Object sharing happens when there are multiple
  references to the same object in different places in the object hierarchy being
  serialized.  :mod:`pickle` stores such objects only once, and ensures that all
  other references point to the master copy.  Shared objects remain shared, which
  can be very important for mutable objects.

* :mod:`marshal` cannot be used to serialize user-defined classes and their
  instances.  :mod:`pickle` can save and restore class instances transparently,
  however the class definition must be importable and live in the same module as
  when the object was stored.

* The :mod:`marshal` serialization format is not guaranteed to be portable
  across Python versions.  Because its primary job in life is to support
  :file:`.pyc` files, the Python implementers reserve the right to change the
  serialization format in non-backwards compatible ways should the need arise.
  The :mod:`pickle` serialization format is guaranteed to be backwards compatible
  across Python releases provided a compatible pickle protocol is chosen and
  pickling and unpickling code deals with Python 2 to Python 3 type differences
  if your data is crossing that unique breaking change language boundary.


.. _comparison-with-json:

Comparison with ``json``
^^^^^^^^^^^^^^^^^^^^^^^^

There are fundamental differences between the pickle protocols and
`JSON (JavaScript Object Notation) <https://json.org>`_:

* JSON is a text serialization format (it outputs unicode text, although
  most of the time it is then encoded to ``utf-8``), while pickle is
  a binary serialization format;

* JSON is human-readable, while pickle is not;

* JSON is interoperable and widely used outside of the Python ecosystem,
  while pickle is Python-specific;

* JSON, by default, can only represent a subset of the Python built-in
  types, and no custom classes; pickle can represent an extremely large
  number of Python types (many of them automatically, by clever usage
  of Python's introspection facilities; complex cases can be tackled by
  implementing :ref:`specific object APIs <pickle-inst>`);

* Unlike pickle, deserializing untrusted JSON does not in itself create an
  arbitrary code execution vulnerability.

.. seealso::
   The :mod:`json` module: a standard library module allowing JSON
   serialization and deserialization.


.. _pickle-protocols:

Data stream format
------------------

.. index::
   single: External Data Representation

The data format used by :mod:`pickle` is Python-specific.  This has the
advantage that there are no restrictions imposed by external standards such as
JSON (which can't represent pointer sharing); however it means that
non-Python programs may not be able to reconstruct pickled Python objects.

By default, the :mod:`pickle` data format uses a relatively compact binary
representation.  If you need optimal size characteristics, you can efficiently
:doc:`compress <archiving>` pickled data.

The module :mod:`pickletools` contains tools for analyzing data streams
generated by :mod:`pickle`.  :mod:`pickletools` source code has extensive
comments about opcodes used by pickle protocols.

There are currently 6 different protocols which can be used for pickling.
The higher the protocol used, the more recent the version of Python needed
to read the pickle produced.

* Protocol version 0 is the original "human-readable" protocol and is
  backwards compatible with earlier versions of Python.

* Protocol version 1 is an old binary format which is also compatible with
  earlier versions of Python.

* Protocol version 2 was introduced in Python 2.3.  It provides much more
  efficient pickling of :term:`new-style classes <new-style class>`.  Refer to :pep:`307` for
  information about improvements brought by protocol 2.

* Protocol version 3 was added in Python 3.0.  It has explicit support for
  :class:`bytes` objects and cannot be unpickled by Python 2.x.  This was
  the default protocol in Python 3.0--3.7.

* Protocol version 4 was added in Python 3.4.  It adds support for very large
  objects, pickling more kinds of objects, and some data format
  optimizations.  This was the default protocol in Python 3.8--3.13.
  Refer to :pep:`3154` for information about improvements brought by
  protocol 4.

* Protocol version 5 was added in Python 3.8.  It adds support for out-of-band
  data and speedup for in-band data.  It is the default protocol starting with
  Python 3.14.  Refer to :pep:`574` for information about improvements brought
  by protocol 5.

.. note::
   Serialization is a more primitive notion than persistence; although
   :mod:`pickle` reads and writes file objects, it does not handle the issue of
   naming persistent objects, nor the (even more complicated) issue of concurrent
   access to persistent objects.  The :mod:`pickle` module can transform a complex
   object into a byte stream and it can transform the byte stream into an object
   with the same internal structure.  Perhaps the most obvious thing to do with
   these byte streams is to write them onto a file, but it is also conceivable to
   send them across a network or store them in a database.  The :mod:`shelve`
   module provides a simple interface to pickle and unpickle objects on
   DBM-style database files.


Module Interface
----------------

To serialize an object hierarchy, you simply call the :func:`dumps` function.
Similarly, to de-serialize a data stream, you call the :func:`loads` function.
However, if you want more control over serialization and de-serialization,
you can create a :class:`Pickler` or an :class:`Unpickler` object, respectively.

The :mod:`pickle` module provides the following constants:


.. data:: HIGHEST_PROTOCOL

   An integer, the highest :ref:`protocol version <pickle-protocols>`
   available.  This value can be passed as a *protocol* value to functions
   :func:`dump` and :func:`dumps` as well as the :class:`Pickler`
   constructor.

.. data:: DEFAULT_PROTOCOL

   An integer, the default :ref:`protocol version <pickle-protocols>` used
   for pickling.  May be less than :data:`HIGHEST_PROTOCOL`.  Currently the
   default protocol is 5, introduced in Python 3.8 and incompatible
   with previous versions. This version introduces support for out-of-band
   buffers, where :pep:`3118`-compatible data can be transmitted separately
   from the main pickle stream.

   .. versionchanged:: 3.0

      The default protocol is 3.

   .. versionchanged:: 3.8

      The default protocol is 4.

   .. versionchanged:: 3.14

      The default protocol is 5.

The :mod:`pickle` module provides the following functions to make the pickling
process more convenient:

.. function:: dump(obj, file, protocol=None, *, fix_imports=True, buffer_callback=None)

   Write the pickled representation of the object *obj* to the open
   :term:`file object` *file*.  This is equivalent to
   ``Pickler(file, protocol).dump(obj)``.

   Arguments *file*, *protocol*, *fix_imports* and *buffer_callback* have
   the same meaning as in the :class:`Pickler` constructor.

   .. versionchanged:: 3.8
      The *buffer_callback* argument was added.

.. function:: dumps(obj, protocol=None, *, fix_imports=True, buffer_callback=None)

   Return the pickled representation of the object *obj* as a :class:`bytes` object,
   instead of writing it to a file.

   Arguments *protocol*, *fix_imports* and *buffer_callback* have the same
   meaning as in the :class:`Pickler` constructor.

   .. versionchanged:: 3.8
      The *buffer_callback* argument was added.

.. function:: load(file, *, fix_imports=True, encoding="ASCII", errors="strict", buffers=None)

   Read the pickled representation of an object from the open :term:`file object`
   *file* and return the reconstituted object hierarchy specified therein.
   This is equivalent to ``Unpickler(file).load()``.

   The protocol version of the pickle is detected automatically, so no
   protocol argument is needed.  Bytes past the pickled representation
   of the object are ignored.

   Arguments *file*, *fix_imports*, *encoding*, *errors*, *strict* and *buffers*
   have the same meaning as in the :class:`Unpickler` constructor.

   .. versionchanged:: 3.8
      The *buffers* argument was added.

.. function:: loads(data, /, *, fix_imports=True, encoding="ASCII", errors="strict", buffers=None)

   Return the reconstituted object hierarchy of the pickled representation
   *data* of an object. *data* must be a :term:`bytes-like object`.

   The protocol version of the pickle is detected automatically, so no
   protocol argument is needed.  Bytes past the pickled representation
   of the object are ignored.

   Arguments *fix_imports*, *encoding*, *errors*, *strict* and *buffers*
   have the same meaning as in the :class:`Unpickler` constructor.

   .. versionchanged:: 3.8
      The *buffers* argument was added.


The :mod:`pickle` module defines three exceptions:

.. exception:: PickleError

   Common base class for the other pickling exceptions.  It inherits from
   :exc:`Exception`.

.. exception:: PicklingError

   Error raised when an unpicklable object is encountered by :class:`Pickler`.
   It inherits from :exc:`PickleError`.

   Refer to :ref:`pickle-picklable` to learn what kinds of objects can be
   pickled.

.. exception:: UnpicklingError

   Error raised when there is a problem unpickling an object, such as a data
   corruption or a security violation.  It inherits from :exc:`PickleError`.

   Note that other exceptions may also be raised during unpickling, including
   (but not necessarily limited to) AttributeError, EOFError, ImportError, and
   IndexError.


The :mod:`pickle` module exports three classes, :class:`Pickler`,
:class:`Unpickler` and :class:`PickleBuffer`:

.. class:: Pickler(file, protocol=None, *, fix_imports=True, buffer_callback=None)

   This takes a binary file for writing a pickle data stream.

   The optional *protocol* argument, an integer, tells the pickler to use
   the given protocol; supported protocols are 0 to :data:`HIGHEST_PROTOCOL`.
   If not specified, the default is :data:`DEFAULT_PROTOCOL`.  If a negative
   number is specified, :data:`HIGHEST_PROTOCOL` is selected.

   The *file* argument must have a write() method that accepts a single bytes
   argument.  It can thus be an on-disk file opened for binary writing, an
   :class:`io.BytesIO` instance, or any other custom object that meets this
   interface.

   If *fix_imports* is true and *protocol* is less than 3, pickle will try to
   map the new Python 3 names to the old module names used in Python 2, so
   that the pickle data stream is readable with Python 2.

   If *buffer_callback* is ``None`` (the default), buffer views are
   serialized into *file* as part of the pickle stream.

   If *buffer_callback* is not ``None``, then it can be called any number
   of times with a buffer view.  If the callback returns a false value
   (such as ``None``), the given buffer is :ref:`out-of-band <pickle-oob>`;
   otherwise the buffer is serialized in-band, i.e. inside the pickle stream.

   It is an error if *buffer_callback* is not ``None`` and *protocol* is
   ``None`` or smaller than 5.

   .. versionchanged:: 3.8
      The *buffer_callback* argument was added.

   .. method:: dump(obj)

      Write the pickled representation of *obj* to the open file object given in
      the constructor.

   .. method:: persistent_id(obj)

      Do nothing by default.  This exists so a subclass can override it.

      If :meth:`persistent_id` returns ``None``, *obj* is pickled as usual.  Any
      other value causes :class:`Pickler` to emit the returned value as a
      persistent ID for *obj*.  The meaning of this persistent ID should be
      defined by :meth:`Unpickler.persistent_load`.  Note that the value
      returned by :meth:`persistent_id` cannot itself have a persistent ID.

      See :ref:`pickle-persistent` for details and examples of uses.

      .. versionchanged:: 3.13
         Add the default implementation of this method in the C implementation
         of :class:`!Pickler`.

   .. attribute:: dispatch_table

      A pickler object's dispatch table is a registry of *reduction
      functions* of the kind which can be declared using
      :func:`copyreg.pickle`.  It is a mapping whose keys are classes
      and whose values are reduction functions.  A reduction function
      takes a single argument of the associated class and should
      conform to the same interface as a :meth:`~object.__reduce__`
      method.

      By default, a pickler object will not have a
      :attr:`dispatch_table` attribute, and it will instead use the
      global dispatch table managed by the :mod:`copyreg` module.
      However, to customize the pickling for a specific pickler object
      one can set the :attr:`dispatch_table` attribute to a dict-like
      object.  Alternatively, if a subclass of :class:`Pickler` has a
      :attr:`dispatch_table` attribute then this will be used as the
      default dispatch table for instances of that class.

      See :ref:`pickle-dispatch` for usage examples.

      .. versionadded:: 3.3

   .. method:: reducer_override(obj)

      Special reducer that can be defined in :class:`Pickler` subclasses. This
      method has priority over any reducer in the :attr:`dispatch_table`.  It
      should conform to the same interface as a :meth:`~object.__reduce__` method, and
      can optionally return :data:`NotImplemented` to fallback on
      :attr:`dispatch_table`-registered reducers to pickle ``obj``.

      For a detailed example, see :ref:`reducer_override`.

      .. versionadded:: 3.8

   .. attribute:: fast

      Deprecated. Enable fast mode if set to a true value.  The fast mode
      disables the usage of memo, therefore speeding the pickling process by not
      generating superfluous PUT opcodes.  It should not be used with
      self-referential objects, doing otherwise will cause :class:`Pickler` to
      recurse infinitely.

      Use :func:`pickletools.optimize` if you need more compact pickles.


.. class:: Unpickler(file, *, fix_imports=True, encoding="ASCII", errors="strict", buffers=None)

   This takes a binary file for reading a pickle data stream.

   The protocol version of the pickle is detected automatically, so no
   protocol argument is needed.

   The argument *file* must have three methods, a read() method that takes an
   integer argument, a readinto() method that takes a buffer argument
   and a readline() method that requires no arguments, as in the
   :class:`io.BufferedIOBase` interface.  Thus *file* can be an on-disk file
   opened for binary reading, an :class:`io.BytesIO` object, or any other
   custom object that meets this interface.

   The optional arguments *fix_imports*, *encoding* and *errors* are used
   to control compatibility support for pickle stream generated by Python 2.
   If *fix_imports* is true, pickle will try to map the old Python 2 names
   to the new names used in Python 3.  The *encoding* and *errors* tell
   pickle how to decode 8-bit string instances pickled by Python 2;
   these default to 'ASCII' and 'strict', respectively.  The *encoding* can
   be 'bytes' to read these 8-bit string instances as bytes objects.
   Using ``encoding='latin1'`` is required for unpickling NumPy arrays and
   instances of :class:`~datetime.datetime`, :class:`~datetime.date` and
   :class:`~datetime.time` pickled by Python 2.

   If *buffers* is ``None`` (the default), then all data necessary for
   deserialization must be contained in the pickle stream.  This means
   that the *buffer_callback* argument was ``None`` when a :class:`Pickler`
   was instantiated (or when :func:`dump` or :func:`dumps` was called).

   If *buffers* is not ``None``, it should be an iterable of buffer-enabled
   objects that is consumed each time the pickle stream references
   an :ref:`out-of-band <pickle-oob>` buffer view.  Such buffers have been
   given in order to the *buffer_callback* of a Pickler object.

   .. versionchanged:: 3.8
      The *buffers* argument was added.

   .. method:: load()

      Read the pickled representation of an object from the open file object
      given in the constructor, and return the reconstituted object hierarchy
      specified therein.  Bytes past the pickled representation of the object
      are ignored.

   .. method:: persistent_load(pid)

      Raise an :exc:`UnpicklingError` by default.

      If defined, :meth:`persistent_load` should return the object specified by
      the persistent ID *pid*.  If an invalid persistent ID is encountered, an
      :exc:`UnpicklingError` should be raised.

      See :ref:`pickle-persistent` for details and examples of uses.

      .. versionchanged:: 3.13
         Add the default implementation of this method in the C implementation
         of :class:`!Unpickler`.

   .. method:: find_class(module, name)

      Import *module* if necessary and return the object called *name* from it,
      where the *module* and *name* arguments are :class:`str` objects.  Note,
      unlike its name suggests, :meth:`find_class` is also used for finding
      functions.

      Subclasses may override this to gain control over what type of objects and
      how they can be loaded, potentially reducing security risks. Refer to
      :ref:`pickle-restrict` for details.

      .. audit-event:: pickle.find_class module,name pickle.Unpickler.find_class

.. class:: PickleBuffer(buffer)

   A wrapper for a buffer representing picklable data.  *buffer* must be a
   :ref:`buffer-providing <bufferobjects>` object, such as a
   :term:`bytes-like object` or a N-dimensional array.

   :class:`PickleBuffer` is itself a buffer provider, therefore it is
   possible to pass it to other APIs expecting a buffer-providing object,
   such as :class:`memoryview`.

   :class:`PickleBuffer` objects can only be serialized using pickle
   protocol 5 or higher.  They are eligible for
   :ref:`out-of-band serialization <pickle-oob>`.

   .. versionadded:: 3.8

   .. method:: raw()

      Return a :class:`memoryview` of the memory area underlying this buffer.
      The returned object is a one-dimensional, C-contiguous memoryview
      with format ``B`` (unsigned bytes).  :exc:`BufferError` is raised if
      the buffer is neither C- nor Fortran-contiguous.

   .. method:: release()

      Release the underlying buffer exposed by the PickleBuffer object.


.. _pickle-picklable:

What can be pickled and unpickled?
----------------------------------

The following types can be pickled:

* built-in constants (``None``, ``True``, ``False``, ``Ellipsis``, and
  :data:`NotImplemented`);

* integers, floating-point numbers, complex numbers;

* strings, bytes, bytearrays;

* tuples, lists, sets, and dictionaries containing only picklable objects;

* functions (built-in and user-defined) accessible from the top level of a
  module (using :keyword:`def`, not :keyword:`lambda`);

* classes accessible from the top level of a module;

* instances of such classes whose the result of calling :meth:`~object.__getstate__`
  is picklable  (see section :ref:`pickle-inst` for details).

Attempts to pickle unpicklable objects will raise the :exc:`PicklingError`
exception; when this happens, an unspecified number of bytes may have already
been written to the underlying file.  Trying to pickle a highly recursive data
structure may exceed the maximum recursion depth, a :exc:`RecursionError` will be
raised in this case.  You can carefully raise this limit with
:func:`sys.setrecursionlimit`.

Note that functions (built-in and user-defined) are pickled by fully
:term:`qualified name`, not by value. [#]_  This means that only the function name is
pickled, along with the name of the containing module and classes.  Neither
the function's code, nor any of its function attributes are pickled.  Thus the
defining module must be importable in the unpickling environment, and the module
must contain the named object, otherwise an exception will be raised. [#]_

Similarly, classes are pickled by fully qualified name, so the same restrictions in
the unpickling environment apply.  Note that none of the class's code or data is
pickled, so in the following example the class attribute ``attr`` is not
restored in the unpickling environment::

   class Foo:
       attr = 'A class attribute'

   picklestring = pickle.dumps(Foo)

These restrictions are why picklable functions and classes must be defined at
the top level of a module.

Similarly, when class instances are pickled, their class's code and data are not
pickled along with them.  Only the instance data are pickled.  This is done on
purpose, so you can fix bugs in a class or add methods to the class and still
load objects that were created with an earlier version of the class.  If you
plan to have long-lived objects that will see many versions of a class, it may
be worthwhile to put a version number in the objects so that suitable
conversions can be made by the class's :meth:`~object.__setstate__` method.


.. _pickle-inst:

Pickling Class Instances
------------------------

.. currentmodule:: None

In this section, we describe the general mechanisms available to you to define,
customize, and control how class instances are pickled and unpickled.

In most cases, no additional code is needed to make instances picklable.  By
default, pickle will retrieve the class and the attributes of an instance via
introspection. When a class instance is unpickled, its :meth:`~object.__init__` method
is usually *not* invoked.  The default behaviour first creates an uninitialized
instance and then restores the saved attributes.  The following code shows an
implementation of this behaviour::

   def save(obj):
       return (obj.__class__, obj.__dict__)

   def restore(cls, attributes):
       obj = cls.__new__(cls)
       obj.__dict__.update(attributes)
       return obj

Classes can alter the default behaviour by providing one or several special
methods:

.. method:: object.__getnewargs_ex__()

   In protocols 2 and newer, classes that implements the
   :meth:`__getnewargs_ex__` method can dictate the values passed to the
   :meth:`__new__` method upon unpickling.  The method must return a pair
   ``(args, kwargs)`` where *args* is a tuple of positional arguments
   and *kwargs* a dictionary of named arguments for constructing the
   object.  Those will be passed to the :meth:`__new__` method upon
   unpickling.

   You should implement this method if the :meth:`__new__` method of your
   class requires keyword-only arguments.  Otherwise, it is recommended for
   compatibility to implement :meth:`__getnewargs__`.

   .. versionchanged:: 3.6
      :meth:`__getnewargs_ex__` is now used in protocols 2 and 3.


.. method:: object.__getnewargs__()

   This method serves a similar purpose as :meth:`__getnewargs_ex__`, but
   supports only positional arguments.  It must return a tuple of arguments
   ``args`` which will be passed to the :meth:`__new__` method upon unpickling.

   :meth:`__getnewargs__` will not be called if :meth:`__getnewargs_ex__` is
   defined.

   .. versionchanged:: 3.6
      Before Python 3.6, :meth:`__getnewargs__` was called instead of
      :meth:`__getnewargs_ex__` in protocols 2 and 3.


.. method:: object.__getstate__()

   Classes can further influence how their instances are pickled by overriding
   the method :meth:`__getstate__`.  It is called and the returned object
   is pickled as the contents for the instance, instead of a default state.
   There are several cases:

   * For a class that has no instance :attr:`~object.__dict__` and no
     :attr:`~object.__slots__`, the default state is ``None``.

   * For a class that has an instance :attr:`~object.__dict__` and no
     :attr:`~object.__slots__`, the default state is ``self.__dict__``.

   * For a class that has an instance :attr:`~object.__dict__` and
     :attr:`~object.__slots__`, the default state is a tuple consisting of two
     dictionaries:  ``self.__dict__``, and a dictionary mapping slot
     names to slot values.  Only slots that have a value are
     included in the latter.

   * For a class that has :attr:`~object.__slots__` and no instance
     :attr:`~object.__dict__`, the default state is a tuple whose first item
     is ``None`` and whose second item is a dictionary mapping slot names
     to slot values described in the previous bullet.

   .. versionchanged:: 3.11
      Added the default implementation of the ``__getstate__()`` method in the
      :class:`object` class.


.. method:: object.__setstate__(state)

   Upon unpickling, if the class defines :meth:`__setstate__`, it is called with
   the unpickled state.  In that case, there is no requirement for the state
   object to be a dictionary.  Otherwise, the pickled state must be a dictionary
   and its items are assigned to the new instance's dictionary.

   .. note::

      If :meth:`__reduce__` returns a state with value ``None`` at pickling,
      the :meth:`__setstate__` method will not be called upon unpickling.


Refer to the section :ref:`pickle-state` for more information about how to use
the methods :meth:`~object.__getstate__` and :meth:`~object.__setstate__`.

.. note::

   At unpickling time, some methods like :meth:`~object.__getattr__`,
   :meth:`~object.__getattribute__`, or :meth:`~object.__setattr__` may be called upon the
   instance.  In case those methods rely on some internal invariant being
   true, the type should implement :meth:`~object.__new__` to establish such an
   invariant, as :meth:`~object.__init__` is not called when unpickling an
   instance.

.. index:: pair: copy; protocol

As we shall see, pickle does not use directly the methods described above.  In
fact, these methods are part of the copy protocol which implements the
:meth:`~object.__reduce__` special method.  The copy protocol provides a unified
interface for retrieving the data necessary for pickling and copying
objects. [#]_

Although powerful, implementing :meth:`~object.__reduce__` directly in your classes is
error prone.  For this reason, class designers should use the high-level
interface (i.e., :meth:`~object.__getnewargs_ex__`, :meth:`~object.__getstate__` and
:meth:`~object.__setstate__`) whenever possible.  We will show, however, cases where
using :meth:`!__reduce__` is the only option or leads to more efficient pickling
or both.

.. method:: object.__reduce__()

   The interface is currently defined as follows.  The :meth:`__reduce__` method
   takes no argument and shall return either a string or preferably a tuple (the
   returned object is often referred to as the "reduce value").

   If a string is returned, the string should be interpreted as the name of a
   global variable.  It should be the object's local name relative to its
   module; the pickle module searches the module namespace to determine the
   object's module.  This behaviour is typically useful for singletons.

   When a tuple is returned, it must be between two and six items long.
   Optional items can either be omitted, or ``None`` can be provided as their
   value.  The semantics of each item are in order:

   .. XXX Mention __newobj__ special-case?

   * A callable object that will be called to create the initial version of the
     object.

   * A tuple of arguments for the callable object.  An empty tuple must be given
     if the callable does not accept any argument.

   * Optionally, the object's state, which will be passed to the object's
     :meth:`__setstate__` method as previously described.  If the object has no
     such method then, the value must be a dictionary and it will be added to
     the object's :attr:`~object.__dict__` attribute.

   * Optionally, an iterator (and not a sequence) yielding successive items.
     These items will be appended to the object either using
     ``obj.append(item)`` or, in batch, using ``obj.extend(list_of_items)``.
     This is primarily used for list subclasses, but may be used by other
     classes as long as they have
     :ref:`append and extend methods <typesseq-common>` with
     the appropriate signature.  (Whether :meth:`!append` or :meth:`!extend` is
     used depends on which pickle protocol version is used as well as the number
     of items to append, so both must be supported.)

   * Optionally, an iterator (not a sequence) yielding successive key-value
     pairs.  These items will be stored to the object using ``obj[key] =
     value``.  This is primarily used for dictionary subclasses, but may be used
     by other classes as long as they implement :meth:`__setitem__`.

   * Optionally, a callable with a ``(obj, state)`` signature. This
     callable allows the user to programmatically control the state-updating
     behavior of a specific object, instead of using ``obj``'s static
     :meth:`__setstate__` method. If not ``None``, this callable will have
     priority over ``obj``'s :meth:`__setstate__`.

     .. versionadded:: 3.8
        The optional sixth tuple item, ``(obj, state)``, was added.


.. method:: object.__reduce_ex__(protocol)

   Alternatively, a :meth:`__reduce_ex__` method may be defined.  The only
   difference is this method should take a single integer argument, the protocol
   version.  When defined, pickle will prefer it over the :meth:`__reduce__`
   method.  In addition, :meth:`__reduce__` automatically becomes a synonym for
   the extended version.  The main use for this method is to provide
   backwards-compatible reduce values for older Python releases.

.. currentmodule:: pickle

.. _pickle-persistent:

Persistence of External Objects
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

.. index::
   single: persistent_id (pickle protocol)
   single: persistent_load (pickle protocol)

For the benefit of object persistence, the :mod:`pickle` module supports the
notion of a reference to an object outside the pickled data stream.  Such
objects are referenced by a persistent ID, which should be either a string of
alphanumeric characters (for protocol 0) [#]_ or just an arbitrary object (for
any newer protocol).

The resolution of such persistent IDs is not defined by the :mod:`pickle`
module; it will delegate this resolution to the user-defined methods on the
pickler and unpickler, :meth:`~Pickler.persistent_id` and
:meth:`~Unpickler.persistent_load` respectively.

To pickle objects that have an external persistent ID, the pickler must have a
custom :meth:`~Pickler.persistent_id` method that takes an object as an
argument and returns either ``None`` or the persistent ID for that object.
When ``None`` is returned, the pickler simply pickles the object as normal.
When a persistent ID string is returned, the pickler will pickle that object,
along with a marker so that the unpickler will recognize it as a persistent ID.

To unpickle external objects, the unpickler must have a custom
:meth:`~Unpickler.persistent_load` method that takes a persistent ID object and
returns the referenced object.

Here is a comprehensive example presenting how persistent ID can be used to
pickle external objects by reference.

.. literalinclude:: ../includes/dbpickle.py

.. _pickle-dispatch:

Dispatch Tables
^^^^^^^^^^^^^^^

If one wants to customize pickling of some classes without disturbing
any other code which depends on pickling, then one can create a
pickler with a private dispatch table.

The global dispatch table managed by the :mod:`copyreg` module is
available as :data:`!copyreg.dispatch_table`.  Therefore, one may
choose to use a modified copy of :data:`!copyreg.dispatch_table` as a
private dispatch table.

For example ::

   f = io.BytesIO()
   p = pickle.Pickler(f)
   p.dispatch_table = copyreg.dispatch_table.copy()
   p.dispatch_table[SomeClass] = reduce_SomeClass

creates an instance of :class:`pickle.Pickler` with a private dispatch
table which handles the ``SomeClass`` class specially.  Alternatively,
the code ::

   class MyPickler(pickle.Pickler):
       dispatch_table = copyreg.dispatch_table.copy()
       dispatch_table[SomeClass] = reduce_SomeClass
   f = io.BytesIO()
   p = MyPickler(f)

does the same but all instances of ``MyPickler`` will by default
share the private dispatch table.  On the other hand, the code ::

   copyreg.pickle(SomeClass, reduce_SomeClass)
   f = io.BytesIO()
   p = pickle.Pickler(f)

modifies the global dispatch table shared by all users of the :mod:`copyreg` module.

.. _pickle-state:

Handling Stateful Objects
^^^^^^^^^^^^^^^^^^^^^^^^^

.. index::
   single: __getstate__() (copy protocol)
   single: __setstate__() (copy protocol)

Here's an example that shows how to modify pickling behavior for a class.
The :class:`!TextReader` class below opens a text file, and returns the line number and
line contents each time its :meth:`!readline` method is called. If a
:class:`!TextReader` instance is pickled, all attributes *except* the file object
member are saved. When the instance is unpickled, the file is reopened, and
reading resumes from the last location. The :meth:`!__setstate__` and
:meth:`!__getstate__` methods are used to implement this behavior. ::

   class TextReader:
       """Print and number lines in a text file."""

       def __init__(self, filename):
           self.filename = filename
           self.file = open(filename)
           self.lineno = 0

       def readline(self):
           self.lineno += 1
           line = self.file.readline()
           if not line:
               return None
           if line.endswith('\n'):
               line = line[:-1]
           return "%i: %s" % (self.lineno, line)

       def __getstate__(self):
           # Copy the object's state from self.__dict__ which contains
           # all our instance attributes. Always use the dict.copy()
           # method to avoid modifying the original state.
           state = self.__dict__.copy()
           # Remove the unpicklable entries.
           del state['file']
           return state

       def __setstate__(self, state):
           # Restore instance attributes (i.e., filename and lineno).
           self.__dict__.update(state)
           # Restore the previously opened file's state. To do so, we need to
           # reopen it and read from it until the line count is restored.
           file = open(self.filename)
           for _ in range(self.lineno):
               file.readline()
           # Finally, save the file.
           self.file = file


A sample usage might be something like this::

   >>> reader = TextReader("hello.txt")
   >>> reader.readline()
   '1: Hello world!'
   >>> reader.readline()
   '2: I am line number two.'
   >>> new_reader = pickle.loads(pickle.dumps(reader))
   >>> new_reader.readline()
   '3: Goodbye!'

.. _reducer_override:

Custom Reduction for Types, Functions, and Other Objects
--------------------------------------------------------

.. versionadded:: 3.8

Sometimes, :attr:`~Pickler.dispatch_table` may not be flexible enough.
In particular we may want to customize pickling based on another criterion
than the object's type, or we may want to customize the pickling of
functions and classes.

For those cases, it is possible to subclass from the :class:`Pickler` class and
implement a :meth:`~Pickler.reducer_override` method. This method can return an
arbitrary reduction tuple (see :meth:`~object.__reduce__`). It can alternatively return
:data:`NotImplemented` to fallback to the traditional behavior.

If both the :attr:`~Pickler.dispatch_table` and
:meth:`~Pickler.reducer_override` are defined, then
:meth:`~Pickler.reducer_override` method takes priority.

.. Note::
   For performance reasons, :meth:`~Pickler.reducer_override` may not be
   called for the following objects: ``None``, ``True``, ``False``, and
   exact instances of :class:`int`, :class:`float`, :class:`bytes`,
   :class:`str`, :class:`dict`, :class:`set`, :class:`frozenset`, :class:`list`
   and :class:`tuple`.

Here is a simple example where we allow pickling and reconstructing
a given class::

   import io
   import pickle

   class MyClass:
       my_attribute = 1

   class MyPickler(pickle.Pickler):
       def reducer_override(self, obj):
           """Custom reducer for MyClass."""
           if getattr(obj, "__name__", None) == "MyClass":
               return type, (obj.__name__, obj.__bases__,
                             {'my_attribute': obj.my_attribute})
           else:
               # For any other object, fallback to usual reduction
               return NotImplemented

   f = io.BytesIO()
   p = MyPickler(f)
   p.dump(MyClass)

   del MyClass

   unpickled_class = pickle.loads(f.getvalue())

   assert isinstance(unpickled_class, type)
   assert unpickled_class.__name__ == "MyClass"
   assert unpickled_class.my_attribute == 1


.. _pickle-oob:

Out-of-band Buffers
-------------------

.. versionadded:: 3.8

In some contexts, the :mod:`pickle` module is used to transfer massive amounts
of data.  Therefore, it can be important to minimize the number of memory
copies, to preserve performance and resource consumption.  However, normal
operation of the :mod:`pickle` module, as it transforms a graph-like structure
of objects into a sequential stream of bytes, intrinsically involves copying
data to and from the pickle stream.

This constraint can be eschewed if both the *provider* (the implementation
of the object types to be transferred) and the *consumer* (the implementation
of the communications system) support the out-of-band transfer facilities
provided by pickle protocol 5 and higher.

Provider API
^^^^^^^^^^^^

The large data objects to be pickled must implement a :meth:`~object.__reduce_ex__`
method specialized for protocol 5 and higher, which returns a
:class:`PickleBuffer` instance (instead of e.g. a :class:`bytes` object)
for any large data.

A :class:`PickleBuffer` object *signals* that the underlying buffer is
eligible for out-of-band data transfer.  Those objects remain compatible
with normal usage of the :mod:`pickle` module.  However, consumers can also
opt-in to tell :mod:`pickle` that they will handle those buffers by
themselves.

Consumer API
^^^^^^^^^^^^

A communications system can enable custom handling of the :class:`PickleBuffer`
objects generated when serializing an object graph.

On the sending side, it needs to pass a *buffer_callback* argument to
:class:`Pickler` (or to the :func:`dump` or :func:`dumps` function), which
will be called with each :class:`PickleBuffer` generated while pickling
the object graph.  Buffers accumulated by the *buffer_callback* will not
see their data copied into the pickle stream, only a cheap marker will be
inserted.

On the receiving side, it needs to pass a *buffers* argument to
:class:`Unpickler` (or to the :func:`load` or :func:`loads` function),
which is an iterable of the buffers which were passed to *buffer_callback*.
That iterable should produce buffers in the same order as they were passed
to *buffer_callback*.  Those buffers will provide the data expected by the
reconstructors of the objects whose pickling produced the original
:class:`PickleBuffer` objects.

Between the sending side and the receiving side, the communications system
is free to implement its own transfer mechanism for out-of-band buffers.
Potential optimizations include the use of shared memory or datatype-dependent
compression.

Example
^^^^^^^

Here is a trivial example where we implement a :class:`bytearray` subclass
able to participate in out-of-band buffer pickling::

   class ZeroCopyByteArray(bytearray):

       def __reduce_ex__(self, protocol):
           if protocol >= 5:
               return type(self)._reconstruct, (PickleBuffer(self),), None
           else:
               # PickleBuffer is forbidden with pickle protocols <= 4.
               return type(self)._reconstruct, (bytearray(self),)

       @classmethod
       def _reconstruct(cls, obj):
           with memoryview(obj) as m:
               # Get a handle over the original buffer object
               obj = m.obj
               if type(obj) is cls:
                   # Original buffer object is a ZeroCopyByteArray, return it
                   # as-is.
                   return obj
               else:
                   return cls(obj)

The reconstructor (the ``_reconstruct`` class method) returns the buffer's
providing object if it has the right type.  This is an easy way to simulate
zero-copy behaviour on this toy example.

On the consumer side, we can pickle those objects the usual way, which
when unserialized will give us a copy of the original object::

   b = ZeroCopyByteArray(b"abc")
   data = pickle.dumps(b, protocol=5)
   new_b = pickle.loads(data)
   print(b == new_b)  # True
   print(b is new_b)  # False: a copy was made

But if we pass a *buffer_callback* and then give back the accumulated
buffers when unserializing, we are able to get back the original object::

   b = ZeroCopyByteArray(b"abc")
   buffers = []
   data = pickle.dumps(b, protocol=5, buffer_callback=buffers.append)
   new_b = pickle.loads(data, buffers=buffers)
   print(b == new_b)  # True
   print(b is new_b)  # True: no copy was made

This example is limited by the fact that :class:`bytearray` allocates its
own memory: you cannot create a :class:`bytearray` instance that is backed
by another object's memory.  However, third-party datatypes such as NumPy
arrays do not have this limitation, and allow use of zero-copy pickling
(or making as few copies as possible) when transferring between distinct
processes or systems.

.. seealso:: :pep:`574` -- Pickle protocol 5 with out-of-band data


.. _pickle-restrict:

Restricting Globals
-------------------

.. index::
   single: find_class() (pickle protocol)

By default, unpickling will import any class or function that it finds in the
pickle data.  For many applications, this behaviour is unacceptable as it
permits the unpickler to import and invoke arbitrary code.  Just consider what
this hand-crafted pickle data stream does when loaded::

    >>> import pickle
    >>> pickle.loads(b"cos\nsystem\n(S'echo hello world'\ntR.")
    hello world
    0

In this example, the unpickler imports the :func:`os.system` function and then
apply the string argument "echo hello world".  Although this example is
inoffensive, it is not difficult to imagine one that could damage your system.

For this reason, you may want to control what gets unpickled by customizing
:meth:`Unpickler.find_class`.  Unlike its name suggests,
:meth:`Unpickler.find_class` is called whenever a global (i.e., a class or
a function) is requested.  Thus it is possible to either completely forbid
globals or restrict them to a safe subset.

Here is an example of an unpickler allowing only few safe classes from the
:mod:`builtins` module to be loaded::

   import builtins
   import io
   import pickle

   safe_builtins = {
       'range',
       'complex',
       'set',
       'frozenset',
       'slice',
   }

   class RestrictedUnpickler(pickle.Unpickler):

       def find_class(self, module, name):
           # Only allow safe classes from builtins.
           if module == "builtins" and name in safe_builtins:
               return getattr(builtins, name)
           # Forbid everything else.
           raise pickle.UnpicklingError("global '%s.%s' is forbidden" %
                                        (module, name))

   def restricted_loads(s):
       """Helper function analogous to pickle.loads()."""
       return RestrictedUnpickler(io.BytesIO(s)).load()

A sample usage of our unpickler working as intended::

    >>> restricted_loads(pickle.dumps([1, 2, range(15)]))
    [1, 2, range(0, 15)]
    >>> restricted_loads(b"cos\nsystem\n(S'echo hello world'\ntR.")
    Traceback (most recent call last):
      ...
    pickle.UnpicklingError: global 'os.system' is forbidden
    >>> restricted_loads(b'cbuiltins\neval\n'
    ...                  b'(S\'getattr(__import__("os"), "system")'
    ...                  b'("echo hello world")\'\ntR.')
    Traceback (most recent call last):
      ...
    pickle.UnpicklingError: global 'builtins.eval' is forbidden


.. XXX Add note about how extension codes could evade our protection
   mechanism (e.g. cached classes do not invokes find_class()).

As our examples shows, you have to be careful with what you allow to be
unpickled.  Therefore if security is a concern, you may want to consider
alternatives such as the marshalling API in :mod:`xmlrpc.client` or
third-party solutions.


Performance
-----------

Recent versions of the pickle protocol (from protocol 2 and upwards) feature
efficient binary encodings for several common features and built-in types.
Also, the :mod:`pickle` module has a transparent optimizer written in C.


.. _pickle-example:

Examples
--------

For the simplest code, use the :func:`dump` and :func:`load` functions. ::

   import pickle

   # An arbitrary collection of objects supported by pickle.
   data = {
       'a': [1, 2.0, 3+4j],
       'b': ("character string", b"byte string"),
       'c': {None, True, False}
   }

   with open('data.pickle', 'wb') as f:
       # Pickle the 'data' dictionary using the highest protocol available.
       pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)


The following example reads the resulting pickled data. ::

   import pickle

   with open('data.pickle', 'rb') as f:
       # The protocol version used is detected automatically, so we do not
       # have to specify it.
       data = pickle.load(f)


.. XXX: Add examples showing how to optimize pickles for size (like using
.. pickletools.optimize() or the gzip module).


.. seealso::

   Module :mod:`copyreg`
      Pickle interface constructor registration for extension types.

   Module :mod:`pickletools`
      Tools for working with and analyzing pickled data.

   Module :mod:`shelve`
      Indexed databases of objects; uses :mod:`pickle`.

   Module :mod:`copy`
      Shallow and deep object copying.

   Module :mod:`marshal`
      High-performance serialization of built-in types.


.. rubric:: Footnotes

.. [#] Don't confuse this with the :mod:`marshal` module

.. [#] This is why :keyword:`lambda` functions cannot be pickled:  all
    :keyword:`!lambda` functions share the same name:  ``<lambda>``.

.. [#] The exception raised will likely be an :exc:`ImportError` or an
   :exc:`AttributeError` but it could be something else.

.. [#] The :mod:`copy` module uses this protocol for shallow and deep copying
   operations.

.. [#] The limitation on alphanumeric characters is due to the fact
   that persistent IDs in protocol 0 are delimited by the newline
   character.  Therefore if any kind of newline characters occurs in
   persistent IDs, the resulting pickled data will become unreadable.


================================================
File: /Doc/library/pickletools.rst
================================================
:mod:`!pickletools` --- Tools for pickle developers
===================================================

.. module:: pickletools
   :synopsis: Contains extensive comments about the pickle protocols and
              pickle-machine opcodes, as well as some useful functions.

**Source code:** :source:`Lib/pickletools.py`

--------------


This module contains various constants relating to the intimate details of the
:mod:`pickle` module, some lengthy comments about the implementation, and a
few useful functions for analyzing pickled data.  The contents of this module
are useful for Python core developers who are working on the :mod:`pickle`;
ordinary users of the :mod:`pickle` module probably won't find the
:mod:`pickletools` module relevant.

.. _pickletools-cli:

Command line usage
------------------

.. versionadded:: 3.2

When invoked from the command line, ``python -m pickletools`` will
disassemble the contents of one or more pickle files.  Note that if
you want to see the Python object stored in the pickle rather than the
details of pickle format, you may want to use ``-m pickle`` instead.
However, when the pickle file that you want to examine comes from an
untrusted source, ``-m pickletools`` is a safer option because it does
not execute pickle bytecode.

For example, with a tuple ``(1, 2)`` pickled in file ``x.pickle``:

.. code-block:: shell-session

    $ python -m pickle x.pickle
    (1, 2)

    $ python -m pickletools x.pickle
        0: \x80 PROTO      3
        2: K    BININT1    1
        4: K    BININT1    2
        6: \x86 TUPLE2
        7: q    BINPUT     0
        9: .    STOP
    highest protocol among opcodes = 2

Command line options
^^^^^^^^^^^^^^^^^^^^

.. program:: pickletools

.. option:: -a, --annotate

   Annotate each line with a short opcode description.

.. option:: -o, --output=<file>

   Name of a file where the output should be written.

.. option:: -l, --indentlevel=<num>

   The number of blanks by which to indent a new MARK level.

.. option:: -m, --memo

   When multiple objects are disassembled, preserve memo between
   disassemblies.

.. option:: -p, --preamble=<preamble>

   When more than one pickle file are specified, print given preamble
   before each disassembly.



Programmatic Interface
----------------------


.. function:: dis(pickle, out=None, memo=None, indentlevel=4, annotate=0)

   Outputs a symbolic disassembly of the pickle to the file-like
   object *out*, defaulting to ``sys.stdout``.  *pickle* can be a
   string or a file-like object.  *memo* can be a Python dictionary
   that will be used as the pickle's memo; it can be used to perform
   disassemblies across multiple pickles created by the same
   pickler. Successive levels, indicated by ``MARK`` opcodes in the
   stream, are indented by *indentlevel* spaces.  If a nonzero value
   is given to *annotate*, each opcode in the output is annotated with
   a short description.  The value of *annotate* is used as a hint for
   the column where annotation should start.

   .. versionchanged:: 3.2
      Added the *annotate* parameter.

.. function:: genops(pickle)

   Provides an :term:`iterator` over all of the opcodes in a pickle, returning a
   sequence of ``(opcode, arg, pos)`` triples.  *opcode* is an instance of an
   :class:`OpcodeInfo` class; *arg* is the decoded value, as a Python object, of
   the opcode's argument; *pos* is the position at which this opcode is located.
   *pickle* can be a string or a file-like object.

.. function:: optimize(picklestring)

   Returns a new equivalent pickle string after eliminating unused ``PUT``
   opcodes. The optimized pickle is shorter, takes less transmission time,
   requires less storage space, and unpickles more efficiently.


================================================
File: /Doc/library/pipes.rst
================================================
:mod:`!pipes` --- Interface to shell pipelines
==============================================

.. module:: pipes
   :synopsis: Removed in 3.13.
   :deprecated:

.. deprecated-removed:: 3.11 3.13

This module is no longer part of the Python standard library.
It was :ref:`removed in Python 3.13 <whatsnew313-pep594>` after
being deprecated in Python 3.11.  The removal was decided in :pep:`594`.

Applications should use the :mod:`subprocess` module instead.

The last version of Python that provided the :mod:`!pipes` module was
`Python 3.12 <https://docs.python.org/3.12/library/pipes.html>`_.


================================================
File: /Doc/library/pkgutil.rst
================================================
:mod:`!pkgutil` --- Package extension utility
=============================================

.. module:: pkgutil
   :synopsis: Utilities for the import system.

**Source code:** :source:`Lib/pkgutil.py`

--------------

This module provides utilities for the import system, in particular package
support.

.. class:: ModuleInfo(module_finder, name, ispkg)

    A namedtuple that holds a brief summary of a module's info.

    .. versionadded:: 3.6

.. function:: extend_path(path, name)

   Extend the search path for the modules which comprise a package.  Intended
   use is to place the following code in a package's :file:`__init__.py`::

      from pkgutil import extend_path
      __path__ = extend_path(__path__, __name__)

   For each directory on :data:`sys.path` that has a subdirectory that matches the
   package name, add the subdirectory to the package's
   :attr:`~module.__path__`. This is useful
   if one wants to distribute different parts of a single logical package as multiple
   directories.

   It also looks for :file:`\*.pkg` files beginning where ``*`` matches the
   *name* argument.  This feature is similar to :file:`\*.pth` files (see the
   :mod:`site` module for more information), except that it doesn't special-case
   lines starting with ``import``.  A :file:`\*.pkg` file is trusted at face
   value: apart from skipping blank lines and ignoring comments, all entries
   found in a :file:`\*.pkg` file are added to the path, regardless of whether
   they exist on the filesystem (this is a feature).

   If the input path is not a list (as is the case for frozen packages) it is
   returned unchanged.  The input path is not modified; an extended copy is
   returned.  Items are only appended to the copy at the end.

   It is assumed that :data:`sys.path` is a sequence.  Items of :data:`sys.path`
   that are not strings referring to existing directories are ignored. Unicode
   items on :data:`sys.path` that cause errors when used as filenames may cause
   this function to raise an exception (in line with :func:`os.path.isdir`
   behavior).


.. function:: get_importer(path_item)

   Retrieve a :term:`finder` for the given *path_item*.

   The returned finder is cached in :data:`sys.path_importer_cache` if it was
   newly created by a path hook.

   The cache (or part of it) can be cleared manually if a rescan of
   :data:`sys.path_hooks` is necessary.

   .. versionchanged:: 3.3
      Updated to be based directly on :mod:`importlib` rather than relying
      on the package internal :pep:`302` import emulation.


.. function:: iter_importers(fullname='')

   Yield :term:`finder` objects for the given module name.

   If fullname contains a ``'.'``, the finders will be for the package
   containing fullname, otherwise they will be all registered top level
   finders (i.e. those on both :data:`sys.meta_path` and :data:`sys.path_hooks`).

   If the named module is in a package, that package is imported as a side
   effect of invoking this function.

   If no module name is specified, all top level finders are produced.

   .. versionchanged:: 3.3
      Updated to be based directly on :mod:`importlib` rather than relying
      on the package internal :pep:`302` import emulation.


.. function:: iter_modules(path=None, prefix='')

   Yields :class:`ModuleInfo` for all submodules on *path*, or, if
   *path* is ``None``, all top-level modules on :data:`sys.path`.

   *path* should be either ``None`` or a list of paths to look for modules in.

   *prefix* is a string to output on the front of every module name on output.

   .. note::

      Only works for a :term:`finder` which defines an ``iter_modules()``
      method. This interface is non-standard, so the module also provides
      implementations for :class:`importlib.machinery.FileFinder` and
      :class:`zipimport.zipimporter`.

   .. versionchanged:: 3.3
      Updated to be based directly on :mod:`importlib` rather than relying
      on the package internal :pep:`302` import emulation.


.. function:: walk_packages(path=None, prefix='', onerror=None)

   Yields :class:`ModuleInfo` for all modules recursively on
   *path*, or, if *path* is ``None``, all accessible modules.

   *path* should be either ``None`` or a list of paths to look for modules in.

   *prefix* is a string to output on the front of every module name on output.

   Note that this function must import all *packages* (*not* all modules!) on
   the given *path*, in order to access the ``__path__`` attribute to find
   submodules.

   *onerror* is a function which gets called with one argument (the name of the
   package which was being imported) if any exception occurs while trying to
   import a package.  If no *onerror* function is supplied, :exc:`ImportError`\s
   are caught and ignored, while all other exceptions are propagated,
   terminating the search.

   Examples::

      # list all modules python can access
      walk_packages()

      # list all submodules of ctypes
      walk_packages(ctypes.__path__, ctypes.__name__ + '.')

   .. note::

      Only works for a :term:`finder` which defines an ``iter_modules()``
      method. This interface is non-standard, so the module also provides
      implementations for :class:`importlib.machinery.FileFinder` and
      :class:`zipimport.zipimporter`.

   .. versionchanged:: 3.3
      Updated to be based directly on :mod:`importlib` rather than relying
      on the package internal :pep:`302` import emulation.


.. function:: get_data(package, resource)

   Get a resource from a package.

   This is a wrapper for the :term:`loader`
   :meth:`get_data <importlib.abc.ResourceLoader.get_data>` API.  The
   *package* argument should be the name of a package, in standard module format
   (``foo.bar``).  The *resource* argument should be in the form of a relative
   filename, using ``/`` as the path separator.  The parent directory name
   ``..`` is not allowed, and nor is a rooted name (starting with a ``/``).

   The function returns a binary string that is the contents of the specified
   resource.

   For packages located in the filesystem, which have already been imported,
   this is the rough equivalent of::

      d = os.path.dirname(sys.modules[package].__file__)
      data = open(os.path.join(d, resource), 'rb').read()

   If the package cannot be located or loaded, or it uses a :term:`loader`
   which does not support :meth:`get_data <importlib.abc.ResourceLoader.get_data>`,
   then ``None`` is returned.  In particular, the :term:`loader` for
   :term:`namespace packages <namespace package>` does not support
   :meth:`get_data <importlib.abc.ResourceLoader.get_data>`.


.. function:: resolve_name(name)

   Resolve a name to an object.

   This functionality is used in numerous places in the standard library (see
   :issue:`12915`) - and equivalent functionality is also in widely used
   third-party packages such as setuptools, Django and Pyramid.

   It is expected that *name* will be a string in one of the following
   formats, where W is shorthand for a valid Python identifier and dot stands
   for a literal period in these pseudo-regexes:

   * ``W(.W)*``
   * ``W(.W)*:(W(.W)*)?``

   The first form is intended for backward compatibility only. It assumes that
   some part of the dotted name is a package, and the rest is an object
   somewhere within that package, possibly nested inside other objects.
   Because the place where the package stops and the object hierarchy starts
   can't be inferred by inspection, repeated attempts to import must be done
   with this form.

   In the second form, the caller makes the division point clear through the
   provision of a single colon: the dotted name to the left of the colon is a
   package to be imported, and the dotted name to the right is the object
   hierarchy within that package. Only one import is needed in this form. If
   it ends with the colon, then a module object is returned.

   The function will return an object (which might be a module), or raise one
   of the following exceptions:

   :exc:`ValueError` -- if *name* isn't in a recognised format.

   :exc:`ImportError` -- if an import failed when it shouldn't have.

   :exc:`AttributeError` -- If a failure occurred when traversing the object
   hierarchy within the imported package to get to the desired object.

   .. versionadded:: 3.9


================================================
File: /Doc/library/platform.rst
================================================
:mod:`!platform` ---  Access to underlying platform's identifying data
======================================================================

.. module:: platform
   :synopsis: Retrieves as much platform identifying data as possible.

.. moduleauthor:: Marc-André Lemburg <mal@egenix.com>
.. sectionauthor:: Bjorn Pettersen <bpettersen@corp.fairisaac.com>

**Source code:** :source:`Lib/platform.py`

--------------

.. note::

   Specific platforms listed alphabetically, with Linux included in the Unix
   section.


Cross Platform
--------------


.. function:: architecture(executable=sys.executable, bits='', linkage='')

   Queries the given executable (defaults to the Python interpreter binary) for
   various architecture information.

   Returns a tuple ``(bits, linkage)`` which contain information about the bit
   architecture and the linkage format used for the executable. Both values are
   returned as strings.

   Values that cannot be determined are returned as given by the parameter presets.
   If bits is given as ``''``, the ``sizeof(pointer)`` (or
   ``sizeof(long)`` on Python version < 1.5.2) is used as indicator for the
   supported pointer size.

   The function relies on the system's :file:`file` command to do the actual work.
   This is available on most if not all Unix  platforms and some non-Unix platforms
   and then only if the executable points to the Python interpreter.  Reasonable
   defaults are used when the above needs are not met.

   .. note::

      On macOS (and perhaps other platforms), executable files may be
      universal files containing multiple architectures.

      To get at the "64-bitness" of the current interpreter, it is more
      reliable to query the :data:`sys.maxsize` attribute::

         is_64bits = sys.maxsize > 2**32


.. function:: machine()

   Returns the machine type, e.g. ``'AMD64'``. An empty string is returned if the
   value cannot be determined.


.. function:: node()

   Returns the computer's network name (may not be fully qualified!). An empty
   string is returned if the value cannot be determined.


.. function:: platform(aliased=False, terse=False)

   Returns a single string identifying the underlying platform with as much useful
   information as possible.

   The output is intended to be *human readable* rather than machine parseable. It
   may look different on different platforms and this is intended.

   If *aliased* is true, the function will use aliases for various platforms that
   report system names which differ from their common names, for example SunOS will
   be reported as Solaris.  The :func:`system_alias` function is used to implement
   this.

   Setting *terse* to true causes the function to return only the absolute minimum
   information needed to identify the platform.

   .. versionchanged:: 3.8
      On macOS, the function now uses :func:`mac_ver`, if it returns a
      non-empty release string, to get the macOS version rather than the darwin
      version.


.. function:: processor()

   Returns the (real) processor name, e.g. ``'amdk6'``.

   An empty string is returned if the value cannot be determined. Note that many
   platforms do not provide this information or simply return the same value as for
   :func:`machine`.  NetBSD does this.


.. function:: python_build()

   Returns a tuple ``(buildno, builddate)`` stating the Python build number and
   date as strings.


.. function:: python_compiler()

   Returns a string identifying the compiler used for compiling Python.


.. function:: python_branch()

   Returns a string identifying the Python implementation SCM branch.


.. function:: python_implementation()

   Returns a string identifying the Python implementation. Possible return values
   are: 'CPython', 'IronPython', 'Jython', 'PyPy'.


.. function:: python_revision()

   Returns a string identifying the Python implementation SCM revision.


.. function:: python_version()

   Returns the Python version as string ``'major.minor.patchlevel'``.

   Note that unlike the Python ``sys.version``, the returned value will always
   include the patchlevel (it defaults to 0).


.. function:: python_version_tuple()

   Returns the Python version as tuple ``(major, minor, patchlevel)`` of strings.

   Note that unlike the Python ``sys.version``, the returned value will always
   include the patchlevel (it defaults to ``'0'``).


.. function:: release()

   Returns the system's release, e.g. ``'2.2.0'`` or ``'NT'``. An empty string is
   returned if the value cannot be determined.


.. function:: system()

   Returns the system/OS name, such as ``'Linux'``, ``'Darwin'``, ``'Java'``,
   ``'Windows'``. An empty string is returned if the value cannot be determined.

   On iOS and Android, this returns the user-facing OS name (i.e, ``'iOS``,
   ``'iPadOS'`` or ``'Android'``). To obtain the kernel name (``'Darwin'`` or
   ``'Linux'``), use :func:`os.uname`.

.. function:: system_alias(system, release, version)

   Returns ``(system, release, version)`` aliased to common marketing names used
   for some systems.  It also does some reordering of the information in some cases
   where it would otherwise cause confusion.


.. function:: version()

   Returns the system's release version, e.g. ``'#3 on degas'``. An empty string is
   returned if the value cannot be determined.

   On iOS and Android, this is the user-facing OS version. To obtain the
   Darwin or Linux kernel version, use :func:`os.uname`.

.. function:: uname()

   Fairly portable uname interface. Returns a :func:`~collections.namedtuple`
   containing six attributes: :attr:`system`, :attr:`node`, :attr:`release`,
   :attr:`version`, :attr:`machine`, and :attr:`processor`.

   :attr:`processor` is resolved late, on demand.

   Note: the first two attribute names differ from the names presented by
   :func:`os.uname`, where they are named :attr:`sysname` and
   :attr:`nodename`.

   Entries which cannot be determined are set to ``''``.

   .. versionchanged:: 3.3
      Result changed from a tuple to a :func:`~collections.namedtuple`.

   .. versionchanged:: 3.9
      :attr:`processor` is resolved late instead of immediately.


Java Platform
-------------


.. function:: java_ver(release='', vendor='', vminfo=('','',''), osinfo=('','',''))

   Version interface for Jython.

   Returns a tuple ``(release, vendor, vminfo, osinfo)`` with *vminfo* being a
   tuple ``(vm_name, vm_release, vm_vendor)`` and *osinfo* being a tuple
   ``(os_name, os_version, os_arch)``. Values which cannot be determined are set to
   the defaults given as parameters (which all default to ``''``).

   .. deprecated-removed:: 3.13 3.15
      It was largely untested, had a confusing API,
      and was only useful for Jython support.


Windows Platform
----------------


.. function:: win32_ver(release='', version='', csd='', ptype='')

   Get additional version information from the Windows Registry and return a tuple
   ``(release, version, csd, ptype)`` referring to OS release, version number,
   CSD level (service pack) and OS type (multi/single processor). Values which
   cannot be determined are set to the defaults given as parameters (which all
   default to an empty string).

   As a hint: *ptype* is ``'Uniprocessor Free'`` on single processor NT machines
   and ``'Multiprocessor Free'`` on multi processor machines. The ``'Free'`` refers
   to the OS version being free of debugging code. It could also state ``'Checked'``
   which means the OS version uses debugging code, i.e. code that checks arguments,
   ranges, etc.

.. function:: win32_edition()

   Returns a string representing the current Windows edition, or ``None`` if the
   value cannot be determined.  Possible values include but are not limited to
   ``'Enterprise'``, ``'IoTUAP'``, ``'ServerStandard'``, and ``'nanoserver'``.

   .. versionadded:: 3.8

.. function:: win32_is_iot()

   Return ``True`` if the Windows edition returned by :func:`win32_edition`
   is recognized as an IoT edition.

   .. versionadded:: 3.8


macOS Platform
--------------

.. function:: mac_ver(release='', versioninfo=('','',''), machine='')

   Get macOS version information and return it as tuple ``(release, versioninfo,
   machine)`` with *versioninfo* being a tuple ``(version, dev_stage,
   non_release_version)``.

   Entries which cannot be determined are set to ``''``.  All tuple entries are
   strings.

iOS Platform
------------

.. function:: ios_ver(system='', release='', model='', is_simulator=False)

   Get iOS version information and return it as a
   :func:`~collections.namedtuple` with the following attributes:

   * ``system`` is the OS name; either ``'iOS'`` or ``'iPadOS'``.
   * ``release`` is the iOS version number as a string (e.g., ``'17.2'``).
   * ``model`` is the device model identifier; this will be a string like
     ``'iPhone13,2'`` for a physical device, or ``'iPhone'`` on a simulator.
   * ``is_simulator`` is a boolean describing if the app is running on a
     simulator or a physical device.

   Entries which cannot be determined are set to the defaults given as
   parameters.


Unix Platforms
--------------

.. function:: libc_ver(executable=sys.executable, lib='', version='', chunksize=16384)

   Tries to determine the libc version against which the file executable (defaults
   to the Python interpreter) is linked.  Returns a tuple of strings ``(lib,
   version)`` which default to the given parameters in case the lookup fails.

   Note that this function has intimate knowledge of how different libc versions
   add symbols to the executable is probably only usable for executables compiled
   using :program:`gcc`.

   The file is read and scanned in chunks of *chunksize* bytes.


Linux Platforms
---------------

.. function:: freedesktop_os_release()

   Get operating system identification from ``os-release`` file and return
   it as a dict. The ``os-release`` file is a `freedesktop.org standard
   <https://www.freedesktop.org/software/systemd/man/os-release.html>`_ and
   is available in most Linux distributions. A noticeable exception is
   Android and Android-based distributions.

   Raises :exc:`OSError` or subclass when neither ``/etc/os-release`` nor
   ``/usr/lib/os-release`` can be read.

   On success, the function returns a dictionary where keys and values are
   strings. Values have their special characters like ``"`` and ``$``
   unquoted. The fields ``NAME``, ``ID``, and ``PRETTY_NAME`` are always
   defined according to the standard. All other fields are optional. Vendors
   may include additional fields.

   Note that fields like ``NAME``, ``VERSION``, and ``VARIANT`` are strings
   suitable for presentation to users. Programs should use fields like
   ``ID``, ``ID_LIKE``, ``VERSION_ID``, or ``VARIANT_ID`` to identify
   Linux distributions.

   Example::

      def get_like_distro():
          info = platform.freedesktop_os_release()
          ids = [info["ID"]]
          if "ID_LIKE" in info:
              # ids are space separated and ordered by precedence
              ids.extend(info["ID_LIKE"].split())
          return ids

   .. versionadded:: 3.10


Android Platform
----------------

.. function:: android_ver(release="", api_level=0, manufacturer="", \
                          model="", device="", is_emulator=False)

   Get Android device information. Returns a :func:`~collections.namedtuple`
   with the following attributes. Values which cannot be determined are set to
   the defaults given as parameters.

   * ``release`` - Android version, as a string (e.g. ``"14"``).

   * ``api_level`` - API level of the running device, as an integer (e.g. ``34``
     for Android 14). To get the API level which Python was built against, see
     :func:`sys.getandroidapilevel`.

   * ``manufacturer`` - `Manufacturer name
     <https://developer.android.com/reference/android/os/Build#MANUFACTURER>`__.

   * ``model`` - `Model name
     <https://developer.android.com/reference/android/os/Build#MODEL>`__ –
     typically the marketing name or model number.

   * ``device`` - `Device name
     <https://developer.android.com/reference/android/os/Build#DEVICE>`__ –
     typically the model number or a codename.

   * ``is_emulator`` - ``True`` if the device is an emulator; ``False`` if it's
     a physical device.

   Google maintains a `list of known model and device names
   <https://storage.googleapis.com/play_public/supported_devices.html>`__.

   .. versionadded:: 3.13


Miscellaneous
-------------

.. function:: invalidate_caches()

   Clear out the internal cache of information, such as the :func:`uname`.
   This is typically useful when the platform's :func:`node` is changed
   by an external process and one needs to retrieve the updated value.

   .. versionadded:: 3.14


================================================
File: /Doc/library/plistlib.rst
================================================
:mod:`!plistlib` --- Generate and parse Apple ``.plist`` files
==============================================================

.. module:: plistlib
   :synopsis: Generate and parse Apple plist files.

.. moduleauthor:: Jack Jansen
.. sectionauthor:: Georg Brandl <georg@python.org>
.. (harvested from docstrings in the original file)

**Source code:** :source:`Lib/plistlib.py`

.. index::
   pair: plist; file
   single: property list

--------------

This module provides an interface for reading and writing the "property list"
files used by Apple, primarily on macOS and iOS. This module supports both binary
and XML plist files.

The property list (``.plist``) file format is a simple serialization supporting
basic object types, like dictionaries, lists, numbers and strings.  Usually the
top level object is a dictionary.

To write out and to parse a plist file, use the :func:`dump` and
:func:`load` functions.

To work with plist data in bytes or string objects, use :func:`dumps`
and :func:`loads`.

Values can be strings, integers, floats, booleans, tuples, lists, dictionaries
(but only with string keys), :class:`bytes`, :class:`bytearray`
or :class:`datetime.datetime` objects.

.. versionchanged:: 3.4
   New API, old API deprecated.  Support for binary format plists added.

.. versionchanged:: 3.8
   Support added for reading and writing :class:`UID` tokens in binary plists as used
   by NSKeyedArchiver and NSKeyedUnarchiver.

.. versionchanged:: 3.9
   Old API removed.

.. seealso::

   `PList manual page <https://developer.apple.com/library/archive/documentation/Cocoa/Conceptual/PropertyLists/>`_
      Apple's documentation of the file format.


This module defines the following functions:

.. function:: load(fp, *, fmt=None, dict_type=dict, aware_datetime=False)

   Read a plist file. *fp* should be a readable and binary file object.
   Return the unpacked root object (which usually is a
   dictionary).

   The *fmt* is the format of the file and the following values are valid:

   * :data:`None`: Autodetect the file format

   * :data:`FMT_XML`: XML file format

   * :data:`FMT_BINARY`: Binary plist format

   The *dict_type* is the type used for dictionaries that are read from the
   plist file.

   When *aware_datetime* is true, fields with type ``datetime.datetime`` will
   be created as :ref:`aware object <datetime-naive-aware>`, with
   :attr:`!tzinfo` as :attr:`datetime.UTC`.

   XML data for the :data:`FMT_XML` format is parsed using the Expat parser
   from :mod:`xml.parsers.expat` -- see its documentation for possible
   exceptions on ill-formed XML.  Unknown elements will simply be ignored
   by the plist parser.

   The parser for the binary format raises :exc:`InvalidFileException`
   when the file cannot be parsed.

   .. versionadded:: 3.4

   .. versionchanged:: 3.13
      The keyword-only parameter *aware_datetime* has been added.


.. function:: loads(data, *, fmt=None, dict_type=dict, aware_datetime=False)

   Load a plist from a bytes or string object. See :func:`load` for an
   explanation of the keyword arguments.

   .. versionadded:: 3.4

   .. versionchanged:: 3.13
      *data* can be a string when *fmt* equals :data:`FMT_XML`.

.. function:: dump(value, fp, *, fmt=FMT_XML, sort_keys=True, skipkeys=False, aware_datetime=False)

   Write *value* to a plist file. *Fp* should be a writable, binary
   file object.

   The *fmt* argument specifies the format of the plist file and can be
   one of the following values:

   * :data:`FMT_XML`: XML formatted plist file

   * :data:`FMT_BINARY`: Binary formatted plist file

   When *sort_keys* is true (the default) the keys for dictionaries will be
   written to the plist in sorted order, otherwise they will be written in
   the iteration order of the dictionary.

   When *skipkeys* is false (the default) the function raises :exc:`TypeError`
   when a key of a dictionary is not a string, otherwise such keys are skipped.

   When *aware_datetime* is true and any field with type ``datetime.datetime``
   is set as an :ref:`aware object <datetime-naive-aware>`, it will convert to
   UTC timezone before writing it.

   A :exc:`TypeError` will be raised if the object is of an unsupported type or
   a container that contains objects of unsupported types.

   An :exc:`OverflowError` will be raised for integer values that cannot
   be represented in (binary) plist files.

   .. versionadded:: 3.4

   .. versionchanged:: 3.13
      The keyword-only parameter *aware_datetime* has been added.


.. function:: dumps(value, *, fmt=FMT_XML, sort_keys=True, skipkeys=False, aware_datetime=False)

   Return *value* as a plist-formatted bytes object. See
   the documentation for :func:`dump` for an explanation of the keyword
   arguments of this function.

   .. versionadded:: 3.4


The following classes are available:

.. class:: UID(data)

   Wraps an :class:`int`.  This is used when reading or writing NSKeyedArchiver
   encoded data, which contains UID (see PList manual).

   It has one attribute, :attr:`data`, which can be used to retrieve the int value
   of the UID.  :attr:`data` must be in the range ``0 <= data < 2**64``.

   .. versionadded:: 3.8


The following constants are available:

.. data:: FMT_XML

   The XML format for plist files.

   .. versionadded:: 3.4


.. data:: FMT_BINARY

   The binary format for plist files

   .. versionadded:: 3.4


Examples
--------

Generating a plist::

    import datetime
    import plistlib

    pl = dict(
        aString = "Doodah",
        aList = ["A", "B", 12, 32.1, [1, 2, 3]],
        aFloat = 0.1,
        anInt = 728,
        aDict = dict(
            anotherString = "<hello & hi there!>",
            aThirdString = "M\xe4ssig, Ma\xdf",
            aTrueValue = True,
            aFalseValue = False,
        ),
        someData = b"<binary gunk>",
        someMoreData = b"<lots of binary gunk>" * 10,
        aDate = datetime.datetime.now()
    )
    print(plistlib.dumps(pl).decode())

Parsing a plist::

    import plistlib

    plist = b"""<plist version="1.0">
    <dict>
        <key>foo</key>
        <string>bar</string>
    </dict>
    </plist>"""
    pl = plistlib.loads(plist)
    print(pl["foo"])


================================================
File: /Doc/library/poplib.rst
================================================
:mod:`!poplib` --- POP3 protocol client
=======================================

.. module:: poplib
   :synopsis: POP3 protocol client (requires sockets).

.. sectionauthor:: Andrew T. Csillag
.. revised by ESR, January 2000

**Source code:** :source:`Lib/poplib.py`

.. index:: pair: POP3; protocol

--------------

This module defines a class, :class:`POP3`, which encapsulates a connection to a
POP3 server and implements the protocol as defined in :rfc:`1939`. The
:class:`POP3` class supports both the minimal and optional command sets from
:rfc:`1939`. The :class:`POP3` class also supports the ``STLS`` command introduced
in :rfc:`2595` to enable encrypted communication on an already established connection.

Additionally, this module provides a class :class:`POP3_SSL`, which provides
support for connecting to POP3 servers that use SSL as an underlying protocol
layer.

Note that POP3, though widely supported, is obsolescent.  The implementation
quality of POP3 servers varies widely, and too many are quite poor. If your
mailserver supports IMAP, you would be better off using the
:class:`imaplib.IMAP4` class, as IMAP servers tend to be better implemented.

.. include:: ../includes/wasm-notavail.rst

The :mod:`poplib` module provides two classes:


.. class:: POP3(host, port=POP3_PORT[, timeout])

   This class implements the actual POP3 protocol.  The connection is created when
   the instance is initialized. If *port* is omitted, the standard POP3 port (110)
   is used. The optional *timeout* parameter specifies a timeout in seconds for the
   connection attempt (if not specified, the global default timeout setting will
   be used).

   .. audit-event:: poplib.connect self,host,port poplib.POP3

   .. audit-event:: poplib.putline self,line poplib.POP3

      All commands will raise an :ref:`auditing event <auditing>`
      ``poplib.putline`` with arguments ``self`` and ``line``,
      where ``line`` is the bytes about to be sent to the remote host.

   .. versionchanged:: 3.9
      If the *timeout* parameter is set to be zero, it will raise a
      :class:`ValueError` to prevent the creation of a non-blocking socket.

.. class:: POP3_SSL(host, port=POP3_SSL_PORT, *, timeout=None, context=None)

   This is a subclass of :class:`POP3` that connects to the server over an SSL
   encrypted socket.  If *port* is not specified, 995, the standard POP3-over-SSL
   port is used.  *timeout* works as in the :class:`POP3` constructor.
   *context* is an optional :class:`ssl.SSLContext` object which allows
   bundling SSL configuration options, certificates and private keys into a
   single (potentially long-lived) structure.  Please read :ref:`ssl-security`
   for best practices.

   .. audit-event:: poplib.connect self,host,port poplib.POP3_SSL

   .. audit-event:: poplib.putline self,line poplib.POP3_SSL

      All commands will raise an :ref:`auditing event <auditing>`
      ``poplib.putline`` with arguments ``self`` and ``line``,
      where ``line`` is the bytes about to be sent to the remote host.

   .. versionchanged:: 3.2
      *context* parameter added.

   .. versionchanged:: 3.4
      The class now supports hostname check with
      :attr:`ssl.SSLContext.check_hostname` and *Server Name Indication* (see
      :const:`ssl.HAS_SNI`).

   .. versionchanged:: 3.9
      If the *timeout* parameter is set to be zero, it will raise a
      :class:`ValueError` to prevent the creation of a non-blocking socket.

   .. versionchanged:: 3.12
      The deprecated *keyfile* and *certfile* parameters have been removed.

One exception is defined as an attribute of the :mod:`poplib` module:


.. exception:: error_proto

   Exception raised on any errors from this module (errors from :mod:`socket`
   module are not caught). The reason for the exception is passed to the
   constructor as a string.


.. seealso::

   Module :mod:`imaplib`
      The standard Python IMAP module.

   `Frequently Asked Questions About Fetchmail <http://www.catb.org/~esr/fetchmail/fetchmail-FAQ.html>`_
      The FAQ for the :program:`fetchmail` POP/IMAP client collects information on
      POP3 server variations and RFC noncompliance that may be useful if you need to
      write an application based on the POP protocol.


.. _pop3-objects:

POP3 Objects
------------

All POP3 commands are represented by methods of the same name, in lowercase;
most return the response text sent by the server.

A :class:`POP3` instance has the following methods:


.. method:: POP3.set_debuglevel(level)

   Set the instance's debugging level.  This controls the amount of debugging
   output printed.  The default, ``0``, produces no debugging output.  A value of
   ``1`` produces a moderate amount of debugging output, generally a single line
   per request.  A value of ``2`` or higher produces the maximum amount of
   debugging output, logging each line sent and received on the control connection.


.. method:: POP3.getwelcome()

   Returns the greeting string sent by the POP3 server.


.. method:: POP3.capa()

   Query the server's capabilities as specified in :rfc:`2449`.
   Returns a dictionary in the form ``{'name': ['param'...]}``.

   .. versionadded:: 3.4


.. method:: POP3.user(username)

   Send user command, response should indicate that a password is required.


.. method:: POP3.pass_(password)

   Send password, response includes message count and mailbox size. Note: the
   mailbox on the server is locked until :meth:`~POP3.quit` is called.


.. method:: POP3.apop(user, secret)

   Use the more secure APOP authentication to log into the POP3 server.


.. method:: POP3.rpop(user)

   Use RPOP authentication (similar to UNIX r-commands) to log into POP3 server.


.. method:: POP3.stat()

   Get mailbox status.  The result is a tuple of 2 integers: ``(message count,
   mailbox size)``.


.. method:: POP3.list([which])

   Request message list, result is in the form ``(response, ['mesg_num octets',
   ...], octets)``. If *which* is set, it is the message to list.


.. method:: POP3.retr(which)

   Retrieve whole message number *which*, and set its seen flag. Result is in form
   ``(response, ['line', ...], octets)``.


.. method:: POP3.dele(which)

   Flag message number *which* for deletion.  On most servers deletions are not
   actually performed until QUIT (the major exception is Eudora QPOP, which
   deliberately violates the RFCs by doing pending deletes on any disconnect).


.. method:: POP3.rset()

   Remove any deletion marks for the mailbox.


.. method:: POP3.noop()

   Do nothing.  Might be used as a keep-alive.


.. method:: POP3.quit()

   Signoff:  commit changes, unlock mailbox, drop connection.


.. method:: POP3.top(which, howmuch)

   Retrieves the message header plus *howmuch* lines of the message after the
   header of message number *which*. Result is in form ``(response, ['line', ...],
   octets)``.

   The POP3 TOP command this method uses, unlike the RETR command, doesn't set the
   message's seen flag; unfortunately, TOP is poorly specified in the RFCs and is
   frequently broken in off-brand servers. Test this method by hand against the
   POP3 servers you will use before trusting it.


.. method:: POP3.uidl(which=None)

   Return message digest (unique id) list. If *which* is specified, result contains
   the unique id for that message in the form ``'response mesgnum uid``, otherwise
   result is list ``(response, ['mesgnum uid', ...], octets)``.


.. method:: POP3.utf8()

   Try to switch to UTF-8 mode. Returns the server response if successful,
   raises :class:`error_proto` if not. Specified in :RFC:`6856`.

   .. versionadded:: 3.5


.. method:: POP3.stls(context=None)

   Start a TLS session on the active connection as specified in :rfc:`2595`.
   This is only allowed before user authentication

   *context* parameter is a :class:`ssl.SSLContext` object which allows
   bundling SSL configuration options, certificates and private keys into
   a single (potentially long-lived) structure.  Please read :ref:`ssl-security`
   for best practices.

   This method supports hostname checking via
   :attr:`ssl.SSLContext.check_hostname` and *Server Name Indication* (see
   :const:`ssl.HAS_SNI`).

   .. versionadded:: 3.4


Instances of :class:`POP3_SSL` have no additional methods. The interface of this
subclass is identical to its parent.


.. _pop3-example:

POP3 Example
------------

Here is a minimal example (without error checking) that opens a mailbox and
retrieves and prints all messages::

   import getpass, poplib

   M = poplib.POP3('localhost')
   M.user(getpass.getuser())
   M.pass_(getpass.getpass())
   numMessages = len(M.list()[1])
   for i in range(numMessages):
       for j in M.retr(i+1)[1]:
           print(j)

At the end of the module, there is a test section that contains a more extensive
example of usage.


================================================
File: /Doc/library/posix.rst
================================================
:mod:`!posix` --- The most common POSIX system calls
====================================================

.. module:: posix
   :platform: Unix
   :synopsis: The most common POSIX system calls (normally used via module os).

--------------

This module provides access to operating system functionality that is
standardized by the C Standard and the POSIX standard (a thinly disguised Unix
interface).

.. availability:: Unix.

.. index:: pair: module; os

**Do not import this module directly.**  Instead, import the module :mod:`os`,
which provides a *portable* version of this interface.  On Unix, the :mod:`os`
module provides a superset of the :mod:`posix` interface.  On non-Unix operating
systems the :mod:`posix` module is not available, but a subset is always
available through the :mod:`os` interface.  Once :mod:`os` is imported, there is
*no* performance penalty in using it instead of :mod:`posix`.  In addition,
:mod:`os` provides some additional functionality, such as automatically calling
:func:`~os.putenv` when an entry in ``os.environ`` is changed.

Errors are reported as exceptions; the usual exceptions are given for type
errors, while errors reported by the system calls raise :exc:`OSError`.


.. _posix-large-files:

Large File Support
------------------

.. index::
   single: large files
   single: file; large files

.. sectionauthor:: Steve Clift <clift@mail.anacapa.net>

Several operating systems (including AIX and Solaris) provide
support for files that are larger than 2 GiB from a C programming model where
:c:expr:`int` and :c:expr:`long` are 32-bit values. This is typically accomplished
by defining the relevant size and offset types as 64-bit values. Such files are
sometimes referred to as :dfn:`large files`.

Large file support is enabled in Python when the size of an :c:type:`off_t` is
larger than a :c:expr:`long` and the :c:expr:`long long` is at least as large
as an :c:type:`off_t`.
It may be necessary to configure and compile Python with certain compiler flags
to enable this mode. For example, with Solaris 2.6 and 2.7 you need to do
something like::

   CFLAGS="`getconf LFS_CFLAGS`" OPT="-g -O2 $CFLAGS" \
           ./configure

On large-file-capable Linux systems, this might work::

   CFLAGS='-D_LARGEFILE64_SOURCE -D_FILE_OFFSET_BITS=64' OPT="-g -O2 $CFLAGS" \
           ./configure


.. _posix-contents:

Notable Module Contents
-----------------------

In addition to many functions described in the :mod:`os` module documentation,
:mod:`posix` defines the following data item:

.. data:: environ

   A dictionary representing the string environment at the time the interpreter
   was started. Keys and values are bytes on Unix and str on Windows. For
   example, ``environ[b'HOME']`` (``environ['HOME']`` on Windows) is the
   pathname of your home directory, equivalent to ``getenv("HOME")`` in C.

   Modifying this dictionary does not affect the string environment passed on by
   :func:`~os.execv`, :func:`~os.popen` or :func:`~os.system`; if you need to
   change the environment, pass ``environ`` to :func:`~os.execve` or add
   variable assignments and export statements to the command string for
   :func:`~os.system` or :func:`~os.popen`.

   .. versionchanged:: 3.2
      On Unix, keys and values are bytes.

   .. note::

      The :mod:`os` module provides an alternate implementation of ``environ``
      which updates the environment on modification. Note also that updating
      :data:`os.environ` will render this dictionary obsolete. Use of the
      :mod:`os` module version of this is recommended over direct access to the
      :mod:`posix` module.


================================================
File: /Doc/library/pprint.rst
================================================
:mod:`!pprint` --- Data pretty printer
======================================

.. module:: pprint
   :synopsis: Data pretty printer.

.. moduleauthor:: Fred L. Drake, Jr. <fdrake@acm.org>
.. sectionauthor:: Fred L. Drake, Jr. <fdrake@acm.org>

**Source code:** :source:`Lib/pprint.py`

--------------

The :mod:`pprint` module provides a capability to "pretty-print" arbitrary
Python data structures in a form which can be used as input to the interpreter.
If the formatted structures include objects which are not fundamental Python
types, the representation may not be loadable.  This may be the case if objects
such as files, sockets or classes are included, as well as many other
objects which are not representable as Python literals.

The formatted representation keeps objects on a single line if it can, and
breaks them onto multiple lines if they don't fit within the allowed width,
adjustable by the *width* parameter defaulting to 80 characters.

Dictionaries are sorted by key before the display is computed.

.. versionchanged:: 3.9
   Added support for pretty-printing :class:`types.SimpleNamespace`.

.. versionchanged:: 3.10
   Added support for pretty-printing :class:`dataclasses.dataclass`.

.. _pprint-functions:

Functions
---------

.. function:: pp(object, stream=None, indent=1, width=80, depth=None, *, \
                     compact=False, sort_dicts=False, underscore_numbers=False)

   Prints the formatted representation of *object*, followed by a newline.
   This function may be used in the interactive interpreter
   instead of the :func:`print` function for inspecting values.
   Tip: you can reassign ``print = pprint.pp`` for use within a scope.

   :param object:
      The object to be printed.

   :param stream:
      A file-like object to which the output will be written
      by calling its :meth:`!write` method.
      If ``None`` (the default), :data:`sys.stdout` is used.
   :type stream: :term:`file-like object` | None

   :param int indent:
      The amount of indentation added for each nesting level.

   :param int width:
      The desired maximum number of characters per line in the output.
      If a structure cannot be formatted within the width constraint,
      a best effort will be made.

   :param depth:
      The number of nesting levels which may be printed.
      If the data structure being printed is too deep,
      the next contained level is replaced by ``...``.
      If ``None`` (the default), there is no constraint
      on the depth of the objects being formatted.
   :type depth: int | None

   :param bool compact:
      Control the way long :term:`sequences <sequence>` are formatted.
      If ``False`` (the default),
      each item of a sequence will be formatted on a separate line,
      otherwise as many items as will fit within the *width*
      will be formatted on each output line.

   :param bool sort_dicts:
      If ``True``, dictionaries will be formatted with
      their keys sorted, otherwise
      they will be displayed in insertion order (the default).

   :param bool underscore_numbers:
      If ``True``,
      integers will be formatted with the ``_`` character for a thousands separator,
      otherwise underscores are not displayed (the default).

   >>> import pprint
   >>> stuff = ['spam', 'eggs', 'lumberjack', 'knights', 'ni']
   >>> stuff.insert(0, stuff)
   >>> pprint.pp(stuff)
   [<Recursion on list with id=...>,
    'spam',
    'eggs',
    'lumberjack',
    'knights',
    'ni']

   .. versionadded:: 3.8


.. function:: pprint(object, stream=None, indent=1, width=80, depth=None, *, \
                     compact=False, sort_dicts=True, underscore_numbers=False)

   Alias for :func:`~pprint.pp` with *sort_dicts* set to ``True`` by default,
   which would automatically sort the dictionaries' keys,
   you might want to use :func:`~pprint.pp` instead where it is ``False`` by default.


.. function:: pformat(object, indent=1, width=80, depth=None, *, \
                      compact=False, sort_dicts=True, underscore_numbers=False)

   Return the formatted representation of *object* as a string.  *indent*,
   *width*, *depth*, *compact*, *sort_dicts* and *underscore_numbers* are
   passed to the :class:`PrettyPrinter` constructor as formatting parameters
   and their meanings are as described in the documentation above.


.. function:: isreadable(object)

   .. index:: pair: built-in function; eval

   Determine if the formatted representation of *object* is "readable", or can be
   used to reconstruct the value using :func:`eval`.  This always returns ``False``
   for recursive objects.

      >>> pprint.isreadable(stuff)
      False


.. function:: isrecursive(object)

   Determine if *object* requires a recursive representation.  This function is
   subject to the same limitations as noted in :func:`saferepr` below and may raise an
   :exc:`RecursionError` if it fails to detect a recursive object.


.. function:: saferepr(object)

   Return a string representation of *object*, protected against recursion in
   some common data structures, namely instances of :class:`dict`, :class:`list`
   and :class:`tuple` or subclasses whose ``__repr__`` has not been overridden.  If the
   representation of object exposes a recursive entry, the recursive reference
   will be represented as ``<Recursion on typename with id=number>``.  The
   representation is not otherwise formatted.

   >>> pprint.saferepr(stuff)
   "[<Recursion on list with id=...>, 'spam', 'eggs', 'lumberjack', 'knights', 'ni']"

.. _prettyprinter-objects:

PrettyPrinter Objects
---------------------

.. index:: single: ...; placeholder

.. class:: PrettyPrinter(indent=1, width=80, depth=None, stream=None, *, \
                         compact=False, sort_dicts=True, underscore_numbers=False)

   Construct a :class:`PrettyPrinter` instance.

   Arguments have the same meaning as for :func:`~pprint.pp`.
   Note that they are in a different order, and that *sort_dicts* defaults to ``True``.

   >>> import pprint
   >>> stuff = ['spam', 'eggs', 'lumberjack', 'knights', 'ni']
   >>> stuff.insert(0, stuff[:])
   >>> pp = pprint.PrettyPrinter(indent=4)
   >>> pp.pprint(stuff)
   [   ['spam', 'eggs', 'lumberjack', 'knights', 'ni'],
       'spam',
       'eggs',
       'lumberjack',
       'knights',
       'ni']
   >>> pp = pprint.PrettyPrinter(width=41, compact=True)
   >>> pp.pprint(stuff)
   [['spam', 'eggs', 'lumberjack',
     'knights', 'ni'],
    'spam', 'eggs', 'lumberjack', 'knights',
    'ni']
   >>> tup = ('spam', ('eggs', ('lumberjack', ('knights', ('ni', ('dead',
   ... ('parrot', ('fresh fruit',))))))))
   >>> pp = pprint.PrettyPrinter(depth=6)
   >>> pp.pprint(tup)
   ('spam', ('eggs', ('lumberjack', ('knights', ('ni', ('dead', (...)))))))


   .. versionchanged:: 3.4
      Added the *compact* parameter.

   .. versionchanged:: 3.8
      Added the *sort_dicts* parameter.

   .. versionchanged:: 3.10
      Added the *underscore_numbers* parameter.

   .. versionchanged:: 3.11
      No longer attempts to write to :data:`!sys.stdout` if it is ``None``.


:class:`PrettyPrinter` instances have the following methods:


.. method:: PrettyPrinter.pformat(object)

   Return the formatted representation of *object*.  This takes into account the
   options passed to the :class:`PrettyPrinter` constructor.


.. method:: PrettyPrinter.pprint(object)

   Print the formatted representation of *object* on the configured stream,
   followed by a newline.

The following methods provide the implementations for the corresponding
functions of the same names.  Using these methods on an instance is slightly
more efficient since new :class:`PrettyPrinter` objects don't need to be
created.


.. method:: PrettyPrinter.isreadable(object)

   .. index:: pair: built-in function; eval

   Determine if the formatted representation of the object is "readable," or can be
   used to reconstruct the value using :func:`eval`.  Note that this returns
   ``False`` for recursive objects.  If the *depth* parameter of the
   :class:`PrettyPrinter` is set and the object is deeper than allowed, this
   returns ``False``.


.. method:: PrettyPrinter.isrecursive(object)

   Determine if the object requires a recursive representation.

This method is provided as a hook to allow subclasses to modify the way objects
are converted to strings.  The default implementation uses the internals of the
:func:`saferepr` implementation.


.. method:: PrettyPrinter.format(object, context, maxlevels, level)

   Returns three values: the formatted version of *object* as a string, a flag
   indicating whether the result is readable, and a flag indicating whether
   recursion was detected.  The first argument is the object to be presented.  The
   second is a dictionary which contains the :func:`id` of objects that are part of
   the current presentation context (direct and indirect containers for *object*
   that are affecting the presentation) as the keys; if an object needs to be
   presented which is already represented in *context*, the third return value
   should be ``True``.  Recursive calls to the :meth:`.format` method should add
   additional entries for containers to this dictionary.  The third argument,
   *maxlevels*, gives the requested limit to recursion; this will be ``0`` if there
   is no requested limit.  This argument should be passed unmodified to recursive
   calls. The fourth argument, *level*, gives the current level; recursive calls
   should be passed a value less than that of the current call.


.. _pprint-example:

Example
-------

To demonstrate several uses of the :func:`~pprint.pp` function and its parameters,
let's fetch information about a project from `PyPI <https://pypi.org>`_::

   >>> import json
   >>> import pprint
   >>> from urllib.request import urlopen
   >>> with urlopen('https://pypi.org/pypi/sampleproject/1.2.0/json') as resp:
   ...     project_info = json.load(resp)['info']

In its basic form, :func:`~pprint.pp` shows the whole object::

   >>> pprint.pp(project_info)
   {'author': 'The Python Packaging Authority',
    'author_email': 'pypa-dev@googlegroups.com',
    'bugtrack_url': None,
    'classifiers': ['Development Status :: 3 - Alpha',
                    'Intended Audience :: Developers',
                    'License :: OSI Approved :: MIT License',
                    'Programming Language :: Python :: 2',
                    'Programming Language :: Python :: 2.6',
                    'Programming Language :: Python :: 2.7',
                    'Programming Language :: Python :: 3',
                    'Programming Language :: Python :: 3.2',
                    'Programming Language :: Python :: 3.3',
                    'Programming Language :: Python :: 3.4',
                    'Topic :: Software Development :: Build Tools'],
    'description': 'A sample Python project\n'
                   '=======================\n'
                   '\n'
                   'This is the description file for the project.\n'
                   '\n'
                   'The file should use UTF-8 encoding and be written using '
                   'ReStructured Text. It\n'
                   'will be used to generate the project webpage on PyPI, and '
                   'should be written for\n'
                   'that purpose.\n'
                   '\n'
                   'Typical contents for this file would include an overview of '
                   'the project, basic\n'
                   'usage examples, etc. Generally, including the project '
                   'changelog in here is not\n'
                   'a good idea, although a simple "What\'s New" section for the '
                   'most recent version\n'
                   'may be appropriate.',
    'description_content_type': None,
    'docs_url': None,
    'download_url': 'UNKNOWN',
    'downloads': {'last_day': -1, 'last_month': -1, 'last_week': -1},
    'home_page': 'https://github.com/pypa/sampleproject',
    'keywords': 'sample setuptools development',
    'license': 'MIT',
    'maintainer': None,
    'maintainer_email': None,
    'name': 'sampleproject',
    'package_url': 'https://pypi.org/project/sampleproject/',
    'platform': 'UNKNOWN',
    'project_url': 'https://pypi.org/project/sampleproject/',
    'project_urls': {'Download': 'UNKNOWN',
                     'Homepage': 'https://github.com/pypa/sampleproject'},
    'release_url': 'https://pypi.org/project/sampleproject/1.2.0/',
    'requires_dist': None,
    'requires_python': None,
    'summary': 'A sample Python project',
    'version': '1.2.0'}

The result can be limited to a certain *depth* (ellipsis is used for deeper
contents)::

   >>> pprint.pp(project_info, depth=1)
   {'author': 'The Python Packaging Authority',
    'author_email': 'pypa-dev@googlegroups.com',
    'bugtrack_url': None,
    'classifiers': [...],
    'description': 'A sample Python project\n'
                   '=======================\n'
                   '\n'
                   'This is the description file for the project.\n'
                   '\n'
                   'The file should use UTF-8 encoding and be written using '
                   'ReStructured Text. It\n'
                   'will be used to generate the project webpage on PyPI, and '
                   'should be written for\n'
                   'that purpose.\n'
                   '\n'
                   'Typical contents for this file would include an overview of '
                   'the project, basic\n'
                   'usage examples, etc. Generally, including the project '
                   'changelog in here is not\n'
                   'a good idea, although a simple "What\'s New" section for the '
                   'most recent version\n'
                   'may be appropriate.',
    'description_content_type': None,
    'docs_url': None,
    'download_url': 'UNKNOWN',
    'downloads': {...},
    'home_page': 'https://github.com/pypa/sampleproject',
    'keywords': 'sample setuptools development',
    'license': 'MIT',
    'maintainer': None,
    'maintainer_email': None,
    'name': 'sampleproject',
    'package_url': 'https://pypi.org/project/sampleproject/',
    'platform': 'UNKNOWN',
    'project_url': 'https://pypi.org/project/sampleproject/',
    'project_urls': {...},
    'release_url': 'https://pypi.org/project/sampleproject/1.2.0/',
    'requires_dist': None,
    'requires_python': None,
    'summary': 'A sample Python project',
    'version': '1.2.0'}

Additionally, maximum character *width* can be suggested. If a long object
cannot be split, the specified width will be exceeded::

   >>> pprint.pp(project_info, depth=1, width=60)
   {'author': 'The Python Packaging Authority',
    'author_email': 'pypa-dev@googlegroups.com',
    'bugtrack_url': None,
    'classifiers': [...],
    'description': 'A sample Python project\n'
                   '=======================\n'
                   '\n'
                   'This is the description file for the '
                   'project.\n'
                   '\n'
                   'The file should use UTF-8 encoding and be '
                   'written using ReStructured Text. It\n'
                   'will be used to generate the project '
                   'webpage on PyPI, and should be written '
                   'for\n'
                   'that purpose.\n'
                   '\n'
                   'Typical contents for this file would '
                   'include an overview of the project, '
                   'basic\n'
                   'usage examples, etc. Generally, including '
                   'the project changelog in here is not\n'
                   'a good idea, although a simple "What\'s '
                   'New" section for the most recent version\n'
                   'may be appropriate.',
    'description_content_type': None,
    'docs_url': None,
    'download_url': 'UNKNOWN',
    'downloads': {...},
    'home_page': 'https://github.com/pypa/sampleproject',
    'keywords': 'sample setuptools development',
    'license': 'MIT',
    'maintainer': None,
    'maintainer_email': None,
    'name': 'sampleproject',
    'package_url': 'https://pypi.org/project/sampleproject/',
    'platform': 'UNKNOWN',
    'project_url': 'https://pypi.org/project/sampleproject/',
    'project_urls': {...},
    'release_url': 'https://pypi.org/project/sampleproject/1.2.0/',
    'requires_dist': None,
    'requires_python': None,
    'summary': 'A sample Python project',
    'version': '1.2.0'}


================================================
File: /Doc/library/profile.rst
================================================
.. _profile:

********************
The Python Profilers
********************

**Source code:** :source:`Lib/profile.py` and :source:`Lib/pstats.py`

--------------

.. _profiler-introduction:

Introduction to the profilers
=============================

.. index::
   single: deterministic profiling
   single: profiling, deterministic

:mod:`cProfile` and :mod:`profile` provide :dfn:`deterministic profiling` of
Python programs. A :dfn:`profile` is a set of statistics that describes how
often and for how long various parts of the program executed. These statistics
can be formatted into reports via the :mod:`pstats` module.

The Python standard library provides two different implementations of the same
profiling interface:

1. :mod:`cProfile` is recommended for most users; it's a C extension with
   reasonable overhead that makes it suitable for profiling long-running
   programs.  Based on :mod:`lsprof`, contributed by Brett Rosen and Ted
   Czotter.

2. :mod:`profile`, a pure Python module whose interface is imitated by
   :mod:`cProfile`, but which adds significant overhead to profiled programs.
   If you're trying to extend the profiler in some way, the task might be easier
   with this module.  Originally designed and written by Jim Roskind.

.. note::

   The profiler modules are designed to provide an execution profile for a given
   program, not for benchmarking purposes (for that, there is :mod:`timeit` for
   reasonably accurate results).  This particularly applies to benchmarking
   Python code against C code: the profilers introduce overhead for Python code,
   but not for C-level functions, and so the C code would seem faster than any
   Python one.


.. _profile-instant:

Instant User's Manual
=====================

This section is provided for users that "don't want to read the manual." It
provides a very brief overview, and allows a user to rapidly perform profiling
on an existing application.

To profile a function that takes a single argument, you can do::

   import cProfile
   import re
   cProfile.run('re.compile("foo|bar")')

(Use :mod:`profile` instead of :mod:`cProfile` if the latter is not available on
your system.)

The above action would run :func:`re.compile` and print profile results like
the following::

         214 function calls (207 primitive calls) in 0.002 seconds

   Ordered by: cumulative time

   ncalls  tottime  percall  cumtime  percall filename:lineno(function)
        1    0.000    0.000    0.002    0.002 {built-in method builtins.exec}
        1    0.000    0.000    0.001    0.001 <string>:1(<module>)
        1    0.000    0.000    0.001    0.001 __init__.py:250(compile)
        1    0.000    0.000    0.001    0.001 __init__.py:289(_compile)
        1    0.000    0.000    0.000    0.000 _compiler.py:759(compile)
        1    0.000    0.000    0.000    0.000 _parser.py:937(parse)
        1    0.000    0.000    0.000    0.000 _compiler.py:598(_code)
        1    0.000    0.000    0.000    0.000 _parser.py:435(_parse_sub)

The first line indicates that 214 calls were monitored.  Of those calls, 207
were :dfn:`primitive`, meaning that the call was not induced via recursion. The
next line: ``Ordered by: cumulative time`` indicates the output is sorted
by the ``cumtime`` values. The column headings include:

ncalls
   for the number of calls.

tottime
   for the total time spent in the given function (and excluding time made in
   calls to sub-functions)

percall
   is the quotient of ``tottime`` divided by ``ncalls``

cumtime
   is the cumulative time spent in this and all subfunctions (from invocation
   till exit). This figure is accurate *even* for recursive functions.

percall
   is the quotient of ``cumtime`` divided by primitive calls

filename:lineno(function)
   provides the respective data of each function

When there are two numbers in the first column (for example ``3/1``), it means
that the function recursed.  The second value is the number of primitive calls
and the former is the total number of calls.  Note that when the function does
not recurse, these two values are the same, and only the single figure is
printed.

Instead of printing the output at the end of the profile run, you can save the
results to a file by specifying a filename to the :func:`run` function::

   import cProfile
   import re
   cProfile.run('re.compile("foo|bar")', 'restats')

The :class:`pstats.Stats` class reads profile results from a file and formats
them in various ways.

.. _profile-cli:

The files :mod:`cProfile` and :mod:`profile` can also be invoked as a script to
profile another script.  For example::

   python -m cProfile [-o output_file] [-s sort_order] (-m module | myscript.py)

``-o`` writes the profile results to a file instead of to stdout

``-s`` specifies one of the :func:`~pstats.Stats.sort_stats` sort values to sort
the output by. This only applies when ``-o`` is not supplied.

``-m`` specifies that a module is being profiled instead of a script.

.. versionadded:: 3.7
   Added the ``-m`` option to :mod:`cProfile`.

.. versionadded:: 3.8
   Added the ``-m`` option to :mod:`profile`.

The :mod:`pstats` module's :class:`~pstats.Stats` class has a variety of methods
for manipulating and printing the data saved into a profile results file::

   import pstats
   from pstats import SortKey
   p = pstats.Stats('restats')
   p.strip_dirs().sort_stats(-1).print_stats()

The :meth:`~pstats.Stats.strip_dirs` method removed the extraneous path from all
the module names. The :meth:`~pstats.Stats.sort_stats` method sorted all the
entries according to the standard module/line/name string that is printed. The
:meth:`~pstats.Stats.print_stats` method printed out all the statistics.  You
might try the following sort calls::

   p.sort_stats(SortKey.NAME)
   p.print_stats()

The first call will actually sort the list by function name, and the second call
will print out the statistics.  The following are some interesting calls to
experiment with::

   p.sort_stats(SortKey.CUMULATIVE).print_stats(10)

This sorts the profile by cumulative time in a function, and then only prints
the ten most significant lines.  If you want to understand what algorithms are
taking time, the above line is what you would use.

If you were looking to see what functions were looping a lot, and taking a lot
of time, you would do::

   p.sort_stats(SortKey.TIME).print_stats(10)

to sort according to time spent within each function, and then print the
statistics for the top ten functions.

You might also try::

   p.sort_stats(SortKey.FILENAME).print_stats('__init__')

This will sort all the statistics by file name, and then print out statistics
for only the class init methods (since they are spelled with ``__init__`` in
them).  As one final example, you could try::

   p.sort_stats(SortKey.TIME, SortKey.CUMULATIVE).print_stats(.5, 'init')

This line sorts statistics with a primary key of time, and a secondary key of
cumulative time, and then prints out some of the statistics. To be specific, the
list is first culled down to 50% (re: ``.5``) of its original size, then only
lines containing ``init`` are maintained, and that sub-sub-list is printed.

If you wondered what functions called the above functions, you could now (``p``
is still sorted according to the last criteria) do::

   p.print_callers(.5, 'init')

and you would get a list of callers for each of the listed functions.

If you want more functionality, you're going to have to read the manual, or
guess what the following functions do::

   p.print_callees()
   p.add('restats')

Invoked as a script, the :mod:`pstats` module is a statistics browser for
reading and examining profile dumps.  It has a simple line-oriented interface
(implemented using :mod:`cmd`) and interactive help.

:mod:`profile` and :mod:`cProfile` Module Reference
=======================================================

.. module:: cProfile
.. module:: profile
   :synopsis: Python source profiler.

Both the :mod:`profile` and :mod:`cProfile` modules provide the following
functions:

.. function:: run(command, filename=None, sort=-1)

   This function takes a single argument that can be passed to the :func:`exec`
   function, and an optional file name.  In all cases this routine executes::

      exec(command, __main__.__dict__, __main__.__dict__)

   and gathers profiling statistics from the execution. If no file name is
   present, then this function automatically creates a :class:`~pstats.Stats`
   instance and prints a simple profiling report. If the sort value is specified,
   it is passed to this :class:`~pstats.Stats` instance to control how the
   results are sorted.

.. function:: runctx(command, globals, locals, filename=None, sort=-1)

   This function is similar to :func:`run`, with added arguments to supply the
   globals and locals mappings for the *command* string. This routine
   executes::

      exec(command, globals, locals)

   and gathers profiling statistics as in the :func:`run` function above.

.. class:: Profile(timer=None, timeunit=0.0, subcalls=True, builtins=True)

   This class is normally only used if more precise control over profiling is
   needed than what the :func:`cProfile.run` function provides.

   A custom timer can be supplied for measuring how long code takes to run via
   the *timer* argument. This must be a function that returns a single number
   representing the current time. If the number is an integer, the *timeunit*
   specifies a multiplier that specifies the duration of each unit of time. For
   example, if the timer returns times measured in thousands of seconds, the
   time unit would be ``.001``.

   Directly using the :class:`Profile` class allows formatting profile results
   without writing the profile data to a file::

      import cProfile, pstats, io
      from pstats import SortKey
      pr = cProfile.Profile()
      pr.enable()
      # ... do something ...
      pr.disable()
      s = io.StringIO()
      sortby = SortKey.CUMULATIVE
      ps = pstats.Stats(pr, stream=s).sort_stats(sortby)
      ps.print_stats()
      print(s.getvalue())

   The :class:`Profile` class can also be used as a context manager (supported
   only in :mod:`cProfile` module. see :ref:`typecontextmanager`)::

      import cProfile

      with cProfile.Profile() as pr:
          # ... do something ...

          pr.print_stats()

   .. versionchanged:: 3.8
      Added context manager support.

   .. method:: enable()

      Start collecting profiling data. Only in :mod:`cProfile`.

   .. method:: disable()

      Stop collecting profiling data. Only in :mod:`cProfile`.

   .. method:: create_stats()

      Stop collecting profiling data and record the results internally
      as the current profile.

   .. method:: print_stats(sort=-1)

      Create a :class:`~pstats.Stats` object based on the current
      profile and print the results to stdout.

      The *sort* parameter specifies the sorting order of the displayed
      statistics. It accepts a single key or a tuple of keys to enable
      multi-level sorting, as in :func:`Stats.sort_stats <pstats.Stats.sort_stats>`.

      .. versionadded:: 3.13
         :meth:`~Profile.print_stats` now accepts a tuple of keys.

   .. method:: dump_stats(filename)

      Write the results of the current profile to *filename*.

   .. method:: run(cmd)

      Profile the cmd via :func:`exec`.

   .. method:: runctx(cmd, globals, locals)

      Profile the cmd via :func:`exec` with the specified global and
      local environment.

   .. method:: runcall(func, /, *args, **kwargs)

      Profile ``func(*args, **kwargs)``

Note that profiling will only work if the called command/function actually
returns.  If the interpreter is terminated (e.g. via a :func:`sys.exit` call
during the called command/function execution) no profiling results will be
printed.

.. _profile-stats:

The :class:`Stats` Class
========================

Analysis of the profiler data is done using the :class:`~pstats.Stats` class.

.. module:: pstats
   :synopsis: Statistics object for use with the profiler.

.. class:: Stats(*filenames or profile, stream=sys.stdout)

   This class constructor creates an instance of a "statistics object" from a
   *filename* (or list of filenames) or from a :class:`Profile` instance. Output
   will be printed to the stream specified by *stream*.

   The file selected by the above constructor must have been created by the
   corresponding version of :mod:`profile` or :mod:`cProfile`.  To be specific,
   there is *no* file compatibility guaranteed with future versions of this
   profiler, and there is no compatibility with files produced by other
   profilers, or the same profiler run on a different operating system.  If
   several files are provided, all the statistics for identical functions will
   be coalesced, so that an overall view of several processes can be considered
   in a single report.  If additional files need to be combined with data in an
   existing :class:`~pstats.Stats` object, the :meth:`~pstats.Stats.add` method
   can be used.

   Instead of reading the profile data from a file, a :class:`cProfile.Profile`
   or :class:`profile.Profile` object can be used as the profile data source.

   :class:`Stats` objects have the following methods:

   .. method:: strip_dirs()

      This method for the :class:`Stats` class removes all leading path
      information from file names.  It is very useful in reducing the size of
      the printout to fit within (close to) 80 columns.  This method modifies
      the object, and the stripped information is lost.  After performing a
      strip operation, the object is considered to have its entries in a
      "random" order, as it was just after object initialization and loading.
      If :meth:`~pstats.Stats.strip_dirs` causes two function names to be
      indistinguishable (they are on the same line of the same filename, and
      have the same function name), then the statistics for these two entries
      are accumulated into a single entry.


   .. method:: add(*filenames)

      This method of the :class:`Stats` class accumulates additional profiling
      information into the current profiling object.  Its arguments should refer
      to filenames created by the corresponding version of :func:`profile.run`
      or :func:`cProfile.run`. Statistics for identically named (re: file, line,
      name) functions are automatically accumulated into single function
      statistics.


   .. method:: dump_stats(filename)

      Save the data loaded into the :class:`Stats` object to a file named
      *filename*.  The file is created if it does not exist, and is overwritten
      if it already exists.  This is equivalent to the method of the same name
      on the :class:`profile.Profile` and :class:`cProfile.Profile` classes.


   .. method:: sort_stats(*keys)

      This method modifies the :class:`Stats` object by sorting it according to
      the supplied criteria.  The argument can be either a string or a SortKey
      enum identifying the basis of a sort (example: ``'time'``, ``'name'``,
      ``SortKey.TIME`` or ``SortKey.NAME``). The SortKey enums argument have
      advantage over the string argument in that it is more robust and less
      error prone.

      When more than one key is provided, then additional keys are used as
      secondary criteria when there is equality in all keys selected before
      them.  For example, ``sort_stats(SortKey.NAME, SortKey.FILE)`` will sort
      all the entries according to their function name, and resolve all ties
      (identical function names) by sorting by file name.

      For the string argument, abbreviations can be used for any key names, as
      long as the abbreviation is unambiguous.

      The following are the valid string and SortKey:

      +------------------+---------------------+----------------------+
      | Valid String Arg | Valid enum Arg      | Meaning              |
      +==================+=====================+======================+
      | ``'calls'``      | SortKey.CALLS       | call count           |
      +------------------+---------------------+----------------------+
      | ``'cumulative'`` | SortKey.CUMULATIVE  | cumulative time      |
      +------------------+---------------------+----------------------+
      | ``'cumtime'``    | N/A                 | cumulative time      |
      +------------------+---------------------+----------------------+
      | ``'file'``       | N/A                 | file name            |
      +------------------+---------------------+----------------------+
      | ``'filename'``   | SortKey.FILENAME    | file name            |
      +------------------+---------------------+----------------------+
      | ``'module'``     | N/A                 | file name            |
      +------------------+---------------------+----------------------+
      | ``'ncalls'``     | N/A                 | call count           |
      +------------------+---------------------+----------------------+
      | ``'pcalls'``     | SortKey.PCALLS      | primitive call count |
      +------------------+---------------------+----------------------+
      | ``'line'``       | SortKey.LINE        | line number          |
      +------------------+---------------------+----------------------+
      | ``'name'``       | SortKey.NAME        | function name        |
      +------------------+---------------------+----------------------+
      | ``'nfl'``        | SortKey.NFL         | name/file/line       |
      +------------------+---------------------+----------------------+
      | ``'stdname'``    | SortKey.STDNAME     | standard name        |
      +------------------+---------------------+----------------------+
      | ``'time'``       | SortKey.TIME        | internal time        |
      +------------------+---------------------+----------------------+
      | ``'tottime'``    | N/A                 | internal time        |
      +------------------+---------------------+----------------------+

      Note that all sorts on statistics are in descending order (placing most
      time consuming items first), where as name, file, and line number searches
      are in ascending order (alphabetical). The subtle distinction between
      ``SortKey.NFL`` and ``SortKey.STDNAME`` is that the standard name is a
      sort of the name as printed, which means that the embedded line numbers
      get compared in an odd way.  For example, lines 3, 20, and 40 would (if
      the file names were the same) appear in the string order 20, 3 and 40.
      In contrast, ``SortKey.NFL`` does a numeric compare of the line numbers.
      In fact, ``sort_stats(SortKey.NFL)`` is the same as
      ``sort_stats(SortKey.NAME, SortKey.FILENAME, SortKey.LINE)``.

      For backward-compatibility reasons, the numeric arguments ``-1``, ``0``,
      ``1``, and ``2`` are permitted.  They are interpreted as ``'stdname'``,
      ``'calls'``, ``'time'``, and ``'cumulative'`` respectively.  If this old
      style format (numeric) is used, only one sort key (the numeric key) will
      be used, and additional arguments will be silently ignored.

      .. For compatibility with the old profiler.

      .. versionadded:: 3.7
         Added the SortKey enum.

   .. method:: reverse_order()

      This method for the :class:`Stats` class reverses the ordering of the
      basic list within the object.  Note that by default ascending vs
      descending order is properly selected based on the sort key of choice.

      .. This method is provided primarily for compatibility with the old
         profiler.


   .. method:: print_stats(*restrictions)

      This method for the :class:`Stats` class prints out a report as described
      in the :func:`profile.run` definition.

      The order of the printing is based on the last
      :meth:`~pstats.Stats.sort_stats` operation done on the object (subject to
      caveats in :meth:`~pstats.Stats.add` and
      :meth:`~pstats.Stats.strip_dirs`).

      The arguments provided (if any) can be used to limit the list down to the
      significant entries.  Initially, the list is taken to be the complete set
      of profiled functions.  Each restriction is either an integer (to select a
      count of lines), or a decimal fraction between 0.0 and 1.0 inclusive (to
      select a percentage of lines), or a string that will interpreted as a
      regular expression (to pattern match the standard name that is printed).
      If several restrictions are provided, then they are applied sequentially.
      For example::

         print_stats(.1, 'foo:')

      would first limit the printing to first 10% of list, and then only print
      functions that were part of filename :file:`.\*foo:`.  In contrast, the
      command::

         print_stats('foo:', .1)

      would limit the list to all functions having file names :file:`.\*foo:`,
      and then proceed to only print the first 10% of them.


   .. method:: print_callers(*restrictions)

      This method for the :class:`Stats` class prints a list of all functions
      that called each function in the profiled database.  The ordering is
      identical to that provided by :meth:`~pstats.Stats.print_stats`, and the
      definition of the restricting argument is also identical.  Each caller is
      reported on its own line.  The format differs slightly depending on the
      profiler that produced the stats:

      * With :mod:`profile`, a number is shown in parentheses after each caller
        to show how many times this specific call was made.  For convenience, a
        second non-parenthesized number repeats the cumulative time spent in the
        function at the right.

      * With :mod:`cProfile`, each caller is preceded by three numbers: the
        number of times this specific call was made, and the total and
        cumulative times spent in the current function while it was invoked by
        this specific caller.


   .. method:: print_callees(*restrictions)

      This method for the :class:`Stats` class prints a list of all function
      that were called by the indicated function.  Aside from this reversal of
      direction of calls (re: called vs was called by), the arguments and
      ordering are identical to the :meth:`~pstats.Stats.print_callers` method.


   .. method:: get_stats_profile()

      This method returns an instance of StatsProfile, which contains a mapping
      of function names to instances of FunctionProfile. Each FunctionProfile
      instance holds information related to the function's profile such as how
      long the function took to run, how many times it was called, etc...

      .. versionadded:: 3.9
         Added the following dataclasses: StatsProfile, FunctionProfile.
         Added the following function: get_stats_profile.

.. _deterministic-profiling:

What Is Deterministic Profiling?
================================

:dfn:`Deterministic profiling` is meant to reflect the fact that all *function
call*, *function return*, and *exception* events are monitored, and precise
timings are made for the intervals between these events (during which time the
user's code is executing).  In contrast, :dfn:`statistical profiling` (which is
not done by this module) randomly samples the effective instruction pointer, and
deduces where time is being spent.  The latter technique traditionally involves
less overhead (as the code does not need to be instrumented), but provides only
relative indications of where time is being spent.

In Python, since there is an interpreter active during execution, the presence
of instrumented code is not required in order to do deterministic profiling.
Python automatically provides a :dfn:`hook` (optional callback) for each event.
In addition, the interpreted nature of Python tends to add so much overhead to
execution, that deterministic profiling tends to only add small processing
overhead in typical applications.  The result is that deterministic profiling is
not that expensive, yet provides extensive run time statistics about the
execution of a Python program.

Call count statistics can be used to identify bugs in code (surprising counts),
and to identify possible inline-expansion points (high call counts).  Internal
time statistics can be used to identify "hot loops" that should be carefully
optimized.  Cumulative time statistics should be used to identify high level
errors in the selection of algorithms.  Note that the unusual handling of
cumulative times in this profiler allows statistics for recursive
implementations of algorithms to be directly compared to iterative
implementations.


.. _profile-limitations:

Limitations
===========

One limitation has to do with accuracy of timing information. There is a
fundamental problem with deterministic profilers involving accuracy.  The most
obvious restriction is that the underlying "clock" is only ticking at a rate
(typically) of about .001 seconds.  Hence no measurements will be more accurate
than the underlying clock.  If enough measurements are taken, then the "error"
will tend to average out. Unfortunately, removing this first error induces a
second source of error.

The second problem is that it "takes a while" from when an event is dispatched
until the profiler's call to get the time actually *gets* the state of the
clock.  Similarly, there is a certain lag when exiting the profiler event
handler from the time that the clock's value was obtained (and then squirreled
away), until the user's code is once again executing.  As a result, functions
that are called many times, or call many functions, will typically accumulate
this error. The error that accumulates in this fashion is typically less than
the accuracy of the clock (less than one clock tick), but it *can* accumulate
and become very significant.

The problem is more important with :mod:`profile` than with the lower-overhead
:mod:`cProfile`.  For this reason, :mod:`profile` provides a means of
calibrating itself for a given platform so that this error can be
probabilistically (on the average) removed. After the profiler is calibrated, it
will be more accurate (in a least square sense), but it will sometimes produce
negative numbers (when call counts are exceptionally low, and the gods of
probability work against you :-). )  Do *not* be alarmed by negative numbers in
the profile.  They should *only* appear if you have calibrated your profiler,
and the results are actually better than without calibration.


.. _profile-calibration:

Calibration
===========

The profiler of the :mod:`profile` module subtracts a constant from each event
handling time to compensate for the overhead of calling the time function, and
socking away the results.  By default, the constant is 0. The following
procedure can be used to obtain a better constant for a given platform (see
:ref:`profile-limitations`). ::

   import profile
   pr = profile.Profile()
   for i in range(5):
       print(pr.calibrate(10000))

The method executes the number of Python calls given by the argument, directly
and again under the profiler, measuring the time for both. It then computes the
hidden overhead per profiler event, and returns that as a float.  For example,
on a 1.8Ghz Intel Core i5 running macOS, and using Python's time.process_time() as
the timer, the magical number is about 4.04e-6.

The object of this exercise is to get a fairly consistent result. If your
computer is *very* fast, or your timer function has poor resolution, you might
have to pass 100000, or even 1000000, to get consistent results.

When you have a consistent answer, there are three ways you can use it::

   import profile

   # 1. Apply computed bias to all Profile instances created hereafter.
   profile.Profile.bias = your_computed_bias

   # 2. Apply computed bias to a specific Profile instance.
   pr = profile.Profile()
   pr.bias = your_computed_bias

   # 3. Specify computed bias in instance constructor.
   pr = profile.Profile(bias=your_computed_bias)

If you have a choice, you are better off choosing a smaller constant, and then
your results will "less often" show up as negative in profile statistics.

.. _profile-timers:

Using a custom timer
====================

If you want to change how current time is determined (for example, to force use
